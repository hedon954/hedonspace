[{"title":"读书笔记丨《Unit Testing Principles, Practices, and Patterns》","path":"/2025/04/09/note-unit-testing/","content":"揪心疑惑 在撰写单元测试的过程中，你是否曾经被以下问题困扰过？ 为什么要写单元测试？单元测试的目标是什么？ 单元测试的粒度是怎样的？什么叫单元？a class, a function, or a behavior, or an observable behavior? 单测覆盖率真的有用吗？有什么用？又有哪些限制？ 怎样才能写好单元测试？怎样才能写出性价比最高的单元测试？ 如何判断一个单元测试的好坏？有没有具体可供参阅的维度？ 哪些代码需要写单元测试，哪些代码没必要写单元测试？ 单元测试和集成测试的边界是什么？ （单元丨集成）测试到底是要测什么东西？ 单元测试的侧重点是什么？集成测试的侧重点是什么？二者的比例该是怎样的？ 如何使用 Mock？哪些东西是需要 Mock 的？哪些东西是不应该 Mock 的？需要 Mock 的东西，应该在哪个层次进行 Mock？（你的 repository 层需要 Mock 吗？） 为什么你的测试代码很脆弱，总是需要频繁修改，维护起来难度很大？ 如何减少测试结果的假阳性和假阴性？ 四根柱子 对于第 5 个问题，作者提出了 4 个维度： Protection against regressions：防止回归，通过自动化验证代码修改后原有功能不受破坏。 The amount of code that is executed during the test. The complexity of that code. The code’s domain significance. Resistance to refactoring：抗重构性，重构业务代码时，测试代码无需过多变动便可通过用例，证明重构无误。 Tests provide an early warning when you break existing functionality. You become confident that your code changes won’t lead to regressions. Fast feedback：快速反馈。 Maintainability：可维护性。 How hard it is to understand the test. How hard it is to run the test. 对于这 4 个问题，你是否又有以下疑问： 哪个维度是最重要的？ 怎样才能写出满足各个维度的测试代码？ 如果维度之间存在矛盾，如何 trade off？ 为什么要写单元测试？ 三个最重要的原因： 验证你的程序逻辑正确性。 带来更好的代码设计。 因为单元测试能够让你站在使用者的角度去使用暴露的接口，如果接口不好用，逻辑不好测，测试条件不好构建，大概率说明代码的设计本身是有缺陷的，包括但不限于：抽象不合理、逻辑划分不清晰、与其他模块耦合严重等。 使软件项目更可持续发展。 如果你的需求没有发生变化，那原本能运行通过的单测应该一直都能运行，这有助于避免在团队协作中不小心改坏你不知道的代码，也有助于你执行各种重构措施。 这三个原因的重要性是显而易见的，但笔者个人觉得还有一个更深层次的最重要的原因： 你要对你做的事情负责，好的代码一定要先过自己这关。 单元测试的粒度是什么？ 这是一个很有争议的话题，单元测试的「单元」到底是什么？ 一个类？ 一个函数？ 还是多个类组成的一个模块？ 还是多个函数组成的一个大逻辑？ 在《Unit Testing》书中，作者指出：「单元」指的是 an observable behavior，即一个外部系统可观测到的行为。 换言之，也就是我在撰写单元测试的时候，我就是在使用系统提供的能力，我就是个使用者， 我只要验证你能提供我要的功能，就 OK 了，你背后怎么做，为了这个功能所拆分的类也好，小的辅助函数也好，都不重要，都不属于我要验证的范畴。 所以这更像是黑盒测试（black-box test）。 当然，会有例外，如果你底层有一个特别特别复杂的逻辑，你有必要专门花精力去验证它的逻辑正确性，那是可以针对它撰写专门的白盒测试（white-box test）的。针对这个情况，作者其实也提出了一个观点，对于这个复杂的逻辑，也可以抽成一个单独的模块，由它来提供能力给你当前模块使用。 总结： 优先选择黑盒测试。 对于涉及复杂算法的逻辑，单独撰写白盒测试。 结合覆盖率工具去看哪些代码没被覆盖，然后再站在使用者的角度去思考为什么没被覆盖，是这个分支压根没必要存在，还是还有未考虑到的使用场景。 如何组织单元测试？ 两种结构： AAA: Arrange-Act-Assert GWT: Given-When-Then 其实都是一个思路：准备前置条件→执行待验证代码→验证逻辑正确性。 几个建议： 尽量避免一个单元测试中包含多个 AAA/GWT。 避免在单元测试中使用 if 等分支语句。 命名的时候，尽可能让非程序员也能看懂，即这个命名需要描述一个领域问题。 如何发挥单测的最大价值？ 单元测试用例必须持续不断反复执行验证。 用最小的维护代价提供最大价值的单元测试。 识别一个有价值的测试 撰写一个有价值的测试 验证代码中最重要的部分（领域模型）。 1. 单元测试用例必须持续不断反复执行验证 这里推荐笔者的个人实践： 在 pre-commit 执行增量单元测试，确保本次修改的代码涉及的单测可正确通过。 在 gitlab-ci/github-action 流程中执行全量单元测试，全面覆盖，避免本次修改的代码影响到其他模块的正常功能。同时如果是合并到主分支的请求，加入增量覆盖率阈值检测，不满足阈值的，发送飞书消息卡片进行告警通知。 pre-commit 增量单测 .pre-commit-config.yaml 配置如下： repos: - repo: local hooks: - id: go-unit-tests name: go-unit-tests description: run go tests with race detector entry: bash -c ./script/run_diff_go_test.sh language: golang files: \\.*$ pass_filenames: false run_diff_go_test.sh 脚本如下： #!/bin/bashexport GOTOOLCHAIN=auto# 获取当前改动的 Go 文件changed_files=$(git diff --name-only --cached --diff-filter=d | grep \\.go$)# 如果没有改动的 Go 文件，退出if [ -z $changed_files ]; then echo No Go files changed. exit 0fi# 提取改动文件所在的包路径（使用相对路径），并排除 vendor 目录test_dirs=$(echo $changed_files | xargs -n1 dirname | grep -v ^vendor | sort -u)# 对每个改动的包路径运行 go testfor dir in $test_dirs; do # 检查目录是否存在 if [ ! -d $dir ]; then echo Directory $dir does not exist. Skipping... continue fi # 检查是否存在 go.mod 文件，确保在 Go 模块路径中 if [ -f $dir/go.mod ] || [ -f ./go.mod ]; then echo Running tests in $dir... (cd $dir go test -mod=vendor -gcflags=all=-l -short ./...) if [ $? -ne 0 ]; then echo Tests failed in $dir exit 1 fi else echo Skipping $dir (no go.mod found) fidoneecho All tests passed. gitlab-ci 全量单测 gitlab-ci.yml 配置如下： go-unit-test: stage: go-unit-test script: - sh script/unittest.sh $CI_MERGE_REQUEST_TITLE $GITLAB_USER_EMAIL $CI_PIPELINE_ID $CI_MERGE_REQUEST_TARGET_BRANCH_NAME $CI_JOB_ID rules: - if: $CI_PIPELINE_SOURCE == merge_request_event $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == dev - if: $CI_PIPELINE_SOURCE == merge_request_event $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == release coverage: /coverage: \\d+.\\d+% of statements/ unittest.sh 单测执行脚本如下： #!/bin/bashexport GOPROXY=https://goproxy.cn,directfunction generate_coverage_report gocover-cobertura coverage.out coverage.xml# 使用 gotestsum 执行单元测试# 如果单测执行失败，会发送飞书消息卡片到告警群中if ! gotestsum --junitfile report.xml --post-run-command=./script/send_fs_card.sh \\$1\\ \\$2\\ \\$3\\ \\$5\\ -- ./... -timeout 3s -short -mod=vendor -gcflags=all=-l -coverpkg=./... -coverprofile=coverage.out ; then generate_coverage_report sh script/cal_diff_coverage.sh $4 exit 1fi# 生成单元测试覆盖率报告generate_coverage_report# 如果增量覆盖率不满足阈值，会发送飞书消息卡片到告警群中source script/cal_diff_coverage.sh $4if [[ $4 == release ]]; then source script/check_test_coverage.sh $1 $2 $3fi 其中 cal_diff_coverage.sh 用于计算增量覆盖率： #!/bin/bashexport COVERAGE_PERCENT=0.0# 确保 coverage.xml 文件存在if [ ! -f coverage.xml ]; then echo coverage: 0.0% of statements exit 0fi# 使用 diff-cover 生成覆盖率报告diff-cover coverage.xml --exclude **/docs.go --html-report report.html --compare-branch $1 diff_detail.txt# 检查是否成功生成报告if [ ! -f report.html ]; then echo coverage: 0.0% of statements exit 0fi# 使用 grep 和 awk 提取覆盖率信息COVERAGE=$(grep Coverage: diff_detail.txt | awk print $2)# 如果找到了覆盖率数据，检查是否包含小数点if [ -n $COVERAGE ]; then if [[ $COVERAGE != *.* ]]; then # 如果没有小数点，在百分号前面加上 .0 # 这里这么做的目的是不知道为什么 gitlab ci 无法正确解析下面这个正则 # /coverage: \\d+(.\\d+)?% of statements/ # 只能解析这个 # /coverage: \\d+.\\d+% of statements/ COVERAGE=$COVERAGE/\\%/.0% fi echo coverage: $COVERAGE of statementselse COVERAGE=0.0% echo coverage: 0.0% of statementsfi# 将 COVERAGE 的百分号去掉，只保留数字export COVERAGE_PERCENT=$(echo $COVERAGE | sed s/%//) 2. 用最小的维护代价提供最大价值的单元测试 如何评价一个单元测试价值是否足够大呢？或者，更简单的说法是，这个单元测试写得好不好？ 可以从 4 个角度进行评估： protection againts regressions resistance to refactoring fast feedback maintainability 3. 验证代码中最重要的部分","tags":["单元测试","读书笔记"],"categories":["读书笔记"]},{"title":"读书笔记丨《Unit Testing Principles, Practices, and Patterns》","path":"/2025/04/09/note-unit-testing-excerpt/","content":"Learning unit testing doesn’t stop at mastering the technical bits of it, such as your favorite test framework, mocking library, and so on. There’s much more to unit testing than the act of writing tests. You always have to achieve the best return on the time you invest in unit testing, minimizing the effort you put into tests and maximizing the benefits they provide. Achieving both things isn’t an easy task. They grow effortlessly, don’t require much maintenance, and can quickly adapt to their customers’ ever-changing needs. The ratio between the production code and the test code could be anywhere between 1:1 and 1:3. Coverage limitations You can’t guarantee that the test verifies all the possible outcomes of the system under test. No coverage metric can take into account code paths in external libraries. The goal of unit testing lead to a better code design enable sustainable(可持续的) growth of the software project the cost components of writing unit tests: refactoring the test when you refactor the underlying code running the test on each code change dealing with false alarms raised by the test spending time reading the test when you’re trying to understanding how the underlying code behaves a successful test suite must: integrated into the development cycle targets only the most important parts of the code base 👉🏻 domain logic infrastructure code external services and dependencies code that glues everything together provides maximum value with minimum maintenance costs recognize a valuable test (and, by extension, a test of low value) write a valuable test What is a unit test? verifies a single unit of behavior dose it quickly dost it in isolation from other tests An integration test, then, is a test that doesn’t meet one of these criteria. End-to-end tests are a subset of integration tests. How to structure a unit test? Type Components AAA Arrange - Act - Assert GWT Given - When - Then avoid multiple arrange, act, and assert sections. avoid if statements in tests. name the test as if you were describing the scenario to a non-programmer who is familiar with the problem domain. separate words with underscores. structure a test is to make it tell a story about the problem domain Four pillars of a good unit test code is not an asset, it’s a liability. protection against regressions the amount of code that is executed during the test the complexity of that code the code’s domain significance resistance to refactoring the fewer false positives the test generates, the better tests provides an early warning when you break exisiting functionality you become confident that your code changes won’t lead to regressions the more the test is coupled to the implementation details of the system under set(SUT), the more false alarms it generates you need to make sure the test verifies the end result the SUT delivers: its observable behavior, not the steps it takes to do that. the best way to structure a test is to make it tell a story about the problem domain fast feedback maintainability how hard it is to understand the test, which is a function of the test’s size how hard it is to run the test, which is a function of how many out-of-process dependencies the test works with directly The intrinsic connection between the first two attributes Type II Error: if functionality is broken, the test should fail, but if the test also passed, means it is not a good unit test, should if it fails, means it offers protection against regressions. Type I Error: if functionality is correct but the test fails, means that the test dose not test the nature of behavior. The good unit test should always pass when the functionality is correct. This would help us a lot when we try to do refactor. If we refactor the code correctly, but the unit tests always failed, means that the unit tests are not good enough, we need to optimize them. An ideal test value = [0..1] * [0..1] * [0..1] * [0..1](corresponding to the four pillars) black-box and white-box testing choose black-box testing over white-box testing by default. the only exception is when the test covers utility code with high algorithmic complexity use code coverage tools to see which code branches are not exercised, but then turn around and test them as if you know nothing about the code’s internal structure. Mock types of test doubles mock: help to emulate and examine outcoming interactions —— change state mock: generated by tools spy: written manually stub: help to emulate incoming interactions —— get input data stub: can configure to return different values for different scenarios. dummy: a simple, hardcoded value such as a null value or a made-up string. fake: the same as a stub for most purposes, only except for its creation, it is usually implemented to replace a dependency that dose not yet exist never asserting interactions with stubs. Observable behavior expose an operation that helps the client achieve one of its goals. An operation is a method that performs a calculation or incurs a side effect or both. expose a state that helps the client achieve one of its goals. State is the current condition of the system. Whether the code is observable behavior depends on who its client is and what the goals of that client are. Ideally, the system’s public API surface should coincide with its observable behavior, and all its implementation details should be hidden from the eyes of the clients. Mocks and test fragility Intra-system communications are communications between classes inside your application. Inter-system communications are when your application talks to other applications. The use of mocks is beneficial when verifying the communication pattern between your system and external applications. Using mocks to verify communications between classes inside your system results in tests that couple to implementation details and therefore fall short of the resistance-to-refactoring metric. Types of dependencies shared dependency: a dependency shared by test (not production code) out-of-process dependency: a dependency hosted by a process other than the program’s execution process (database, stmp server) private dependency: any dependency that is not shared Styles of unit testing output-based: only need to verify the output. state-based: the underlying code changes its own state, the state of its collaborators, or the state of an out-of-process dependency. communication-based: use mocks to verify communications between the SUT and its collaborators, to verify the communication situations. compare protection against regressions for the most part, they are not very different but overusing the communication-based style can result in shallow tests that verify only a thin slice of code and mock out everything else. fast feedback for the most part, they are not very different communication-based testing can be slightly worse because the cost of mocks. resistance to refactoring state-based is the best one. communication-based is the worse one, because it is the most vulnerable to false alarms. maintainability output-based is the best one, because they do not deal with out-of-process dependencies. state-based is less maintainable because state verification takes up more space than output verification. communication-based is the worst one, it requires setting up test doubles and interaction assertions, and that takes up a lot of space. functional architecture *Functional architecture* maximizes the amount of code written in a purely functional (immutable) way, while minimizing code that deals with side effects. Immutable means unchangeable: once an object is created, its state can’t be modified. This is in contrast to a *mutable* object (changeable object), which can be modified after it is created. Separate two kinds of code: code that make a decision code that acts upon that decision Tips Moving from using an out-of-process dependency to using mocks. Moving from using mocks to using functional architecture Four kinds of code Domain model and algorithms Trivial code Controllers Overcomplicated code Tips always write completed unit tests for domain model the algorithms code never test trivial code write integration test for controllers do not write overcomplicated code, try to separate it into domain model and algorithms and controllers Trade-off domain model testability controller simplicity performance push all external reads and writes to the edges anyway inject the out-of-process dependencies into the domain model split the decision-making process into more granular steps 👈 CanExecute/Execute pattern domain events CanExecute/Execute pattern You can use CanExecute/Execute pattern to balance the performance and testability , but concedes controller simplicity, but it is manageable in most cases. Domain events Domain events help track important changes in the domain model, and then convert those changes to calls to out-of-process dependencies. This pattern removes the tracking responsibility from the controller. extract a DomainEvent base class and introduce a base class for all domain classes, which would contain a collection of such events: ListDomainEvent events Integration tests check as many of the business scenario’s edge cases as possible with unit tests use integration tests to cover one happy path, as well as any edge cases that can’t be covered by unit tests if there’s no one path that goes through all happy paths, write additional integration tests—as many as needed to capture communications with every external system attempt to apply the fail-fast principle as a viable alternative to integration test. two types of out-of-process dependencies managed dependencies: only accessible through your application. it is implement details and should not be mock. unmanaged dependencies: you don’t have full control over it. It is observable behavior and you should mock it. interface misunderstand 🙋🏻‍♀️ Genuine abstractions are discovered, not invented. 👉🏻 For an interface to be a genuine abstraction, it must have at lease two implemtations. The common reasoning behind the use of interfaces is that they help to: Abstract out-of-process dependencies, thus achieving loose coupling. Add new functionality without changing the existing code, thus adhering to the Open-Closed principle Misconceptions: Interfaces with a single implementation are not abstractions and don’t provide loose coupling any more than concrete classes that implement those interfaces. The second reason violates a more foundational principle: YAGNI (You are not gonna need it). The only reason to use interfaces for out-of-process dependencies it is to enable testing! Do not introduce interfaces for out-of-process dependencies unless you need to mock out those dependencies. integration test best practices making domain model boundaries explicit reducing the number of layers in the application eliminating circular dependencies maximozing mock’s value when mocking, always try to verify interactions with unmanaged dependencies at the very edges of your system. Mocking IBus instead of IMessageBus maximizes the mock’s protection against regressions. A call to an unmanaged dependency goes through several stages before it leaves your application. Pick the last such stage. It is the best way to ensure backward compatibility with external systems, which is the goal that mocks help you achieve. In some cases, you can use spy instead of mock for more succinct and expressive. [Fact]public void Changing_email_from_corporate_to_non_corporate() var busSpy = new BusSpy(); var messageBus = new MessageBus(busSpy); var loggerMock = new MockIDomainLogger(); var sut = new UserController(db, messageBus, loggerMock.Object); /* ... */ busSpy.ShouldSendNumberOfMessages(1) .WithEmailChangedMessage(user.UserId, new@gmail.com); mocking best practices applying mocks to unmanaged dependencies only verifying the interactions with those dependencies at the very edges of your system using mocks in integration tests only, not in unit test always verifying the number of calls made to the mock do not rely on production code when making assertions. Use a separate set of literals and constants in tests. mocking only types that you own always write your own adapters on top of third-party libraries and mock those adapters instead of the underlying types. only expose features you need from the library do that using your project’s domain language this guideline dose not apply to in-process dependencies. There is no need to abstract in-memory or managed dependencies. Similarly, there’s no need to abstract an ORM as long as it’s used for accessing a database that isn’t visible to external applications. Testing the database prerequisites keeping the database in the source control system database schemas reference data using a separate database instance for every developer applying the migration-based approach to database delivery applying every modification to the database schema (including reference data) through migrations. Do not modify migrations once they are committed to the source control. If a migration is incorrect, create a new migration instead of fixing the old one. Make exceptions to this rule only when the incorrect migration can lead to data loss. transaction split the Database class into repositories and a transaction: repositories are classes that enable access to and modification of the data in the database. transaction is a class that either commits or rolls back data updates in full. This will be a custom class relying on the underlying database’s transactions to provide atomicity of data modification. tips use at least three transactions or units of work in an integrations test: one per each arrange, act and assert section. your tests should not depend on the state of the database. Your tests should bring that state to the required condition on their own. create two collections for unit and integrations, and then disable test parallelization in the collection with the integration test. clean up data at the beginning of a test write the SQL script manually. It’s simpler and gives you more granular control over the deletion process. the best way to shorten integration is by extracting technical, non-business-related bits into private methods or helper classes. only the most complex or important read operations should be test, disregard the rest. do not test repositories directly, only as part of the overarching integration test suite. Unit testing anti-patterns ⚠️ Do not do the things like below! unit testing private methods Private methods are implementation details! Just test observable behaviors! If the private method is too complex to be tested as part of the public API that uses it, that’s an indication of a missing abstraction. Extract this abstraction into a separate class instead of making the private method public. expose private state leaking domain knowledges to tests public class CalculatorTests [Fact] public void Adding_two_numbers() int value1 = 1; int value2 = 3; int expected = value1 + value2; // -----The leakage // int expected = 4 // the better one int actual = Calculator.Add(value1, value2); Assert.Equal(expected, actual); code pollution Code pollution is adding production code that’s only needed for testing. mocking concrete classes working with time","tags":["单元测试","读书笔记"],"categories":["读书笔记","单元测试"]},{"title":"一步步推导出 MySQL 数据的底层存储结构","path":"/2025/04/08/mysql-ibd/","content":"以下均以 InnoDB 引擎为基础进行分析。假设我们现在有 3 行数据，如下： 其中： id 是主键索引。 a 和 b 都是数据字段。 tx_id 是隐藏字段，表示事务 id，用于实现 MVCC。 rollback_ptr 是回指针，用于 undo log。 在将数据存储到文件的时候，我们会将这三行数据进行序列化，然后以二进制流的形式存储到文件中。 现在我们要解决第一个问题： 如何按照主键（id）排序？ 在 InnoDB 中，会在每一行的前面，加一个 next_record 字段，用于指向比当前数据 id 大的下一条数据，我们假设一行数据占 20 个字节，那么就如下图所示： 另外，为了便于定位每一行，InnoDB 会在每一行前面再加一个字段 heap_no，它的规则很简单，就是自增，在内部会用于定位一行记录，方便上锁等各种操作。 所以现在的存储结构如下图所示： 现在我们来解决解决第二个问题： 如何快速定位到起点（最小）和终点（最大）？ 在最前面加 2 条特殊的记录： PAGE_NEW_INFIMUM：指向最小记录。 PAGE_NEW_SUPERMUM：最大记录，最大的一个 id 会指向它。 第三个问题： 每次 select * from t where id = ? 都要进行 I/O 操作吗？ 很显然是不行的，效率太低了。这个相信绝大多数读者都知道 ，InnoDB 会以 Page（默认 16KB）为最小单位，一次性将数据从磁盘加载到内存中。为此，需要在最前面再加一条记录，且该记录的前三行分别为： page_no：页号，自增，InnoDB 最多支持 32 位页号，所以存储上限是 16KB * 2^32^ = 64T。 prev_page：指向上一页。 next_page：指向下一页。 如果一个 Page 放不下呢？ 很显然，那就要进行分页，即按照 ID 的顺序进行一分为二，前者取范围 [a, b)，后者取范围 [b, c)。 如何快速定位到数据在哪个 Page 上呢？ 这个时候，我们需要新创建一个 Page，专门用于管理这些数据 Page 的，这个 Page 我们这里暂且称为索引 Page。 其中核心数据就是 2 个： min_id：即当前页存储的最小主键 ID。 page_no：页号，用于定位到 Page。 这是什么呀？这其实就是 B+ 树！在文件层面的存储，是连续存储的，但是为了便于理解，我们可以在逻辑层面将其绘制成 B+ 树的形态。如下图可以看到这其实就是一颗 B+ 树。 在主键索引树上： 叶子节点存储的就是具体某一行的数据（聚簇索引）。 非叶子节点存储的是索引。 每一层的节点，都是一条有序的双向链表。 如果对非主键索引 a 创建索引呢？ 因为要建索引，所以需要先对 a 进行排序，然后针对 a 建立一颗 b+ 树。而且由于 a 是非主键索引，即辅助索引，所以叶子节点存储的是主键的值，用于回表。 假设 a =15 的数据非常多，一个 page 放不下呢？ 会加入主键 ID 作为二维排序来进行分裂： 估算一下一个三层的 B+ 树可以存储多少条数据？ 一个 Page 是 16KB 假设 1 个 Page 可以存放 1000 个 key 假设 1 个 Page 可以存放 200 条记录 基于这种估算： 第 1 层：1 个节点是 1 个 Page，存放 1000 个 key，对应 1000 个分叉 第 2 层：1000 个节点 1000 个 Page，存放 1000*1000 个 Key，对应 1000*1000 个分叉 第 3 层：1000*1000 个 Page，每个 Page 200 条数据，共 1000*1000*200=2 亿条数据 = 16KB*1000*1000=16GB 🐂🐂🐂","tags":["mysql"],"categories":["数据库","mysql"]},{"title":"Python 知识图谱","path":"/2025/04/05/python-mindmap/","content":"","tags":["python","mindmap"],"categories":["python","mindmap"]},{"title":"后端开发之路","path":"/2025/03/17/backend-road/","content":"svg.markmap { width: 100%; height: 100vh; } - 后端开发之路 - 基础知识 - 计算机基础 - 网络基础 - 数据库基础 - 操作系统基础 - 编程语言基础 - 编程语言 - Java - Python - Node.js - Go - PHP - Ruby - C# - C++ - C - JavaScript - TypeScript - Kotlin - Swift - 框架 - Spring Boot - Django - Flask - Express - Koa - Nest.js - 数据库 - MySQL - PostgreSQL - MongoDB - Redis - SQLite - Oracle - 中间件 - Nginx - Apache - Tomcat - Jetty - Undertow - 设计模式 - 单例模式 - 工厂模式 - 观察者模式 - 策略模式 - 装饰器模式 - 适配器模式 - 门面模式 - 架构模式 - 微服务架构 - 事件驱动架构 - 发布订阅架构 - 流式处理架构 - 服务网格架构 - 性能优化 - 代码优化 - 数据库优化 - 缓存优化 - 异步编程 - 并发编程 - 多线程编程 - 分布式编程 - 高可用性设计","tags":["roadmap"],"categories":["roadmap"]},{"title":"在 Hexo 博客中优雅地集成 Markmap 思维导图","path":"/2025/03/17/mindmap-for-hexo/","content":"在技术博客写作中，思维导图是一个非常有用的工具，它可以帮助我们更清晰地展示知识结构和概念关系。本文将介绍如何在 Hexo 博客中集成 Markmap，让你能够直接在 Markdown 文件中创建交互式思维导图。 什么是 Markmap？ Markmap 是一个将 Markdown 格式的文本转换为思维导图的开源工具。它允许我们使用熟悉的 Markdown 语法来创建漂亮的、交互式的思维导图。 https://markmap.js.org/https://markmap.js.org/ 实现方案 1. 安装必要依赖 首先，我们需要安装 uuid 包，这是用来给我们每一个思维导图生成一个唯一的 ID： npm install uuid --save 2. 创建自定义标签插件 在 scripts/markmap_tag.js 中创建自定义标签： /** * Markmap Tag Plugin for Hexo */use strict;const v4: uuidv4 = require(uuid);hexo.extend.tag.register( markmap, function (args, content) const id = uuidv4(); return `div class=markmap id=markmap-$id script type=text/template$content /script/divscriptdocument.addEventListener(DOMContentLoaded, () = const template = document.querySelector(#markmap-$id script[type=text/template]); if (template) const content = template.textContent; window.markmap.autoLoader.renderString(content, null, document.querySelector(#markmap-$id)); );/script `; , ends: true ); 3. 添加样式 创建 source/css/markmap.css： /* Markmap Styles */.markmap width: 100%; height: 500px; margin: 20px 0; border: 1px solid #eaeaea; border-radius: 5px; overflow: hidden;.markmap svg width: 100%; height: 100%;/* 响应式设计 */@media (max-width: 768px) .markmap height: 400px; @media (max-width: 480px) .markmap height: 300px; 4. 更新主题配置 在主题配置文件中添加必要的资源引用： inject: head: - link rel=stylesheet href=/css/markmap.css - script src=https://cdn.jsdelivr.net/npm/markmap-autoloader@0.18/script 使用方法 代码块效果% markmap %- 技术栈 - 前端 - Vue.js - React - Angular - 后端 - Node.js - Python - Go - 数据库 - MySQL - MongoDB - Redis% endmarkmap % svg.markmap { width: 100%; height: 500px; } 技术栈 前端 Vue.js React Angular 后端 Node.js Python Go 数据库 MySQL MongoDB Redis 工作原理 1. Hexo 插件系统 Hexo 提供了强大的插件系统，允许我们通过 hexo.extend API 来扩展功能 我们使用了 hexo.extend.tag 来注册自定义标签，这是 Hexo 提供的标准扩展点之一 2. 标签插件的工作原理 hexo.extend.tag.register( markmap, function (args, content) const id = uuidv4(); // 生成唯一ID return ` div class=markmap id=markmap-$id script type=text/template $content /script /div ... `; , ends: true ); 当 Hexo 解析到 markmap 标签时，会调用这个注册的函数 content 参数包含了标签之间的所有内容（你的 markdown 结构） ends: true 表示这是一个闭合标签（需要 endmarkmap 结束） 3. Markmap 库的渲染过程 Markmap 库使用 markmap-autoloader 自动处理 markdown 到思维导图的转换 转换过程： Markdown 文本被解析成层级结构 层级结构被转换为 SVG 路径 SVG 被渲染到页面上，并添加交互功能 4. HTML 结构设计 div class=markmap id=markmap-$id script type=text/template $content /script/div 使用 script type=text/template 来存储原始 markdown 每个思维导图都有唯一 ID，避免页面上多个图表互相干扰 5. JavaScript 初始化 document.addEventListener(DOMContentLoaded, () = const template = document.querySelector( #markmap-$id script[type=text/template] ); if (template) const content = template.textContent; window.markmap.autoLoader.renderString( content, null, document.querySelector(#markmap-$id) ); ); 等待页面加载完成 获取模板中的 markdown 内容 使用 markmap 库渲染思维导图 6. 样式控制 .markmap width: 100%; height: 500px; margin: 20px 0; border: 1px solid #eaeaea; border-radius: 5px; overflow: hidden; 提供响应式布局 确保思维导图在各种屏幕尺寸下都能正常显示 7. 主题集成 在主题配置中注入必要的 CSS 和 JavaScript 确保资源在正确的时机加载","tags":["hexo","markmap"],"categories":["小技术"]},{"title":"为什么 OpenTelemetry 的 SDK 中不支持尾采样 Hook？","path":"/2025/03/13/opentelemetry-tail-sampler/","content":"在分布式追踪系统中，采样策略直接影响着系统的性能和可观测性。OpenTelemetry 作为当前最流行的可观测性框架，其采样机制设计有着深刻的考量。本文将深入探讨 OpenTelemetry 的采样机制，特别是为什么它在 SDK 层面不支持尾采样。 前置采样 vs 尾采样 在讨论 OpenTelemetry 的采样机制前，我们需要理解两种主要的采样策略： 前置采样（Head-based Sampling）： 在链路开始时就决定是否采样 决策一旦做出，整个链路都遵循这个决策 不需要缓存完整的链路数据 尾采样（Tail-based Sampling）： 在链路结束后决定是否保留 可以基于完整链路信息（如总耗时、是否有错误）做决策 需要临时缓存所有链路数据 OpenTelemetry 的采样实现 通过分析 OpenTelemetry Go SDK 的源码，我们可以清晰地看到它采用的是前置采样策略。关键代码如下： func (tr *tracer) newSpan(ctx context.Context, name string, config *trace.SpanConfig) trace.Span // ... 前面的代码 ... // 执行采样决策 samplingResult := tr.provider.sampler.ShouldSample(SamplingParameters ParentContext: ctx, TraceID: tid, Name: name, Kind: config.SpanKind(), Attributes: config.Attributes(), Links: config.Links(), ) // 设置采样标志 if isSampled(samplingResult) scc.TraceFlags = psc.TraceFlags() | trace.FlagsSampled else scc.TraceFlags = psc.TraceFlags() ^ trace.FlagsSampled // ... 后面的代码 ... 这段代码揭示了几个关键点： 采样决策在 span 创建时就已经做出 采样标志通过位操作设置在 TraceFlags 中 这个标志会随着 SpanContext 传播到整个分布式系统 采样标志的传播机制 特别值得注意的是设置采样标志的代码： if isSampled(samplingResult) scc.TraceFlags = psc.TraceFlags() | trace.FlagsSampled else scc.TraceFlags = psc.TraceFlags() ^ trace.FlagsSampled 这段代码使用位操作来设置或清除采样标志： | 操作用于设置采样标志，保留其他标志位不变 ^ 操作用于清除采样标志，同样保留其他标志位不变 这确保了采样决策能够一致地传播到整个分布式链路中。 为什么 OpenTelemetry 不支持尾采样？ 最重要的原因是：在 SDK 中找不到尾巴！因为不知道链路什么时候结束！ 在分布式系统中，一条链路可能跨越多个服务，所以你在某一个服务中，是不知道链路是否结束的，而 OpenTelemetry 也不是一次性上报一整条链路，而是每个 span 独立上报，最后再拼接到一起。 OpenTelemetry 上报原理 独立上报 每个 span 在结束时（调用 span.End()）会被传递给 SpanProcessor SpanProcessor 决定如何处理这个 span（立即导出或批量导出） 导出是独立的，不会等待整个 trace 完成 批处理机制 默认使用 BatchSpanProcessor，它会收集一定数量的 spans 或等待一定时间然后批量导出 但这个批处理与 trace 完整性无关，只是为了效率 Collector 如何实现尾采样 Collector 通过以下方式解决这些问题： 设置等待时间窗口 为每个 trace 设置一个等待期（如 10 秒） 在此期间收集该 trace 的所有 spans 超过等待期后，基于已收集的 spans 做决策 集中式收集 所有服务的 spans 都发送到 Collector Collector 有更全面的视图来关联 spans 专门的资源分配：Collector 作为独立组件，有专门的资源处理这种复杂逻辑，不会影响应用性能。 如何在 OpenTelemetry 生态中实现尾采样？ 虽然 SDK 不直接支持尾采样，但 OpenTelemetry 生态提供了其他方式实现类似功能： 1. 使用 OpenTelemetry Collector Collector 提供了 Tail Sampling Processor，可以在数据聚合层实现尾采样： processors: tail_sampling: decision_wait: 10s num_traces: 100 expected_new_traces_per_sec: 10 policies: - name: error-policy type: status_code status_code: ERROR 2. 结合前置采样和错误捕获 可以实现一个智能的前置采样器，对特定场景（如包含错误属性）强制采样： type SmartSampler struct baseSamplingRate float64func (s *SmartSampler) ShouldSample(p trace.SamplingParameters) trace.SamplingResult // 错误请求必采样 for _, attr := range p.Attributes if attr.Key == error return trace.SamplingResultDecision: trace.RecordAndSample // 其他请求使用基础采样率 if float64(p.TraceID[0])/255.0 s.baseSamplingRate return trace.SamplingResultDecision: trace.RecordAndSample return trace.SamplingResultDecision: trace.Drop 3. 使用专门的后端系统 一些专门的可观测性后端系统提供了尾采样功能： Jaeger 的 Adaptive Sampling SkyWalking 的 Trace Sampling Grafana Tempo 的 Trace Sampling 结论 OpenTelemetry SDK 采用前置采样而非尾采样，是基于分布式系统一致性、性能优化和架构分层等多方面考虑的结果。虽然这意味着无法基于完整链路信息做采样决策，但 OpenTelemetry 生态提供了多种方式来弥补这一限制。 在实际应用中，我们可以： 在 SDK 层使用智能前置采样策略，确保关键链路被采样 在 Collector 层实现尾采样，进一步筛选有价值的链路 结合使用多种采样策略，平衡性能和可观测性 通过这种分层设计，OpenTelemetry 既保证了高效的数据收集，又为高级采样策略提供了可能性，满足了不同场景的需求。 实战案例 笔者实现一个 Go 语言的开源项目 goapm，对多个 Go 语言中常用的组件进行了 trace、log 和 metrics 的集成封装，用于快速在 Go 语言项目中实现可观测性，同时还提供了 goapm-example 实战案例，可供参考。 https://github.com/hedon954/goapmhttps://github.com/hedon954/goapm https://github.com/hedon954/goapm-examplehttps://github.com/hedon954/goapm-example","tags":["opentelemetry","服务监控"],"categories":["服务监控"]},{"title":"读书笔记丨《悟道领域驱动设计》","path":"/2025/03/11/note-ddd-awareness/","content":"思维转变 领域驱动设计（Domain-Driven Design，以下简称 DDD）的核心价值在于其对「业务领域」的深度聚焦。这里的「领域」并非单纯的技术范畴，而是指代软件系统所要映射的现实业务场景及其核心价值主张。DDD 通过建立与业务高度契合的领域模型，使得技术实现与业务本质形成同频共振，从而有效解决复杂业务场景下的认知鸿沟问题。 在 VUCA（Volatile 易变性、Uncertain 不确定性、Complex 复杂性、Ambiguous 模糊性）特征愈发显著的现代商业环境中，任何架构设计都面临固有局限。这种局限性既源于业务需求本身的动态演进，也受制于人类认知的有限性——正如 Eric Evans 在开山之作中强调的“模型永远是对现实的近似抽象”。但正是这种局限性，凸显了 DDD 方法论的战略意义： 它通过战略设计构建业务全景图，运用限界上下文划定领域边界，通过战术设计落地聚合根、实体/值对象等模式，形成应对复杂性的结构化解决方案。 需要特别指出的是，DDD 的复杂性并非方法论本身的缺陷，而是其应对现实业务复杂度的必要代价。这种复杂性体现在三个维度： 认知复杂性：要求开发团队与领域专家共建通用语言，实现业务概念与代码模型的精准映射。 架构复杂性：通过分层架构实现业务逻辑与技术实现的解耦，采用防腐层处理系统集成问题。 演进复杂性：借助子域划分和上下文映射，为持续演进的业务提供可扩展的架构基础。 对于实践者而言，DDD 的价值不在于提供完美无缺的终极方案，而是为 VUCA 环境下的系统建设提供基础性指引。其核心思想——无论是通过限界上下文实现的领域自治，还是通过聚合根维护的业务一致性——都为控制软件熵增提供了可落地的模式库。即便不完全采用DDD 完整体系，其领域建模思想、分层架构理念等核心要素，仍能显著提升复杂系统的可维护性和演进能力。这种开放包容的哲学，恰是 DDD 历经二十年仍保持生命力的关键所在。 贫血模型 vs. 充血模型 贫血模型：指的是只有属性而没有行为的模型。 充血模型：指的是既有属性又有行为的模型。 笔者过往的实践中，基本上都使用类似于 controller→service→repository[model] 的三层架构： conrtoller 负责暴露对外接口。 service 负责执行所有的业务逻辑。 repository 复杂数据的存储和缓存，包含数据对象 model 的定义。 在这个模式下，基本上所有的核心逻辑都充斥在 service 层中，所以 service 层一般都会非常大，它要扮演多面手，即要负责跟各个模块协作，还要负责处理具体的业务规则，最终完成一个业务行为。这个过程中，model 即为贫血模型，因为逻辑都给 service 处理了，这种架构也称为贫血三层架构。 在 DDD 的理念下，很多的核心业务概念都会被建模为「领域对象」，这些「领域对象」本身就是一种业务规则的体现，所以把业务的处理逻辑，都归属到这些「领域对象」的行为当中了，即所谓的充血模型。 在这个理念下，一个优化后的充血四层架构如下图所示： 贫血模型推荐场景：业务简单、迭代快速、团队技术栈偏传统（如 Spring Boot+MyBatis）时，避免过度设计。 充血模型推荐场景：业务复杂、需长期演进（如核心交易系统）、团队具备 DDD 经验时，通过实体、值对象、领域服务等战术设计理念降低系统熵增。 混合使用的场景：部分核心领域用充血模型（如订单、支付），非核心模块用贫血模型（如日志、配置），平衡效率与质量。 实际上，充血模型因其状态完整，适合进行状态变更类的操作，以确保业务操作符合领域规则；贫血模型由于其轻量级，更适合作为不会涉及状态变更的操作的数据容器。这其实就是 CQRS 的理念。 概念清单 战术设计 实体 定义：会随着业务变化发生变化的业务概念叫作实体对象。关键点：实体需要唯一表示 值对象 定义：一些对象在表达业务概念时是必须的，可业务并不围绕着它们进行，它们仅是对这些重要业务概念的描述，这一类对象叫作值对象。关键点：值对象的意义取决于属性，只要对象的属性一模一样，那么对象就是相同的。尽量把值对象实现为不可变对象。 领域服务 定义：领域服务自身是没有数据的，只是表达了某种业务计算逻辑，或者业务的某种策略。关键点：领域服务是无状态的。只有在确实表达了一个相对独立的业务概念或者业务策略，并且不能简单地把它归结到某个既有的业务对象上时，才是一个真正的领域服务。 领域事件 定义：领域事件代表从业务专家视角看到的某种重要的事情发生了。关键点：领域事件是一种特殊的值对象。应该根据限界上下文中的通用语言来命名事件：AccountActivited。应该将事件建模成值对象或贫血对象。 聚合 定义：聚合从本质上讲是在基础的构造块上增加了一层边界，用边界把那些紧密相关的对象放到了一起。关键点：紧密相关的对象存在数据一致性问题；缺乏边界时，维护数据一致性是困难的；划分边界的关键在于既不要让整个系统成为一个整体，又让每个单独划分出的聚合具有明确的业务意义；聚合需要关注三条法则：生命周期一致性：如果一个对象在聚合根消失之后仍然有意义，那么说明此时在系统中必然存在能够访问该对象的方法。这和聚合的定义矛盾，所以聚合内的其他元素必然在聚合根消失后失效。问题域一致性：不属于同一个问题域的对象，不应该出现在同一个聚合中。尽量小的聚合：聚合的本质作用是提升对象系统的粒度，确保一致性、降低复杂度。不过，粒度绝不是越大越好。如果聚合的粒度太大，那内部的逻辑复杂度也会大大增加还会影响到复用度。因此，要能够比较容易地断开聚合。 资源库 定义：对于查询、创建、修改、删除数据的操作，领域模型使用“资源库(Repository)”这个概念来承载它们。关键点：一个聚合对应一个资源库，应以聚合根命名资源库，除了聚合根之外的其他对象，都不应该提供资源库对象。 工厂 定义：工厂用于构建聚合。关键点：一个聚合往往包含多个对象，这些对象的数据之间又可能存在联系，如果允许分别创建这些对象，就会让聚合是业务完整性的单元这个定义面临失败。 战略设计 统一语言 定义：与业务专家协作定义全团队通用的术语表，消除沟通歧义。关键点：同一个概念在不同的上下文中可能存在不同的含义；同一个概念在同一上下文中的不同环节，也可能存在不同的含义，需要非常明确清晰的界定，降低沟通成本。 子域 定义：子域是对业务领域的逻辑划分，用于分解复杂问题。通常分为核心子域（业务核心竞争力）、支撑子域（辅助核心业务）和通用子域（可复用的标准化能力）。关键点：因业务目标、团队定位和组织发展阶段等方面的不同，这三个子域的划分并非一成不变，而是会互相转换。 限界上下文 定义：限界上下文本质上是一个自治的小世界，它有完备的职责，还有清晰的边界。关键点：一个子域的一切资产，包括领域模型、数据库、包、可执行程序、接口声明等，都应该封装在限界上下文中，避免跨越边界。如何平衡边界的价值和不利影响，是划分边界时要做的一种重要取舍。一个较为稳妥的策略是考虑认知的渐进特征，不要过早隔离。在已经确定的边界上进行划分，延缓划分那些尚具模糊性的边界，在这些边界逐渐变得清晰时再分离它们。 上下文映射 定义：限界上下文约定了基于领域模型的架构层次的设计分解，而分解必然意味着集成和协作。上下文映射就是对限界上下文之间的协作关系的模式总结。关键点：在边界上完成概念映射是一种基本模式。通过在应用层组装或者使用适配器完成概念映射，可以保持领域概念的清晰，避免领域模型遭到不必要的污染。防腐层模式、标准开放服务模式、客户-供应商模式、追随者模式。 串讲 在应对复杂业务系统时，DDD 通过分治策略将业务领域拆分为多个子域（如电商系统的订单、支付子域），每个子域对应一个限界上下文——这是技术与业务对齐的关键边界，既承载领域模型的实现，也通过上下文映射（如防腐层、共享内核等模式）实现跨子域协作，避免模型污染。 限界上下文内的领域对象是业务逻辑的载体：具备唯一标识和生命周期的实体（如订单实体通过 ID 跟踪状态变化）、描述特征且不可变的值对象（如地址由省市构成，修改需整体替换），以及通过聚合根统一操作保证一致性的聚合（如订单聚合根管理订单项和配送信息）。当业务逻辑跨越多个聚合时，由无状态的领域服务协调（如支付计算需整合订单、账户聚合）。 对象的创建与持久化分别由工厂（封装复杂初始化逻辑）和资源库（隔离存储细节）负责，而领域事件（如订单支付成功事件）则驱动跨上下文的异步协作。 战术设计 factory factory 用于构建复杂的领域对象。 repository 只有聚合根有 repository。 repository 就只提供 load 和 save 功能，且要保证事务一致性。 尽可能提供行级的 repository，而不是表级的 repository，对于表级的 repository，可以抽成一个领域服务。 设计模式 责任链模式 将请求的发送者和接受者解耦，使多个对象都有机会处理请求。 责任链模式的使用要点在于要将维护责任链的代码和业务代码分开。 在 DDD 中使用责任链模式时，应创建一个领域服务，在领域服务中完成责任链的创建和执行。 尽量不要在责任链的处理器中通过 set 修改领域对象（聚合根）的状态，责任链应仅用于某些值的计算，最终将计算结果交给聚合根完成业务操作。 笔者实现了一个快速构建责任链的工具： https://github.com/hedon954/devkit-go/blob/main/designmode/responsibility/builder.gohttps://github.com/hedon954/devkit-go/blob/main/designmode/responsibility/builder.go 策略模式 允许在运行时根据需要选择不同的实现。 在 DDD 中使用策略模式时，通常先定义一个领域服务接口，再在其实现类中完成策略的加载、选择和执行。 注意屏蔽策略模式的实现细节，避免上层关注领域服务内的设计模式细节。 桥接模式 旨在通过解耦抽象和实现，使两者能够独立扩展和变化。 多维解耦机制：桥接模式通过组合/聚合关系替代继承关系，将原本紧密耦合的抽象层（功能定义）与实现层（具体操作）分离例如遥控器（抽象）与电视（实现）的协作，遥控器通过接口控制电视，无需关注具体品牌。 正交扩展能力：支持两个独立变化维度（如消息类型与通知渠道、图形与渲染方式），避免类数量呈指数级增长（M×N 组合问题）。电商物流系统中，新增微信通知渠道时，无需修改所有消息类即可实现扩展。 规约模式 规约模式是一种用于定义业务领域中规则和约束的模式，通常由规约接口（Specification）和验证器（Validator）两个部分组成。 在 DDD 中，规约模式并不是在聚合根进行业务操作之前做前置校验，而是在聚合根完成业务操作之后做后置校验，确保 Repository 保存的聚合根符合业务规则。 适配器模式 将被适配者（Adaptee）的接口转换为目标接口（Target），使原本因接口不兼容而无法协同工作的类能够协同。 在 DDD 中，可以使用适配器模式来实现防腐层，以将外部上下文接口（如开放主机服务）返回的模型转换为本地上下文定义的领域模型，并将本地上下文的操作转换为对外部上下文的操作。可以有效隔离外部上下文的领域模型，避免互相污染。 领域事件 幂等性 领域事件的定义 领域事件是领域模型的组成部分，它通常由聚合根产生，并被其他聚合或者限界上下文订阅和处理，触发相应的业务逻辑。 注意点： 应该根据限界上下文中的通用语言来命名事件：AccountActivited。 应该将事件建模成值对象或贫血对象。 应用： 解耦领域对象之间的关系； 触发其他领域对象的行为； 记录领域内已发生的状态变化； 实现跨聚合的最终一致性； 进行限界上下文集成。 消息体： event_id: , event_type: , entity_id: , event_time: 0, extra_data: 领域事件的生成 应用层创建领域事件。 聚合根创建领域事件。 要避免在聚合根内部调用基础实施发布领域事件，而是生成后返回给应用层，由应用层去发布。 type Entity struct Events []Eventfunc(e *Entity)ResgisterEvent(event Event) e.Events = append(e.Events. event)func(e *Entity) GetEvents() []Event res := e.Events() e.Events = []Event return res 领域事件的发布 直接发布并轮询补偿：为事件存储一个发布状态标识，用于记录是否补发成功。并提供定时任务检索超时未发布成功的事件进行重新发布。 采用事务日志拖尾：引入变更数据捕获组件（Change Data Capture，简称 CDC），捕获数据的变更日志，解析后获得领域事件并发布。 领域事件的订阅 将领域事件订阅者放置在用户接口层 user-interface-subscriber，收到事件后调用应用服务执行业务逻辑。 事件溯源 事件溯源（Event Sourcing）是一种将所有的领域事件（Domain Event）存储到事件存储（Event Store）中，并通过重放历史事件来还原领域对象状态的模式。 核心思想是将系统中所有的状态变更都视为事件，将这些事件以事件顺序记录下来，并存储到事件存储中。这样，可以通过重放这些事件，来还原任意时刻的系统状态。 三种方案： 通过回放所有的历史事件重建聚合根。 通过快照提高重建聚合根的效率。 通过拉链表生成所有事件对应的快照。 拉链表是一种用于处理缓慢变化维度问题的数据结构，它可以有效地处理维度数据的历史变化。在拉链表中，每个记录都有一个开始时间和结束时间，用于描述该记录的存活时间，即该记录的有效期。 CQRS CQRS 将系统的操作分为两类： 命令（Command）：负责数据的写操作（增、删、改），不返回数据。 查询（Query）：负责数据的读操作，仅返回结果且不修改数据。 两者的数据模型可独立设计，甚至使用不同的数据库或存储技术。 适用场景 应对高并发读写场景案例 1：B 站点赞系统在日均活跃用户近亿的 B 站，点赞功能通过 CQRS 分离读写操作。写入端通过消息队列（如 Kafka）异步处理请求，避免数据库锁竞争；查询端通过缓存优化读取性能，显著提升系统吞吐量和稳定性。案例 2：实时答题 PK 游戏高并发的答题得分计算场景中，CQRS 结合事件溯源（Event Sourcing）记录每个操作事件，确保读写模型的最终一致性，同时支持复杂战况数据的实时展示。解决复杂查询需求案例 3：电商订单查询随着订单查询需求多样化（如按时间筛选、跨实体聚合数据），CQRS 通过独立读模型简化查询逻辑，避免领域模型被复杂查询逻辑污染。案例 4：微服务数据聚合在微服务架构中，CQRS 允许通过事件同步跨服务数据到专用读库，避免跨服务联表查询的性能瓶颈（如行程管理服务与用户信息服务的聚合查询）。提升数据模型灵活性案例 5：文本增量更新针对大型文本编辑场景，CQRS 拆分读写模型，增量保存修改记录并通过事件合并，减少网络传输数据量，同时支持任意版本的历史数据恢复。 不适用场景 简单 CRUD 系统（如小型管理后台）强一致性要求的金融交易场景（如实时扣款）团队缺乏事件驱动架构经验时 一致性 聚合内事务实现 聚合内事务控制不要放在应用层，会使应用层承担过多的责任。应用层应专注于协调领域对象和基础设施以完成业务操作，不应过多涉及数据访问和事务控制的细节。 聚合内事务控制可以交给 Repository 来实现，采用乐观锁解决并发问题，可以基于版本号和时间戳，一般重试 1-3 次即可。 聚合间事务实现 聚合间控制可以单独建立一个领域服务 Domain Service 来完成。 对于实时性要求不高，仅需最终一致性，可以使用本地消息表或者最大努力通知的方案。 对于实时性一致性要求比较高，可以采用 TCC（Try-Confirm-Cancel） 事务方案。 对于长事务场景，或者涉及外部系统、遗留系统，可以考虑 Saga 事务方案。 Saga 将事务分为多个事务，这些分支事务按照一定的顺序执行。当某个分支事务执行成功后，会通过消息通知下一个分支执行；当某个分支事务执行失败时，会按照正常事务执行顺序的相反方向进行一系列的补偿操作，以确保全局事务的一致性。 战略设计 事件风暴 核心概念与元素 元素名称 颜色标识 说明 领域事件（Domain Event） 橙色 表示已发生的业务事实，以“动词过去式”命名（如“订单已提交”），是事件风暴的核心起点。 命令（Command） 深蓝色 触发领域事件的操作或意图（如“提交订单”），通常由用户或系统触发。 参与者（Actor） 黄色 执行命令的角色，包括用户、部门或外部系统（如“客户”触发支付命令）。 外部系统（External System） 粉色 与当前系统交互的第三方服务（如支付网关回调生成事件）。 策略（Policy） 紫色 业务规则或约束条件（如“库存不足时取消订单”），决定事件触发的逻辑。 读模型（Read Model） 绿色 为查询优化的数据视图（如“用户订单列表”），支持决策展示。 聚合（Aggregate） 大黄色 业务对象集合（如“订单聚合”包含订单项和状态），维护一致性和完整性。 问题（Question） 红色 未达成共识的争议点（如事件定义分歧），需后续专项讨论。 实施流程与步骤 准备工作 参与人员：业务专家、开发、产品、测试等跨职能角色，需领域专家主导。 物料：多色便签、白板、马克笔，线上工具辅助远程协作。 识别领域事件 团队通过头脑风暴罗列所有可能事件（如电商场景的“订单已创建”“库存已扣减”），按时间轴排列，争议事件用红色便签标记并暂存。 补充命令与角色 为每个事件关联触发命令及执行者（如“客户”执行“支付订单”命令生成“支付完成”事件），区分内部操作与外部系统调用。 定义策略与读模型 添加业务规则（如“订单金额≥1000元需审核”）和数据展示需求（如“实时库存看板”）。 构建聚合与划分子域 将相关事件、命令归类为聚合（如“支付聚合”），划分限界上下文（如“订单服务”“库存服务”），明确微服务边界。 注意事项 事件粒度的把控：避免过度细化（如“用户已睁眼）或过于宽泛（如“订单已修改”），需聚焦业务关键节点。 争议处理与迭代：对未达成共识的事件标记为“问题”（红色便签），后续专题讨论；定期回顾模型，修正错误或补充遗漏。 技术实现衔接 ：事件风暴的输出需转化为代码模型，例如通过事件溯源（Event Sourcing）持久化事件流，或结合 CQRS 分离读写逻辑。 C4 架构模型 https://c4model.com/https://c4model.com/ 层级 核心目标 受众 关键元素 Context（上下文） 描述系统与外部实体（用户、第三方系统）的交互关系 非技术人员（如业务方、客户） 系统边界、用户角色、外部依赖（如支付网关） Container（容器） 展示系统内部的高阶技术组件（进程级单元） 技术管理者、架构师 Web 应用、数据库、消息队列等独立进程单元，关注技术选型与通信协议（如 REST API、gRPC） Component（组件） 细化容器内部的业务模块与交互逻辑 开发团队 服务、模块、接口（如订单服务、库存服务），强调职责划分与依赖关系 Code（代码） 展示组件实现的代码结构 开发者 类、方法、数据库表（如 UML 类图、ER 图），通常由 IDE 工具自动生成 除了四层核心视图，C4 模型还提供： 部署图：展示容器在物理环境中的分布（如 Kubernetes 集群部署）。 动态图：描述业务流程（如用户下单到支付完成的时序交互）。 系统景观图：多系统协同的全局视图（如企业级中台架构）。 ContextContainerComponentCode 实践案例 参考作者的 ddd-archetype ，笔者实现了一个 Go 版本的 ddd-archetype-go： https://github.com/hedon-go-road/ddd-archetype-gohttps://github.com/hedon-go-road/ddd-archetype-go 整体架构如下：","tags":["读书笔记","DDD"],"categories":["读书笔记"]},{"title":"Go 1.24 新特性解读：使用 testing/synctest 优雅地测试并发代码","path":"/2025/03/06/go-lib-synctest/","content":"在 Go 语言开发中，并发编程一直是其最引人注目的特性之一。然而，如何有效地测试并发代码却常常让开发者感到头疼。Go 1.24 版本引入的实验性包 testing/synctest 为这个问题带来了优雅的解决方案。今天，让我们深入了解这个新特性。 并发测试的传统困境 在介绍新方案之前，我们先看看传统的并发测试面临哪些问题： func TestTraditional(t *testing.T) done := false go func() // 执行某些操作 time.Sleep(100 * time.Millisecond) done = true () // 等待操作完成 time.Sleep(200 * time.Millisecond) if !done t.Fatal(操作未完成) 这种方式存在明显的问题： 时间依赖：需要通过 Sleep 等待，导致测试运行缓慢 不稳定性：在不同环境下可能产生不同结果 精确性差：难以准确把握检查时机 synctest：优雅的解决方案 testing/synctest 包通过两个核心函数改变了这一切： Run(): 创建隔离的测试环境（bubble） Wait(): 等待所有 goroutine 进入稳定状态 让我们看看如何改写上面的测试： func TestWithSynctest(t *testing.T) synctest.Run(func() done := false go func() // 执行某些操作 time.Sleep(100 * time.Millisecond) done = true () synctest.Wait() // 等待所有 goroutine 进入稳定状态 if !done t.Fatal(操作未完成) ) 深入理解 Wait 机制 Wait 的本质 很多开发者初次接触 Wait() 时可能会感到困惑：它到底在等待什么？什么时候会返回？ 想象一个场景：你在拍摄一张全家福，需要等待所有人都找到自己的位置，站好不动，才能按下快门。Wait() 就像这个摄影师，它在等待所有 goroutine（就像照片中的人）都进入一个稳定的状态（站好不动）。 synctest.Run(func() // 类比：三个人要拍全家福 go person1() // 第一个人找位置 go person2() // 第二个人找位置 go person3() // 第三个人找位置 synctest.Wait() // 等待所有人都站好不动 // 这时可以安全地按下快门（检查程序状态）) 为什么需要 Wait？ 在并发程序中，我们经常需要在特定时刻检查程序状态。但是，如果某些 goroutine 还在运行，这个状态可能随时发生变化。Wait() 通过确保所有 goroutine 都进入稳定状态，为我们提供了一个快照时刻。 synctest.Run(func() result := false go func() // 模拟耗时操作 time.Sleep(1 * time.Second) result = true () synctest.Wait() // 等待 goroutine 进入稳定状态 // 此时 result 的值是确定的，不会突然改变 fmt.Println(result)) 持久阻塞的概念 哪些操作会导致持久阻塞？ channel 操作（同一 bubble 内） time.Sleep sync.WaitGroup.Wait sync.Cond.Wait 哪些操作不算持久阻塞？ 互斥锁操作 外部 I/O 外部 channel 操作 虚拟时钟：测试的神器 synctest 的另一个强大特性是虚拟时钟机制。在 bubble 内部，所有时间相关的操作都使用虚拟时钟，这意味着： synctest.Run(func() // 看似等待24小时 time.Sleep(24 * time.Hour) // 实际上立即执行完成！) 这个特性让我们能够： 快速测试长时间操作 精确控制时间流逝 避免测试的不确定性 实战案例：深入理解 HTTP 100 Continue 测试 背景知识 HTTP 的 100 Continue 机制是一个优化大文件上传的协议特性： 客户端想上传大文件时，先发送带有 “Expect: 100-continue” 头的请求 服务器可以决定是否接受这个上传： 如果接受，返回 “100 Continue” 如果拒绝，可以直接返回错误状态码 客户端根据服务器的响应决定是否发送文件内容 详细测试实现 func TestHTTPContinue(t *testing.T) synctest.Run(func() // 第一步：建立测试环境 srvConn, cliConn := net.Pipe() defer srvConn.Close() defer cliConn.Close() // 第二步：配置 HTTP 客户端 tr := http.Transport DialContext: func(ctx context.Context, network, address string) (net.Conn, error) return cliConn, nil , ExpectContinueTimeout: 5 * time.Second, // 第三步：准备测试数据 body := request body // 第四步：发送请求 go func() req, _ := http.NewRequest(PUT, http://test.tld/, strings.NewReader(body)) req.Header.Set(Expect, 100-continue) resp, err := tr.RoundTrip(req) if err != nil t.Errorf(请求失败: %v, err) else resp.Body.Close() () // 第五步：验证请求头 req, err := http.ReadRequest(bufio.NewReader(srvConn)) if err != nil t.Fatalf(读取请求失败: %v, err) // 第六步：验证请求体未发送 var gotBody strings.Builder go io.Copy(gotBody, req.Body) synctest.Wait() if got := gotBody.String(); got != t.Fatalf(在发送 100 Continue 之前，意外收到请求体: %q, got) // 第七步：发送 100 Continue srvConn.Write([]byte(HTTP/1.1 100 Continue\\r \\r )) // 第八步：验证请求体 synctest.Wait() if got := gotBody.String(); got != body t.Fatalf(收到的请求体 %q，期望 %q, got, body) // 第九步：完成请求 srvConn.Write([]byte(HTTP/1.1 200 OK\\r \\r )) ) 测试的关键点解析 使用 net.Pipe() 创建内存中的网络连接 避免依赖真实网络 保证测试的可重复性 请求发送过程 在独立的 goroutine 中发送请求 设置 “Expect: 100-continue” 头 准备要发送的请求体 验证关键行为 确认请求头正确发送 验证请求体在收到 100 Continue 之前未发送 验证请求体在收到 100 Continue 后正确发送 使用 Wait 的时机 在检查请求体之前调用 Wait 确保所有数据传输操作都已完成或阻塞 获得稳定的程序状态进行验证 使用建议 明确边界：理解什么操作会导致持久阻塞，什么不会 清理资源：确保所有 goroutine 在测试结束前退出 模拟 I/O：使用内存管道替代真实网络连接 合理使用 Wait：在需要检查状态的关键点调用 注意事项 目前是实验性功能，需要设置 GOEXPERIMENT=synctest 不支持测试真实的外部 I/O 操作 互斥锁操作不被视为持久阻塞","tags":["Go","单元测试"],"categories":["Go"]},{"title":"直播系统推拉流原理","path":"/2025/03/04/live-stream-push-pull/","content":"直播系统推拉流原理概述 直播系统的核心功能是实现主播端视频采集后的实时传输，以及观众端的实时观看。整个过程主要包含：推流、服务器处理、拉流三个环节。 核心概念解析 1. 推流（Push） 推流是指主播端将视频数据传输到服务器的过程。主要使用 RTMP 协议（Real Time Messaging Protocol）。 比如可能有如下推流 URL 的生成逻辑： public static String generatePushUrl(String pushDomain, String pushKey, String appName, String streamName, long expireTime) String pushUrl = ; // 推流域名未开启鉴权功能的情况下 if (StringUtils.isBlank(pushKey)) pushUrl = rtmp:// + pushDomain + / + appName + / + streamName; else long timeStamp = System.currentTimeMillis() / 1000L + expireTime; String stringToMd5 = / + appName + / + streamName + - + Long.toString(timeStamp) + -0-0- + pushKey; String authKey = md5(stringToMd5); pushUrl = rtmp:// + pushDomain + / + appName + / + streamName + ?auth_key= + Long.toString(timeStamp) + -0-0- + authKey; return pushUrl; 推流地址的组成部分： rtmp:// - 协议 pushDomain - 推流域名 appName - 应用名称 streamName - 流名称 auth_key - 鉴权参数（可选） 2. 拉流（Pull） 拉流是观众观看直播的过程。支持多种协议： RTMP：延迟低（1-3秒） HTTP-FLV：延迟适中（2-5秒） HLS(m3u8)：延迟较高（5-30秒） // FLV 格式public static String generalPullUrlFlv(String pullDomain, String pullKey, String appName, String streamName, long expireTime) if (StringUtils.isBlank(pullKey)) return http:// + pullDomain + / + appName + / + streamName + .flv; // ... 鉴权逻辑// HLS 格式public static String generalPullUrlHls(String pullDomain, String pullKey, String appName, String streamName, long expireTime) if (StringUtils.isBlank(pullKey)) return http:// + pullDomain + / + appName + / + streamName + .m3u8; // ... 鉴权逻辑 直播流程 主播开播： 系统生成唯一的 streamId 生成带鉴权的推流地址 主播端推流软件（如 OBS）开始推流 服务器处理： 流媒体服务器接收推流 进行转码、录制等处理 将流分发到 CDN 节点 观众观看： 获取对应格式的拉流地址 通过播放器拉取直播流 实现实时观看 实现建议 选择合适的流媒体服务器： 商业云服务：阿里云直播、腾讯云直播 开源方案：SRS、Nginx-RTMP 根据业务场景选择协议： 普通直播：HTTP-FLV 低延迟场景：RTMP 移动端兼容性要求高：HLS 关注关键指标： 延迟控制 卡顿率 首屏时间 带宽成本 安全鉴权： 防盗链机制","tags":["直播系统"],"categories":["解决方案","直播系统"]},{"title":"网络数据包的完整旅程：从发送到接收的全过程","path":"/2025/03/01/net-data-journey/","content":"不知道你是否曾经好奇你发出的一个网络请求，最终是怎么到达对端，并将你想要的信息返回给你的。本文将通过一个 HTTP 请求与响应，从一个比较宏观的角度来梳理下一个数据包在网络中的旅途，旨在帮助笔者和各位读者建立起对计算机网络模型一个比较全面的认知。 本文参考极客时间《网络架构实战课（谢友鹏）》，再根据笔者的知识面、按照个人理解，补充更多丰富具体的内容。 实战 好，那我们直接开始，我们先使用 curl 来发起一个 HTTP 请求，看看这过程中发生了什么： curl -o /dev/null -v https://example.com 在笔者的 mac 机器上，这行命令的输出如下： 当我们发起请求时，首先会对 example.com 进行域名解析，分别尝试解析到它的 IPv6 和 IPv4。 * IPv6: (none)* IPv4: 23.215.0.138, 96.7.128.198, 23.192.228.80, 23.192.228.84, 23.215.0.136, 96.7.128.175 因为我们使用的是 https 协议，所以会尝试跟这些地址的 443 端口建立 TCP 连接，（如果是 https 则跟 80 端口），并进行 TLS 握手验证，如果成功了，则会建立 TCP 连接。 * Trying 23.215.0.138:443......[TLS handshake]* Connected to example.com (23.215.0.138) port 443 建立连接后，就开始发送 HTTP 请求，这里使用的是 HTTP2 协议。 * using HTTP/2 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* [HTTP/2] [1] OPENED stream for https://example.com/* [HTTP/2] [1] [:method: GET]* [HTTP/2] [1] [:scheme: https]* [HTTP/2] [1] [:authority: example.com]* [HTTP/2] [1] [:path: /]* [HTTP/2] [1] [user-agent: curl/8.10.1]* [HTTP/2] [1] [accept: */*] [5 bytes data] GET / HTTP/2 Host: example.com User-Agent: curl/8.10.1 Accept: */** Request completely sent off 最后，服务器返回了 HTTP 200 OK 的响应。 [5 bytes data]* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4): [265 bytes data]* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4): [265 bytes data] HTTP/2 200 content-type: text/html etag: 84238dfc8092e5d9c0dac8ef93371a07:1736799080.121134 last-modified: Mon, 13 Jan 2025 20:11:20 GMT cache-control: max-age=1374 date: Sat, 01 Mar 2025 05:01:03 GMT alt-svc: h3=:443; ma=93600,h3-29=:443; ma=93600,quic=:443; ma=93600; v=43 content-length: 1256 [5 bytes data]100 1256 100 1256 0 0 1172 0 0:00:01 0:00:01 --:--:-- 1172* Connection #0 to host example.com left intact 要进一步了解网络数据包的细节，我们可以通过抓包工具进行分析。你可以使用 tcpdump 抓取与 example.com 的通信数据包。 运行如下命令： sudo tcpdump host example.com -w example.com.pcap 然后再另外一个命令行窗口再次发送请求： curl -o /dev/null -v https://example.com 回到 tcpdump 的窗口并结束监听，我们就会得到 example.com.pcap 的抓包文件，可以通过 Wireshark 软件打开该文件： 网络分层 通过上述实验，我们可以清晰看到网络是分层的，主流的分层模型有 OSI 七层模型和 TCP/IP 四层模型，它们的对应关系及常见的协议如下图所示： 我们在 Wireshark 上方随便选择一个数据包，使用鼠标点击下方左侧的每一层，可以在右侧看到对应的层级数据。从链路层到应用层，每一层的数据都是对下一层的进一步封装。 在发送方，用户程序需要传输的数据会经过逐层封装。首先添加应用层的 HTTP Header，然后是传输层的 TCP Header，接着是网络层的 IP Header，最后在链路层添加以太网帧的帧头和帧尾，包括源 MAC 地址、目的 MAC 地址等链路层信息，最终形成网络中传输的完整数据包。 在接收方，数据包会按相反的顺序逐层解封装。接收设备从链路层开始解析数据，依次解读网络层、传输层和应用层的信息，最后将数据传递给接收方的应用程序。 如下图所示： 我们在 Wireshark 中点开下面的每一层，可以看到如下信息，我在图标注了最重要的几个信息： 网络之旅 经过上述实验，我们可以做个小总结： 通过上述实验，我们可以清晰理解数据包的传输过程： HTTP 请求是网络通信的应用层内容，它需要通过各层网络协议的封装才能实现端到端传输。 从发送方角度，数据传输遵循一个明确的逻辑顺序：首先将域名（example.com）解析为 IP 地址，然后基于该 IP 地址和目标端口（443）建立 TCP 连接，接着找到目标 IP 的 MAC 地址，最终由网卡将完整封装的数据包发送到网络中。 从接收方角度，服务器处理数据包的过程是一个自下而上的解封装过程：数据链路层接收到的帧包含源 MAC 地址，网络层解析出 IPv4 地址和协议类型，传输层识别出 TCP 协议和源端口号，最终在应用层获取并处理 HTTP 请求数据。服务器根据这些信息构建响应，并按相反顺序封装返回给客户端。 这种分层处理机制确保了网络通信的灵活性和可靠性，每层只需关注自己的职责，共同完成端到端的数据传输任务。 好，那么这里就有 2 个最关键的问题： 如何通过域名获得 IP 地址？ 如何通过 IP 地址获取 MAC 地址？ DNS 解析 DNS（Domain Name System，域名系统）是互联网的一项核心服务，它允许我们使用易记的域名（如 example.com）而不是数字 IP 地址（如 93.184.216.34）来访问网站。 当你在浏览器中输入一个域名时，DNS 解析按以下步骤进行： 浏览器缓存检查：浏览器首先检查自己的缓存，看是否已经存储了该域名对应的 IP 地址。 操作系统缓存检查：如果浏览器缓存中没有，系统会检查操作系统的 DNS 缓存（如 Windows 的 DNS Client 服务）。 路由器缓存检查：若系统缓存中也没有，请求会被发送到你的路由器，它也维护着一个 DNS 缓存。 ISP DNS 服务器查询：如果以上缓存都未命中，请求会被发送到你的 ISP（互联网服务提供商）的 DNS 服务器。 递归查询：ISP 的 DNS 服务器会执行递归查询： 首先查询根域名服务器（Root DNS Server） 根服务器会引导到顶级域名服务器（TLD DNS Server，如 .com, .net, .org 等） 顶级域名服务器会引导到权威域名服务器（Authoritative DNS Server） 权威服务器会返回该域名的 IP 地址 结果返回与缓存：一旦获取到 IP 地址，它会被沿着查询路径返回，并在各个层级上缓存一段时间（由 TTL 值决定）。 你可以使用以下工具查询 DNS 信息： nslookup：nslookup example.com dig：dig example.com host：host example.com 这些工具可以帮助你了解域名的解析过程和结果。 ➜ ~ host example.comexample.com has address 23.215.0.138example.com has address 23.192.228.84example.com has address 23.215.0.136example.com has address 23.192.228.80example.com has address 96.7.128.175example.com has address 96.7.128.198example.com has IPv6 address 2600:1408:ec00:36::1736:7f31example.com has IPv6 address 2600:1406:3a00:21::173e:2e65example.com has IPv6 address 2600:1406:3a00:21::173e:2e66example.com has IPv6 address 2600:1406:bc00:53::b81e:94c8example.com has IPv6 address 2600:1406:bc00:53::b81e:94ceexample.com has IPv6 address 2600:1408:ec00:36::1736:7f24example.com mail is handled by 0 . 通过 DNS 解析将域名转换为 IP 地址后，网络通信的下一步就是确定如何将数据包发送到目标 IP 地址，这就需要用到 ARP 协议来获取目标设备的 MAC 地址。 穿越客户端局域网 当我们发送一个网络请求时，数据包如何找到离开家庭/办公网络的出口？ 数据包首先需要解决的是该往哪走的问题： 问题：我需要直接联系目标设备还是找个中介？ 解决方案：子网判断 设备会比较目标 IP 与自己的 IP 和子网掩码 就像判断收件人是不是住在同一个小区 问题：如何找到同一网络中的设备？ 解决方案：ARP 协议 类似于小区广播：“谁是 202 号房的？请告诉我你的门牌号！” 目标设备回应自己的 MAC 地址（设备的身份证号） 问题：目标在远方，如何离开本地网络？ 解决方案：默认网关 就像不认识远方收件人的地址，先交给小区门卫（路由器） 数据包头上标注最终目的地 IP，但先送到网关的 MAC 地址 问题：数据如何在本地网络中转发？ 解决方案：交换机的 MAC 地址表 交换机就像小区内的快递员，记住了每家每户的门牌号 它查表后将包裹精确送到对应的门口，不会打扰其他住户 简单来说，数据包在本地网络中的旅程就像是快递先确认收件人是否在同一小区，如果是，直接送达；如果不是，则交给小区出口的保安，由他负责进一步转发。 穿越公网 数据包离开了本地网络，如何在茫茫互联网中找到遥远的目标服务器？ 数据包在互联网上的旅程就像一次跨国旅行： 问题：如何从私人区域进入公共世界？ 解决方案：NAT（网络地址转换） 就像多人共用一个护照出国，本地设备共享一个公网 IP 路由器会记住谁发了什么请求，回程时能送回正确的设备 问题：互联网如此庞大复杂，谁来管理这些网络？ 解决方案：自治系统（Autonomous System, AS） AS 就像互联网世界的国家或独立王国 每个 AS 由单一技术管理机构控制（如 ISP、大企业或教育机构） 你的数据包首先进入你的 ISP 所在的 AS，然后可能穿越多个 AS 每个 AS 有唯一的 AS 号（ASN），如 AS7018(ATT) 或 AS8075(Microsoft) 问题：这些网络王国如何相互通信和合作？ 解决方案：BGP 协议(边界网关协议) BGP 是 AS 之间的外交语言，用于宣告路由信息 它告诉其他 AS：“通过我可以到达这些网络” 路由器根据 BGP 信息，决定数据包应该经过哪些 AS 问题：如何决定数据包在 AS 内部该走哪条路？ 解决方案：内部路由协议 AS 内部使用 OSPF 或 IS-IS 等协议来找到最佳路径 路由器像城市中的交通指挥，根据路况决定下一个方向 问题：不同运营商之间如何连接？ 解决方案：互联网交换中心（IXP） 就像不同航空公司在大型枢纽机场交换乘客 数据包在 IXP 从一个 AS “转机”到另一个 AS 这减少了路径长度，提高了传输效率 问题：我能知道我的数据经过了哪些地方吗？ 解决方案：路径追踪工具 traceroute/tracert 就像给数据包装上 GPS 你可以看到数据包穿越的不同 AS 和路由器 互联网就像一个巨大的全球快递网络，你的数据包可能穿越多个国家、经过海底电缆，由不同的运营商接力传递，最终到达目的地的网络。 穿越服务端局域网 数据包到达目标所在网络后，如何找到并到达最终的服务器？ 数据包抵达目的地网络，就像国际快递到达目标城市，还需要最后一段本地配送： 问题：如何确保只有合法请求能进入网络？ 解决方案：防火墙和安全策略 就像机场海关，检查入境者是否符合入境条件 只有合法的数据包才能通过安全检查 问题：大型网站如何处理海量请求？ 解决方案：负载均衡 像大型医院的分诊台，将病人分配到不同的医生处 根据服务器负载、用户位置等因素智能分发请求 问题：如何在数据中心复杂环境中找到目标服务器？ 解决方案：内部路由与最后一跳 ARP 数据中心内部有自己的地图和道路系统 最后一个路由器会通过 ARP 找到服务器的具体位置 问题：现代云环境中，服务器可能是虚拟的，怎么处理？ 解决方案：虚拟网络 物理服务器上可能运行多个虚拟机或容器 虚拟交换机将数据包准确送达虚拟环境中的目标应用 这就像国际快递最后的“最后一公里”配送 - 从目的地城市的分拣中心，经过层层筛选，最终送到收件人手中。 总结 网络请求就像一封国际信件的旅程： 本地投递：从你家出发，判断收件人是否在同小区。如不在，交给小区出口的门卫（网关）。 国际运输： 先经过你所在“国家”（你 ISP 的 AS）的海关（NAT） 然后可能穿越多个“国家”（不同的 AS） 各国海关（路由器）通过“国际条约”（BGP）决定包裹走向 有时通过“国际中转站”（IXP）快速转运到其他“国家” 目的地配送： 通过目的地“海关”（防火墙）入境检查 经过“分拣中心”（负载均衡器）分配处理人员 最终通过“本地快递员”（内部路由和交换）送达收件人手中 数据包就这样完成了客户端设备到服务器的全程旅行，然后服务器的响应再沿着类似的路径返回到客户端设备，完成整个请求-响应循环。 参考 极客时间《网络架构实战课》 Difference Between OSI Model and TCP/IP Model","tags":["计算机网络"],"categories":["计算机基础","计算机网络"]},{"title":"解决方案丨游戏后端中的 Push-ACK 机制设计与内存优化","path":"/2025/02/27/solution-push-ack/","content":"引言 在现代在线游戏开发中，服务器与客户端之间实时、可靠的通信机制是游戏体验的基石。作为一名游戏后端开发者，我曾经遇到过这样的场景：更新了一个公会系统的新功能，服务器需要向成千上万个在线玩家推送公会状态变更。短短几小时后，服务器内存使用率飙升至 90%，系统告警不断。问题出在哪里？Push 消息的可靠性机制实现不当导致了内存泄漏。 本文将深入探讨游戏后端中 Push-ACK 机制的设计与实现，特别关注如何避免内存暴涨问题，分享我在多个大型游戏项目中积累的经验与教训。 背景：为什么需要应用层的 ACK 机制？ TCP 协议确实提供了可靠的数据传输保证，包括数据包的序列号、校验和、超时重传等机制。那么，为什么我们还需要在应用层实现额外的 ACK 机制呢？ TCP 可靠性的边界 TCP 只能保证数据被送达到客户端的网络栈，但无法保证： 数据被客户端应用程序正确处理 处理过程中没有出现异常 客户端的业务逻辑正确执行 想象这样一个场景：服务器向玩家推送了一条获得稀有装备的消息，TCP 确保了数据送达客户端，但如果客户端在处理这个消息时崩溃了呢？对于游戏这类状态敏感的应用，我们需要知道消息是否被成功处理，而不仅仅是成功传输。 业务可靠性需求 实际游戏开发中，不同类型的消息有不同的可靠性需求： 消息类型 示例 可靠性需求 关键状态变更 道具获取、货币变化 极高（必须确认处理） 游戏进程通知 任务更新、成就解锁 高（需要确认） 实时位置同步 玩家位置、NPC 移动 中（新数据可覆盖旧数据） 环境信息 天气变化、背景音乐 低（可接受偶尔丢失） 设计通用的 Push-ACK 机制 一个完善的 Push-ACK 机制需要考虑以下几个方面：消息唯一标识、优先级分级、超时重试、批量确认和失败处理。下面是基于 Go 语言的设计实现： 核心数据结构 // Message 表示服务器推送的消息type Message struct MsgID string `json:msg_id` // 唯一消息标识 MsgType string `json:msg_type` // 消息类型 Timestamp int64 `json:timestamp` // 发送时间戳 Priority int `json:priority` // 优先级：1-高，2-中，3-低 Payload interface `json:payload` // 消息内容 RequiresAck bool `json:requires_ack` // 是否需要确认 Expiration int64 `json:expiration` // 过期时间戳// AckMessage 表示客户端的确认消息type AckMessage struct AckID string `json:ack_id` // 对应原消息ID Status string `json:status` // 状态：success/failed/partial ClientTimestamp int64 `json:client_timestamp` // 客户端处理时间 ErrorCode int `json:error_code` // 错误码 ErrorMessage string `json:error_message` // 错误信息// BatchAckMessage 表示批量确认消息type BatchAckMessage struct BatchAck bool `json:batch_ack` // 批量确认标志 AckIDs []string `json:ack_ids` // 消息ID列表 Status string `json:status` // 状态 ClientTimestamp int64 `json:client_timestamp`// 确认时间// PendingMessageInfo 表示等待确认的消息信息type PendingMessageInfo struct ClientID string // 客户端ID Message *Message // 原始消息 SentTime int64 // 发送时间 RetryCount int // 重试次数 服务器端 Push 管理器实现 // PushManager 负责管理推送消息和确认type PushManager struct pendingMessages map[string]*PendingMessageInfo // 等待确认的消息 clientMessageCount map[string]int // 每个客户端的消息数量 ackTimeout int64 // 确认超时时间(秒) maxRetries int // 最大重试次数 maxPendingPerClient int // 每客户端最大消息数 maxMessageAge int64 // 消息最大生存时间(秒) // 内存监控相关 memoryThresholdMB int64 // 内存阈值(MB) criticalThresholdMB int64 // 危险内存阈值(MB) mutex sync.RWMutex // 保护并发访问 // 网络接口（依赖外部实现） networkLayer NetworkInterface// NewPushManager 创建一个新的推送管理器func NewPushManager(networkLayer NetworkInterface) *PushManager pm := PushManager pendingMessages: make(map[string]*PendingMessageInfo), clientMessageCount: make(map[string]int), ackTimeout: 10, maxRetries: 3, maxPendingPerClient: 1000, maxMessageAge: 300, memoryThresholdMB: 1000, // 1GB criticalThresholdMB: 1500, // 1.5GB networkLayer: networkLayer, // 启动后台任务 go pm.checkTimeoutsLoop() go pm.cleanupLoop() go pm.memoryMonitorLoop() return pm// PushMessage 向客户端推送消息func (pm *PushManager) PushMessage(clientID string, message *Message) bool // 如果不需要确认，直接发送 if !message.RequiresAck return pm.networkLayer.SendToClient(clientID, message) pm.mutex.Lock() defer pm.mutex.Unlock() // 检查客户端消息数是否超限 if pm.clientMessageCount[clientID] = pm.maxPendingPerClient pm.handleQueueOverflow(clientID, message) return false // 存储待确认消息 pm.pendingMessages[message.MsgID] = PendingMessageInfo ClientID: clientID, Message: message, SentTime: time.Now().Unix(), RetryCount: 0, // 更新客户端消息计数 pm.clientMessageCount[clientID]++ // 发送消息 return pm.networkLayer.SendToClient(clientID, message)// ProcessAck 处理客户端的确认消息func (pm *PushManager) ProcessAck(clientID string, ack *AckMessage) bool pm.mutex.Lock() defer pm.mutex.Unlock() info, exists := pm.pendingMessages[ack.AckID] if !exists || info.ClientID != clientID return false // 确认成功，删除消息 delete(pm.pendingMessages, ack.AckID) pm.clientMessageCount[clientID]-- // 如果客户端没有待确认消息了，清理计数器 if pm.clientMessageCount[clientID] = 0 delete(pm.clientMessageCount, clientID) return true// ProcessBatchAck 处理批量确认func (pm *PushManager) ProcessBatchAck(clientID string, batchAck *BatchAckMessage) int pm.mutex.Lock() defer pm.mutex.Unlock() confirmedCount := 0 for _, ackID := range batchAck.AckIDs info, exists := pm.pendingMessages[ackID] if exists info.ClientID == clientID delete(pm.pendingMessages, ackID) pm.clientMessageCount[clientID]-- confirmedCount++ // 如果客户端没有待确认消息了，清理计数器 if pm.clientMessageCount[clientID] = 0 delete(pm.clientMessageCount, clientID) return confirmedCount// 后台任务：超时检查与重试func (pm *PushManager) checkTimeoutsLoop() ticker := time.NewTicker(5 * time.Second) defer ticker.Stop() for range ticker.C pm.checkTimeouts() // 超时检查与重试func (pm *PushManager) checkTimeouts() pm.mutex.Lock() defer pm.mutex.Unlock() now := time.Now().Unix() for msgID, info := range pm.pendingMessages // 检查是否超时 if now - info.SentTime pm.ackTimeout if info.RetryCount pm.maxRetries // 增加重试次数 info.RetryCount++ info.SentTime = now // 重新发送 pm.networkLayer.SendToClient(info.ClientID, info.Message) log.Printf(Retrying message %s to client %s, attempt %d, msgID, info.ClientID, info.RetryCount) else // 超出最大重试次数，放弃并记录 log.Printf(Message %s to client %s failed after %d attempts, msgID, info.ClientID, pm.maxRetries) delete(pm.pendingMessages, msgID) pm.clientMessageCount[info.ClientID]-- // 通知业务层处理失败 go pm.notifyMessageFailed(info.ClientID, info.Message) 解决内存暴涨问题 在大型游戏中，服务器可能同时维护数十万甚至上百万个连接，如果每个连接都有数百条待确认消息，服务器内存很快就会爆满。以下是我在实践中总结的几种高效内存管理策略： 1. 周期性过期消息清理 // 清理过期消息的后台循环func (pm *PushManager) cleanupLoop() ticker := time.NewTicker(1 * time.Minute) defer ticker.Stop() for range ticker.C pm.cleanExpiredMessages() // 清理过期消息func (pm *PushManager) cleanExpiredMessages() pm.mutex.Lock() defer pm.mutex.Unlock() now := time.Now().Unix() expiredCount := 0 for msgID, info := range pm.pendingMessages // 检查消息是否过期 if now - info.SentTime pm.maxMessageAge delete(pm.pendingMessages, msgID) pm.clientMessageCount[info.ClientID]-- expiredCount++ // 记录日志 log.Printf(Cleaned expired message %s to client %s (age: %d seconds), msgID, info.ClientID, now - info.SentTime) if expiredCount 0 log.Printf(Cleanup: Removed %d expired messages, expiredCount) 2. 消息压缩与合并 // CompressMessage 压缩消息以减少内存占用func CompressMessage(message *Message) []byte // 将消息转为JSON jsonData, err := json.Marshal(message) if err != nil log.Printf(Error marshaling message: %v, err) return nil // 使用gzip压缩 var buf bytes.Buffer writer := gzip.NewWriter(buf) _, err = writer.Write(jsonData) if err != nil log.Printf(Error compressing message: %v, err) return nil if err := writer.Close(); err != nil log.Printf(Error closing gzip writer: %v, err) return nil return buf.Bytes()// DecompressMessage 解压缩消息func DecompressMessage(compressed []byte) (*Message, error) reader, err := gzip.NewReader(bytes.NewReader(compressed)) if err != nil return nil, fmt.Errorf(create gzip reader: %w, err) defer reader.Close() var buf bytes.Buffer if _, err := io.Copy(buf, reader); err != nil return nil, fmt.Errorf(decompress data: %w, err) var message Message if err := json.Unmarshal(buf.Bytes(), message); err != nil return nil, fmt.Errorf(unmarshal json: %w, err) return message, nil 3. 分级存储策略 // PushManager 增加分级存储功能type PushManager struct // ... 之前的字段 ... // 内存中存储高优先级消息 memoryPending map[string]*PendingMessageInfo // Redis客户端，用于存储低优先级消息 redisClient *redis.Client redisKeyPrefix string redisExpiry time.Duration// PushMessage 分级存储版本func (pm *PushManager) PushMessage(clientID string, message *Message) bool // 如果不需要确认，直接发送 if !message.RequiresAck return pm.networkLayer.SendToClient(clientID, message) pm.mutex.Lock() defer pm.mutex.Unlock() // 检查客户端消息数量限制 if pm.clientMessageCount[clientID] = pm.maxPendingPerClient pm.handleQueueOverflow(clientID, message) return false pm.clientMessageCount[clientID]++ // 根据优先级选择存储位置 if message.Priority = 2 // 高优先级和中优先级 // 存入内存 pm.memoryPending[message.MsgID] = PendingMessageInfo ClientID: clientID, Message: message, SentTime: time.Now().Unix(), RetryCount: 0, else // 低优先级 // 存入Redis messageInfo := PendingMessageInfo ClientID: clientID, Message: message, SentTime: time.Now().Unix(), RetryCount: 0, jsonData, err := json.Marshal(messageInfo) if err != nil log.Printf(Error marshaling message: %v, err) pm.clientMessageCount[clientID]-- return false redisKey := pm.redisKeyPrefix + message.MsgID err = pm.redisClient.Set(context.Background(), redisKey, jsonData, pm.redisExpiry).Err() if err != nil log.Printf(Error storing message in Redis: %v, err) pm.clientMessageCount[clientID]-- return false // 发送消息 return pm.networkLayer.SendToClient(clientID, message)// ProcessAck 分级存储版本func (pm *PushManager) ProcessAck(clientID string, ack *AckMessage) bool pm.mutex.Lock() defer pm.mutex.Unlock() // 先检查内存中的消息 info, existsInMemory := pm.memoryPending[ack.AckID] if existsInMemory info.ClientID == clientID delete(pm.memoryPending, ack.AckID) pm.clientMessageCount[clientID]-- if pm.clientMessageCount[clientID] = 0 delete(pm.clientMessageCount, clientID) return true // 再检查Redis中的消息 redisKey := pm.redisKeyPrefix + ack.AckID exists, err := pm.redisClient.Exists(context.Background(), redisKey).Result() if err != nil log.Printf(Error checking message in Redis: %v, err) return false if exists == 1 // 获取消息以验证客户端ID jsonData, err := pm.redisClient.Get(context.Background(), redisKey).Bytes() if err != nil log.Printf(Error getting message from Redis: %v, err) return false var messageInfo PendingMessageInfo if err := json.Unmarshal(jsonData, messageInfo); err != nil log.Printf(Error unmarshaling message from Redis: %v, err) return false if messageInfo.ClientID == clientID // 从Redis删除并更新计数 pm.redisClient.Del(context.Background(), redisKey) pm.clientMessageCount[clientID]-- if pm.clientMessageCount[clientID] = 0 delete(pm.clientMessageCount, clientID) return true return false 4. 内存自适应调整 内存自适应调整是我在实际项目中解决突发流量问题的关键策略。它能够根据当前系统负载动态调整消息处理参数，确保系统稳定性。 // 内存监控循环func (pm *PushManager) memoryMonitorLoop() ticker := time.NewTicker(10 * time.Second) defer ticker.Stop() for range ticker.C memoryMB := pm.getMemoryUsageMB() if memoryMB pm.criticalThresholdMB // 紧急情况，进行应急清理 pm.emergencyCleanup(memoryMB) else if memoryMB pm.memoryThresholdMB // 超过警戒线，调整参数 pm.adjustParameters(memoryMB) // 获取当前进程内存使用量（MB）func (pm *PushManager) getMemoryUsageMB() int64 var memStats runtime.MemStats runtime.ReadMemStats(memStats) return int64(memStats.Alloc / 1024 / 1024)// 根据内存使用情况调整参数func (pm *PushManager) adjustParameters(currentMemoryMB int64) pm.mutex.Lock() defer pm.mutex.Unlock() // 计算内存超出比例 excessRatio := float64(currentMemoryMB - pm.memoryThresholdMB) / float64(pm.memoryThresholdMB) // 调整每客户端最大消息数 newMaxPerClient := int(float64(pm.maxPendingPerClient) * (1 - excessRatio*0.5)) if newMaxPerClient 100 newMaxPerClient = 100 // 确保至少保留100条 // 调整消息最大生存时间 newMaxAge := int64(float64(pm.maxMessageAge) * (1 - excessRatio*0.5)) if newMaxAge 60 newMaxAge = 60 // 至少60秒 // 更新参数 pm.maxPendingPerClient = newMaxPerClient pm.maxMessageAge = newMaxAge log.Printf(Memory usage: %d MB, adjusted parameters: maxPending=%d, maxAge=%ds, currentMemoryMB, pm.maxPendingPerClient, pm.maxMessageAge) // 执行一次清理 pm.cleanExpiredMessages()// 紧急清理func (pm *PushManager) emergencyCleanup(currentMemoryMB int64) pm.mutex.Lock() defer pm.mutex.Unlock() log.Printf(CRITICAL: Memory usage at %d MB, performing emergency cleanup, currentMemoryMB) // 大幅降低参数 pm.maxPendingPerClient = 100 pm.maxMessageAge = 60 // 清理低优先级消息 for msgID, info := range pm.memoryPending if info.Message.Priority 1 // 只保留最高优先级 delete(pm.memoryPending, msgID) pm.clientMessageCount[info.ClientID]-- log.Printf(Emergency cleanup completed) 5. 队列溢出处理策略 // 处理队列溢出func (pm *PushManager) handleQueueOverflow(clientID string, newMessage *Message) log.Printf(Queue overflow for client %s, clientID) // 策略1: 根据消息优先级决定是否替换现有消息 if newMessage.Priority == 1 // 高优先级消息 // 查找并替换该客户端的一条低优先级消息 for msgID, info := range pm.memoryPending if info.ClientID == clientID info.Message.Priority 1 // 记录 log.Printf(Replacing low priority message %s with high priority message, msgID) // 删除旧消息 delete(pm.memoryPending, msgID) // 添加新消息 pm.memoryPending[newMessage.MsgID] = PendingMessageInfo ClientID: clientID, Message: newMessage, SentTime: time.Now().Unix(), RetryCount: 0, // 发送新消息 pm.networkLayer.SendToClient(clientID, newMessage) return // 策略2: 丢弃旧消息以腾出空间 // 查找该客户端最旧的消息 var oldestMsgID string var oldestTime int64 = math.MaxInt64 for msgID, info := range pm.memoryPending if info.ClientID == clientID info.SentTime oldestTime oldestMsgID = msgID oldestTime = info.SentTime if oldestMsgID != log.Printf(Dropping oldest message %s for client %s, oldestMsgID, clientID) delete(pm.memoryPending, oldestMsgID) // 添加新消息 pm.memoryPending[newMessage.MsgID] = PendingMessageInfo ClientID: clientID, Message: newMessage, SentTime: time.Now().Unix(), RetryCount: 0, // 发送新消息 pm.networkLayer.SendToClient(clientID, newMessage) else // 极端情况，无法找到可替换的消息 log.Printf(Cannot find message to replace for client %s, clientID) 客户端实现 客户端实现同样关键，特别是批量确认机制能显著减少网络流量： // PushReceiver 客户端推送接收处理器type PushReceiver struct connection Connection // 网络连接接口 processedMsgIDs map[string]int64 // 已处理消息ID及处理时间 pendingAcks []string // 待确认的消息ID ackBatchSize int // 批量确认大小 ackInterval time.Duration // 批量确认间隔 messageHandlers map[string]MessageHandler // 消息处理函数 mutex sync.Mutex // 保护并发访问 stopChan chan struct // 停止信号// MessageHandler 消息处理函数类型type MessageHandler func(payload interface) error// NewPushReceiver 创建推送接收器func NewPushReceiver(conn Connection) *PushReceiver receiver := PushReceiver connection: conn, processedMsgIDs: make(map[string]int64), pendingAcks: make([]string, 0, 100), ackBatchSize: 50, ackInterval: time.Second, messageHandlers: make(map[string]MessageHandler), stopChan: make(chan struct), // 启动批量确认任务 go receiver.ackLoop() // 启动过期消息ID清理任务 go receiver.cleanupLoop() return receiver// RegisterHandler 注册消息处理函数func (r *PushReceiver) RegisterHandler(msgType string, handler MessageHandler) r.mutex.Lock() defer r.mutex.Unlock() r.messageHandlers[msgType] = handler// HandleMessage 处理收到的消息func (r *PushReceiver) HandleMessage(message *Message) r.mutex.Lock() defer r.mutex.Unlock() msgID := message.MsgID // 检查是否已处理过该消息 if _, exists := r.processedMsgIDs[msgID]; exists // 已处理过，再次发送确认 if message.RequiresAck r.pendingAcks = append(r.pendingAcks, msgID) // 如果积累的确认数量超过批量大小，立即发送 if len(r.pendingAcks) = r.ackBatchSize go r.sendBatchAcks() return // 查找处理函数 handler, exists := r.messageHandlers[message.MsgType] if !exists log.Printf(No handler for message type: %s, message.MsgType) // 未知消息类型也需要确认 if message.RequiresAck r.sendErrorAck(msgID, Unknown message type) return // 处理消息 err := handler(message.Payload) if err != nil log.Printf(Error processing message %s: %v, msgID, err) if message.RequiresAck r.sendErrorAck(msgID, err.Error()) return // 记录已处理的消息 r.processedMsgIDs[msgID] = time.Now().Unix() // 如果需要确认，加入待确认队列 if message.RequiresAck r.pendingAcks = append(r.pendingAcks, msgID) // 如果积累的确认数量超过批量大小，立即发送 if len(r.pendingAcks) = r.ackBatchSize go r.sendBatchAcks() // 发送批量确认func (r *PushReceiver) sendBatchAcks() r.mutex.Lock() // 如果没有待确认消息，直接返回 if len(r.pendingAcks) == 0 r.mutex.Unlock() return // 复制当前的待确认ID列表 ackIDs := make([]string, len(r.pendingAcks)) copy(ackIDs, r.pendingAcks) // 清空待确认列表 r.pendingAcks = r.pendingAcks[:0] r.mutex.Unlock() // 创建批量确认消息 batchAck := BatchAckMessage BatchAck: true, AckIDs: ackIDs, Status: success, ClientTimestamp: time.Now().Unix(), // 发送确认 r.connection.Send(batchAck)// 发送错误确认func (r *PushReceiver) sendErrorAck(msgID string, errorMessage string) ack := AckMessage AckID: msgID, Status: failed, ClientTimestamp: time.Now().Unix(), ErrorCode: 1001, ErrorMessage: errorMessage, r.connection.Send(ack)// 批量确认定时器func (r *PushReceiver) ackLoop() ticker := time.NewTicker(r.ackInterval) defer ticker.Stop() for select case -ticker.C: r.sendBatchAcks() case -r.stopChan: return // 清理过期的已处理消息IDfunc (r *PushReceiver) cleanupLoop() // 每小时清理一次 ticker := time.NewTicker(1 * time.Hour) defer ticker.Stop() for select case -ticker.C: r.cleanupProcessedIDs() case -r.stopChan: return // 清理过期的已处理消息IDfunc (r *PushReceiver) cleanupProcessedIDs() r.mutex.Lock() defer r.mutex.Unlock() now := time.Now().Unix() expireTime := int64(86400) // 24小时过期 for msgID, processTime := range r.processedMsgIDs if now - processTime expireTime delete(r.processedMsgIDs, msgID) // Close 关闭推送接收器func (r *PushReceiver) Close() // 发送所有待确认消息 r.sendBatchAcks() // 停止所有后台任务 close(r.stopChan) 实战经验与最佳实践 在多个千万用户级别的游戏项目实践中，我总结了以下几点 Push-ACK 机制的最佳实践： 1. 消息分级是关键 不是所有消息都需要相同级别的可靠性保证。在一个 MMORPG 项目中，我们将消息分为四级： 关键级：直接影响游戏平衡和经济的消息，如道具获取、货币变化 重要级：影响游戏进程的消息，如任务更新、排行榜变动 普通级：一般游戏状态信息，如其他玩家动作、环境变化 低优先级：可以容忍丢失的背景信息，如聊天、天气效果 高级别消息使用完整的 ACK 机制，低级别消息可以简化甚至取消 ACK 需求，这样大大减轻了服务器内存压力。 2. 利用统计指标进行调优 监控以下关键指标： ACK 响应时间分布 消息重试率 每客户端平均待确认消息数 内存使用增长曲线 在一个足球经理类游戏中，通过这些指标我们发现，将 ACK 超时时间从 10 秒调整到 5 秒，并将最大重试次数从 3 次增加到 5 次，可以将消息最终确认率从 99.2%提高到 99.8%，同时减少了 25%的内存使用。 3. 针对不同网络环境优化 移动网络环境差异很大，针对不同网络条件动态调整策略： // 根据网络条件调整参数func (pm *PushManager) adjustForNetworkCondition(clientID string, rtt time.Duration) // 网络条件良好 if rtt 100*time.Millisecond pm.clientTimeouts[clientID] = 3 // 3秒超时 pm.clientRetries[clientID] = 2 // 2次重试 else if rtt 300*time.Millisecond pm.clientTimeouts[clientID] = 5 // 5秒超时 pm.clientRetries[clientID] = 3 // 3次重试 else pm.clientTimeouts[clientID] = 10 // 10秒超时 pm.clientRetries[clientID] = 5 // 5次重试 4. 定期压力测试 在一个大型开放世界游戏中，我们每月进行一次混沌测试，模拟极端情况： 突发 50%客户端同时掉线然后重连 模拟网络延迟突然从 50ms 增加到 500ms 模拟 10%的确认消息丢失 这种测试让我们发现了很多边缘情况，并建立了更健壮的防御机制。 结论 一个设计良好的 Push-ACK 机制是现代游戏服务器架构的核心组件。它确保了游戏状态的一致性，提升了玩家体验，同时也为运营团队提供了可靠的数据基础。最重要的是，它必须是高性能且资源友好的。 通过采用本文介绍的多级存储、自适应参数调整、消息优先级和过期策略等技术，我们可以构建一个既可靠又高效的推送确认系统，即使在面对数十万并发","tags":["解决方案","游戏后端","Push-Ack"],"categories":["解决方案","游戏后端"]},{"title":"服务监控丨Prometheus 四大数据类型详解","path":"/2025/02/26/prometheus-data-type/","content":"前言 在微服务和云原生架构的世界中，一套强大的监控系统是保障服务稳定性的基石。Prometheus 作为 CNCF 的明星项目，凭借其简单高效的特性，已成为事实上的云原生监控标准。本文将深入剖析 Prometheus 的四大数据类型及其 PromQL 查询语言，帮助开发团队构建强大的可观测性系统。 结论先行：Prometheus 四大数据类型速览 特性 Counter Gauge Histogram Summary 定义 只增不减的累积计数器 可增可减的瞬时值 观测值分布的分桶统计 客户端计算的分位数统计 重置行为 服务重启时归零 保持当前值 桶计数归零 计数归零 典型应用 请求计数、错误数、流量统计 温度、内存使用、连接数 请求延迟、响应大小 请求延迟、队列等待时间 数据点 单一值 单一值 _bucket、_sum、count {quantile=“x”}、_sum、_count 查询重点 rate()、increase() 直接使用、预测函数 histogram_quantile() 直接读取分位数 分布式聚合 可以（sum、rate） 可以（avg、max、min） 可以（百分位也可聚合） 有限（分位数不可聚合） 资源消耗 低 低 中（依赖桶数量） 中（客户端计算） 一、Prometheus 核心数据类型详解 1. Counter（计数器）：持续增长的累积值 Counter 是最简单但也最常用的指标类型，代表一个只增不减的累积数值。每当事件发生，计数器增加；当监控目标重启时，计数器归零。 适用场景： API 请求总数 错误发生次数 处理任务的数量 网络流量字节数 正确的代码实现： // 声明带标签的计数器requestCounter := prometheus.NewCounterVec( prometheus.CounterOpts Name: http_requests_total, Help: Total number of HTTP requests, , []stringmethod, path, status, // 定义标签维度)prometheus.MustRegister(requestCounter)// 使用标签记录请求requestCounter.WithLabelValues(GET, /api/users, 200).Inc() PromQL 查询技巧： # 每秒请求率（5分钟窗口）rate(http_requests_totalstatus=200[5m])# 错误率计算sum(rate(http_requests_totalstatus=~5..[5m])) / sum(rate(http_requests_total[5m]))# 1小时内的请求增量increase(http_requests_total[1h]) 最佳实践： 永远不要直接使用 Counter 的原始值，总是使用 rate() 或 increase() 使用有意义的标签进行多维度分析，但避免高基数标签 Counter 重置（如服务重启）会被 rate() 函数自动处理 2. Gauge（仪表盘）：可变的瞬时值 Gauge 表示一个可增可减的瞬时测量值，反映系统的当前状态。 适用场景： 内存使用量 CPU 使用率 当前活跃连接数 队列深度 温度等物理量 正确的代码实现： // 声明带标签的仪表盘memoryGauge := prometheus.NewGaugeVec( prometheus.GaugeOpts Name: app_memory_usage_bytes, Help: Current memory usage in bytes, , []stringcomponent, instance,)prometheus.MustRegister(memoryGauge)// 设置当前值memoryGauge.WithLabelValues(api-server, instance-1).Set(float64(getCurrentMemoryUsage())) PromQL 查询技巧： # 直接使用当前值app_memory_usage_bytescomponent=api-server# 统计聚合avg_over_time(app_memory_usage_bytes[1h])max_over_time(app_memory_usage_bytes[24h])# 趋势预测（线性回归）predict_linear(app_memory_usage_bytes[6h], 4 * 3600)# 计算变化率(app_memory_usage_bytes - app_memory_usage_bytes offset 1h) / app_memory_usage_bytes offset 1h 最佳实践： Gauge 可以直接使用其瞬时值，不需要像 Counter 那样使用 rate 对于容易波动的指标，考虑使用 avg_over_time 平滑数据 利用 predict_linear 进行容量规划和趋势预测 3. Histogram（直方图）：观测值分布的分桶统计 Histogram 允许对观测值（如请求延迟）进行分布式统计，将数据分散到预定义的桶中，是分析性能分布的理想工具。 自动生成的指标： metric_bucketle=upper bound: 小于等于特定阈值的观测值计数 metric_sum: 所有观测值的总和 metric_count: 观测值总数 适用场景： 请求延迟分布 响应大小分布 批处理任务执行时间 任何需要百分位数分析的场景 正确的代码实现： // 声明带标签的直方图durationHistogram := prometheus.NewHistogramVec( prometheus.HistogramOpts Name: http_request_duration_seconds, Help: HTTP request duration in seconds, Buckets: prometheus.ExponentialBuckets(0.001, 2, 10), // 从1ms开始指数增长 , []stringmethod, path,)prometheus.MustRegister(durationHistogram)// 记录请求延迟durationHistogram.WithLabelValues(GET, /api/users).Observe(responseTime) PromQL 查询技巧： # 计算平均响应时间rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])# 计算P90延迟histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[5m]))# 按API路径分析P95延迟histogram_quantile(0.95, sum by(path, le) (rate(http_request_duration_seconds_bucket[5m])))# 计算SLO：延迟小于100ms的请求比例sum(rate(http_request_duration_seconds_bucketle=0.1[5m])) / sum(rate(http_request_duration_seconds_count[5m])) 最佳实践： 仔细设计桶边界，覆盖关键分位数区域 对于延迟指标，通常使用指数桶比线性桶更合理 利用 histogram_quantile 计算任意分位数 桶的数量会影响存储和性能，权衡精度和开销 4. Summary（摘要）：客户端计算的分位数统计 Summary 与 Histogram 类似，但在客户端直接计算并存储分位数，无需服务器端计算。 自动生成的指标： metricquantile=φ: φ 分位数的值 metric_sum: 所有观测值的总和 metric_count: 观测值总数 适用场景： 需要高精度分位数的场景 客户端计算分位数更高效的情况 对服务器端聚合要求不高的场景 正确的代码实现： // 声明带标签的摘要durationSummary := prometheus.NewSummaryVec( prometheus.SummaryOpts Name: http_request_duration_seconds_summary, Help: HTTP request duration in seconds, Objectives: map[float64]float640.5: 0.05, 0.9: 0.01, 0.99: 0.001, , []stringmethod, path,)prometheus.MustRegister(durationSummary)// 记录请求延迟durationSummary.WithLabelValues(POST, /api/login).Observe(responseTime) PromQL 查询技巧： # 直接读取P99延迟http_request_duration_seconds_summaryquantile=0.99, method=GET, path=/api/users# 计算平均响应时间rate(http_request_duration_seconds_summary_sum[5m]) / rate(http_request_duration_seconds_summary_count[5m])# 每个服务的中位数延迟max by(service) (http_request_duration_seconds_summaryquantile=0.5) 最佳实践与限制： Summary 预计算的分位数不能跨实例聚合（这是关键限制） 适用于分位数精度要求高且实例相对独立的场景 客户端计算分位数会增加应用资源消耗 分位数设置后不可更改，需提前规划好监控需求 二、PromQL 查询语言精通 PromQL 是 Prometheus 的强大武器，掌握它能让我们精确提取所需的监控数据。 1. 基础查询与标签选择 # 基本查询与精确匹配http_requests_totalstatus=200, method=GET# 正则表达式匹配http_requests_totalpath=~/api/v1/.+, method!=OPTIONS# 范围查询（返回时间序列）http_requests_totalstatus=500[5m] 2. 操作符与函数 算术运算符： # 计算内存使用率百分比100 * (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes 聚合函数： # 按服务和路径分组求和sum by(service, path) (rate(http_requests_total[5m]))# 丢弃instance标签求最大值max without(instance) (node_cpu_seconds_total) 瞬时向量函数： # 标签替换label_replace(up, host, $1, instance, (.*):.*)# 按标签分组取topktopk by(path) (5, http_request_duration_seconds_sum / http_request_duration_seconds_count) 3. 复杂查询模式 SLI/SLO 监控： # 服务可用性SLIsum(rate(http_requests_totalstatus=~2..|3..[5m])) / sum(rate(http_requests_total[5m]))# 延迟SLOhistogram_quantile(0.99, sum by(le) (rate(http_request_duration_seconds_bucket[5m]))) 0.3 异常检测： # 相对于历史同期的异常增长rate(http_requests_total[5m]) 2 * avg_over_time(rate(http_requests_total[5m])[1d:5m] offset 1d) 预测分析： # 磁盘空间预测predict_linear(node_filesystem_free_bytesmountpoint=/[6h], 7 * 24 * 3600) 10 * 1024 * 1024 * 1024 三、实战应用场景 1. 服务健康度监控 RED 方法实现： # Rate - 请求率sum by(service) (rate(http_requests_total[5m]))# Error - 错误率sum by(service) (rate(http_requests_totalstatus=~5..[5m])) / sum by(service) (rate(http_requests_total[5m]))# Duration - P95延迟histogram_quantile(0.95, sum by(service, le) (rate(http_request_duration_seconds_bucket[5m]))) 服务依赖健康度： # 数据库查询错误率sum(rate(database_query_errors_total[5m])) / sum(rate(database_queries_total[5m]))# 第三方API调用延迟histogram_quantile(0.99, sum by(api_name, le) (rate(api_request_duration_seconds_bucket[5m]))) 2. 性能瓶颈分析 热点 API 发现： # 延迟最高的10个接口topk(10, histogram_quantile(0.95, sum by(method, path, le) (rate(http_request_duration_seconds_bucket[5m]))))# 请求量最大的接口topk(10, sum by(method, path) (rate(http_requests_total[5m]))) 数据库性能分析： # 平均查询时间趋势rate(db_query_duration_seconds_sum[5m]) / rate(db_query_duration_seconds_count[5m])# 慢查询比例sum(rate(db_query_duration_seconds_bucketle=+Inf[5m])) - sum(rate(db_query_duration_seconds_bucketle=0.1[5m])) / sum(rate(db_query_duration_seconds_bucketle=+Inf[5m])) 3. 容量规划与告警 资源预测： # CPU使用率预测predict_linear(avg by(instance) (rate(node_cpu_seconds_totalmode!=idle[6h])) [3d:], 7 * 24 * 3600) 0.85# 内存压力告警(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes 0.9 流量容量规划： # 带宽使用预测predict_linear(rate(node_network_transmit_bytes_total[12h])[7d:], 30 * 24 * 3600) 四、最佳实践与性能优化 1. 指标命名与标签设计 命名规范： 使用 snake_case 包含单位后缀（_bytes, _seconds, _total） 保持风格一致性 标签最佳实践： // 合理设计标签维度apiLatency := prometheus.NewHistogramVec( prometheus.HistogramOpts Name: api_request_duration_seconds, Help: API request duration in seconds, Buckets: prometheus.ExponentialBuckets(0.001, 2, 10), , []stringservice, endpoint, status_code, // 合理的低基数标签)// 不可变标签使用ConstLabelsprometheus.NewGaugeVec( prometheus.GaugeOpts Name: service_info, Help: Service information, ConstLabels: prometheus.Labelsversion: v2.1.3, environment: production, , []stringinstance,) 2. 客户端性能优化 // 缓存常用标签组合以提高性能getCounter := requestCounter.WithLabelValues(GET, /api/users, 200)for i := 0; i 100; i++ getCounter.Inc() // 重用标签组合，避免重复创建// 批量更新方式var rpcDurations = prometheus.NewSummaryVec( prometheus.SummaryOpts Name: rpc_durations_seconds, Help: RPC latency distributions., Objectives: map[float64]float640.5: 0.05, 0.9: 0.01, 0.99: 0.001, , []stringservice,)func ObserveBatch(durations map[string]float64) for service, duration := range durations rpcDurations.WithLabelValues(service).Observe(duration) 3. 查询优化 # 优化前：高基数查询sum(rate(http_requests_totalpath=~/api/.*[5m])) by (path, method, status)# 优化后：降低基数，按需聚合sum(rate(http_requests_totalpath=~/api/.*[5m])) by (method, status)# 优化聚合顺序（先聚合再求和）sum( avg by(instance) (rate(node_cpu_seconds_totalmode!=idle[5m]))) 五、常见陷阱与解决方案 1. 高基数问题 问题：标签组合过多导致时间序列爆炸 解决方案： 限制标签基数，避免使用 UserID、SessionID 等作为标签 使用label_replace和正则表达式转换高基数标签 考虑使用 Exemplars 而非标签存储高基数数据 2. 数据类型选择误区 Counter vs Gauge：请求数应使用 Counter 而非 Gauge Histogram vs Summary：需要聚合分析请使用 Histogram，精确分位数可选 Summary 3. 查询性能问题 问题：复杂查询导致 Prometheus 高负载 解决方案： 使用记录规则预计算常用查询 合理设置 scrape 间隔，避免过度采集 对高请求量接口使用客户端聚合 总结与展望 Prometheus 的四种数据类型各有所长：Counter 适合累积事件计数，Gauge 适合瞬时状态测量，Histogram 适合分布统计和百分位分析，Summary 适合客户端精确分位数计算。与之配合的 PromQL 提供了强大的数据查询和分析能力，共同构成了完整的监控解决方案。 随着云原生技术的发展，Prometheus 生态也在不断壮大，与 Grafana、Alertmanager、Thanos 等工具集成，能够构建更完善的监控告警平台。在微服务架构中，结合 RED（Rate、Error、Duration）和 USE（Utilization、Saturation、Errors）方法论，可以构建全面的可观测性系统。 无论你是刚开始使用 Prometheus 的新手，还是寻求优化监控系统的资深工程师，希望本文对你理解和应用 Prometheus 有所帮助。记住，好的监控不仅能及时发现问题，更能预测和防范问题，最终服务于业务可靠性和用户体验的提升。 参考资源: Prometheus 官方文档: https://prometheus.io/docs/ Google SRE 书籍: https://sre.google/sre-book/monitoring-distributed-systems/ Prometheus 实战: https://prometheusbook.com/","tags":["服务监控","prometheus"],"categories":["服务监控"]},{"title":"在 Go 项目中实现 JWT 用户认证与续期机制","path":"/2025/02/15/go-action-jwt/","content":"JWT (JSON Web Token) 是一种广泛使用的用户认证方案，因其无状态、跨域支持和灵活性而受到欢迎。本文将结合实际代码，详细讲解如何在 Go 项目中实现 JWT 认证机制，并探讨两种常见的 Token 续期策略：自动续期和 Refresh Token。 1. JWT 基础概念 JWT 由三部分组成：Header、Payload 和 Signature。使用 JWT 进行登录认证的基本工作流程是： 用户登录成功后，服务器生成 JWT。 服务器将 token 返回给客户端。 客户端后续请求携带 token。 服务器验证 token 的有效性。 我们可以在 https://jwt.io/ 网站对 JWT 进行分析，查看其具体的组成成分。 2. 基本准备 在本篇，我们将使用 Go 语言，通过一个完整的案例实现在 HTTP 接口中，使用 JWT 进行用户登录和认证流程。本文假设读者已掌握基本的 Go 语言语法和网络编程经验，并对 Gin 框架有基本的了解。 为了快速响应失败，本文案例中使用了封装好的异常处理机制： package utilsvar (\tErrUser = errors.New()\tErrSys = errors.New())// 定义用户侧错误，会直接将错误内容返回给用户，不打印日志。func UserErr(msg string) error return fmt.Errorf(%w%v, ErrUser, msg)func UserErrf(format string, a ...any) error return fmt.Errorf(%w%v, ErrUser, fmt.Sprintf(format, a...))// 定义系统内部错误，会固定返回 internal server error 给用户，但是会将原始错误信息输出到日志中，便于内部排查。func SystemErr(err error) error return fmt.Errorf(%w%v, ErrSys, err)func SystemErrf(format string, a ...any) error return fmt.Errorf(%w%v, ErrSys, fmt.Sprintf(format, a...))func GinErr(c *gin.Context, req any, err error, msgs ...string) if errors.Is(err, ErrUser) c.JSON(http.StatusOK, err.Error()) return msg := internal server error\tif len(msgs) 0 msg = msgs[0] slog.Error(msg, slog.Any(req, req), slog.String(err, err.Error()),\t)\tc.JSON(http.StatusOK, internal server error) 3. 实现用户认证 在进行实际代码编写之前，你需要先初始化好项目并引入 jwt 依赖： go get -u github.com/golang-jwt/jwt/v5 在代码中使用的时候，可以： import github.com/golang-jwt/jwt/v5 那接下来我们就正式开始我们的功能实现。 3.1 定义 Claims 结构 首先，我们需要定义 JWT 的载荷（Payload）结构，即决定将什么信息存储在 token 当中。 type UserClaims struct jwt.RegisteredClaims UserID uint64 `json:user_id` // 用户ID UserAgent string `json:user_agent` // 用户设备信息 这里我们： 组合了 jwt.RegisteredClaims，它包含了标准的 JWT 字段（如过期时间），帮助我们实现了 jwt.Clamis 接口： type Claims interface GetExpirationTime() (*NumericDate, error)\tGetIssuedAt() (*NumericDate, error)\tGetNotBefore() (*NumericDate, error)\tGetIssuer() (string, error)\tGetSubject() (string, error)\tGetAudience() (ClaimStrings, error) jwt.RegisteredClaims 的实现如下： type RegisteredClaims struct Issuer string `json:iss,omitempty`\tSubject string `json:sub,omitempty`\tAudience ClaimStrings `json:aud,omitempty`\tExpiresAt *NumericDate `json:exp,omitempty`\tNotBefore *NumericDate `json:nbf,omitempty`\tIssuedAt *NumericDate `json:iat,omitempty`\tID string `json:jti,omitempty`func (c RegisteredClaims) GetExpirationTime() (*NumericDate, error) return c.ExpiresAt, nilfunc (c RegisteredClaims) GetNotBefore() (*NumericDate, error) return c.NotBefore, nilfunc (c RegisteredClaims) GetIssuedAt() (*NumericDate, error) return c.IssuedAt, nilfunc (c RegisteredClaims) GetAudience() (ClaimStrings, error) return c.Audience, nilfunc (c RegisteredClaims) GetIssuer() (string, error) return c.Issuer, nilfunc (c RegisteredClaims) GetSubject() (string, error) return c.Subject, nil 添加了自定义字段 UserID 和 UserAgent 用于安全控制。你可以根据自己的业务需求，添加任意非敏感信息到这个结构中。 3.2 登录接口实现 const ( AccessTokenDuration = time.Minute * 15 RefreshTokenDuration = time.Hour * 24 * 7)func (u *UserHandler) LoginJWT(ctx *gin.Context) // 1. 校验用户信息，在本案例中，使用邮箱加密码进行登录 user, err := u.svc.Login(ctx.Request.Context(), req.Email, req.Password) if err != nil utils.GinErr(ctx, req, utils.UserErr(err), login failed) return // 2. 创建 JWT Claims accessClaims := UserClaims UserID: user.ID, UserAgent: ctx.Request.UserAgent(), RegisteredClaims: jwt.RegisteredClaims ExpiresAt: jwt.NewNumericDate(time.Now().Add(AccessTokenDuration)), // 15分钟过期 , // 3. 生成 Access Token accessToken := jwt.NewWithClaims(jwt.SigningMethodHS512, accessClaims) accessTokenStr, err := accessToken.SignedString(AccessTokenKey) if err != nil utils.GinErr(ctx, req, utils.SystemErr(err), generate access token failed) return // 4. 生成 Refresh Token，用于 Token 续期 refreshClaims := RefreshClaims UserID: user.ID, UserAgent: ctx.Request.UserAgent(), RegisteredClaims: jwt.RegisteredClaims ExpiresAt: jwt.NewNumericDate(time.Now().Add(RefreshTokenDuration)), // 7天过期 , refreshToken := jwt.NewWithClaims(jwt.SigningMethodHS512, refreshClaims) refreshTokenStr, err := refreshToken.SignedString(RefreshTokenKey) if err != nil utils.GinErr(ctx, req, utils.SystemErr(err), generate refresh token failed) return // 5. 返回两个 token ctx.Header(x-jwt-token, accessTokenStr) ctx.Header(x-refresh-token, refreshTokenStr) ctx.JSON(http.StatusOK, login success) 3.3 JWT 中间件实现 type LoginJWTMiddlewareBuilder struct whiteList []stringfunc NewLoginJWTMiddlewareBuilder() *LoginJWTMiddlewareBuilder return LoginJWTMiddlewareBuilder whiteList: []string,\tfunc (b *LoginJWTMiddlewareBuilder) IgnorePaths(paths ...string) *LoginJWTMiddlewareBuilder b.whiteList = append(b.whiteList, paths...)\treturn bfunc (b *LoginJWTMiddlewareBuilder) Build() gin.HandlerFunc return func(ctx *gin.Context) // 1. 提取 token authCode := ctx.GetHeader(Authorization) tokenStr := strings.TrimPrefix(authCode, Bearer ) // 2. 解析和验证 token uc := web.UserClaims token, err := jwt.ParseWithClaims(tokenStr, uc, func(token *jwt.Token) (interface, error) return web.AccessTokenKey, nil ) // 3. 验证 token 有效性 if token == nil || !token.Valid ctx.AbortWithStatus(http.StatusUnauthorized) return // 4. 验证 UserAgent if uc.UserAgent != ctx.Request.UserAgent() ctx.AbortWithStatus(http.StatusUnauthorized) return // 5. 设置用户信息到上下文 ctx.Set(user_id, uc.UserID) ctx.Set(claims, uc) 3.4 注册中间件 func initWebServer() *gin.Engine server := gin.Default()\tserver.Use( middleware.CORS(), middleware.NewLoginJWTMiddlewareBuilder(). IgnorePaths(/users/signup). IgnorePaths(/users/login). Build(),\t)\tweb.RegisterRoutes(server)\treturn serverfunc RegisterRoutes(server *gin.Engine) // ...\tuserHandler.RegisterRoutes(server)func (u *UserHandler) RegisterRoutes(server *gin.Engine) ur := server.Group(/users) ur.POST(/login, u.LoginJWT) // ... 4. 在其他接口中使用 Token 的相关信息 func (u *UserHandler) Profile(ctx *gin.Context) // 可以获取 user_id\tuserID := ctx.GetUint64(user_id) // 也可以直接获取整个 claims。 // 这里我们可以选择不进行断言，因为理论上我们的可以保证这里通过断言。 // 如果这里发生 panic 了，则说明我们的内部逻辑没有形成闭环，存在问题。 // panic 可以第一时间暴露问题，然后被解决掉。 // 不过这个时候建议你使用 gin 的 recover 中间件进行全局保护，避免整个服务因为 panic 而宕机。 uc, _ := ctx.Get(claims)\tuserClaims := uc.(*UserClaims) // ... 5. Refresh Token 机制 5.1 添加刷新 Token 接口 func (u *UserHandler) RefreshToken(ctx *gin.Context) // 从请求头获取 Refresh Token refreshTokenStr := ctx.GetHeader(x-refresh-token) if refreshTokenStr == ctx.AbortWithStatus(http.StatusUnauthorized) return // 解析和验证 Refresh Token var refreshClaims RefreshClaims refreshToken, err := jwt.ParseWithClaims(refreshTokenStr, refreshClaims, func(token *jwt.Token) (interface, error) return RefreshTokenKey, nil ) if err != nil || !refreshToken.Valid ctx.AbortWithStatus(http.StatusUnauthorized) return // 验证 User Agent if refreshClaims.UserAgent != ctx.Request.UserAgent() ctx.AbortWithStatus(http.StatusUnauthorized) return // 生成新的 Access Token accessClaims := UserClaims UserID: refreshClaims.UserID, UserAgent: ctx.Request.UserAgent(), RegisteredClaims: jwt.RegisteredClaims ExpiresAt: jwt.NewNumericDate(time.Now().Add(AccessTokenDuration)), , newAccessToken := jwt.NewWithClaims(jwt.SigningMethodHS512, accessClaims) newAccessTokenStr, err := newAccessToken.SignedString(AccessTokenKey) if err != nil utils.GinErr(ctx, nil, utils.SystemErr(err), generate new access token failed) return // 对 Refresh Token 进行续期 refreshClaims := RefreshClaims UserID: user.ID, UserAgent: ctx.Request.UserAgent(), RegisteredClaims: jwt.RegisteredClaims ExpiresAt: jwt.NewNumericDate(time.Now().Add(RefreshTokenDuration)), // 7天过期 , newRefreshToken := jwt.NewWithClaims(jwt.SigningMethodHS512, refreshClaims) newRefreshTokenStr, err := newRefreshToken.SignedString(RefreshTokenKey) if err != nil utils.GinErr(ctx, req, utils.SystemErr(err), generate new refresh token failed) return // 返回新的 Access Token 和续期后的 Refresh Token ctx.Header(x-jwt-token, newAccessTokenStr) ctx.Header(x-refresh-token, newRefreshTokenStr) ctx.JSON(http.StatusOK, token refreshed) 5.2 注册路由 在 RegisterRoutes 方法中添加新路由： func (u *UserHandler) RegisterRoutes(server *gin.Engine) ur := server.Group(/users) ur.POST(/login, u.LoginJWT) ur.GET(/profile, u.Profile) ur.POST(/refresh, u.RefreshToken) 6. 客户端使用流程 登录后获取 Access Token 和 Refresh Token 使用 Access Token 访问受保护资源 当 Access Token 过期时调用 /refresh 接口获取新的 Access Token 使用新的 Access Token 继续访问 刷新 token 的客户端示例代码（笔者并不擅长写前端代码 hhh，所以这是让 ChatGPT 帮忙写的 😄）： async function refreshAccessToken() const response = await fetch(/users/refresh, method: POST, headers: x-refresh-token: localStorage.getItem(refreshToken) ); if (response.ok) const newAccessToken = response.headers.get(x-jwt-token); localStorage.setItem(accessToken, newAccessToken); const newRefreshToken = response.headers.get(x-refresh-token); localStorage.setItem(refreshToken, newRefreshToken); return newAccessToken; // 如果刷新失败，重定向到登录页 window.location.href = /login; 7. Token 续期策略对比 在前面案例中，细心的读者可以观察到我们对 AccessToken 和 RefreshToken 分别采用了 2 种不同的续期策略。 自动续期 优点： 简单易用：在每次请求时自动检查并续期 Token，用户体验流畅。 无额外存储需求：不需要存储 Refresh Token，减少了存储和管理的复杂性 缺点： 安全性较低：如果 Token 被盗用，攻击者可以通过自动续期保持长时间的访问。 Token 过期时间不固定：Token 的有效期会不断延长，难以控制。 Refresh Token 优点： 更高的安全性：即使 Access Token 被盗用，攻击者也无法续期，除非同时获取 Refresh Token。 可控的 Token 生命周期：Access Token 有固定的短期有效期，Refresh Token 有较长的有效期。 支持 Token 撤销：可以实现 Refresh Token 的黑名单机制，支持手动撤销。 缺点： 实现复杂度较高：需要额外的接口和逻辑来处理 Refresh Token。 存储需求：需要安全存储 Refresh Token，可能需要数据库支持。 8. 总结 JWT 实现用户认证的优势在于无状态、跨域支持和灵活性。通过合理使用 JWT 和选择合适的 Token 续期策略，我们可以构建安全、可靠的用户认证系统。希望本文能帮助您在 Go 项目中更好地实现 JWT 认证。","tags":["Go","JWT","Go 实战"],"categories":["Go","Go 实战"]},{"title":"深入 Go 语言核心：map 和 slice 的传参有什么不同","path":"/2025/02/14/go-slice-vs-map/","content":"在 Go 开发中，经常会遇到需要在函数中修改 map 或 slice 的场景。虽然它们都支持动态扩容，但在函数传参时的行为却大不相同。今天，让我们通过实例深入理解这个问题。 一个困惑的开始 看这样一个例子： func main() // Map 示例 m := map[string]intold: 1 modifyMap(m) fmt.Println(m) // 输出: map[new:1] // Slice 示例 s := []int1, 2, 3 modifySlice(s) fmt.Println(s) // 输出: [100 2 3]，而不是 [100 2 3 200]func modifyMap(m map[string]int) m[new] = 1 // 会影响原始 map delete(m, old) // 也会影响原始 mapfunc modifySlice(s []int) s[0] = 100 // 会影响原始 slice s = append(s, 200) // 不会影响原始 slice 有趣的是： map 的所有操作都会影响原始数据 slice 的简单索引修改会影响原始数据，但 append 可能不会 为什么会这样？让我们从内部结构开始分析。 内部结构解析 Map 的内部结构 type hmap struct count int // 元素个数 flags uint8 // 状态标志 B uint8 // 桶的对数 B buckets unsafe.Pointer // 指向桶数组的指针 // ... 其他字段 当我们声明一个 map 变量时： m := make(map[string]int)// 实际上 m 是 *hmap，即指向 hmap 结构的指针 Slice 的内部结构 type slice struct array unsafe.Pointer // 指向底层数组的指针 len int // 当前长度 cap int // 当前容量 当我们声明一个 slice 变量时： s := make([]int, 0, 10)// s 是一个完整的 slice 结构体，而不是指针 深入理解传参行为 场景一：简单修改（不涉及扩容） func modifyBoth(m map[string]int, s []int) m[key] = 1 // 通过指针修改原始 map s[0] = 100 // 通过指向相同底层数组的指针修改 图解： Map:main()中的 m ----- hmap... ----- modifyBoth()中的 m(同一个底层结构)Slice:main()中的 s = slicearray: 指向数组1, len: 3, cap: 3 | v [1 2 3] ^modifyBoth()中的 s = slicearray: 指向数组1, len: 3, cap: 3 场景二：涉及扩容的操作 func expandBoth(m map[string]int, s []int) // map 扩容 for i := 0; i 100; i++ m[fmt.Sprintf(key%d, i)] = i // slice 扩容 s = append(s, 200) 图解： Map 扩容过程：Before:main()中的 m ----- hmapbuckets: 指向存储A ^expandBoth()中的 m ---------|After:main()中的 m ----- hmapbuckets: 指向更大的存储B // 同一个 hmap，只是更新了内部指针 ^expandBoth()中的 m ---------|Slice 扩容过程：Before:main()中的 s = slicearray: 指向数组A, len: 3, cap: 3 | v [1 2 3] ^expandBoth()中的 s = slicearray: 指向数组A, len: 3, cap: 3After append:main()中的 s = slicearray: 指向数组A, len: 3, cap: 3 // 保持不变 | v [1 2 3]expandBoth()中的 s = slicearray: 指向数组B, len: 4, cap: 6 // 新的结构体，指向新数组 | v [1 2 3 200] 关键区别解析 传递方式不同： map 传递的是指针，函数内外使用的是同一个 hmap 结构 slice 传递的是结构体副本，函数内的修改发生在副本上 扩容行为不同： map 扩容时，原有的 hmap 结构保持不变，只更新内部的 buckets 指针 slice 扩容时，会创建新的底层数组，并返回一个指向新数组的新 slice 结构体 修改效果不同： map 的所有操作（包括扩容）都会反映到原始数据 slice 的行为分两种情况： 不涉及扩容的修改会影响原始数据（因为指向同一个底层数组） 涉及扩容的操作（如 append）会创建新的底层数组，修改不会影响原始数据 最佳实践 基于以上原理，在编码时应注意： 对于 map： func modifyMap(m map[string]int) m[key] = 1 // 直接修改即可，不需要返回 对于 slice： func modifySlice(s []int) []int // 如果需要 append 或其他可能导致扩容的操作 return append(s, 1)// 使用时s = modifySlice(s) 总结 理解 map 和 slice 的这些差异，关键在于： map 是指针类型，始终指向同一个 hmap 结构 slice 是结构体，包含了指向底层数组的指针 扩容时 map 只更新内部指针，而 slice 需要创建新的底层数组 这种设计各有优势： map 的行为更加统一和直观 slice 的设计提供了更多的灵活性和控制权 在实际编程中，正确理解和处理这些差异，是写出健壮 Go 代码的关键。","tags":["Go"],"categories":["Go"]},{"title":"读书笔记丨解密 QUIC/HTTP3：未来互联网的基石","path":"/2025/01/15/book-quic-http3/","content":"1. QUIC 产生背景 常见网络协议 UDP TCP SCTP（Stream Control Transmission Protocol）：用于电话网络。 KCP：基于 UDP 在应用层实现可靠性传输，牺牲带宽换取效率。 RTP（Real-time Transport Protocol）：与 RTCP 配合传输实时数据，如交互式音频和视频数据。 RTCP：传输控制信息 RTP：传输实时数据 TSL 版本演化 SSLv2：安全性低 SSLv3：分为握手阶段和数据传输阶段。 握手阶段完成对端点的认证和确定保护数据传输的密钥。 一旦确定了密钥，后面的数据传输和SSL协议过程都受到加密和完整性保护。 TSL1.0：基于 SSLv3，存在 CBC（Cipher Block Chaining，密文分组链接）加密和解密模式漏洞，使得主动攻击者可以观察到当前记录的 IV（Intiallization Vector，初始化向量），猜测一个数据库，进行数据注入。 TSL1.1：修复了 TSL1.0 的一些关键安全问题： BC 加密使用每条记录一个的显式IV； 为了防止 CBC 填充攻击，使用 bad_record_mac 错误码代替 decryption_failed 回复填充错误； 支持传输参数的IANA（Internet Assigned Numbers Authority，互联网数字分配机构）注册，增加了传输参数的灵活性； 改进了连接关闭过早情况下的连接恢复问题。 有些加密算法还是存在安全漏洞，使用的 MD5 也不安全。 TSL1.2：主要关注了架构灵活性和安全问题。 架构： 客户端可以指定自己支持的签名和 hash 算法列表； 支持非协议固定的算法； 安全： 增加了对 AEAD（Authenticated Encryption with Associated Data 关联数据认证加密）的支持，可以在加密中认证没有加密部分的关键数据，甚至是不在报文中的关键数据，可以保护更大的范围。 规定必须实现密码套件 TLS_RSA_WITH_AES_128_CBC_SHA。 增加了 HMAC-SHA256 密码套件。 删除了包含已废弃算法的 IDEA 和 DES 密码套件。 对 EncryptedPreMasterSecret 版本号进行了更严格的检查。 TSL1.3：除了增加安全性，重点改进了连接速度，首次连接发送数据最低可以 1-RTT，恢复连接发送数据最低可以 0-RTT。 安全： 删除了所有被证明有问题的对称加密算法，只保留了 AEAD 的加密套件。密码套件的概念也已经改变，将认证和密钥交换机制与加密算法和散列（用于密钥导出函数和握手消息认证码）分离。 删除 RSA 和静态 DH 密码套件，因为静态 RSA 加密预主密钥的方式和使用静态 DH 私钥都不能保证前向安全性，很容易泄露密钥。只保留能保证前向安全的密钥交换算法，如使用临时私钥的 ECDHE（Elliptic Curve Diffie-Hellman Ephemeral，椭圆曲线 DH 临时密钥交换算法）和 DHE（Diffie-Hellman Ephemeral, DH 临时密钥交换算法）。 ServerHello 之后的消息都加密传输。 删除了压缩功能。之前版本的压缩功能由于存在被攻击的风险实际上很少使用，而且现代的压缩基本都在应用层实现，比如HTTP 就自己实现的压缩。 HTTP 版本演化 HTTP0.9：仅支持简单的请求响应，只能访问简单的文本文档。 HTTP1.0：HTTP1 中引入了请求头和响应头，请求时可以指定 HTTP 版本号、用户代理、接收类型等，响应可以指明响应状态、内容长度、内容类型等。 HTTP1.1：增加了重用 TCP 连接（keep-alive）的方法，默认保持连接，除非显式通知关闭连接[插图]。这样可以在一个 TCP 连接上完成多个请求-响应，消除了 TCP 建立的延迟，也避免了新建立的 TCP 连接的慢启动过程。 HTTP1.1 在 HTTP 请求首部中增加了 Host 字段，用来支持共享 IP 地址的虚拟主机服务器。 同时支持了更多的方法，如 PUT、PATCH、DELETE、OPTIONS。 引入分块传输支持动态内容。 引入了更多的缓存控制策略。 支持请求部分内容。 HTTP2：修改了 HTTP1.1 的封装格式，增加了一个二进制分帧层。基于二进制分层，HTTP2 实现了 HTTP 的多路复用。HTTP2 为每个请求分配了一个流标识，服务器响应时带上相同的流标识，客户端就可以方便地将响应与请求关联起来，而不用依赖顺序，从而可以降低延迟和提高吞吐量。 HTTP2 还增加了首部压缩 HPACK（Header Compression for HTTP2，HTTP2 首部压缩算法）。 支持请求优先级。 支持服务器主动推送。 增加了 ALPN（Application-Layer Protocol Negotiation，应用层协议协商）。 支持认证、加密和完整性保护，即 HTTPS。 但多个请求或响应在同一个 TCP 上发送时，仍然受制于 TCP 的队首阻塞问题。 HTTP3：基于 QUIC 协议，底层使用 UDP 实现，摆脱了 TCP 的队首阻塞问题。同时改进了 TCP 中存在的一些其他问题，比如拥塞控制、协议僵化、启动慢、重连慢、安全弱等。 实现了没有队首阻塞的并发。如果 QUIC 丢了一个报文，仅仅影响对应流的交付，不会阻塞其他流。 与 TLS1.3 紧密合作，尽可能的加密。还增加了 QUIC 报文的首部加密，除保证了报文安全性，提高了攻击门槛，还避免了协议僵化。 选择 UDP 作为底层实现。一方面避免了 TCP 的首部阻塞，另一方面互联网中绝大部分的主机和中间件都是 TCP 和 UDP 的天下，所以天然支持。 用户态实现。不依赖于内核，容易单独升级。 低延迟的建立。实现了首次最低 1-RTT 发送应用数据，恢复连接时发送应用数据最低只需 0-RTT。 无缝的连接迁移。QUIC 的连接基于连接标识，改变 IP 或者 UDP 端口号并不影响连接的识别，因此可以实现无缝的连接迁移。但是负载均衡就麻烦了。 改进的流量控制。 协议行为作为负载。 2. QUIC 报文 长首部报文：用于建立 QUIC 连接和建立连接前发送应用数据。 短首部报文：用于在 QUIC 连接建立后发送应用数据和 QUIC 协议内容。 无状态重置报文：当服务器丢失了连接状态但仍然收到该连接的数据包时，可以发送无状态重置报文通知客户端立即终止连接。 初始报文：客户端使用初始报文来发起连接，服务器使用初始报文和握手报文回应客户端的请求。 0-RTT 报文：用于承载 QUIC 连接之前想要发送的数据，一般用于恢复连接后立即发送数据。 握手报文：用来携带服务器和客户端的 TLS 加密握手信息和确认，载荷一般是 CRYPTO 帧和 ACK 帧。 重试报文：是服务器用来验证客户端地址的报文，可以防止源地址欺骗。 服务器使用重试报文通知客户端按照要求重新发送初始报文，在重试报文中携带重试令牌给客户端，并使用服务器选择的连接标识作为重试报文的源连接标识；客户端需要使用服务器指定的连接标识作为目的连接标识，携带服务器指定的重试令牌，构建新的初始报文，重新发送给服务器。 版本协商报文：当服务器收到包含自己不支持的版本号的初始报文时，就会发送版本协商报文。客户端收到版本协商报文后需要在其中选择一个自己支持的版本号，重新以新版本号发送初始报文。 短首部报文：一般也叫作 1-RTT 报文，连接在协商出 1-RTT 密钥后就可以发送短首部报文，用于携带应用数据。","tags":["QUIC","HTTP3","计算机网络"],"categories":["计算机基础","计算机网络"]},{"title":"匠心码道丨01 编写优质代码的十大黄金法则","path":"/2024/12/12/clean-code-10-rules/","content":"代码质量的优劣直接影响着项目的可维护性和团队的开发效率。一个经验丰富的开发者不仅要能实现功能，更要善于编写清晰易懂、结构合理的代码。本文将介绍 10 条帮助你编写清晰、易维护且可扩展代码的重要规则。 规则 1. 使用有意义的变量和函数名称 变量、函数和类的命名应该具有描述性和意义。你的代码应该能够清晰地表达其意图，而无需额外的注释来解释。 反面示例： let a = 10;const d = new Date();const res = await api.get();const arr = users.filter(u = u.a === true); 正面示例： let maxRetries = 10;const currentDate = new Date();const userResponse = await api.getUserProfile();const activeUsers = users.filter(user = user.isActive === true); 有意义的命名能讲述代码的故事。读者应该能够仅通过名称就理解变量或函数的用途。 💡实践建议： 使用动词前缀命名函数：getUserProfile()、validateInput()、calculateTotal() 使用名词命名变量：userCount、activeUsers、orderStatus 布尔值使用 is/has/should 等前缀：isValid、hasPermission、shouldUpdate 2. 保持函数简短且专注 函数应该保持简短，并且只做一件事。函数承担的责任越多，测试、调试和理解起来就越困难。 反面示例： def process_order(order): # 多个责任：验证、定价、折扣、配送等 pass 正面示例： def validate_order(order): passdef calculate_total(order): passdef apply_discount(order): pass 每个函数应该只有一个责任。如果你需要用和来描述函数的功能，那么这个函数可能做得太多了。 💡 最佳实践： 函数建议保持在 20-30 行以内 如果超过 50 行，应该考虑拆分 一个函数最好不要超过 3 个参数 3. 避免深层嵌套 深层嵌套的循环和条件语句会使代码难以理解。通过使用提前返回、函数拆分或将大问题分解为小问题来使代码扁平化。 反面示例： if (user != null) if (user.isActive()) if (order != null) processOrder(order); 正面示例： if (user == null || !user.isActive()) return;if (order == null) return;processOrder(order); 提前返回可以减少读者的认知负担，使代码更简单、更容易理解。 4. 明智地使用注释 注释不应该解释代码做了什么；代码本身应该是自解释的。只在必要时使用注释来解释复杂逻辑背后的原因，而不是是什么。 反面示例： // 设置用户状态为激活$user-isActive = true; 正面示例： // 登录成功后将用户标记为激活状态$user-isActive = true; 注释应该增加价值，解释特定实现背后的原因或解释复杂的业务逻辑。 5. 保持一致的格式 一致的代码格式使代码更容易阅读和导航。在项目中使用统一的缩进、间距和对齐方式。 反面示例： function calculate(a,b)return a+b; 正面示例： function calculate(a, b) return a + b; 许多团队使用 Prettier 或 ESLint 等工具来自动格式化并强制执行代码风格规则。 6. 不要重复自己（DRY 原则） 代码重复会导致不一致、bug 和不必要的复杂性。应用 DRY 原则可以保持代码库精简，更易于维护。 反面示例： if ($userType == admin) // 复杂逻辑if ($userType == superadmin) // 相同的复杂逻辑 正面示例： if (userIsAdmin($userType)) // 复杂逻辑 通过将共同逻辑抽象到函数、类或工具中来避免代码重复。 7. 单一责任原则（SRP） 每个类和函数应该只有一个改变的理由。遵循单一责任原则使代码模块化，更容易重构。 反面示例： class User void register(); void login(); void sendEmail(); 正面示例： class User void register(); void login();class EmailService void sendEmail(); 承担太多责任的类更难维护。SRP 使代码更模块化，更容易测试。 8. 避免魔法数字和字符串 魔法数字（或字符串）是没有上下文或解释的硬编码值。使用常量或枚举代替，这样可以增加代码的清晰度。 反面示例： discount = 0.05if user.role == admin: 正面示例： DISCOUNT_RATE = 0.05ADMIN_ROLE = admindiscount = DISCOUNT_RATEif user.role == ADMIN_ROLE: 常量为数字或字符串提供了含义，使代码更容易理解。 9. 编写测试 单元测试和集成测试确保你的代码按预期工作，并且在进行更改时不会出错。编写测试使代码更可靠，长期更易于维护。 反面示例： // 这个方法没有测试public void processOrder(Order order) // 逻辑 正面示例： @Testpublic void testProcessOrder() Order order = new Order(); // 断言 测试应该成为你工作流程的一部分，确保代码无 BUG 且稳定。 10. 保持简单（KISS 原则） KISS（Keep It Simple, Stupid）原则提醒我们简单是关键。复杂的解决方案会导致混淆，更难维护。在面对决策时，选择最简单、最直接的方案来满足需求。 反面示例： // 过度复杂的购物车商品总价计算function calculateTotal(items) let total = 0; let discount = 0; // 复杂的折扣计算逻辑 items.forEach(item = if (item.category === electronics) if (item.price 1000) discount += item.price * 0.1; else if (item.price 500) discount += item.price * 0.05; else if (item.category === books) if (item.quantity 3) discount += item.price * item.quantity * 0.15; total += item.price * item.quantity; ); return total - discount; 正面示例： // 将复杂逻辑拆分成小函数function calculateDiscount(item) if (item.category === electronics) return item.price 1000 ? 0.1 : (item.price 500 ? 0.05 : 0); if (item.category === books item.quantity 3) return 0.15; return 0;function calculateTotal(items) return items.reduce((total, item) = const discount = calculateDiscount(item); const itemTotal = item.price * item.quantity; return total + itemTotal * (1 - discount); , 0); 💡 最佳实践： 将复杂逻辑拆分成小的、容易理解的函数 避免在一个函数中处理过多的条件判断 使用清晰的命名来表达意图 保持函数的单一职责 总结 干净的代码对于可维护性、可读性和协作至关重要。遵循这 10 条规则——使用有意义的命名、保持函数简短、避免魔法数字、编写测试等，将会带来更健壮、更易理解和更易扩展的代码库。编写代码不仅仅是要让它能工作，更要让其他人（包括未来的你）能够轻松理解和扩展。 代码审查清单 在提交代码前，可以使用以下清单进行自查： [ ] 变量和函数名称是否具有描述性 [ ] 函数是否只做一件事 [ ] 是否存在重复代码 [ ] 是否有未使用的魔法数字 [ ] 是否编写了相应的测试 [ ] 代码格式是否统一 [ ] 注释是否有价值 [ ] 嵌套是否过深 参考 top-10-clean-code-rules-every-developer-should-follow","tags":["编程规范","代码质量","最佳实践"],"categories":["匠心码道"]},{"title":"KCP 源码分析与原理总结","path":"/2024/12/01/kcp/","content":"序言 本文很大部分参考了 详解 KCP 协议的原理和实现，非常感谢该文作者的讲解。本文再此基础上，加入了一些笔者的思考和分析图示，以期更好地理解 KCP 的底层原理。 结论先行 KCP 是一个快速可靠协议，能以比 TCP 浪费 10%-20% 的带宽的代价，换取平均延迟降低 30%-40%，且最大延迟降低三倍的传输效果。 TCP 是为流量设计的（每秒内可以传输多少 KB 的数据），讲究的是充分利用带宽。而 KCP 是为流速设计的（单个数据包从一端发送到一端需要多少时间），以 10%-20% 带宽浪费的代价换取了比 TCP 快 30%-40% 的传输速度。TCP 信道是一条流速很慢，但每秒流量很大的大运河，而 KCP 是水流湍急的小激流。 KCP 增加的带宽在哪里？增加的速度又在哪里？ KCP 核心特性 快速重传： KCP 支持快速重传机制，不像 TCP 那样依赖超时重传。KCP 可以根据接收方返回的确认信息快速判断哪些数据包已经丢失，并迅速进行重传。 选择性确认（Selective Acknowledgment, SACK）： KCP 支持 SACK，这允许接收端告知发送端哪些包已经收到，从而仅重传未被确认接收的数据包，减少不必要的重传。 无连接操作： 基于 UDP 的实现使得 KCP 在传输数据前不需要像 TCP 那样进行三次握手建立连接，这减少了初始的延迟，并使其能在连接性较差的网络环境下更加灵活和快速。 拥塞控制： KCP 实现了类似 TCP 的拥塞控制算法，但更为简化，能够快速适应网络条件的变化，如带宽波动和丢包。 流量控制： KCP 允许调整发送和接收的窗口大小，使得发送方可以根据接收方的处理能力和网络条件调整数据发送速率，优化网络利用率和减少拥塞。 可配置的传输策略： KCP 允许用户根据应用需求调整内部参数，如传输间隔、窗口大小等，以达到最优的传输效率和延迟。 前向错误校正（Forward Error Correction, FEC）： KCP 还可以结合使用 FEC 技术，通过发送额外的冗余数据来恢复丢失的包，进一步提高在高丢包环境下的数据传输可靠性。 为什么 TCP 做不到 KCP 这样？ TCP 作为一种成熟且广泛使用的传输协议，在设计上注重可靠性和通用性，因此在拥塞控制和流量控制方面相对保守，以确保在各种网络条件下都能稳定运行。然而，这些设计上的保守性也导致了 TCP 在某些情况下的灵活性和自适应性不如 KCP。 特性类别 协议 描述 拥塞控制机制 TCP 固定算法（慢启动、拥塞避免等），保守的调整策略（指数和线性增长） KCP 灵活算法，动态调整策略，快速调整窗口大小 重传机制的延迟 TCP 固定重传间隔（RTO），多次确认触发重传，需要主动开启选择性重传（SACK） KCP 快速重传，选择性重传，减少重传延迟 流量控制 TCP 固定流量控制（依赖接收窗口和发送窗口），通用性设计 KCP 自适应流量控制，应用层反馈调整发送窗口和重传策略 应用场景 TCP 广泛应用于各种网络环境，标准化要求高 KCP 优化特定场景（如高丢包率和高延迟网络），灵活实现 1. 拥塞控制机制的固定性 TCP： 固定算法：TCP 的拥塞控制算法，如慢启动（Slow Start）、拥塞避免（Congestion Avoidance）、快速重传（Fast Retransmit）和快速恢复（Fast Recovery），在设计时考虑了广泛的兼容性和可靠性。这些算法虽然有效，但其调整机制相对固定，响应速度较慢。 保守的调整策略：TCP 的拥塞控制算法采用了保守的调整策略，例如指数增长和线性增长，这在高丢包率或高延迟网络中，可能会导致拥塞窗口（cwnd）增长速度较慢，影响传输效率。 KCP： 灵活算法：KCP 的拥塞控制机制更为灵活，可以根据实时网络状况进行快速调整。例如，KCP 的快速重传和选择性重传机制，使其能更快速地响应网络丢包情况。 动态调整策略：KCP 的拥塞窗口调整更为灵活，可以根据网络状况快速增加或减少窗口大小，提高传输效率。 2. 重传机制的延迟 TCP： 固定重传间隔：TCP 使用固定的重传超时（RTO），并随着每次重传逐渐增加（指数回退），这种保守的重传机制在高延迟和高丢包率网络中可能导致重传延迟较长。 多次确认触发重传：TCP 的快速重传需要等待三个重复的 ACK 才能触发，这在丢包率较高的情况下，可能会导致较长的延迟。 KCP： 快速重传：KCP 在检测到丢包后立即进行重传，而不需要等待多个重复的 ACK，这显著减少了重传延迟。 选择性重传：KCP 只重传丢失的数据包，而不是所有未确认的数据包，减少了不必要的重传开销。（TCP 其实也支持选择性重传 SACK） 3. 流量控制的灵活性 TCP： 固定流量控制：TCP 的流量控制主要依赖于接收窗口（rwnd）和发送窗口（swnd），在处理突发流量或变化较大的网络条件时，调整速度较慢。 通用性设计：TCP 作为一种通用协议，其设计必须兼顾各种网络环境，因此在流量控制上相对保守，以确保在任何环境下都能稳定运行。 KCP： 自适应流量控制：KCP 的流量控制机制可以根据实际应用需求进行更细粒度的调整。例如，KCP 可以根据延迟抖动、丢包率等动态参数调整发送速率，确保在不同网络条件下都能保持高效传输。 应用层反馈：KCP 可以根据应用层的实时反馈，动态调整发送窗口和重传策略，进一步优化传输效率。 4. 应用场景的差异 TCP： 广泛应用：TCP 设计用于广泛的网络环境，包括稳定的有线网络和不稳定的无线网络，因此其机制必须足够通用和保守，保证在各种情况下的可靠性。 标准化要求：作为互联网的基础协议，TCP 的各项机制经过严格标准化，任何修改都需要广泛测试和验证，以确保不会影响现有网络的稳定性。 KCP： 特定优化：KCP 设计初衷是优化特定场景下的传输性能，特别是高丢包率和高延迟网络，因此在设计上更加灵活，能够根据实时网络状况进行调整。 灵活实现：KCP 可以根据具体应用需求进行优化，例如在实时通信和在线游戏等场景中，灵活的流量控制和快速重传机制显著提升了传输效率。 结论 虽然 TCP 在拥塞控制和流量控制方面具备基本的动态调整能力，但其保守的设计和标准化要求使得其在高丢包率和高延迟网络中的适应性和灵活性不如 KCP。KCP 通过灵活的拥塞控制、快速重传和自适应流量控制机制，能够更有效地应对不同网络条件下的传输需求，提供更高效的传输性能。 KCP 一定比 TCP 快吗？ 不一定。KCP 并不一定在所有情况下都比 TCP 快。虽然 KCP 在某些特定网络环境（如高丢包率和高延迟的网络）中表现更优异，但在某些情况下，TCP 可能更合适。 1. 网络环境 高丢包率和高延迟网络： KCP：KCP 通过快速重传和选择性重传机制，以及动态调整的窗口和重传间隔，能够更好地应对高丢包率和高延迟网络，减少传输延迟，提高传输效率。 TCP：TCP 的重传机制和保守的拥塞控制在这种环境中可能导致较高的延迟和较低的带宽利用率。 低丢包率和低延迟网络： KCP：在稳定的低丢包率和低延迟网络中，KCP 的频繁重传和控制报文可能会导致额外的带宽开销，未必有明显的性能优势。 TCP：TCP 在这种环境中表现稳定，且由于其带宽开销较小，可能比 KCP 更高效。 2. 带宽利用率 带宽充足的网络： KCP：KCP 由于其频繁的重传和控制报文，可能会占用更多的带宽，但如果带宽充足，这种开销对整体性能影响较小，且其低延迟优势可能更明显。 TCP：TCP 的带宽利用率较高，适合带宽充足的环境。 带宽受限的网络： KCP：KCP 的额外带宽开销在带宽受限的网络中可能会显著影响整体传输效率。 TCP：TCP 的较低带宽开销使其在带宽受限的环境中更有优势。 3. 应用场景 实时应用（如在线游戏、视频会议）： KCP：KCP 的低延迟和快速响应能力使其非常适合实时应用，在这些场景中，传输的及时性比带宽利用率更重要。 TCP：TCP 在这些场景中的表现可能不如 KCP，特别是在高丢包率和高延迟的网络中。 非实时应用（如文件传输、网页浏览）： KCP：KCP 在这些场景中可能不如 TCP 高效，特别是在网络稳定且带宽有限的情况下。 TCP：TCP 的可靠性和高带宽利用率使其非常适合非实时应用。 4. 实现和配置 实现复杂性： KCP：实现和配置 KCP 可能比 TCP 更复杂，需要根据具体应用和网络环境进行优化和调整。 TCP：TCP 是一个成熟的协议，系统和库的支持较好，配置和使用相对简单。 总结 KCP 在某些特定环境和应用场景中确实比 TCP 更快，尤其是高丢包率和高延迟的网络环境，以及对低延迟要求较高的实时应用。但在网络稳定、带宽有限或非实时应用场景中，TCP 可能表现更好。因此，选择使用 KCP 还是 TCP 应根据具体的网络条件和应用需求进行权衡。 前置准备 笔者不想那么快就贴出大段大段的代码进行分析，这可能会使读者不知所云。为了更好地阐述 KCP 的底层原理，笔者的设想是先对原理部分进行概要总结，然后再带着这些结论去分析源码，进一步填充里面的边角细节。 但是呢，为了更好地理解 KCP 的原理，又不得不对涉及源码的一些重要设计，为了避免在原理分析阶段，对源码进行过多的涉及，笔者决定添加这单独的一章内容，对 KCP 的“接口设计”、“报文段”、“KCP 控制块”以及“队列和缓冲区”先进行简要概述，以辅助读者更好地理解后续的内容。 接口设计 在 kcp.h 文件中，定义了 KCP 最核心的几个接口： // 创建一个新的 KCP 控制对象ikcpcb* ikcp_create(IUINT32 conv, void *user);// 释放一个 KCP 控制对象。void ikcp_release(ikcpcb *kcp);// 设置 KCP 的输出回调函数，这个回调函数在 KCP 需要发送数据时被调用。void ikcp_setoutput(ikcpcb *kcp, int (*output)(const char *buf, int len,\tikcpcb *kcp, void *user));// 从 KCP 的接收队列中接收数据，用于上层从 KCP 中读取数据。int ikcp_recv(ikcpcb *kcp, char *buffer, int len);// 向 KCP 的发送队列中添加数据，用于上层向 KCP 发送数据，KCP 会管理这些数据并负责其可靠传输。int ikcp_send(ikcpcb *kcp, const char *buffer, int len);// 更新 KCP 的内部状态，通常需要定期调用。// 这个函数负责处理 KCP 的超时、重传等操作，需要在一定的时间间隔内反复调用（通常每 10-100 毫秒）。void ikcp_update(ikcpcb *kcp, IUINT32 current);// 判断是否要调用 ikcp_updateIUINT32 ikcp_check(const ikcpcb *kcp, IUINT32 current);// 处理接收到的低层数据包（例如 UDP 包）。int ikcp_input(ikcpcb *kcp, const char *data, long size);// 将缓冲区可以发送的包发送出去，会在 ikcp_update 中被调用。void ikcp_flush(ikcpcb *kcp); ikcp_create: conv: 会话标识符，用于标识两个端点之间的连接。这个标识符在两个通信端点之间必须一致。 user: 用户数据指针，可以传递任意用户数据，这个数据在 KCP 的 output 回调中会被传递回去。 返回值: 一个指向新创建的 KCP 控制块（ikcpcb）的指针。 ikcp_release: 释放一个 KCP 控制对象。 ikcp_setoutput: 设置 KCP 的输出回调函数。 output: 输出回调函数指针。这个回调函数在 KCP 需要发送数据时被调用。 buf: 要发送的数据缓冲区。 len: 数据长度。 kcp: 当前的 KCP 对象。 user: 用户数据。 通过这个回调，KCP 可以将要发送的数据传递给下层的网络层，比如 UDP 套接字。 ikcp_recv: 从 KCP 的接收队列中接收数据。 kcp: KCP 控制对象的指针。 buffer: 用户提供的缓冲区，用于存储接收到的数据。 len: 缓冲区的长度。 返回值: 成功接收的数据大小；如果没有数据可接收，返回负值（例如，EAGAIN）。 这个函数用于上层从 KCP 中读取数据。 ikcp_send: 向 KCP 的发送队列中添加数据。 kcp: KCP 控制对象的指针。 buffer: 要发送的数据缓冲区。 len: 数据的长度。 返回值: 成功发送的数据大小；如果发送失败，返回负值。 这个函数用于上层向 KCP 发送数据，KCP 会管理这些数据并负责其可靠传输。 ikcp_update: 更新 KCP 的内部状态，通常需要定期调用。 kcp: KCP 控制对象的指针。 current: 当前的时间戳（以毫秒为单位）。 这个函数负责处理 KCP 的超时、重传等操作，需要在一定的时间间隔内反复调用（通常每 10-100 毫秒）。 ikcp_input: 处理接收到的低层数据包（例如 UDP 包）。 kcp: KCP 控制对象的指针。 data: 收到的数据缓冲区。 size: 数据的长度。 返回值: 成功处理的数据大小；如果处理失败，返回负值。 ikcp_flush: 刷新待发送的数据。 其中最重要的是这 4 个： ikcp_send: 将数据放在发送队列中等待发送。 ikcp_recv: 从接收队列中读取数据。 ikcp_input: 读取下层协议输入数据，解析报文段，如果是数据，就将数据放入接收缓冲区，如果是 ACK，就在发送缓冲区中标记对应的报文段已送达。 ikcp_flush: 调用输出回调将发送缓冲区的数据发送出去。 这里就先简要介绍到这里，后面在源码分析篇章再对这些接口进行详细分析。 报文段 KCP 的报文段大小为 24 字节，结构如下图所示： 每个字段的含义如下： conv: 连接标识 cmd：报文类型 frg：分片数量，表示随后还有多少个报文属于同一个包 wnd：发送方剩余接收窗口的大小 ts：时间戳 sn：报文编号 una：发送方的接收缓冲区中最小还未收到的报文段的编号，也就是说，比它小的报文段都已全部接收 len：数据段长度 data：数据段，只有数据报文会有这个字段 其中 cmd 共有 4 种报文类型： 数据报文：IKCP_CMD_PUSH 确认报文：IKCP_CMD_ACK 窗口探测报文：IKCP_CMD_WASK 询问对端剩余接收窗口的大小 窗口通知报文：IKCP_CMD_WINS 通知对端剩余接收窗口的大小 在 KCP 中，报文段结构定义在 kcp.h 文件中，如下： struct IKCPSEG\tstruct IQUEUEHEAD node;\tIUINT32 conv;\tIUINT32 cmd;\tIUINT32 frg;\tIUINT32 wnd;\tIUINT32 ts;\tIUINT32 sn;\tIUINT32 una;\tIUINT32 len;\tIUINT32 resendts;\tIUINT32 rto;\tIUINT32 fastack;\tIUINT32 xmit;\tchar data[1];; IKCPSEG 结构还多出了几个字段，这是为了支持 KCP 协议的可靠性和效率： resendts: 记录报文的下次重传时间，用于实现重传机制。如果报文在一定时间内没有被确认收到，就会在这个时间戳之后被重新发送。 rto: 表示当前报文的重传超时时间（RTT 的估计值）。用于计算每个报文的重传时间，如果超过 rto 时间没有收到 ACK，会触发重传。 fastack: 快速重传计数，记录该报文被跳过的次数。如果一个报文的 ACK 连续接收到多个对同一报文的确认，而不是新的报文，会增加这个计数，用于实现快速重传机制。 xmit: 记录报文已经被发送的次数。用于统计一个报文的重传次数，帮助判断传输的可靠性。如果操作 dead_link 次，则会判断为连接失效，KCP 会断开连接。 node: 链表节点，用于将多个 IKCPSEG 结构体链接在一起。KCP 的队列和缓冲区都是循环双链表结构。 这些字段共同作用，帮助 KCP 实现以下功能： 可靠性：通过 sn、una 和 ack 确保数据包按顺序接收和重传。 流量控制：通过 wnd 控制数据流量，避免接收方过载。 高效传输：通过 resendts 和 rto 进行超时和重传控制，fastack 提供快速重传机制。 灵活管理：使用链表节点 node 组织数据，便于内部管理。 KCP 控制块 ikcpcb 上面我们提到的 ikcp_create 和 ikcp_release 就是对 KCP 控制块 ikcpcb 的创建和释放，每个 KCP 连接都对应一个 KCP 控制块。它定义在 kcp.h 中： struct IKCPCB\tIUINT32 conv, mtu, mss, state;\tIUINT32 snd_una, snd_nxt, rcv_nxt;\tIUINT32 ts_recent, ts_lastack, ssthresh;\tIINT32 rx_rttval, rx_srtt, rx_rto, rx_minrto;\tIUINT32 snd_wnd, rcv_wnd, rmt_wnd, cwnd, probe;\tIUINT32 current, interval, ts_flush, xmit;\tIUINT32 nrcv_buf, nsnd_buf;\tIUINT32 nrcv_que, nsnd_que;\tIUINT32 nodelay, updated;\tIUINT32 ts_probe, probe_wait;\tIUINT32 dead_link, incr;\tstruct IQUEUEHEAD snd_queue;\tstruct IQUEUEHEAD rcv_queue;\tstruct IQUEUEHEAD snd_buf;\tstruct IQUEUEHEAD rcv_buf;\tIUINT32 *acklist;\tIUINT32 ackcount;\tIUINT32 ackblock;\tvoid *user;\tchar *buffer;\tint fastresend;\tint fastlimit;\tint nocwnd, stream;\tint logmask;\tint (*output)(const char *buf, int len, struct IKCPCB *kcp, void *user);\tvoid (*writelog)(const char *log, struct IKCPCB *kcp, void *user);; 字段的含义如下，读者可在后续分析过程回过来查阅： 字段名 含义 conv 连接标识符，用于识别一个特定的会话。 mtu 最大传输单元（Maximum Transmission Unit），表示网络层传输数据包的最大字节数。 mss 最大报文段长度（Maximum Segment Size），表示应用层传输数据的最大字节数。 state 连接状态，标识当前的传输状态。 snd_una 未确认的发送序号，表示最早未确认的包的序号。 snd_nxt 下一个发送序号，表示即将发送的包的序号。 rcv_nxt 下一个接收序号，表示期望接收的下一个包的序号。 ts_recent 最近的时间戳，用于延迟测量。 ts_lastack 最近的确认时间戳，用于 RTT 计算。 ssthresh 拥塞避免的慢启动阈值。 rx_rttval RTT 的偏差，用于计算 RTT 的波动。 rx_srtt 平滑的 RTT 值，用于计算平均 RTT。 rx_rto 重新传输超时时间，根据 RTT 动态调整。 rx_minrto 最小的重新传输超时时间。 snd_wnd 发送窗口大小，控制发送流量的窗口。 rcv_wnd 接收窗口大小，控制接收流量的窗口。 rmt_wnd 远端窗口大小，表示对方接收窗口的大小。 cwnd 拥塞窗口大小，控制发送流量的窗口，用于拥塞控制。 probe 探测标志，表示是否需要进行窗口探测。 current 当前的时间戳。 interval 刷新间隔时间，表示定期刷新 KCP 状态的间隔。 ts_flush 下次刷新时间戳，用于确定何时执行下一次状态刷新。 xmit 发送次数，表示数据包重传的次数。 nrcv_buf 接收缓冲区的数据包数量。 nsnd_buf 发送缓冲区的数据包数量。 nrcv_que 接收队列中的数据包数量。 nsnd_que 发送队列中的数据包数量。 nodelay 延迟模式标志，表示是否启用无延迟模式。 updated 更新标志，表示是否需要更新 KCP 状态。 ts_probe 下次探测时间戳，用于窗口探测。 probe_wait 探测等待时间，表示等待多长时间后进行下一次窗口探测。 dead_link 死链标志，表示连接是否已经失效。 incr 增量，用于控制流量的增加速率。 snd_queue 发送队列，用于存储待发送的数据包。 rcv_queue 接收队列，用于存储待处理的数据包。 snd_buf 发送缓冲区，用于存储已经发送但未确认的数据包。 rcv_buf 接收缓冲区，用于存储已经接收到但未处理的数据包。 acklist 确认列表，用于存储待发送的确认序号。 ackcount 确认计数，表示确认列表中的条目数量。 ackblock 确认块大小，表示确认列表的内存分配大小。 user 用户数据指针，用于存储用户自定义的数据。 buffer 缓冲区，用于临时存储发送的数据。 fastresend 快速重传标志，表示启用快速重传功能。 fastlimit 快速重传限制，表示在一个 RTT 内允许的最大重传次数。 nocwnd 无拥塞窗口控制标志，表示是否禁用拥塞窗口控制。 stream 流模式标志，表示是否启用流模式。 logmask 日志掩码，用于控制日志输出的级别。 output 发送数据回调函数，用于发送数据。 writelog 日志回调函数，用于输出日志。 队列和缓冲区 struct IKCPCB ...\tstruct IQUEUEHEAD snd_queue;\tstruct IQUEUEHEAD rcv_queue;\tstruct IQUEUEHEAD snd_buf;\tstruct IQUEUEHEAD rcv_buf; ...;struct IQUEUEHEAD struct IQUEUEHEAD *next, *prev;; KCP 中队列和缓冲区都是循环双链表，链表由宏实现，笔者并不擅长，所以本文就不探讨该链表的实现了，有数据结构基础的笔者应该很好理解这一块。 队列和缓冲区是 KCP 最核心的部分，它们的作用流程大概如下图所示，读者可以自行阅读尝试理解，后续我们会进行详细的分析。 原理分析 这一节我们详细讨论 KCP 的整个 ARQ 流程。首先我们会对整体流程进行简要概述，然后详细讨论滑动窗口中的发送和接收过程，接着讨论超时重传和快速重传，在这之后我们会将 KCP 和 TCP 的重传策略进行简单对比，最后介绍一下拥塞控制策略。 1. 整体流程 KCP 的全流程如上图所示： 发送方调用 ikcp_send 将发送数据，这个时候会创建报文段实例，并放入 snd_queue 发送队列中。 KCP 会定时调用 ikcp_update 判断是否要调用 ikcp_flush。 调用 ikcp_flush 时会将合适的报文段放入 snd_buf 缓冲区中，具体包括： 发送 ACK 列表中所有 ACK； 根据是否需要发送窗口探测和通知报文，需要则发； 根据发送窗口大小，将适量的报文段从 snd_queue 移入 snd_buf 中； 发送 snd_buf 中的报文，包括新加入的、RTO 内未收到 ACK 的和 ACK 失序若干次的； 根据丢包情况计算 ssthresh 和 cwnd。 发送的时候会调用由 ikcp_setoutput 设置的回调函数，将数据发送到对端。 接收方收到数据后，会调用 ikcp_input，将数据放入 rcv_buf 缓冲区，具体包括： 根据所有报文的 una 将相应的报文标记为已送达； 如果是 ACK，就将相应的报文标记为已送达； 如果是数据报文，就将它放入 rcv_buf，然后将 rcv_buf 中顺序正确的报文移入 rcv_queue 接收队列中，接着将相关信息插入 ACK 列表，在稍后的 ikcp_flush 中会发送相应的 ACK； 如果是窗口探测报文，就标记“需要发送窗口通知”，在稍后的 ikcp_flush 中会发送窗口通知报文； 包括窗口通知报文在内的所有报文都有 wnd 字段，据此更新 rmt_wnd； 根据 ACK 失序情况决定是否进行快速重传； 计算 cwnd。 调用 ikcp_recv 从 rcv_queue 中接收数据。 2. 滑动窗口 发送缓冲区 snd_buf 和接收缓冲区 rcv_buf 中活动的报文都是在滑动窗口之中的。这对于我们理解 KCP 的发送和接收流程非常重要，所有我们先从滑动窗口开始介绍。 滑动窗口实际是一个抽象的概念, 不能简单地认为它是缓冲区的一部分，准确的说，滑动窗口是由队列加缓冲区共同组成的。 2.1 发送 snd_una 和 snd_nxt 会努力往右移动： ikcp_flush 时，会从 snd_queue 中取出报文插入到 snd_nxt 的位置上； 如果 snd_nxt - snd_una = cwnd，则不允许新的报文插入； 当 snd_una 的 ACK 报文到达时，snd_una 就会右移到第一个没有收到 ACK 报文的位置； 发送窗口中未确认到达的报文何时重传？ 报文在一个 RTO 时间内仍未确认到达，就会重传。报文 RTO 初始值是 rx_rto ，会持续增长，速率支持配置。 2.2 接收 每收到一个数据报文, 都会根据它的编号将它插入到 rcv_buf 对应的位置中； 接着检查 rcv_nxt 能否向右移动, 只有当报文的顺序正确且连续才能移动； 在上图的例子中由于 4 号报文的缺失, rcv_nxt 只能处于 4 号位置等待，5, 6 号报文也不能移动到 rcv_queue 中； 等到 4 号报文到达后，才能将 4, 5, 6 号报文一并移动到 rcv_queue 中，同时 rcv_nxt 会右移到 7 号位置。 2.3 案例分析 我们举个简单的例子演示整个 ARQ 的流程。下图中实线箭头表示数据报文，虚线箭头表示 ACK。 ① t1 时刻发送方发送 1 号报文, 1 号报文放入发送缓冲区中, snd_una 指向 1, snd_nxt 指向 2. ② t2 至 t3 时刻发送方依次发送 2 至 3 号报文, snd_nxt 依次后移. ③ 1 号报文丢包. ④ t4, t5 时刻接收方收到 3 号和 2 号报文, 放入 rcv_buf 中; 随后回复 3 号和 2 号 ACK. 此时由于 1 号报文缺失, rcv_nxt 始终指向 1. ⑤ 3 号 ACK 丢包. ⑥ t7 时刻发送方收到 2 号 ACK, 将 2 号报文标记为已送达. 此时由于 3 号 ACK 丢包, 3 号报文未标记为已送达. 由于 1 号报文未确认送达, snd_una 亦指向 1. ⑦ t8 时刻 1 号报文超时, 重传. ⑧ t9 时刻接收方收到 1 号报文, 放入 rcv_buf 中; 这时 1, 2, 3 号报文顺序正确, rcv_nxt 右移到 4 号位置. 接收方回复 1 号 ACK, 同时带上 una = 4. ⑨ t10 时刻发送方收到 1 号 ACK, 将 1 号报文标记为已送达. 同时 una 表明 1, 2, 3 号报文均已送达, 因此也将 3 号报文标记为已送达. snd_una 移动到 4. 3. 超时重传 超时重传是当发送的数据包在预定时间内未被确认时，重新发送该数据包的机制。在 KCP 中，这个时间由重新传输超时（RTO）决定。KCP 计算 RTO 初始值的方法是 TCP 的标准方法, 规定在 RFC 6298 中。 这里还是贴出源码讲比较直观： static void ikcp_update_ack(ikcpcb *kcp, IINT32 rtt)\tIINT32 rto = 0;\tif (kcp-rx_srtt == 0) kcp-rx_srtt = rtt; kcp-rx_rttval = rtt / 2; else long delta = rtt - kcp-rx_srtt; if (delta 0) delta = -delta; kcp-rx_rttval = (3 * kcp-rx_rttval + delta) / 4; kcp-rx_srtt = (7 * kcp-rx_srtt + rtt) / 8; if (kcp-rx_srtt 1) kcp-rx_srtt = 1; rto = kcp-rx_srtt + _imax_(kcp-interval, 4 * kcp-rx_rttval);\tkcp-rx_rto = _ibound_(kcp-rx_minrto, rto, IKCP_RTO_MAX); 这个计算过程笔者就不做详细介绍了，代码里面的公式读者可以尝试自行画图进行理解，这里就不花大篇幅画公式了，下面我尝试以更通俗易懂的话语解释 RTO，只需要理解它在做什么，为什么这么做，就可以了，个人觉得对公式的细节可以暂且忽略。 3.1 RTO 计算目的 KCP 的 RTO 计算是为了确定在多长时间内未收到确认（ACK）时，应该重新发送数据包。这段时间被称为重传超时时间（RTO）。计算 RTO 的目的是在网络条件变化的情况下，既能快速响应数据丢失，也能避免不必要的重传，从而保持高效的传输。 3.2 RTO 计算涉及的变量解释 RTT 和 SRTT 的概念: RTT（Round-Trip Time）: 是从发送一个数据包到收到其确认（ACK）所花的时间。 SRTT（Smoothed RTT）: 是 RTT 的加权平均值，它代表了 RTT 的一个更稳定的估计值。SRTT 的目的是减少 RTT 的短期波动对 RTO 的影响。 RTT 变化值（RTT variance）：网络传输时间并不总是固定的，有时会因为网络拥塞或其他原因出现波动。我们通过计算 RTT 变化值（RTT variance）来估计这种波动的大小。 为什么需要 SRTT 和 RTT 变化值： SRTT 给我们一个平均的 RTT 估计值。 RTT 变化值告诉我们网络的波动性。如果波动很大，我们希望 RTO 更大，以免因为短暂的网络延迟就触发不必要的重传。 3.3 RTO 计算步骤 1. 初始化：初次计算时，我们没有历史 RTT 值，所以直接用第一次测量的 RTT 来初始化 SRTT，并将 RTT 变化值设为 RTT 的一半。 2. 更新 SRTT 和 RTT 变化值: 每次我们测量新的 RTT，就用它来更新 SRTT 和 RTT 变化值。 更新 SRTT：我们不直接替换旧的 SRTT，而是用一个平滑的方式（即加权平均），使得 SRTT 逐渐靠近新 RTT，但又不会剧烈变化。 更新 RTT 变化值：计算新的 RTT 与 SRTT 的差值，用这个差值来更新 RTT 变化值，使其反映当前网络波动的大小。 3. 计算 RTO: 用 SRTT 加上四倍的 RTT 变化值来计算 RTO，这样可以确保 RTO 足够长，能涵盖大部分的网络波动。 我们还要确保 RTO 不小于一个最小值（rx_minrto），以防止 RTO 过小导致频繁重传；也不能大于一个最大值（IKCP_RTO_MAX），以防止 RTO 过大影响响应速度。 4. RTO 计算效果 稳定的传输: SRTT 提供了一个稳定的平均 RTT 估计，使得 RTO 能适应网络的长期变化。 适应网络波动: RTT 变化值使得 RTO 能够应对网络的短期波动，减少因短暂延迟而导致的重传。 快速响应: RTO 设置合理后，能够在数据丢失时快速重传，保持传输的高效和及时性。 通过这样的计算方式，KCP 能够在不同的网络条件下，自动调整重传策略，从而在保证数据可靠性的同时，保持较高的传输效率。 4. 快速重传 在网络传输中，数据包可能会由于网络拥塞、丢包等原因而丢失。超时重传依赖于重传超时时间（RTO）来判断是否需要重传，这可能会导致响应延迟。而快速重传通过检测重复的确认包（ACK）来快速判断数据包的丢失，并立即触发重传，显著缩短了数据丢失的恢复时间。 4.1 何时快速重传？ 每个报文的 fastack 记录了它检测到 ACK 失序的次数，每当 KCP 收到一个编号为 sn 的 ACK 时，就会检查 snd_buf 中编号小于 sn 且未确认送达的报文，并将其 fastack 加 1。 可以通过配置 fastresend 指定失序多少次就执行快速重传。 每次调用 ikcp_flush 都会重传 snd_buf 中 fastask = fastresend 的报文。 4.2 无限快速重传吗？ 每个报文的 xmit 记录它被传输的次数，可以配置 fastlimit 规定传输次数小于 fastlimit 的报文才能执行快速重传。 5. 比较 TCP 的超时重传和快速重传 TCP 也实现了类似的机制，但在复杂性和应用场景上有所不同。 5.1 TCP 的超时重传 1. RTT 估算: TCP 通过接收确认包来估算 RTT，并使用 RTT 的变化范围来计算 RTO。 TCP 使用 Jacobson/Karels 算法进行 RTT 估算和 RTO 计算： // SRTT and RTTVAR calculationRTTVAR = (1 - β) * RTTVAR + β * |RTTsample - SRTT|SRTT = (1 - α) * SRTT + α * RTTsampleRTO = SRTT + 4 * RTTVAR 其中，SRTT 是平滑的 RTT，RTTVAR 是 RTT 的变化范围，α 和 β 是权重因子。 2. 重传策略: 如果在 RTO 时间内未收到 ACK，TCP 会重传未确认的数据包。 每次重传，RTO 值会按照指数增长（指数退避算法）。 3. 拥塞控制: TCP 使用复杂的拥塞控制机制，如慢启动、拥塞避免等，来调整发送窗口和传输速率。 5.2 TCP 的快速重传 当接收到三个重复的 ACK 时，TCP 会立即重传丢失的数据包，而不等待 RTO 超时。 快速重传后，TCP 进入快速恢复状态，调整拥塞窗口，避免拥塞窗口过度收缩。 5.3 比较分析 特性 KCP TCP RTT 估算 基于加权移动平均，较为简单 使用 Jacobson/Karels 算法，复杂但精确 RTO 计算 简化的计算公式 基于 RTT 的复杂计算 重传机制 超时重传和快速重传 超时重传和快速重传 拥塞控制 简单的拥塞控制，适合低延迟应用 复杂的拥塞控制，适合广泛的传输场景 适用场景 实时应用，如游戏、视频会议 通用应用，如文件传输、HTTP 实现复杂度 较为简单，易于理解和实现 复杂，需处理更多的网络状态和控制 可靠性 依赖于用户自定义的重传和控制策略 内置可靠性和流控制机制 响应速度 高效快速，适用于低延迟和高吞吐量场景 可靠但响应速度较慢，适合稳定传输场景 KCP 和 TCP 都提供了可靠的传输机制，但它们适用于不同的应用场景。KCP 设计简单，适合对延迟敏感的实时应用，而 TCP 拥有完善的拥塞控制和可靠性机制，适合广泛的网络应用。 6. 拥塞控制 拥塞控制是网络传输协议中的一个重要机制，用于防止发送过多的数据包导致网络拥塞。在 KCP 中，拥塞控制相对简单，主要通过发送窗口（snd_wnd）和拥塞窗口（cwnd）来管理数据发送速率。 6.1 三种策略 KCP 有 3 种拥塞控制的策略： 慢启动（slow start） 拥塞避免（congestion avoidance） 快速恢复（fast recovery） 慢启动：先将 cwnd 设置为 1，随后平均每经过一个 RTT 时间，cwnd = cwnd * 2，直到阈值 ssthresh。 拥塞避免：cwnd 到 ssthresh 后，cwnd 呈线性增长。 当慢启动或者拥塞避免造成 丢包 后，就采取相应的退让策略： fastack = fastresend - 发生快速重传：将 ssthresh = cwnd / 2，cwnd = ssthresh + fastresend 进入快恢复。 current = resentts - 超时重传：ssthresh = ssthresh / 2，cwnd = 1，进入慢启动。 6.2 核心概念 KCP 的拥塞控制基于以下几个核心概念： 发送窗口 (snd_wnd)：表示发送端在未收到接收端确认之前，允许发送的数据包的数量。它类似于 TCP 中的发送窗口，控制了数据流的速率。 接收窗口 (rcv_wnd)：表示接收端能够处理的最大数据包数量。发送端通过接收端的窗口大小来调整自己的发送速率。 远端窗口 (rmt_wnd)：表示接收端的窗口大小，发送端会根据这个值调整自己的发送窗口，以避免发送的数据超出接收端的处理能力。 拥塞窗口 (cwnd)：用于控制传输中的数据包数量。它基于网络的拥塞情况动态调整，以避免网络拥塞。 慢启动阈值 (ssthresh)：用于确定拥塞控制的模式。当 cwnd 小于 ssthresh 时，KCP 处于慢启动模式，否则进入拥塞避免模式。 6.3 窗口探测（Window Probing） 在某些情况下，接收端的窗口可能会被关闭（即 rmt_wnd 为 0），这意味着接收端无法接收任何新的数据。为了应对这种情况，KCP 实现了窗口探测机制： 当 rmt_wnd 为 0 时，KCP 不会立即停止发送数据，而是会定期发送一个探测包，以检测接收端窗口是否已经打开。 这个探测包会触发接收端返回一个 ACK，其中包含最新的接收窗口大小信息。 6.4 调节和配置 KCP 的拥塞控制机制提供了一些配置参数，用户可以通过调整这些参数来优化传输性能： snd_wnd: 发送窗口大小，用户可以根据应用的需求调整该值，以控制数据发送的最大量。 rcv_wnd: 接收窗口大小，表示接收端能够处理的最大数据包数量。 ssthresh: 慢启动阈值，初始值通常设置为较大的一个常量，用户可以根据网络情况调整。 cwnd: 拥塞窗口大小，初始值通常设置为 1，随传输情况动态调整。 7. 比较 TCP 的拥塞控制 7.1 四个阶段 TCP 拥塞控制有四个关键阶段 慢启动（Slow Start）： 目的：快速探测网络的可用带宽。 机制：当一个连接刚建立或者从丢包恢复时，cwnd（拥塞窗口）从一个较小的值（通常是 1 个 MSS，即最大报文段大小）开始，并以指数增长的方式增加。 过程：每次收到一个 ACK，cwnd 增加一个 MSS，使得 cwnd 每 RTT 增加一倍，直到 cwnd 达到慢启动阈值（ssthresh）。 拥塞避免（Congestion Avoidance）: 目的：逐步探测网络的最大容量，并避免拥塞。 机制：当 cwnd 达到或超过 ssthresh 时，TCP 进入拥塞避免阶段，此时 cwnd 以线性增长的方式增加。 过程：每个 RTT，cwnd 增加 1/cwnd 个 MSS，这种增长方式较为保守，旨在防止过度发送导致的拥塞。 快速重传（Fast Retransmit）: 目的：快速响应丢包，提高传输效率。 机制：当发送端收到三个重复的 ACK 时，立即重传被确认丢失的数据包，而不等待 RTO 超时。 过程：快速重传的目的是迅速恢复丢失的数据包，从而减少因丢包导致的等待时间。 快速恢复（Fast Recovery）: 目的：在拥塞后快速恢复到适当的传输速率。 机制：在快速重传后，TCP 不会直接进入慢启动，而是保持 cwnd 的一部分，以较快的速度恢复到拥塞避免状态。 过程：将 ssthresh 设置为当前 cwnd 的一半，cwnd 被临时减小，然后在接收新 ACK 时快速增加 cwnd，直到恢复到 ssthresh 为止。 7.2 比较分析 特性 TCP KCP 实现复杂度 复杂，包含多个阶段和算法 简单，主要通过窗口大小控制 拥塞检测 通过 RTT 估算和 ACK 检测丢包 主要通过 ACK 和窗口大小检测丢包 响应速度 响应相对较慢，适合稳定传输 响应较快，适合实时性高的传输 适应性 能适应广泛的网络条件 适应性较好，但更适合低延迟网络 配置灵活性 较为固定，依赖于系统配置和优化 提供更多的配置选项，用户可根据需求调整 应用场景 适用于各种需要可靠传输的应用 适用于实时性要求高的应用，如游戏和视频会议 窗口调整 慢启动、拥塞避免、快速重传、快速恢复等机制 主要通过发送窗口和拥塞窗口调整 丢包响应 丢包时通过减小 cwnd 和 ssthresh 来调整 丢包时迅速调整 cwnd 和重传 拥塞控制策略 慢启动、拥塞避免、快速重传、快速恢复等多种策略 主要通过调整 cwnd 和 ssthresh 进行简单控制 优点 稳定可靠、机制全面、应用广泛 实现简单、响应快、灵活性高、适合实时应用 缺点 复杂、响应慢、初始阶段保守 无法应对更加复杂的网络状况、应用场景有限 TCP 和 KCP 都有各自的拥塞控制机制，适用于不同的应用场景。TCP 提供了复杂而全面的拥塞控制，适合于各种网络条件下的可靠传输，而 KCP 提供了简单高效的控制机制，适合于低延迟和高响应速度的实时应用。选择使用哪种协议取决于具体的应用需求和网络环境。 源码分析 1. 核心数据结构 1.1 IKCPSEG 报文段结构 struct IKCPSEG struct IQUEUEHEAD node; // 链表节点 IUINT32 conv; // 会话ID IUINT32 cmd; // 命令类型 IUINT32 frg; // 分片序号 IUINT32 wnd; // 窗口大小 IUINT32 ts; // 时间戳 IUINT32 sn; // 序列号 IUINT32 una; // 待接收的下一个包序号 IUINT32 len; // 数据长度 IUINT32 resendts; // 重传时间戳 IUINT32 rto; // 超时重传时间 IUINT32 fastack; // 快速重传计数器 IUINT32 xmit; // 传输次数 char data[1]; // 数据; 1.2 IKCPCB 控制块 struct IKCPCB // === 基础配置 === IUINT32 conv; // 会话ID，用于标识一个会话 IUINT32 mtu; // 最大传输单元，默认1400字节 IUINT32 mss; // 最大报文段大小，默认mtu-24字节 IUINT32 state; // 连接状态，0=正常，-1=断开 // === 发送和接收序号 === IUINT32 snd_una; // 第一个未确认的包序号 IUINT32 snd_nxt; // 下一个待发送的包序号 IUINT32 rcv_nxt; // 待接收的下一个包序号 // === 时间戳相关 === IUINT32 ts_recent; // 最近一次收到包的时间戳 IUINT32 ts_lastack; // 最近一次收到ACK的时间戳 IUINT32 ssthresh; // 慢启动阈值，默认为IKCP_THRESH_INIT(2) // === RTT相关 === IINT32 rx_rttval; // RTT的变化量 IINT32 rx_srtt; // 平滑后的RTT IINT32 rx_rto; // 超时重传时间，初始为IKCP_RTO_DEF(200ms) IINT32 rx_minrto; // 最小重传超时时间，默认为IKCP_RTO_MIN(100ms) // === 窗口相关 === IUINT32 snd_wnd; // 发送窗口大小，默认32 IUINT32 rcv_wnd; // 接收窗口大小，默认128 IUINT32 rmt_wnd; // 远端窗口大小，默认128 IUINT32 cwnd; // 拥塞窗口大小，初始为0 IUINT32 probe; // 探测标志，用于窗口探测 // === 时间相关 === IUINT32 current; // 当前时间 IUINT32 interval; // 内部更新时间间隔，默认100ms IUINT32 ts_flush; // 下次刷新时间 IUINT32 xmit; // 总重传次数 // === 队列计数器 === IUINT32 nrcv_buf; // 接收缓存中的包数量 IUINT32 nsnd_buf; // 发送缓存中的包数量 IUINT32 nrcv_que; // 接收队列中的包数量 IUINT32 nsnd_que; // 发送队列中的包数量 // === 配置标志 === IUINT32 nodelay; // 是否启用nodelay模式，0=不启用 IUINT32 updated; // 是否调用过update // === 探测相关 === IUINT32 ts_probe; // 下次探测时间 IUINT32 probe_wait; // 探测等待时间 // === 链路控制 === IUINT32 dead_link; // 最大重传次数，默认为IKCP_DEADLINK(20) IUINT32 incr; // 可发送的最大数据量 // === 数据队列 === struct IQUEUEHEAD snd_queue; // 发送队列 struct IQUEUEHEAD rcv_queue; // 接收队列 struct IQUEUEHEAD snd_buf; // 发送缓存 struct IQUEUEHEAD rcv_buf; // 接收缓存 // === ACK相关 === IUINT32 *acklist; // ACK列表 IUINT32 ackcount; // ACK数量 IUINT32 ackblock; // ACK列表大小 // === 用户相关 === void *user; // 用户数据指针 char *buffer; // 临时缓存 // === 快速重传相关 === int fastresend; // 触发快速重传的重复ACK个数 int fastlimit; // 快速重传次数限制，默认IKCP_FASTACK_LIMIT(5) // === 其他配置 === int nocwnd; // 是否关闭拥塞控制，0=不关闭 int stream; // 是否为流模式，0=消息模式(默认)，1=流模式 int logmask; // 日志掩码，控制日志输出级别 // === 回调函数 === // 数据输出回调，用于发送数据 int (*output)(const char *buf, int len, struct IKCPCB *kcp, void *user); // 日志输出回调 void (*writelog)(const char *log, struct IKCPCB *kcp, void *user);; 这个结构体可以大致分为几个主要部分： 基础配置：包含基本的会话标识和传输单元大小设置 序号追踪：用于追踪发送和接收的包序号 时间管理：包含各种时间戳和定时器 窗口控制：实现流量控制和拥塞控制 队列管理：管理数据的发送和接收 ACK 处理：处理确认包 配置选项：各种功能开关和参数设置 回调函数：用于数据输出和日志记录 2. 核心函数 在进入具体的核心函数分析之前，需要先点明 2 点，kcp 的实现者期望其尽可能地简单和减少依赖，所以数据的输出甚至是当前时间都是由使用者来设置的，即 kcp 本身是不依赖于机器时钟的。具体体现在下面 2 个函数： //---------------------------------------------------------------------// set output callback, which will be invoked by kcp//---------------------------------------------------------------------void ikcp_setoutput(ikcpcb *kcp, int (*output)(const char *buf, int len,\tikcpcb *kcp, void *user))\tkcp-output = output;//---------------------------------------------------------------------// update state (call it repeatedly, every 10ms-100ms), or you can ask// ikcp_check when to call it again (without ikcp_input/_send calling).// current - current timestamp in millisec.//---------------------------------------------------------------------void ikcp_update(ikcpcb *kcp, IUINT32 current) ... 2.1 ikcp_send 发送数据 ikcp_send 是应用层接口，负责将用户数据分片并加入到发送队列（snd_queue）。 //---------------------------------------------------------------------// user/upper level send, returns below zero for error//---------------------------------------------------------------------int ikcp_send(ikcpcb *kcp, const char *buffer, int len)\tIKCPSEG *seg;\tint count, i;\tint sent = 0;\t// mtu: 最大传输单元\t// mss: 最大报文段大小\t// mss = mtu - 包头长度(24)\tassert(kcp-mss 0);\tif (len 0) return -1;\t// append to previous segment in streaming mode (if possible)\t// 如果是流模式，则将数据追加到前一个分段中（如果可能）\tif (kcp-stream != 0) // 如果当前发送队列不为空，且前一个分段未满，则将数据追加到前一个分段中 if (!iqueue_is_empty(kcp-snd_queue)) IKCPSEG *old = iqueue_entry(kcp-snd_queue.prev, IKCPSEG, node); if (old-len kcp-mss) int capacity = kcp-mss - old-len; int extend = (len capacity)? len : capacity; seg = ikcp_segment_new(kcp, old-len + extend); assert(seg); if (seg == NULL) return -2; // 将新的 seg-node 放入 snd_queue 中等待发送 iqueue_add_tail(seg-node, kcp-snd_queue); // 把上一个报文的数据拷贝过来 memcpy(seg-data, old-data, old-len); if (buffer) memcpy(seg-data + old-len, buffer, extend); buffer += extend; seg-len = old-len + extend; seg-frg = 0; len -= extend; iqueue_del_init(old-node); // 释放之前老数据的 kcp node ikcp_segment_delete(kcp, old); sent = extend; if (len = 0) return sent; // 1. 非流模式，不追加到上一个报文后面\t// 2. 流模式，但是上一个报文已满，则创建新的报文\t// 计算需要的报文数量，kcp 会对数据进行分段传输\tif (len = (int)kcp-mss) count = 1;\telse count = (len + kcp-mss - 1) / kcp-mss;\t// 接收窗口位置不够，则暂停发送\tif (count = (int)IKCP_WND_RCV) if (kcp-stream != 0 sent 0) return sent; return -2; if (count == 0) count = 1;\t// 发送所有的报文段\tfor (i = 0; i count; i++) int size = len (int)kcp-mss ? (int)kcp-mss : len; seg = ikcp_segment_new(kcp, size); assert(seg); if (seg == NULL) return -2; if (buffer len 0) memcpy(seg-data, buffer, size); seg-len = size; seg-frg = (kcp-stream == 0)? (count - i - 1) : 0; iqueue_init(seg-node); // 将报文段放入 snd_queue 中 iqueue_add_tail(seg-node, kcp-snd_queue); kcp-nsnd_que++; if (buffer) buffer += size; len -= size; sent += size; return sent; 2.2 ikcp_input 接收数据 ikcp_input 负责处理从网络接收到的原始 KCP 数据包，它会处理协议层面的数据，包括 ACK、窗口控制等协议信息，并将接收到的数据放入 KCP 的内部接收缓冲区（rcv_buf 和 rcv_queue）。 2.3 ikcp_recv 获取数据 ikcp_recv 是应用层函数，供上层应用调用以获取完整的消息数据，它从 KCP 的接收队列(rcv_queue)中读取已经排序好的数据，处理分片重组，确保返回完整的消息。 //---------------------------------------------------------------------// user/upper level recv: returns size, returns below zero for EAGAIN// 从 rcv_queue 中获取数据//---------------------------------------------------------------------int ikcp_recv(ikcpcb *kcp, char *buffer, int len)\tstruct IQUEUEHEAD *p;\tint ispeek = (len 0)? 1 : 0;\tint peeksize;\tint recover = 0;\tIKCPSEG *seg;\tassert(kcp);\t// 如果 rcv_queue 为空，则直接返回\tif (iqueue_is_empty(kcp-rcv_queue)) return -1;\t// 如果 len 0，则说明是 peek 操作，准备只查看数据\tif (len 0) len = -len;\t// 计算 rcv_queue 中数据的大小\tpeeksize = ikcp_peeksize(kcp);\t// 无法获得大小，返回 -2\tif (peeksize 0) return -2;\t// 数据过大，返回 -3\tif (peeksize len) return -3;\t// nrcv_que: rcv_queue 的长度\t// rcv_wnd: 接收窗口的大小\t// 如果 nrcv_que = rcv_wnd，则需要进行快恢复\t// 因为 nrcv_que = rcv_wnd，说明接收窗口已经满了，\t// 这个时候需要发送 IKCP_CMD_WINS 告诉发送方窗口大小，\t// 这个时候发送方需要进行快恢复，减小数据传输，以尽快释放接收窗口\tif (kcp-nrcv_que = kcp-rcv_wnd) recover = 1;\t// merge fragment\t// 将多个片段合并成一个完整的片段\t// 合并后，将合并后的片段从 rcv_queue 中删除\tfor (len = 0, p = kcp-rcv_queue.next; p != kcp-rcv_queue; ) int fragment; seg = iqueue_entry(p, IKCPSEG, node); p = p-next; if (buffer) memcpy(buffer, seg-data, seg-len); buffer += seg-len; len += seg-len; fragment = seg-frg; if (ikcp_canlog(kcp, IKCP_LOG_RECV)) ikcp_log(kcp, IKCP_LOG_RECV, recv sn=%lu, (unsigned long)seg-sn); if (ispeek == 0) iqueue_del(seg-node); ikcp_segment_delete(kcp, seg); kcp-nrcv_que--; if (fragment == 0) break; assert(len == peeksize);\t// move available data from rcv_buf - rcv_queue\t// 尝试将 rcv_buf 中编号连续的数据，移动到 rcv_queue 中\t// 移动后，将移动的数据从 rcv_buf 中删除\twhile (! iqueue_is_empty(kcp-rcv_buf)) seg = iqueue_entry(kcp-rcv_buf.next, IKCPSEG, node); if (seg-sn == kcp-rcv_nxt kcp-nrcv_que kcp-rcv_wnd) iqueue_del(seg-node); kcp-nrcv_buf--; iqueue_add_tail(seg-node, kcp-rcv_queue); kcp-nrcv_que++; kcp-rcv_nxt++; else break; // 快恢复\tif (kcp-nrcv_que kcp-rcv_wnd recover) // 在ikcp_flush 中返回 IKCP_CMD_WINS // 通知本段窗口大小给对端 kcp-probe |= IKCP_ASK_TELL; return len; 2.4 ikcp_update 定时时钟 前面我们看了 ikcp_send 、ikcp_input 和 ikcp_recv 三个核心流程的函数，其中的一些细节，你可以回到本文前面的「原理分析」再对照源码仔细阅读。 在前面的原理分析中，我们提到，为了提高传输和处理数据的效率，kcp 设计了队列和缓冲区，同时为了实现可靠性，kcp 也提供了 ACK 和重试、拥塞控制等机制，这些事情都是周期定时去处理的。这里是由 ikcp_update 函数去处理的。 ikcp_update 是 KCP 的定时器函数，负责以固定间隔调用 ikcp_flush 处理数据发送和协议更新，是 KCP 的心跳机制。 //---------------------------------------------------------------------// update state (call it repeatedly, every 10ms-100ms), or you can ask// ikcp_check when to call it again (without ikcp_input/_send calling).// current - current timestamp in millisec.//---------------------------------------------------------------------void ikcp_update(ikcpcb *kcp, IUINT32 current)\tIINT32 slap;\tkcp-current = current;\tif (kcp-updated == 0) kcp-updated = 1; kcp-ts_flush = kcp-current; // 计算间隔\tslap = _itimediff(kcp-current, kcp-ts_flush);\tif (slap = 10000 || slap -10000) kcp-ts_flush = kcp-current; slap = 0; // 达到调用间隔，则执行 ikcp_flush 进行接收数据或发送数据\tif (slap = 0) kcp-ts_flush += kcp-interval; if (_itimediff(kcp-current, kcp-ts_flush) = 0) kcp-ts_flush = kcp-current + kcp-interval; ikcp_flush(kcp); 这个函数很简单，根据注释所说，通常情况下会每 10ms~100ms 执行一次，然后核心是去调用 ikcp_flush 函数，所有的逻辑都在里面。 2.5 ikcp_flush 定时处理 如上所述，ikcp_flush 是 KCP 的核心发送函数，负责将发送队列 snd_queue 中的数据移入发送缓存 snd_buf 并通过 output 回调发送出去，同时处理 ACK 发送、快速重传、超时重传和窗口探测等协议细节。 void ikcp_flush(ikcpcb *kcp)\tIUINT32 current = kcp-current;\t// 当前时间\tchar *buffer = kcp-buffer; // 临时缓冲区\tchar *ptr = buffer;\tint count, size, i;\tIUINT32 resent, cwnd;\tIUINT32 rtomin;\tstruct IQUEUEHEAD *p;\tint change = 0; // 是否执行过快速重传\tint lost = 0; // 是否执行过超时重传\tIKCPSEG seg;\t// 检查是否已调用 ikcp_update\tif (kcp-updated == 0) return;\t// 初始化一个段用于构建各种控制包\tseg.conv = kcp-conv; // 连接标识\tseg.cmd = IKCP_CMD_ACK; // 报文类型：IKCP_CMD_ACK 表示确认报文\tseg.frg = 0; // 分片数量，表示随后还有多少个报文属于同一个包\tseg.wnd = ikcp_wnd_unused(kcp); // 发送方剩余接收窗口的大小\tseg.una = kcp-rcv_nxt; // 发送方的接收缓冲区中最小还未收到的报文段的编号，也就是说，编号比它小的报文段都已全部接收\tseg.len = 0; // 数据段长度\tseg.sn = 0; // 报文编号\tseg.ts = 0; // 时间戳\t// flush acknowledges\t// ① 发送 ACK 队列中的所有 ACK\tcount = kcp-ackcount;\tfor (i = 0; i count; i++) size = (int)(ptr - buffer); // buffer 中累计的数据将要超过 mtu 的时候 // 就调用 ikcp_output 将数据发送出去 if (size + (int)IKCP_OVERHEAD (int)kcp-mtu) ikcp_output(kcp, buffer, size); ptr = buffer; // 从 ACK 列表中取出 sn(报文编号)和 ts(时间戳) ikcp_ack_get(kcp, i, seg.sn, seg.ts); // 将 ACK 报文写入 buffer ptr = ikcp_encode_seg(ptr, seg); // ② ACK 队列已清空\tkcp-ackcount = 0;\t// probe window size (if remote window size equals zero)\t// 对端剩余接收窗口大小为 0，则意味着可能需要发送窗口探测报文：IKCP_CMD_WASK\tif (kcp-rmt_wnd == 0) // 根据 ts_probe 和 probe_wait 确定当前时刻是否需要发送探测报文 // probe_wait: 等待发送探测报文的时间，IKCP_PROBE_INIT=7s, IKCP_PROBE_LIMIT= if (kcp-probe_wait == 0) kcp-probe_wait = IKCP_PROBE_INIT; // 7s 后去发探测报文 kcp-ts_probe = kcp-current + kcp-probe_wait; else if (_itimediff(kcp-current, kcp-ts_probe) = 0) if (kcp-probe_wait IKCP_PROBE_INIT) kcp-probe_wait = IKCP_PROBE_INIT; kcp-probe_wait += kcp-probe_wait / 2; if (kcp-probe_wait IKCP_PROBE_LIMIT) kcp-probe_wait = IKCP_PROBE_LIMIT; kcp-ts_probe = kcp-current + kcp-probe_wait; kcp-probe |= IKCP_ASK_SEND; // 设置是否需要去发送 IKCP_ASK_SEND else kcp-ts_probe = 0; kcp-probe_wait = 0; // flush window probing commands\t// ③ 如果需要，则发送窗口探测报文：IKCP_CMD_WASK\tif (kcp-probe IKCP_ASK_SEND) seg.cmd = IKCP_CMD_WASK; size = (int)(ptr - buffer); if (size + (int)IKCP_OVERHEAD (int)kcp-mtu) ikcp_output(kcp, buffer, size); ptr = buffer; ptr = ikcp_encode_seg(ptr, seg); // flush window probing commands\t// ④ 如果需要，则发送窗口通知报文：IKCP_CMD_WINS\tif (kcp-probe IKCP_ASK_TELL) seg.cmd = IKCP_CMD_WINS; size = (int)(ptr - buffer); if (size + (int)IKCP_OVERHEAD (int)kcp-mtu) ikcp_output(kcp, buffer, size); ptr = buffer; ptr = ikcp_encode_seg(ptr, seg); kcp-probe = 0;\t// calculate window size\t// ⑤ 计算当前窗口大小\tcwnd = _imin_(kcp-snd_wnd, kcp-rmt_wnd);\tif (kcp-nocwnd == 0) cwnd = _imin_(kcp-cwnd, cwnd);\t// move data from snd_queue to snd_buf\t// 5.1 如果符合发送的条件，则创建新的 newseg 并放入 snd_buf 的尾部\twhile (_itimediff(kcp-snd_nxt, kcp-snd_una + cwnd) 0) IKCPSEG *newseg; if (iqueue_is_empty(kcp-snd_queue)) break; newseg = iqueue_entry(kcp-snd_queue.next, IKCPSEG, node); iqueue_del(newseg-node); iqueue_add_tail(newseg-node, kcp-snd_buf); kcp-nsnd_que--; kcp-nsnd_buf++; newseg-conv = kcp-conv; newseg-cmd = IKCP_CMD_PUSH; newseg-wnd = seg.wnd; newseg-ts = current; newseg-sn = kcp-snd_nxt++; newseg-una = kcp-rcv_nxt; newseg-resendts = current; newseg-rto = kcp-rx_rto; newseg-fastack = 0; newseg-xmit = 0; // calculate resent\t// 失序多少次就快速重传。如果 fastresend 大于 0，则取其值；否则，设为最大值 0xffffffff。\tresent = (kcp-fastresend 0)? (IUINT32)kcp-fastresend : 0xffffffff;\t// 最小超时重传时间。如果 nodelay 为 0，则为 rx_rto 的八分之一，否则为 0。\trtomin = (kcp-nodelay == 0)? (kcp-rx_rto 3) : 0;\t// flush data segments\tfor (p = kcp-snd_buf.next; p != kcp-snd_buf; p = p-next) // 从 snd_buf 取出一个报文 IKCPSEG *segment = iqueue_entry(p, IKCPSEG, node); int needsend = 0; // 条件1：第一次发送的报文，直接发送 if (segment-xmit == 0) // 该报文的 xmit 传输次数 needsend = 1; segment-xmit++; segment-rto = kcp-rx_rto; segment-resendts = current + segment-rto + rtomin; else if (_itimediff(current, segment-resendts) = 0) // 条件2：且重传时间到了，则重传 needsend = 1; segment-xmit++; kcp-xmit++; if (kcp-nodelay == 0) segment-rto += _imax_(segment-rto, (IUINT32)kcp-rx_rto); else IINT32 step = (kcp-nodelay 2)? ((IINT32)(segment-rto)) : kcp-rx_rto; segment-rto += step / 2; segment-resendts = current + segment-rto; lost = 1; else if (segment-fastack = resent) // 条件3：达到快速重传次数，则重传 if ((int)segment-xmit = kcp-fastlimit || kcp-fastlimit = 0) needsend = 1; segment-xmit++; segment-fastack = 0; segment-resendts = current + segment-rto; change++; if (needsend) int need; segment-ts = current; segment-wnd = seg.wnd; segment-una = kcp-rcv_nxt; size = (int)(ptr - buffer); need = IKCP_OVERHEAD + segment-len; if (size + need (int)kcp-mtu) ikcp_output(kcp, buffer, size); ptr = buffer; ptr = ikcp_encode_seg(ptr, segment); if (segment-len 0) memcpy(ptr, segment-data, segment-len); ptr += segment-len; // 如果某个数据包的重传次数超过阈值，则标记连接断开。 if (segment-xmit = kcp-dead_link) kcp-state = (IUINT32)-1; // flash remain segments\tsize = (int)(ptr - buffer);\tif (size 0) ikcp_output(kcp, buffer, size); // update ssthresh\t// 1. 如果发生了快速重传，让 ssthresh 减半，进入快恢复\tif (change) IUINT32 inflight = kcp-snd_nxt - kcp-snd_una; kcp-ssthresh = inflight / 2; if (kcp-ssthresh IKCP_THRESH_MIN) kcp-ssthresh = IKCP_THRESH_MIN; kcp-cwnd = kcp-ssthresh + resent; kcp-incr = kcp-cwnd * kcp-mss; // 2. 如果发生了超时重传，则让 ssthresh 减半，然后 cwnd = 1，进入慢启动\tif (lost) kcp-ssthresh = cwnd / 2; if (kcp-ssthresh IKCP_THRESH_MIN) kcp-ssthresh = IKCP_THRESH_MIN; kcp-cwnd = 1; kcp-incr = kcp-mss; // 兜底，cwnd 至少为 1\tif (kcp-cwnd 1) kcp-cwnd = 1; kcp-incr = kcp-mss; 参考 KCP repo 详解 KCP 协议的原理和实现","tags":["KCP","TCP","网络"],"categories":["计算机基础","计算机网络"]},{"title":"Rust 入门丨01 类型系统概述","path":"/2024/11/28/rust-01-type-system/","content":"在 Rust 编程世界中，绝大部分的特性和能力都离不开 Rust 强大的类型系统，所以在这个系列的第 1 篇我们先来对 Rust 的类型系统做一个全局概述，希望可以帮助你建立起对 Rust 的基本印象。在后续的实践过程中，我推荐你可以经常回来思考下为什么 Rust 要构建这样的类型系统，在每一个分支点是如何做出决策的，这些决策又体现在代码的哪些地方。相信这样可以帮助你更好地入门 Rust。 废话不多说，进入正文。 什么是类型系统？ 在进入 Rust 类型系统讨论之前，我们先尝试占在更高的角度，即整个编程语言界的角度去思考，什么是类型系统？ 编程语言的类型系统是指一套规则，用于定义和管理程序中数据的类型。类型系统的主要目的是帮助捕获程序中的错误，提高代码的可靠性和可读性。 类型系统可以根据多种特性进行分类，主要包括以下几个方面： 静态类型和动态类型： 静态类型：在编译时检查变量类型。例如，Java、C++ 和 Haskell 都是静态类型语言。在这些语言中，变量的类型必须在编译时确定，这样可以在编译阶段捕获许多类型错误。 动态类型：在运行时检查变量类型。例如，Python、Ruby 和 JavaScript 是动态类型语言。在这些语言中，变量的类型是在程序运行时确定的，这提供了更大的灵活性，但也可能导致运行时错误。 强类型和弱类型： 强类型：严格限制不同类型之间的操作。例如，Python 和 Java 是强类型语言。强类型系统通常不允许隐式类型转换，这意味着在进行不同类型之间的操作时，必须显式地进行类型转换。 弱类型：允许更多隐式类型转换。例如，JavaScript 和 Perl 是弱类型语言。在这些语言中，编译器或解释器会在需要时自动进行类型转换，这可能导致难以预料的行为。 显式类型和隐式类型： 显式类型：程序员必须明确声明每个变量的类型。例如，Java 和 C++ 要求在声明变量时指定其类型。 隐式类型：编译器或解释器会根据上下文自动推断变量的类型。例如，Python 和 JavaScript 使用隐式类型，程序员不需要显式声明变量类型。 子类型和多态： 子类型：一种类型系统允许一种类型作为另一种类型的子集。例如，在面向对象编程中，子类是父类的子类型。 多态：允许一个接口被多种不同类型实现。多态性有多种形式，包括参数多态（如泛型）和子类型多态（如继承）。 类型推断： 类型推断是指编译器自动确定表达式的类型，而无需明确的类型注释。例如，Haskell 和 Scala 使用类型推断来减少程序员的负担，同时保持静态类型的安全性。 代数数据类型和类型构造： 代数数据类型（ADT）是通过组合其他类型来构造新类型的机制，常见于函数式编程语言，如 Haskell 和 OCaml。ADT 包括产品类型（如元组）和和类型（如枚举）。 结构类型和名义类型： 结构类型：基于对象的结构来确定类型的兼容性。例如，TypeScript 和 Go 使用结构类型系统。 名义类型：基于名称来确定类型的兼容性。例如，Java 和 C++ 使用名义类型系统。 这里我梳理了一张图，供你参考： 注：本图参考了陈天老师在 Rust 训练营课程上提供的教案并进行了增改。 Rust 类型系统 Rust 为了在提供高性能的同时保证内存安全和线程安全，花了大量力气构建了一个强大的类型系统。 基于之前提到的七个方面，我们来梳理下 Rust 的类型系统： 静态类型：Rust 是静态类型语言，这意味着变量的类型在编译时就被确定。这种设计使得 Rust 在编译阶段就可以捕获许多类型错误，从而提高代码的安全性和性能。 fn main() let x: i32 = 10; // 明确指定类型 强类型：Rust 是强类型语言，它严格限制不同类型之间的操作。Rust 不允许隐式类型转换（例如，不能自动将整数转换为浮点数），需要显式地使用 as 进行类型转换。这种严格性有助于避免许多常见的编程错误。 fn main() let x: i32 = 5; let y: f64 = 10.0; // 错误：不能将 i32 隐式转换为 f64 // let sum = x + y; // 正确：需要显式转换 let sum = x as f64 + y; println!(Sum = , sum); 显式类型和类型推断：虽然 Rust 是显式类型语言，要求在某些情况下声明变量类型，但它也具有强大的类型推断能力。编译器可以根据上下文推断出大多数变量的类型，减少了程序员的负担。例如： let mut v = vec![];v.push(5u8); // 结合这里，Rust 编译器可以推断出 v 的类型是 Vecu8 子类型和多态：Rust 支持泛型和 trait，这是一种多态性的实现方式。trait 类似于接口，允许定义类型可以实现的一组方法。泛型允许定义函数、结构体和枚举时使用占位类型，从而实现代码的重用和灵活性。 // 这里 std::fmt::Display 就是一个 trait，目前，你可以先简单理解为 trait 就是接口fn print_valueT: std::fmt::Display(value: T) println!(, value);fn main() print_value(42); // 42 默认为 i32，标准库为其是实现了 Display trait print_value(Hello, world!); // str 也实现了 Display trait 类型推断：Rust 的类型推断系统非常强大，能够根据代码上下文自动推断变量和表达式的类型。这使得代码更简洁，同时保持了类型安全性。 代数数据类型和类型构造：Rust 支持代数数据类型，通过枚举（enum）和结构体（struct）来实现。枚举允许定义一个类型，该类型可以是几种不同的变体之一，每个变体可以携带不同的数据。 enum OptionT Some(T), None, 结构类型和名义类型：Rust 使用名义类型系统。每个类型都有一个显式的名称，类型的兼容性基于名称而不是结构。这意味着即使两个结构体有相同的字段，它们也被视为不同的类型，除非通过特征或显式转换来实现兼容性。 除此之外，Rust 的类型系统还提供了其他非常强大且有用的特效，如所有权和借用、生命周期以及模式匹配。 所有权和借用（Ownership and Borrowing）： Rust 的类型系统与其所有权模型紧密结合。所有权模型通过所有权、借用和生命周期的概念来管理内存，从而在无垃圾回收器的情况下确保内存安全。 fn main() let s = String::from(Hello); let len = calculate_length(s); // 借用 println!(The length of is ., s, len);fn calculate_length(s: String) - usize s.len() 生命周期（Lifetimes）： Rust 使用生命周期标注来跟踪引用的有效范围，确保引用在使用时始终有效。这是 Rust 类型系统中一个独特的特性，帮助防止悬空引用和数据竞争。 fn longesta(x: a str, y: a str) - a str if x.len() y.len() x else y fn main() let string1 = String::from(long string is long); let string2 = xyz; let result = longest(string1.as_str(), string2); println!(The longest string is , result); 模式匹配： Rust 提供强大的模式匹配功能，尤其是在处理枚举和复杂数据结构时，使得代码更具表达力和安全性。 enum Message Quit, Move x: i32, y: i32 , Write(String), ChangeColor(i32, i32, i32),fn process_message(msg: Message) match msg Message::Quit = println!(Quit the application); Message::Move x, y = // 模式匹配能根据数据类型直接拆解出来，使用起来非常方便 println!(Move to coordinates: (, ), x, y); Message::Write(text) = println!(Text message: , text); Message::ChangeColor(r, g, b) = println!(Change color to RGB(, , ), r, g, b); Rust 的类型系统通过上述特性实现了高效、安全和灵活的编程模型，适合系统编程和高性能应用。它在编译期捕获许多潜在错误，使得运行时更为安全可靠。 当然，如果你之前没有学习过 Rust，那这些概念和代码对你来说大概率是云里雾里，不要着急，我们先建立起一个大概的印象就行了。这里我针对 Rust 类型系统梳理了一张图，你可以在以后的学习中时常回来看看： 注：本图参考了陈天老师在 Rust 训练营课程上提供的教案并进行了增改。 本篇就到这里，下篇我们将介绍 Rust 的数据类型，enjoy coding~","tags":["Rust"],"categories":["Rust","Rust 入门"]},{"title":"Rust 入门丨02 数据类型","path":"/2024/11/28/rust-02-data-type/","content":"上文中，我们简单探讨了 Rust 的类型系统，这一篇我们继续来了解 Rust 的数据类型。我画了一张 Rust 基础知识图谱，希望可以帮助你更好地定位当前所在的位置。 mindmap root((Rust 数据类型)) 数值类型 整数 有符号 i8/i16/i32/i64/i128/isize 无符号 u8/u16/u32/u64/u128/usize 浮点数 f32 f64 布尔型 bool 字符型 char 复合类型 元组 Tuple 数组 Array 切片 Slice 字符串 String str 结构体 Struct 枚举 Enum 特殊类型 单元类型 unit Never类型 ! 指针类型 引用 T 原始指针 *const/*mut 智能指针","tags":["Rust"],"categories":["Rust"]},{"title":"Rust 训练营总结丨第三次入门 Rust","path":"/2024/11/26/rust-bootcamp/","content":"缘起 2023 年我给自己定了很多个目标，最终的结果是每个都做了一些事情，但是没有一个是做得比较彻底的，印证了《孙子兵法》的那句：“无所不备，则无所不寡”。 在 2023.10.23 出于好奇，我订阅了《Rust 语言从入门到实战》的专栏，跟着课程的更新节奏学习完了整个专栏。 虽然我第一次入门 Rust 失败了，但也被 Rust 的种种特性所吸引。我是个特别喜欢“痛苦前置”的人，而 Rust 编译器睚眦必报的编译器检查正给予了我被虐的爽感，编译通过后程序的稳定运行也符合我追求成为一位“靠谱”工程师的愿景。 加之我的主力语言是 Go，一门应用编程语言，所以我一直希望学习一门系统编程语言，以期将来有能力窥探一些底层的细节原理。C/C++ 太古老了，特性太多了，大神太多了，我怎么学都不可能赶得上别人，嘿嘿，学个新的，大家都没学过，这不就舒服了么。 后来极客时间决定开设《Rust 训练营》，讲师是陈天老师，我去搜了关于陈天老师的一些资料，看了一些他写的文章和技术分享视频，甚至油管上还有他之前面试的视频。OK，这个人得到了我的认可，我想跟这样的人交个朋友，哪怕只是加个微信，至少我多了个口子，得以窥探精英阶层人士的生活一角。 结合 2023 年的教训，2024 年年初我就给自己制定了一年的目标，只有一个，就是踏踏实实、完完整整学习完整个 Rust 训练营，其他所有事情和目标，都要为其让步。 其实是 2 个目标 hhh，另外一个目标是：完成人生的第一场半程马拉松。 筑基 为了更好服务于《Rust 训练营》，在 1-4 月份，我花了差不多 3 个多月的时间啃下了《Rust 程序设计（第二版）》，对整个 Rust 的语言特性建立了更加完善的体系基础，也多奠定了一些基础，当然，这是我第二次入门 Rust 失败。 修炼 4 月 18 号开营，本来是预计 7 月份结营的，不过陈天老师分享的欲望刹不住车，硬是“拖堂”到了 11 月 22 号。事实上，这是有点难受的，一个事情拖太久，思维上很容易疲惫，懒惰也愈难克服。不过从消费者的角度，这是赚翻了，毕竟，学着学着，花呗的 12 期无息分期也差不多要还完了。 所以，其实一个 1095 的程序员，在 4.20 到 11.22 是可以花 279 小时 54 分钟学完 202 讲课程的。 即使你将来不使用 Rust，相信你学完这门课程后也能成为一位更好的软件工程师。 —— 陈天 是的，在学习中，更多时候感受到的不仅仅是在学习 Rust，而是在重学软件工程，我开始切身接触优秀的软件开发具备了哪些不可或缺的流程。为了效仿这些优秀的思想和实践，在实际工作中，今年我做了一些尝试： 引入更丰富的 CI/CD 流程，尽可能发挥机器的能力，让机器不厌其烦地做那些的重复劳动，而这些不起眼的重复劳动，却能以最小代码为我们排查出最多难以发现的“失误” BUG。 开始学习写单测，开始学习如何将代码写得能单测、易单测，学习着如何将那些不能单测的💩代码改造成可单测的代码，也将单测运行加入了 CI/CD 的流程中。在单测多次帮我揪出那些我意识不到的不小心改错的逻辑的时候，我才切身感受到单测的作用，也真正理解了“写单测并不会影响开发效率，如果影响了，那也是提高了开发效率”。幸运的是，截至目前（11.27），我已经连续 2 次，在上千行代码的需求开发中，提测阶段和线上发布阶段，都是 0 Bug，运气不错。 引入监控系统，在指标上，存储层、应用层、业务层和网关层进行分层监控，在开发时，从业务无关组件（goapm），到业务相关通用组件，最后再到应用程序特定组件的分阶段分层次开发，开始学习着“先解决业务背后的领域问题，顺带解决业务问题”。 开始思考一些架构层面的东西，开始思考一些代码组织、接口契约、领域模块划分的问题，以期写出质量更好的代码。 为了支撑上面这些事情，今年我又顺带读了一些书，我是个很少读书的人，因为我总觉得：“读书好慢”。而且我读书也确实很慢，主要是，很困 😅。然而，当我回望来时路，一切却都在我的意料之外。 这个时候我才知道： 慢就是快 少就是多 历劫 这些书其实都不在我的计划之内，因为 2024 我只有一个目标：完成 Rust 训练营的学习。它们只不过是我完成既定计划之余的加餐罢了。 而幸好我只有一个目标，所以才能有更多时间和精力去应对跟随训练营学习中的一些困难： 晚上 9 点下班，真累啊，休息下吧，真不想学了。 工作了一周，真累啊，周末要不就休息吧，真不想学了。 编译器报错好多啊，算了，要不直接 copy 现成的代码吧。 这知识点在讲啥啊，算了，先不懂装懂吧，后面还那么多课，先赶进度再说。 前端和客户端的知识，好像跟我没啥关系，算了，不听了，过过过。 单测我就不写了，浪费时间。 学完咯，感觉没啥好总结的，算了，下一个吧。 … 运气不错，上述的 n 多种情况，至少在 50-70% 的时候，我能做到： 学一下再说，累了再停。 下午出去玩，早上先学了再说。 算了，狠点，盲写，自己尝试解决一下，咦，也就那么回事。写完后再对比下，哦，其实这块没听懂。 弄懂再说，多听几遍课，重新看几遍书，再搜一些相关博客，哦，这个知识点是这个意思，读书百遍其义自见原来是这味？ 算了，试试现在 LLM 是否如吹的那么牛，嗯，好像用 LLM 来实现前端和客户端的基础功能还真可以，也没那么无聊嘛。 算了，先试着写下单测吧。哦，我的代码这么难测啊，哦，这行代码怎么就犯蠢了呢，哦，花不了多少时间嘛。 要不还是总结下吧，哦，原来这个地方是这个意思，哦，原来还讲到了这个点。 所以这个时候我又知道了： 慢就是快 少就是多 小成 ➜ hedon-rust-road lltotal 0drwxr-xr-x 21 wangjiahan staff 672B Nov 27 18:26 aicommdrwxr-xr-x 23 wangjiahan staff 736B Sep 11 13:55 chatdrwxr-xr-x 17 wangjiahan staff 544B Sep 11 18:31 chatappdrwxr-xr-x 26 wangjiahan staff 832B Nov 27 18:26 crmdrwxr-xr-x 22 wangjiahan staff 704B Nov 27 18:26 dinodrwxr-xr-x 16 wangjiahan staff 512B Nov 27 18:29 error-infodrwxr-xr-x 18 wangjiahan staff 576B Sep 4 19:00 hackernewsdrwxr-xr-x 22 wangjiahan staff 704B Sep 12 15:54 hedon-botdrwxr-xr-x 9 wangjiahan staff 288B Nov 27 18:29 httpiedrwxr-xr-x 13 wangjiahan staff 416B Aug 22 10:40 inverted-index-concurrencydrwxr-xr-x 7 wangjiahan staff 224B Nov 27 18:28 json-macrodrwxr-xr-x 26 wangjiahan staff 832B Sep 3 19:30 learn-ffidrwxr-xr-x 8 wangjiahan staff 256B Nov 27 18:29 learn-proc-macrodrwxr-xr-x 7 wangjiahan staff 224B Nov 27 18:30 mandelbrotdrwxr-xr-x 10 wangjiahan staff 320B Aug 22 10:40 matrix-multidrwxr-xr-x 7 wangjiahan staff 224B Nov 27 18:29 pest-parser-collectiondrwxr-xr-x 19 wangjiahan staff 608B Nov 27 18:27 r-redisdrwxr-xr-x 21 wangjiahan staff 672B Aug 22 10:40 rclidrwxr-xr-x 17 wangjiahan staff 544B Aug 22 10:40 simple-chatdrwxr-xr-x 17 wangjiahan staff 544B Aug 22 10:40 simple-shortenerdrwxr-xr-x 21 wangjiahan staff 672B Aug 22 10:40 taotiedrwxr-xr-x@ 18 wangjiahan staff 576B Nov 27 15:38 thumbordrwxr-xr-x 19 wangjiahan staff 608B Aug 29 10:56 winnow-parser-collection➜ hedon-rust-road tokei -t rust=============================================================================== Language Files Lines Code Comments Blanks=============================================================================== Rust 336 25451 21615 644 3192 |- Markdown 53 546 0 476 70 (Total) 25997 21615 1120 3262=============================================================================== Total 336 25451 21615 644 3192=============================================================================== 看老师画了那么多牛逼的图，要不“邯郸学步”模仿一下吧。故而又忍着“下一个吧”的念头，梳理了下这几个月到底做了些什么。 归元 知是行之始，行是知之成。 遇事不决，可问春风。春风不语，既随本心。 2025 见！","tags":["Rust"],"categories":["Rust","总结","2024"]},{"title":"Rust 原理丨聊一聊 Rust 的 Atomic 和内存顺序","path":"/2024/11/11/rust-memory-order/","content":"Atomic 在 Rust 的 std::sync::atomic 模块中包含了无锁并发编程的原子化类型，与通常的算术运算符和逻辑运算符不同，原子化类型会暴露执行原子化操作的方法，单独的加载、存储、交换和算术运算都会作为一个单元安全地进行，哪怕其他线程也在执行操作同一内存的原子化操作也没问题。 Rust 提供了以下几种原子化类型： AtomicIsize 和 AtomicUsize 是与单线程 isize 类型和 usize 类型对应的共享整数类型。 AtomicI8、AtomicI16、AtomicI32、AtomicI64 及其无符号变体（如 AtomicU8）是共享整数类型，对应于单线程中的类型 i8、i16 等。 AtomicBool 是一个共享的 bool 值。 AtomicPtr 是不安全指针类型 *mut T 的共享值。 这些类型都会以下几类核心功能： Load 、Store: 存取值 Fetch-and-Modify: 获取并修改 Compare-and-Exchange: 比较并交换 下面我们对上述提到的几种核心功能进行举例。 Load Store load: 从原子化类型中获取起对应的基本数据类型的值。 store: 将一个基本数据类型的值存储到其对应的原子化类型中。 在下面的例子中，我们使用 AtomicUsize::new(0) 初始化了一个原子类型，它对应的基本数据类型是 usize。 我们起了一个子线程，在 for 循环中不断地使用 store 函数修改 num_done 的值，然后在主线程中使用 load 获取起对应的值，当发现值为 100 时，就退出循环，进程结束。 得益于原子化类型的并发安全特性，所以这里两个线程对 num_done 进行并发读写都是安全的。 fn main() let num_done = AtomicUsize::new(0); let main_thread = thread::current(); thread::scope(|s| s.spawn(|| for i in 0..100 sleep(Duration::from_millis(10)); num_done.store(i + 1, std::sync::atomic::Ordering::Relaxed); // store 存储 main_thread.unpark(); ); loop let n = num_done.load(std::sync::atomic::Ordering::Relaxed); // load 获取 if n == 100 break; println!(Working... n/100 done); thread::park_timeout(Duration::from_millis(1)); ); println!(Done!); 这里我们暂且忽略 std::sync::atomic::Ordering::Relaxed 这个参数的含义，在后续的「内存顺序」章节会进行详细阐述。 Fetch-and-Modify Fetch-and-Modify 操作用于在获取当前值的同时对其进行修改。这类操作包括 fetch_add、fetch_sub、fetch_and、fetch_or、fetch_xor 等。 我们将上面的例子修改一下，不再是直接 store 一个值，而是不断进行加 1 操作： fn main() let num_done = AtomicUsize::new(0); thread::scope(|s| s.spawn(|| for _ in 0..100 num_done.fetch_add(1, std::sync::atomic::Ordering::Relaxed); // 使用 fetch_add 进行加 1 ); loop let n = num_done.load(std::sync::atomic::Ordering::Relaxed); if n == 100 break; println!(Working... n/100 done); ); println!(Done!); Compare-and-Exchange Compare-and-Exchange 是一种条件更新操作，只有在当前值等于预期值时才会更新。 下面的例子中我们实现了一个函数 allocate_new_id，它支持在并发环境下分配新的 id，这里我们使用了 compare_exchange(id, id+1) 进行条件更新，只有当 id 没有发生变化的时候，才运行对其进行加 1，这就保证了在并发下，只有一个线程可以成功执行该语句，从而保证 id 的递增性和唯一性。 fn allocate_new_id() - u32 static NEXT_ID: AtomicU32 = AtomicU32::new(0); let mut id = NEXT_ID.load(std::sync::atomic::Ordering::Relaxed); loop assert!(id 1000, Too many IDs!); match NEXT_ID.compare_exchange( // 只有 id 没有发生变化，才允许进行加 1 id, id + 1, std::sync::atomic::Ordering::Relaxed, std::sync::atomic::Ordering::Relaxed, ) Ok(_) = return id, Err(v) = id = v, 在 Rust 中，原子化类型还提供了另外一个函数：compare_exchange_weak，它与 compare_exchange 的主要区别在于它们在失败时的行为： compare_exchange:只会在实际值不等于期望值时失败。提供更强的保证，但可能性能较低。适用于不在循环中的单次比较交换操作。compare_exchange_weak:即使实际值等于期望值时也可能失败（称为“虚假失败”或“spurious failure”）。性能可能更好，因为允许在某些架构上生成更高效的代码。最适合在循环中使用，因为需要处理可能的虚假失败。在实际应用中:如果操作在循环中,使用 compare_exchange_weak 通常更好。如果是单次操作,使用 compare_exchange 更合适。在某些平台上，这两个操作可能没有性能差异,但 compare_exchange_weak 的行为仍然可能不同。这种区别的存在是因为在某些 CPU 架构上,允许虚假失败可以生成更高效的机器码。比如在 ARM 架构上，compare_exchange_weak 可以直接映射到单个 LL/SC（Load-Link/Store-Conditional）指令。 硬件原理 在一些处理器架构中，当一个 CPU 执行需要原子性的操作时，它可以通过锁定内存总线来确保在操作完成之前，其他 CPU 无法访问相关的内存地址。 基本工作流程如下： CPU 发出 LOCK 信号 └── 激活处理器的 LOCK# 引脚 └── 获得总线的独占访问权 └── 执行原子操作 └── 释放 LOCK 信号 └── 其他处理器可以访问内存 主流的有 2 种锁定机制： 总线锁定（Bus Locking）：总线锁定是一种机制，它通过锁定内存总线来确保在执行原子操作时，其他处理器无法访问内存。这种方法虽然简单，但会导致总线的其他操作被阻塞，从而影响系统性能。 优点：- 绝对的原子性保证- 适用于所有内存位置缺点：- 性能开销大- 会阻塞其他 CPU 对内存的访问 缓存锁定（Cache Locking）：现代处理器通常使用缓存锁定来实现原子操作。缓存锁定通过锁定处理器的缓存行来实现，而不是锁定整个总线。这种方法可以减少对总线的影响，提高系统的并发性能。 优点：- 性能更好- 不会完全阻塞内存访问条件：- 数据必须在缓存行中- 缓存行必须是独占状态 缓存锁定通常依赖于缓存一致性协议（如 MESI 协议）来确保在多个处理器之间的数据一致性。通过这些协议，处理器可以在本地缓存中执行原子操作，并在必要时与其他处理器同步。 MESI 协议即： M (Modified)：已修改E (Exclusive)：独占S (Shared)：共享I (Invalid)：无效操作流程：1. 检查数据是否在缓存中2. 如果在，将状态改为 Exclusive3. 执行原子操作4. 通知其他 CPU 使其缓存失效 不同的架构有不同的锁定方式： x86/x64：使用 LOCK 前缀 ARM：使用 exclusive load/store 指令 PowerPC：使用 load-linked/store-conditional 以下是 x86 汇编的一个示例： ; 原子加法操作lock add dword ptr [memory], 1; 比较并交换lock cmpxchg dword ptr [memory], eax 为了充分利用缓存锁定的优势，我们在编写代码时，可以有以下的性能考虑： 缓存行对齐，避免伪共享 use std::sync::atomic::AtomicI32, Ordering;// 在 Rust 中，可以使用 #[repr(align(N))] 属性来确保结构体或变量的对齐方式，以避免伪共享。// 伪共享是指多个线程访问不同的变量，但这些变量共享同一个缓存行，从而导致不必要的缓存一致性流量。#[repr(align(64))]struct AlignedCounter counter: AtomicI32,fn main() let counter = AlignedCounter counter: AtomicI32::new(0), ; // 使用 counter.counter.fetch_add(...) 进行操作 避免频繁的总线锁定 use std::sync::atomic::AtomicI32, Ordering;fn main() let counter = AtomicI32::new(0); // 不好的做法：频繁的原子操作 for _ in 0..1000 counter.fetch_add(1, Ordering::SeqCst); // 更好的做法：本地累加后一次性更新 let mut local_sum = 0; for _ in 0..1000 local_sum += 1; counter.fetch_add(local_sum, Ordering::SeqCst); Rust 实战查看汇编 笔者使用的是 ARM64 架构的 macbook。 use std::sync::atomic::AtomicI64, Ordering;use std::thread;static ATOMIC: AtomicI64 = AtomicI64::new(0);fn main() let t1 = thread::spawn(|| ATOMIC.store(10086, Ordering::Release); ); let t2 = thread::spawn(|| let val = ATOMIC.load(Ordering::Acquire); println!(val); ); t1.join().unwrap(); t2.join().unwrap(); 使用 rustc 编译并输出汇编代码： rustc -O --emit asm src/main.rs 代码中我特地设置了 10086 这个特殊的值，这是为了可以在输出的 main.s 文件中快速找到 store 对应的位置： __ZN3std3sys9backtrace28__rust_begin_short_backtrace17h750d7a3a9c81fc67E:\t.cfi_startprocLloh8:\tadrp\tx8, __ZN4main6ATOMIC17hd0b0dbf92e477148E.0@PAGELloh9:\tadd\tx8, x8, __ZN4main6ATOMIC17hd0b0dbf92e477148E.0@PAGEOFF\tmov\tw9, #10086 ; 将值 10086 移入寄存器\tstlr\tx9, [x8] ; Store-Release 指令，原子地存储值\t; InlineAsm Start\t; InlineAsm End\tret\t.loh AdrpAdd\tLloh8, Lloh9\t.cfi_endproc 在这个代码中，stlr 就是 Store Release 的意思，另外一个关键字是 ladpr，表示 Load Acquire 的意思，通过这个关键字，你可以找到 load 对应的汇编代码： Lloh11:\tadd\tx8, x8, __ZN4main6ATOMIC17hd0b0dbf92e477148E.0@PAGEOFF\tldapr\tx8, [x8] ; ; Load-Acquire 指令，原子地加载值\tstr\tx8, [sp, #8] Go 实战查看汇编 笔者使用的是 ARM64 架构的 macbook。 package mainimport (\tsync/atomic)func main() data := atomic.Int64\tgo func() data.Store(10086)\t()\tgo func() a := data.Load() println(a)\t() 使用如下命令，可以输出优化后的汇编代码： go build -gcflags=-S -ldflags=-w main.go 2 assembly.txt 查看输出的文件，我们同样搜索 10086，可以快速找到 store 的位置： 0x0008 00008 (/Users/wangjiahan/go/go1.23.2/src/sync/atomic/type.go:109)\tMOVD\t$10086, R10x000c 00012 (/Users/wangjiahan/go/go1.23.2/src/sync/atomic/type.go:109)\tSTLR\tR1, (R0) 可以看到，这里同样也是使用了 STLR 指令。接着我们看第 14 行代码的位置对应的汇编：可以发现这里使用的 LDAR 指令，也就是 Load Acuqire。 0x001c 00028 (/Users/wangjiahan/goStudy/go-atomic/main.go:14)\tHINT\t$00x0020 00032 (/Users/wangjiahan/go/go1.23.2/src/sync/atomic/type.go:106)\tLDAR\t(R0), R00x0024 00036 (/Users/wangjiahan/go/go1.23.2/src/sync/atomic/type.go:106)\tMOVD\tR0, main..autotmp_6-8(SP) 内存顺序 在了解了 Rust Atomic 的基本用法和基本原理之后，我们回过头来谈一谈原子操作参数中的 std::sync::atomic::Ordering::Relaxed，这个就是本篇的主题：内存顺序。内存顺序要解决的核心问题是如何合理地限制单一线程中的代码执行顺序，使得在不使用锁的情况下，既能最大化利用 CPU 的计算能力，又能保证多线程环境下不会出现逻辑错误。 指令乱序 CPU 和编译器都会在保证程序运行结果不发生改变的前提下，尽一切可能让我们的程序运行得尽可能快。 fn f(a: mut i32, b: mut i32) *a += 1; *b += 1; *a += 1; 像上述代码，编译器完全可以优化成下面的代码，从而提高程序的运行效率： fn f(a: mut i32, b: mut i32) *a += 2; *b += 1; 在这个过程中，就可能会出现指令重排，甚至是代码重写，不过这带来了指令乱序的问题，即程序的实际执行顺序跟我们的代码顺序是不一致的。 不过，编译器保证的是在单线程环境下，执行的结果最终一致，所以，指令乱序在单线程环境下完全是允许的。对于编译器来说，它只知道：在当前线程中，数据的读写以及数据之间的依赖关系。但是，编译器并不知道哪些数据是在线程间共享，而且是有可能会被修改的。而这些是需要开发人员去保证的。 内存模型 为了解决指令乱序带来的并发问题，Rust 采用了内存模型（Memory Model）这一概念。这个概念主要借鉴自 C++11 中引入的内存模型，它定义了在多线程环境下内存访问的行为规范。 内存模型的核心目标是在以下三方面之间取得平衡： 正确性保证：确保多线程程序的行为是可预测和一致的。 性能优化：允许编译器和 CPU 在不违反正确性的前提下进行优化。 跨平台兼容：提供一个统一的抽象层，使代码可以在不同的硬件架构上正确运行。 具体来说，内存模型： 为开发者提供了清晰的规则，说明在多线程环境下，什么样的内存访问行为是合法的，什么样的行为会导致未定义行为。 为编译器开发者提供了明确的标准，指导他们在不同平台上实现必要的内存同步原语。 通过定义不同的内存顺序级别（如 Relaxed、Release/Acquire、SeqCst 等），让开发者可以根据需要选择合适的同步强度。 这种抽象让开发者可以专注于并发逻辑本身，而不必过分关 注底层硬件的具体实现细节。 Sequenced-Before 在讨论内存顺序之前，我们需要先对 2 个重要关系术语进行简单阐述，分别是 Sequenced-Before 和 Happens-Before。 Sequenced-Before 描述的是单个线程内的操作顺序。它基于程序的源代码顺序，表示在同一线程中，一个操作在程序中出现在另一个操作之前。 具体来说，如果操作 A sequenced-before 操作 B，那么： 数据依赖关系：如果 B 依赖于 A 的结果，那么 A 一定会在 B 之前执行。例如： let x = 1; // 操作 Alet y = x + 1; // 操作 B - 依赖于 A 的结果 原子操作的顺序：对同一个原子变量的操作会保持程序顺序。例如： X.fetch_add(5, Relaxed); // 一定先执行X.fetch_add(10, Relaxed); // 一定后执行 独立操作的可重排性：如果两个操作之间没有数据依赖关系，且操作的是不同的变量，那么它们可能会被重排序。例如： X.store(1, Relaxed); // 这两个操作可能会被重排序Y.store(2, Relaxed); // 因为它们操作的是不同的变量 Happens-Before Happens-Before 则描述了跨线程的操作顺序。它定义了不同线程中的操作之间的可见性和顺序关系。如果操作 A Happens-Before 操作 B，那么 A 的内存写入对 B 是可见的。 典型的 Happens-Before 有： 同一线程内，如果先调用 f()，再调佣 g()，则 f() happens-before g()，其实这就是 sequenced-before。 spawing happens-before joining。 lock happens-before unlock。 举个例子： static X: AtomicI32 = AtomicI32::new(0);fn main() X.store(1, Relaxed); let t = thread::spawn(f); X.store(2, Relaxed); t.join().unwrap(); X.store(3, Relaxed);fn f() let x = X.load(Relaxed); assert!(x == 1 || x == 2); 上面这个例子的执行顺序如下图所示，因为 spawn happens-before join，所以我们可以确定的执行顺序是：“store 1 to X”→“store 2 to X”→“store 3 to X”。而 load from X 介于 spawn 和 join 之间，且没有进行任何其他的内存顺序限制，所以它和 store 2 to X 之间的顺序是不确定的，但是可以肯定的是，它一定在 store 3 to X 之前，所以 assert!(x == 1 || x == 2); 是永远成立的。 到这里，相信不少读者已经能够理解为什么需要内存顺序这个东西了，核心问题就是在于 store 2 to X 和 load from X 的执行顺序是否会影响我们的业务逻辑，如果不会，那么我们可以指定最松散的内存顺序要求，如果会，那么我们就要利用指定合适的内存顺序来使得其按照我们的预期顺序进行执行，从而保证业务逻的正确。 Rust 内存顺序 Rust 支持五种内存顺序（Ordering），从最松散到最严格依次为： 内存顺序 说明 保证 适用场景 示例 Relaxed 最宽松的内存顺序 - 仅保证操作的原子性- 不提供任何同步保证- 不建立 happens-before 关系 - 简单计数器- 性能要求极高且确定不需要同步- 已通过其他方式确保同步 counter.fetch_add(1, Ordering::Relaxed) Release 用于存储操作 - 之前的内存访问不会被重排到此操作之后- 与 Acquire 配对使用可建立 happens-before 关系 - 生产者-消费者模式- 发布共享数据- 初始化完成标志 data.store(42, Ordering::Release) Acquire 用于加载操作 - 之后的内存访问不会被重排到此操作之前- 与 Release 配对使用可建立 happens-before 关系 - 生产者-消费者模式- 获取共享数据- 检查初始化标志 data.load(Ordering::Acquire) AcqRel 同时包含 Acquire 和 Release 语义 - 结合了 Acquire 和 Release 的所有保证- 用于读改写操作 - 需要双向同步的原子操作- 锁的实现- 复杂的同步原语 value.fetch_add(1, Ordering::AcqRel) SeqCst 最严格的内存顺序 - 包含 AcqRel 的所有保证- 所有线程看到的所有 SeqCst 操作顺序一致- 提供全局的顺序一致性 - 需要严格的全局顺序- 不确定使用哪种顺序时- 对性能要求不高的场景 flag.store(true, Ordering::SeqCst) 在 C++ 中，其实还有另外一种内存顺序 Consume，它是 Acquire 的一个更弱的版本： Acquire: 保证后续的所有读写操作不会重排到这个操作前面 Consume: 只保证后续与这个操作结果相关的读写操作不会重排到这个操作前面 理论上，Consume 在某些架构上可以提供比 Acquire 更好的性能，因为它只需要对数据依赖的操作进行同步。 然而，由于以下原因，Rust 选择不支持 Consume 顺序： 实现复杂性：很多编译器实现者发现正确实现 Consume 语义非常困难。 性能收益不确定：在实践中，大多数编译器都将 Consume 视为 Acquire 来处理。 标准困惑：C++ 标准委员会也承认当前的 Consume 语义定义存在问题，正在考虑重新设计。 选择建议： 不确定选择哪种顺序时：使用 SeqCst（最安全但性能最低）或咨询有经验的开发者性能优化时：先使用 SeqCst 开发在性能测试后，根据需要降低到 Release/Acquire只有在确实需要时才使用 Relaxed常见组合：Release 写 + Acquire 读：最常见的生产者-消费者模式AcqRel：用于原子的读改写操作Relaxed：用于简单的计数器场景 下面我们来对每种内存顺序进行举例阐述。 Relaxed Relaxed 是最宽松的内存顺序，它只保证了原子操作在并发下的安全性，但不保证执行顺序。 考虑如下代码： static X: AtomicI32 = AtomicI32::new(0);fn a() X.fetch_add(5, Relaxed); X.fetch_add(10, Relaxed); fn b() let a = X.load(Relaxed); let b = X.load(Relaxed); let c = X.load(Relaxed); let d = X.load(Relaxed); println!(a b c d); // 这个输出不一定fn main() thread::scope(|s| s.spawn(a); s.spawn(b); ); println!(:?, X.load(Relaxed)); // 最终结果一定是 15 基于我们上面提到的 sequenced-before 规则，我们可以确定 a 和 b 两个线程内的 happens-before 规则，但是二者之间的 happens-before 是无法确定的，但是我们可以确定最后的结果是 15。下图展示了上述代码的执行顺序示意图： 虽然两个线程之间的 happens-before 是无法确定的，但是我们可以确定 X 的变化顺序：0→5→15。所以线程 b 输出 0 0 0 0、0 0 5 15 和 0 15 15 15 都是可能的，而永远不可能输出 0 5 0 15 或 0 0 10 15 类似的结果。 但是如果是这样子的话，就不一定了： static X: AtomicI32 = AtomicI32::new(0);fn a1() X.fetch_add(5, Relaxed);fn a2() X.fetch_add(10, Relaxed); fn b() let a = X.load(Relaxed); let b = X.load(Relaxed); let c = X.load(Relaxed); let d = X.load(Relaxed); println!(a b c d); // 这个输出不一定fn main() thread::scope(|s| s.spawn(a1); s.apawn(a2); s.spawn(b); ); println!(:?, X.load(Relaxed)); // 最终结果一定是 15 上面这个例子，X 的变化顺序可以是 0→5→15，也可以是 0→10→15，这取决于哪个 fetch_add 先被执行。 再举个例子： static DATA: AtomicI32 = AtomicI32::new(0);static READY: AtomicBool = AtomicBool::new(false);fn main() thread::scope(|s| // 线程 A - 写入者 s.spawn(|| DATA.store(123, Ordering::Relaxed); // ① 准备数据 READY.store(true, Ordering::Relaxed); // ② 发出数据就绪信号 ); // 线程 B - 读取者 s.spawn(|| while !READY.load(Ordering::Relaxed) // ③ 等待数据就绪信号 thread::yield_now(); assert_eq!(DATA.load(Ordering::Relaxed), 123); // ④ 获取数据，这里断言一定成功吗？ ); ); 上面这个例子中，线程 A 执行了： DATA.store(123, Ordering::Relaxed); // 准备数据READY.store(true, Ordering::Relaxed); // 发出数据就绪信号 这是 2 个没有依赖关系的原子操作，且使用的是 Relaxed 内存顺序，所以对于线程 B 来说，这 2 个操作的顺序是不确定的。所以是很可能在 READY.load(Ordering::Relaxed) 返回 true 的时候，DATA.load(Ordering::Relaxed) 依旧还是 0。 那如何确保这个断言一定成功呢？那就需要“升级”一下了~ 这个时候就轮到 Release 和 Acquire 的出场了。 Release Acquire Release 和 Acquire 一般成对出现，它们共同建立了线程间的同步关系： Release: 作用于写操作（store），确保该操作之前的所有内存访问不会被重排到这个 Release 操作之后。 Acquire: 作用于读操作（load），确保该操作之后的所有内存访问不会被重排到这个 Acquire 操作之前。 当一个线程通过 Acquire 读取到另一个线程通过 Release 写入的值时，会建立一个 happens-before 关系：线程 A 中 Release 写入之前的所有内存写操作，对于线程 B 中 Acquire 读取之后的所有内存读操作都是可见的。 修改一下上面的例子： static DATA: AtomicI32 = AtomicI32::new(0);static READY: AtomicBool = AtomicBool::new(false);fn main() thread::scope(|s| s.spawn(|| DATA.store(123, Ordering::Relaxed); READY.store(true, Ordering::Release); // 这里改为 release ); s.spawn(|| while !READY.load(Ordering::Acquire) // 这里改为 acquire thread::yield_now(); assert_eq!(DATA.load(Ordering::Relaxed), 123); // 必定成功 ); ); 如上图所示，在这个例子中： Release-Acquire 同步确保了 READY 的写入和读取之间建立了 happens-before 关系 由于 DATA 的写入在 READY 的 Release 写入之前，而 DATA 的读取在 READY 的 Acquire 读取之后 因此可以保证线程 B 一定能看到线程 A 写入的值 123 更进一步，我们通过观察，可以发现 DATA 都没必要使用 Atomic 类型，因为由 READY 建议的 happens-before 规则已经能保证对 DATA 的读写不可能并发执行了。不过因为 Rust 的类型系统并不允许跨线程进行非原子类型的读写操作，所以这里我们需要使用 unsafe 才能使编译通过，但通过我们之前的分析，我们可以确保下面这段代码是安全的： static mut DATA: u64 = 0;static READY: AtomicBool = AtomicBool::new(false);fn main() thread::spawn(|| // Safety: 此时没有其他线程访问 DATA， // 因为我们还没有设置 READY 标志 unsafe DATA = 123 ; READY.store(true, Release); // 在这个存储操作之前的所有内存操作 .. ); while !READY.load(Acquire) // .. 在这个加载操作返回 true 后都是可见的 thread::sleep(Duration::from_millis(100)); println!(waiting...); // Safety: 没有线程会修改 DATA，因为 READY 已经被设置 println!(, unsafe DATA ); 释放序列（Release Sequence） 我们再来看一段代码示例：use std::sync::atomic::AtomicU8, thread;static mut DATA: Veci64 = vec![];static FLAG: AtomicU8 = AtomicU8::new(0);fn thread_1() unsafe DATA.push(42); FLAG.store(1, std::sync::atomic::Ordering::Release);fn thread_2() let mut expected = 1; // memory_order_relaxed is okay because this is an RMW, // and RMWs (with any ordering) following a release form a release sequence while FLAG .compare_exchange( expected, 2, std::sync::atomic::Ordering::Relaxed, std::sync::atomic::Ordering::Relaxed, ) .is_err() expected = 1 fn thread_3() while FLAG.load(std::sync::atomic::Ordering::Acquire) 2 // if we read the value 2 from the atomic flag, we see 42 in the vector unsafe assert_eq!(DATA[0], 42); // will never fire fn main() thread::scope(|s| s.spawn(thread_1); s.spawn(thread_2); s.spawn(thread_3); );这段代码是参考 cppreference 而翻译成 Rust 代码的，在上述代码中，即使 thread_2 中我们使用的是 Relaxed， 这段代码中的 assert_eq!(DATA[0], 42) 也是一定成功的。为什么呢？这涉及到一个重要的概念——释放序列（Release Sequence）：当一个 release 操作后面跟着一系列的原子读-修改-写(RMW)操作时，这些操作会形成一个释放序列。在这个序列中，后续的 RMW 操作不需要使用 release 或 acquire 语义也能保证同步。在这段代码中：当 thread_2 的 RMW 操作成功的时候，说明 FLAG 是 1，即 thread_1 已经执行了 release 操作，这个时候：thread_1 的 release 操作建立了同步点thread_2 的 RMW 操作自动成为释放序列的一部分当 thread_3 通过 acquire 看到值 2 时，它能看到整个释放序列的所有修改。因此能保证看到 DATA 中的 42。所以在这种场景下使用 relaxed 既安全又高效，因为：它是释放序列的一部分不需要额外的同步开销仍然能保证正确的内存顺序为什么这样设计呢？原子性保证：RMW 操作本身就是原子的，不会产生数据竞争连续性：每个 RMW 操作都直接或间接地基于前一个操作的结果因果关系：形成了一个清晰的修改链条性能考虑：中间的 RMW 操作不需要额外的同步开销 Sequentially Consistent SeqCst 是最严格的内存顺序，它包括获取 release 和 acquire 的所有保证，还保证了全局一致的操作顺序。简单理解就是，你代码的顺序是怎么样，实际的执行顺序就是什么样。 我们来看一段代码： use std::sync::atomic::Ordering::SeqCst;static A: AtomicBool = AtomicBool::new(false);static B: AtomicBool = AtomicBool::new(false);static mut S: String = String::new();fn main() let a = thread::spawn(|| A.store(true, SeqCst); if !B.load(SeqCst) unsafe S.push(!) ; ); let b = thread::spawn(|| B.store(true, SeqCst); if !A.load(SeqCst) unsafe S.push(!) ; ); a.join().unwrap(); b.join().unwrap(); 在这段代码中，两个线程都是希望将自己的原子变量设置为 true，从而阻止另外一个线程对 S 进行 push 操作，其实就类似于锁。因为这里使用了 SeqCst，所以代码的执行顺序是跟代码编写顺序是一致的，那么就可能出现以下 3 种执行情况： 即：同一时刻，最多只可能有一个线程会对 S 进行操作。 内存屏障 除了内存顺序（Memory Order），还有另外一种方式可以控制程序的执行顺序，就是内存屏障（Memory Barrier）。内存屏障是一种底层的同步原语，它能强制处理器按照特定的顺序执行内存操作。内存屏障通过阻止或限制指令重排序，来确保内存操作的可见性和顺序性。 基本概念 内存屏障主要分为以下几种类型： Load Barrier（读屏障） 确保在屏障之前的所有读操作都执行完成 防止后续读操作被重排到屏障之前 对应 Acquire 语义 Store Barrier（写屏障） 确保在屏障之前的所有写操作都执行完成 防止后续写操作被重排到屏障之前 对应 Release 语义 Full Barrier（全屏障） 同时包含读屏障和写屏障的功能 防止任何内存操作的重排序 对应 SeqCst 语义 即下面这 2 种实现方式是等价的： 所以到这里，我们可以更好地理解为什么 release 是阻止其前面的内存访问越过它，而 acquire 是阻止其后面的内存访问越过它了。因为有个 fence 在前面或后面拦着！ 但是一般来说，下面的写法相比上面的写法会有一丢丢的性能损失，因为这会增加一些额外的处理指令。那 fence 的用武之地是什么呢？ 可以同时对多个原子操作进行 fench； 可以根据条件判断，选择是否进行 fench。 举个例子： 这个例子的关键点是： 如果线程 2 中的任何一个 load 操作观察到了线程 1 中对应的 store 操作的值： 比如 A.load() 读到了值 1，或 B.load() 读到了值 2，或 C.load() 读到了值 3 那么：线程 1 中的 release fence 就会 happens-before 线程 2 中的 acquire fence。这意味着线程 1 中 release fence 之前的所有内存操作对线程 2 中 acquire fence 之后的操作都是可见的。 这展示了内存屏障的一个重要优势：一个屏障可以同时为多个原子操作建立同步关系，而不需要在每个原子操作上都使用 Release/Acquire 内存序。这在某些场景下可能会更高效。 用更通俗的话说：这就像在线程 1 设置了一个检查点（release fence），在线程 2 也设置了一个检查点（acquire fence），只要线程 2 看到了线程 1 在其检查点之后做的任何一个改动，那么线程 1 检查点之前的所有操作对线程 2 的检查点之后都是可见的。 硬件实现 不同的处理器架构实现内存屏障的方式不同： ; x86/x64MFENCE ; 全屏障LFENCE ; 读屏障SFENCE ; 写屏障; ARMDMB ; 数据内存屏障DSB ; 数据同步屏障ISB ; 指令同步屏障 与内存顺序的关系 Rust 的内存顺序实际上是通过内存屏障来实现的： // Release 写入会插入 Store Barrieratomic.store(42, Ordering::Release); // 编译器会在此处插入 Store Barrier// Acquire 读取会插入 Load Barrierlet x = atomic.load(Ordering::Acquire); // 编译器会在此处插入 Load Barrier// SeqCst 操作会插入 Full Barrieratomic.store(42, Ordering::SeqCst); // 编译器会在此处插入 Full Barrier 注意：直接使用内存屏障是非常底层的操作，通常我们应该使用 Rust 提供的高级抽象（如原子类型和它们的内存顺序）来实现同步。内存屏障的知识主要用于理解这些高级抽象的工作原理。 Go Atomic 熟悉 Go 语言的读者应该会意识到在使用 Go 语言的原子类型的时候，好像都没见过 Memory Order 这个东西，如下： package mainimport (\tsync/atomic)func main() data := atomic.Int64\tdata.Add(1)\tdata.And(2)\tdata.Or(3)\tdata.Swap(4)\tdata.Store(5)\tdata.Load()\tdata.CompareAndSwap(6, 7) 在 atomic/doc.go 源码中我们可以看到这段话： // The load and store operations, implemented by the LoadT and StoreT// functions, are the atomic equivalents of return *addr and// *addr = val.//// In the terminology of [the Go memory model], if the effect of// an atomic operation A is observed by atomic operation B,// then A “synchronizes before” B.// Additionally, all the atomic operations executed in a program// behave as though executed in some sequentially consistent order.// This definition provides the same semantics as// C++s sequentially consistent atomics and Javas volatile variables.//// [the Go memory model]: https://go.dev/ref/mem Go 语言设计者认为让程序员选择内存序会增加复杂性和出错的可能，所以为了程序的简单性和可预测性，直接就使用了最安全的 Seq-Cst 内存顺序了。 the Go memory model 中还提了一句： If you must read the rest of this document to understand the behavior of your program, you are being too clever.Dont be clever. 这也呼应了 Go 的设计理念： Share memory by communicating; dont communicate by sharing memory. 所以总结一下： Go 的原子操作采用了最强的顺序一致性内存序； 这是一个有意识的设计选择，为了简单性和可预测性； 如果你需要更细粒度的内存序控制，那么 Go 可能不是最佳选择； Go 更推荐使用 channels 和其他同步原语来进行并发控制。 参考 Rust Atomics And Lock 聊一聊内存模型与内存序 cppreference the Go memory model","tags":["Go","Rust","内存顺序","内存屏障","并发控制","Atomic","Happens-Before"],"categories":["Rust","Rust 底层原理"]},{"title":"Rust 实战丨SSE(Server-Sent Events)","path":"/2024/06/06/rust-action-sse/","content":"📌 SSE（Server-Sent Events）是一种允许服务器向客户端浏览器推送信息的技术。它是 HTML5 的一部分，专门用于建立一个单向的从服务器到客户端的通信连接。SSE的使用场景非常广泛，包括实时消息推送、实时通知更新等。 SSE 的本质 严格地说，HTTP 无法做到服务器主动推送信息。但是，有一种变通方法，就是服务器向客户端声明，接下来要发送的是流信息（streaming）。 也就是说，发送的不是一次性的数据包，而是一个数据流，会连续不断地发送过来。这时，客户端不会关闭连接，会一直等着服务器发过来的新的数据流，视频播放就是这样的例子。本质上，这种通信就是以流信息的方式，完成一次用时很长的下载。 SSE 就是利用这种机制，使用流信息向浏览器推送信息。它基于 HTTP 协议，目前除了 IE/Edge，其他浏览器都支持。 特点 持续连接：与传统的 HTTP 请求不同，SSE 保持连接开放，服务器可以随时发送消息。 文本数据流：SSE 主要传输文本数据，这些数据以特定的格式流式传输，使得每条消息都是简单的文本格式。 内置重连机制：浏览器会自动处理连接中断和重连，包括在重连请求中发送最后接收的事件 ID，以便服务器从正确的位置恢复发送事件。 简单的客户端处理：在浏览器中，使用 JavaScript 的 EventSource 接口处理 SSE 非常简单，只需几行代码即可监听服务器发来的事件。 工作原理 建立连接：客户端通过创建一个 EventSource 对象请求特定的 URL 来启动 SSE 连接。这个请求是一个标准的 HTTP 请求，但会要求服务器以特定方式响应。 服务器响应：服务器响应必须设置 Content-Type 为 text/event-stream，然后保持连接打开。 发送消息：服务器可以通过持续发送数据格式为特定事件流的消息来推送更新。每个消息包括一个可选的事件类型、数据和一个可选的 ID。 数据：实际的消息内容，以 data: 开头，多行数据以双换行符 结束。 事件类型：允许客户端根据事件类型来监听，以 event: 开头。 ID：如果连接中断，客户端将发送包含上次接收的最后一个ID的 Last-Event-ID 头，以便服务器从断点继续发送数据。 实战 客户端 !DOCTYPE htmlhtmlhead titleSSE Test/title/headbodyh1Server-Sent Events Test/h1div id=events/divscript // 确保这里的URL匹配你的服务器地址和端口 var eventSource = new EventSource(http://localhost:8000/events); eventSource.onmessage = function(event) console.log(New event:, event.data); document.getElementById(events).innerHTML += event.data + br; ;/script/body/html Rust 服务端 依赖： anyhow = 1.0.86axum = version = 0.7.5 chrono = 0.4.38futures-core = 0.3.30tokio = version = 1.38.0, features = [macros, rt-multi-thread, ] tokio-stream = 0.1.15tower-http = version = 0.5.2, features = [cors] 代码： use std::time::Duration;use axum:: response::sse::Event, Sse, routing::get, Router,;use tokio::net::TcpListener, time::interval;use tokio_stream::wrappers::IntervalStream, StreamExt;use tower_http::cors::Any, CorsLayer;#[tokio::main]async fn main() - anyhow::Result() let cors = CorsLayer::new() .allow_headers(Any) .allow_origin(Any) .allow_headers(Any) .allow_credentials(false); let listener = TcpListener::bind(0.0.0.0:8000).await?; let app = Router::new().route(/events, get(sse_handler)).layer(cors); axum::serve(listener, app).await?; Ok(())async fn sse_handler() - Sseimpl futures_core::StreamItem = ResultEvent, axum::Error let interval = interval(Duration::from_secs(1)); let stream = IntervalStream::new(interval).map(|_| let data = format!( , chrono::Local::now().to_rfc2822()); Ok(Event::default().data(data)) ); Sse::new(stream) Go 服务端 package mainimport (\tfmt\tlog\tnet/http\ttime)func sseHandler(w http.ResponseWriter, r *http.Request) // 设置头部信息，确保允许跨域，并且告诉浏览器这是一个事件流\tw.Header().Set(Content-Type, text/event-stream)\tw.Header().Set(Cache-Control, no-cache)\tw.Header().Set(Connection, keep-alive)\tw.Header().Set(Access-Control-Allow-Origin, *)\t// 不断发送消息\tfor // 生成服务器时间，并发送给客户端 now := time.Now() // 生成消息，格式为 data: content msg := fmt.Sprintf(data: %s , now.Format(time.DateTime)) // 发送消息 if _, err := fmt.Fprintf(w, msg); err != nil log.Println(write error:, err) break // 刷新响应缓冲，确保即时发送 flusher, ok := w.(http.Flusher) if !ok log.Println(Streaming unsupported!) break flusher.Flush() // 每秒发送一次 time.Sleep(1 * time.Second)\tfunc main() http.HandleFunc(/events, sseHandler)\tlog.Println(Server started on port 8000...)\tlog.Fatal(http.ListenAndServe(:8000, nil))","tags":["Go","Rust","SSE"],"categories":["Rust","Rust 实战"]},{"title":"Rust 实战丨通过实现 json! 掌握声明宏","path":"/2024/05/28/rust-action-macro-json/","content":"在 Rust 编程语言中，宏是一种强大的工具，可以用于在编译时生成代码。json! 是一个在 Rust 中广泛使用的宏，它允许我们在 Rust 代码中方便地创建 JSON 数据。 声明宏（declarative macros）是 Rust 中的一种宏，它们使用 macro_rules! 关键字定义。 本文将参考《Rust 程序设计（第二版）》，通过实现 json! 宏，深入理解声明宏的工作原理。 结论先行 本文我们将构建一个 json! 宏，它支持我们以字符串 JSON 风格的语法来编写 Json 值。如下面这个例子： let students = json![ name: Hedon Wang, class_of: 2022, major: Software engineering\t, name: Jun Lei, class_of: 1991, major: Computor science\t] 完整代码 实现 json! 定义 Json enum 首先我们需要思考一下 Json 结构是什么样子的？主要是以下 3 种模式： name: hedon, age: 18, school: name: Wuhan University, address: Hubwi Wuhan [ name: hedon\t, name: john\t] null 为此我们定义一个 Json 结构的枚举： #[derive(Clone, PartialEq, Debug)]pub enum Json Null, Boolean(bool), Number(f64), String(String), Array(VecJson), Object(HashMapString, Json), 你应该可以感到非常奇妙，使用一个这么简单的枚举，居然就可以表示所有的 Json 结构了。遗憾的是，现在这个结构编写 Json 值的语法相当冗长。 let people = Json::Object(HashMap::from([ (name.to_string(), Json::String(hedon.to_string())), (age.to_string(), Json::Number(10.0)), (is_student.to_string(), Json::Boolean(true)), ( detail.to_string(), Json::Object(HashMap::from([ (address.to_string(), Json::String(beijing.to_string())), (phone.to_string(), Json::String(1234567890.to_string())) ])) )])) 我们期望可以以下面这种方式来声明 Json 变量，这看起来就清爽许多了。 let students = json!([ name: Jim Blandy, class_of: 1926, major: Tibetan throat singing , name: Jason Orendorff, class_of: 1702, major: Knots ]); 猜想 json! 我们可以预见 Json 宏内部将会有多条规则，因为 JSON 数据有多种类型：对象、数组、数值等。事实上，我们可以合理地猜测每种 JSON 类型都将有一条规则： macro_rules! json (null) = Json::Null ; ([ ... ]) = Json::Array(...) ; ( ... ) = Json::Object(...) ; (???) = Json::Boolean(...) ; (???) = Json::Number(...) ; (???) = Json::String(...) ; 然而这不太正确，因为宏模式无法区分最后 3 种情况，稍后我们会讨论如何处理。至于前 3 种情况，显然它们是以不同的语法标记开始的，所以这几种情况比较好处理。 实现 Null 我们先从最简单的 Null 分支开始，先编写如下测试用例： #[cfg(test)]mod tests use super::*; #[test] fn test_null_json() let json = json!(null); assert_eq!(json, Json::Null); 想要通过上述测试用例非常简单，我们只需要在 macro_rules! 支持中匹配这种情况即可： #[macro_export]macro_rules! json (null) = Json::Null ; #[macro_export] 注解是 Rust 中的一个属性，用于指示这个宏应该被导出到调用者的作用域中，这样其他模块也可以使用它。 macro_rules! 宏定义了一个自定义的宏。在这里，它创建了一个名为 json 的宏，用于生成 JSON 数据。 宏定义中 (null) 是匹配模式。这意味着当你调用 json! 宏并传递 null 作为参数时，将会触发这个规则。 = 符号用于指示匹配模式后的代码块。在这里，它指定了当匹配 (null) 时应该生成的代码块。 Json::Null 是一个 JSON 类型的枚举值，表示 JSON 中的 null 值。这个宏的目的是将传入的 null 转换为 Json::Null。 实现 Boolean/Number/String 我们先准备如下测试用例： #[test]fn test_boolean_number_string_json() let json = json!(true); assert_eq!(json, Json::Boolean(true)); let json = json!(1.0); assert_eq!(json, Json::Number(1.0)); let json = json!(hello); assert_eq!(json, Json::String(hello.to_string())); 通过观察分析，它们其实都是同一种模式： 现在需要解决的问题就是，如何将这 3 种模式进行统一，这样在 macro_rules! 中才可以统一匹配模式并进行代码生成。 这里我们其实需要做的就是将 bool、f64 和 str 转为对应的 Json 类型。那就需要用到标准库中的 From trait 了。 做法很简单，我们实现如下代码： impl Frombool for Json fn from(value: bool) - Self Json::Boolean(value) impl Fromstr for Json fn from(value: str) - Self Json::String(value.to_string()) impl Fromf64 for Json fn from(value: f64) - Self Json::Number(value) 然后完善我们的 json!，目前的实现如下： #[macro_export]macro_rules! json (null) = Json::Null ; ($value: tt) = Json::from($value) ; 这里我们使用 $value作 为变量来承接匹配到的元素，其类型为 tt ，表示任意的语法标记树。具体可以参考：片段类型。 这时运行上述测试用例，是没有问题的： PASS [ 0.004s] json-macro tests::test_boolean_number_string_jsonPASS [ 0.004s] json-macro tests::test_null_json 美中不足的是，JSON 结构中的数字类型，其实不一定是 f64，也可以是 i32、u32、f32 或其他的数字类型，如果我们要为这全部的数字类型都实现到 Json 的 From trait，那就多冗余。 这个时候我们又可以实现一个宏，用于快速生成 impl FromT for Json 。这个实现比较简单，本文就不赘述了，代码如下： #[macro_export]macro_rules! impl_from_for_primitives ( $( $type: ty ) * ) = $( impl From$type for Json fn from(value: $type) - Self Json::Number(value as f64) )* 然后我们只需要用下面这一行代码，就可以为所有的数字类型实现 From trait 了： impl_from_for_primitives!(u8 u16 u32 u64 i8 i16 i32 i64 f32 f64 isize usize); 记得这个时候你要删除上面手动实现的 impl Fromf64 for Json，不然会有 impl 冲突错误。 再次运行测试，也是可以通过的。 实现 Array 准备如下测试用例： #[test]fn test_array_json() let json = json!([1, null, string, true]); assert_eq!( json, Json::Array(vec![ Json::Number(1.0), Json::Null, Json::String(string.to_string()), Json::Boolean(true) ]) ) 要匹配 [1, null, string, true]这个模式，笔者的分析过程如下： 首先是外面的两个中括号 [ 和 ] ； 再往里，是一个重复匹配的模式，以 , 分割，可以匹配 0 到任意多个元素，所以是 $( ,*) ，具体可以参考：重复模式； 最里面就是第 2 步要匹配的元素了，我们先用 $element 作为变量来承接每一个元素，其类型为 tt ，表示任意的语法标记树。 分析完匹配的表达式后，我们就可以得到： ([ $( $element:tt ), * ]) = /* TODO */ 我们要生成的代码长这个样子： Json::Array(vec![ Json::Number(1.0), Json::Null, Json::String(string.to_string()), Json::Boolean(true)]) 其实就是一个 vec!，然后里面每个元素都是一个 Json，如此递归下去。 即可以得到代码生成部分的逻辑为： Json::Array(vec![$(json!($element)),* ]) 综上，我们实现的代码如下： #[macro_export]macro_rules! json (null) = Json::Null ; ([ $( $element: tt),* ]) = Json::Array(vec![ $( json!($element)), * ]) ; ($value: tt) = Json::from($value) ; 运行测试用例： PASS [ 0.003s] json-macro tests::test_null_jsonPASS [ 0.003s] json-macro tests::test_boolean_number_string_jsonPASS [ 0.004s] json-macro tests::test_array_json 实现 Object 写好如下测试用例，这次我们顺带把 Null、Boolean、Number 和 String 带上了： #[test]fn test_object_json() let json = json!( null: null, name: hedon, age: 10, is_student: true, detail: address: beijing, phone: 1234567890 ); assert_eq!( json, Json::Object(HashMap::from([ (name.to_string(), Json::String(hedon.to_string())), (age.to_string(), Json::Number(10.0)), (is_student.to_string(), Json::Boolean(true)), ( detail.to_string(), Json::Object(HashMap::from([ (address.to_string(), Json::String(beijing.to_string())), (phone.to_string(), Json::String(1234567890.to_string())) ])) ) ])) ) 对比预期的 json! 宏内容和展开后的代码： 完善我们的 macro_rules! json ： #[macro_export]macro_rules! json (null) = Json::Null ; ([ $( $element: tt),* ]) = Json::Array(vec![ $( json!($element)), * ]) ; ( $( $key:tt : $value:tt ),* ) = Json::Object(HashMap::from([ $( ( $key.to_string(), json!($value) ) ), * ])) ; ($value: tt) = Json::from($value) ; 运行测试用例： PASS [ 0.004s] json-macro tests::test_object_jsonPASS [ 0.005s] json-macro tests::test_array_jsonPASS [ 0.004s] json-macro tests::test_null_jsonPASS [ 0.005s] json-macro tests::test_boolean_number_string_json 至此，我们就完成了 json! 宏的构建了！完整源码可见：完整代码 Peace! Enjoy coding~ 附录 重复模式 在 实现 Array 中，我们匹配了这样一个模式： ([ $( $element:tt ), * ]) = /* TODO */ 其中 $($element:tt), *) 就是一个重复模式，其可以进一步抽象为 $( ... ),* ，表示匹配 0 次或多次，以 , 分隔。 Rust 支持以下全部重复模式： 模式 含义 $( … ) * 匹配 0 次或多次，没有分隔符 $( … ), * 匹配 0 次或多次，以逗号分隔 $( … ); * 匹配 0 次或多次，以分号分隔 $( … ) + 匹配 1 次或多次，没有分隔符 $( … ), + 匹配 1 次或多次，以逗号分隔 $( … ); + 匹配 1 次或多次，以分号分隔 $( … ) ? 匹配 0 次或 1 次，没有分隔符 即： * 表示 0 次或多次 + 表示 1 次或多次 ? 表示 0 次或 1 次 可在上述 3 者之前加入分隔符 片段类型 在 实现 Array 中，我们匹配了这样一个模式： ([ $( $element:tt ), * ]) = /* TODO */ 这里我们将 $element 指定为 tt，这个 tt 就是宏中的一种片段类型。 tt 能匹配单个语法标记树，包含： 一对括号，如 (..)、[..]、或 .. ，以及位于其中的所有内容，包括嵌套的语法标记树。 单独的非括号语法标记，比如 1926 或 Knots 。 所以为了匹配任意类型的 Json ，我们选择了 tt 作为 $element 的片段类型。 macro_rules! 支持的片段类型如下所示： 片段类型 匹配（带例子） 后面可以跟 ······ expr 表达式：2 + 2, “udon”, x.len() =,; stmt 表达式或声明，不包括任何尾随分号（很难用，请尝试使用 expr 或 block） =,; ty 类型：String, Vec, (str, bool), dyn Read + Send =,; = path 路径：ferns, ::std::sync::mpsc =,; = pat 模式：_, Some(ref x) =,= item 语法项：struct Point { x: f64, y: f64 }, mod ferns; 任意 block 块：{ s += “ok ”; true } 任意 meta 属性的主体：inline, derive(Copy, Clone), doc=“3D models.” 任意 literal 字面量值：1024, “Hello, world!”, 1_000_000f64 任意 lifetime 生命周期：'a, 'item, 'static 任意 vis 可见性说明符：pub, pub(crate), pub(in module::submodule) 任意 ident 标识符：std, Json, longish_variable_name 任意 tt 语法标记树：;, =, {}, [0 1 (+ 0 1)] 任意 完整代码 use std::collections::HashMap;#[derive(Debug, Clone, PartialEq)]#[allow(unused)]enum Json Null, Boolean(bool), String(String), Number(f64), Array(VecJson), Object(HashMapString, Json),impl Frombool for Json fn from(value: bool) - Self Json::Boolean(value) impl Fromstr for Json fn from(value: str) - Self Json::String(value.to_string()) impl FromString for Json fn from(value: String) - Self Json::String(value) #[macro_export]macro_rules! impl_from_for_primitives ( $( $type: ty ) * ) = $( impl From$type for Json fn from(value: $type) - Self Json::Number(value as f64) )* impl_from_for_primitives!(u8 u16 u32 u64 i8 i16 i32 i64 f32 f64 isize usize);#[macro_export]macro_rules! json (null) = Json::Null ; ([ $( $element: tt),* ]) = Json::Array(vec![ $( json!($element)), * ]) ; ( $( $key:tt : $value:tt ),* ) = Json::Object(HashMap::from([ $( ( $key.to_string(), json!($value) ) ), * ])) ; ($value: tt) = Json::from($value) ;#[cfg(test)]mod tests use super::*; #[test] fn test_null_json() let json = json!(null); assert_eq!(json, Json::Null); #[test] fn test_boolean_number_string_json() let json = json!(true); assert_eq!(json, Json::Boolean(true)); let json = json!(1.0); assert_eq!(json, Json::Number(1.0)); let json = json!(hello); assert_eq!(json, Json::String(hello.to_string())); #[test] fn test_object_json() let json = json!( null: null, name: hedon, age: 10, is_student: true, detail: address: beijing, phone: 1234567890 ); assert_eq!( json, Json::Object(HashMap::from([ (null.to_string(), Json::Null), (name.to_string(), Json::String(hedon.to_string())), (age.to_string(), Json::Number(10.0)), (is_student.to_string(), Json::Boolean(true)), ( detail.to_string(), Json::Object(HashMap::from([ (address.to_string(), Json::String(beijing.to_string())), (phone.to_string(), Json::String(1234567890.to_string())) ])) ) ])) ) #[test] fn test_array_json() let json = json!([1, null, string, true]); assert_eq!( json, Json::Array(vec![ Json::Number(1.0), Json::Null, Json::String(string.to_string()), Json::Boolean(true) ]) )","tags":["Rust","宏","元编程"],"categories":["Rust","Rust 实战"]},{"title":"xgo 原理探索","path":"/2024/05/23/go-xgo-explore/","content":"Go 单测 mock 方案 Mock 方法 原理 依赖 优点 缺点 接口 Mock 为依赖项定义接口，并提供接口的 Mock 实现。 需要定义接口和 Mock 实现。 灵活，遵循 Go 的类型系统；易于替换实现。 需要更多的样板代码来定义接口和 Mock 实现。 Monkey Patching（bouk/moneky） 直接修改函数指针的内存地址来实现对函数的替换。 内存保护；汇编代码。 强大，可以 Mock 任何函数，甚至第三方库的函数。 复杂，容易出错；线程不安全；依赖系统指令集。 bouk/monkey 弊端 bouk/monkey 🐒 monkey 的核心功能是能够在运行时替换某个函数的实现。 原理： 函数指针替换：在 Go 语言中，函数的地址存储在内存中。bouk/monkey 通过直接修改函数指针的内存地址来实现对函数的替换。 汇编代码：使用了汇编代码来实现对函数入口的跳转。这些汇编代码会在函数被调用时，将执行流重定向到新的函数实现。 内存保护：为了修改内存中的函数指针，bouk/monkey 需要临时修改内存页面的保护属性（例如，将页面设为可写）。在修改完毕后，它会恢复原来的保护属性。 反射与 unsafe 包：利用 Go 的反射机制和 unsafe 包，bouk/monkey 可以获取并操作函数的底层实现细节。 实现步骤： 保存原函数：在替换函数之前，bouk/monkey 会保存原始函数的指针，以便在需要时恢复或调用原始函数。 生成跳转代码：bouk/monkey 生成一段汇编跳转代码，这段代码会在函数调用时，将执行流跳转到新的函数实现。 修改函数指针：使用 unsafe 包，bouk/monkey 修改目标函数的入口地址，指向生成的跳转代码。 恢复内存保护：在完成上述修改后，恢复内存页面的保护属性。 有以下几个弊端： 如果启用了内联，Monkey 有时无法修补函数。尝试在禁用内联的情况下运行测试，例如: go test -gcflags=-l。同样的命令行参数也可以用于构建。 Monkey 不能在一些面向安全的操作系统上工作，这些操作系统不允许同时写入和执行内存页。目前的方法并没有真正可靠的解决方案。 线程不安全的。 依赖指令集。 先看 xgo 怎么用 xgo 😈 代码结构如下： .├── greet.go└── greet_test.go 现在在 greet.go 中有一个函数 greet： func greet(s string) string return hello + s 在真实的生产环境中，greet 可能要复杂得多，它可能会依赖各种第三方 API，也可能会依赖数据库等多种外部组件。所以在测试的时候，我们希望对其进行 mock，使其返回一个固定的值，便于我们撰写单元测试。 xgo 参考了 go-monkey 的思想，但是不从 修改指令 这个途径入手，而是另辟蹊径，从 代码重写 的角度实现了 mock 的能力。 为了使用 xgo，我们需要先安装 xgo 这个命令： go install github.com/xhd2015/xgo/cmd/xgo@latest 同时在我们的项目中需要引入 xgo 依赖： go get github.com/xhd2015/xgo/runtime/mock 我们编写的 greet_test.go 如下： package xgo_useimport (\ttesting\tgithub.com/xhd2015/xgo/runtime/mock)func TestOriginGreet(t *testing.T) res := greet(world)\tif res != hello world t.Fatalf(greet() = %q; want %q, res, hello world)\tfunc TestMockGreet(t *testing.T) mock.Patch(greet, func(s string) string return mock + s\t)\tres := greet(world)\tif res != mock world t.Fatalf(greet() = %q; want %q, res, mock world) 可以看到在 TestMockGreet 这个单元测试中，我们将 greet 进行了 mock，返回 mock + s。 mock.Patch(greet, func(s string) string return mock + s) 为了使用 xgo 的能力，我们在执行单元测试的时候，需要运行以下命令： xgo test -v ./ 输出大致如下： ➜ xgo-use git:(master) xgo test -v ./xgo is taking a while to setup, please wait...=== RUN TestOriginGreet--- PASS: TestOriginGreet (0.00s)=== RUN TestMockGreet--- PASS: TestMockGreet (0.00s)PASSok xgo-explore/xgo-use (cached) xgo 的核心原理 xgo 的核心原理是利用 go build -toolexec 的能力。 运行以下命令： go help build 找到 toolexec 的相关说明： -toolexec cmd args a program to use to invoke toolchain programs like vet and asm. For example, instead of running asm, the go command will run cmd args /path/to/asm arguments for asm. The TOOLEXEC_IMPORTPATH environment variable will be set, matching go list -f .ImportPath for the package being built. 一言以蔽之：-toolexec 允许对 go 工具链进行拦截，包括 vet、asm、compile 和 link。 这种技术也被称为：插桩（stubbing）、增强（instrumentation）和代码重写（rewriting）。 基于上述分析，xgo 提出了 代码重写 的思路，实现了 在编译过程中插入拦截器代码 的功能： 所以上述我们的 greet.go 文件中的源代码： func greet(s string) string return hello + s 经过 xgo 编译后最终实际编译的代码如下： import runtimefunc greet(s string) (r0 string) stop, post := runtime.__xgo_trap(Greet, s, r0) if stop return defer post() return hello + s 如图所示，一旦函数被调用，它的控制流首先转移到 Trap，然后一系列拦截器将根据其目的检查当前调用是否应该被 Mock、修改、记录或停止。 如果 greet 注册了 mock 函数，那么就会在 __xgo_trap 中调用 mock 的函数，并将返回值设置到 r0 上进行返回，而跳过原始的执行逻辑。 第 1 步：死代码实现 ➜ 01-deadcode git:(master) tree.├── greet.go├── greet_test.go└── mock.go 我们先从最简单的实现开始，采用侵入性代码实现 xgo 的核心功能，这里我们还用不到 -toolexec。 代码结构如上所示，在 mock.go 中，我们有如下代码： var mockFuncs = sync.Mapfunc RegisterMockFunc(funcName string, fun interface) mockFuncs.Store(funcName, fun) mockFuncs: 用于承载函数与 mock 函数的对应关系，其中 key 为函数名称，value 为 mock 函数。我们使用 sync.Map 来保证并发安全。 RegisterMockFunc 用于为指定的 funcName 注册 mock 函数。 在 greet.go 中，我们有一个 Greet 函数： func Greet(s string) string return hello + s 如果我们要对其支持 mock，那么需要修改其实现为： func Greet(s string) string fun, ok := mockFuncs.Load(Greet)\tif ok f, ok := fun.(func(s string) string) if ok return f(s) return hello + s 在修改后的代码中，我们先判断是否存在 mock 函数，如果存在，则执行 mock 函数，否则执行原始逻辑。 现在我们在 greet_test.go 中编写测试代码： func TestMockGreet(t *testing.T) RegisterMockFunc(Greet, func(s string) string return mock + s\t)\tres := Greet(world)\tif res != mock world t.Fatalf(Greet() = %q; want %q, res, mock world)\tfunc TestOriginGreet(t *testing.T) res := Greet(world)\tif res != hello world t.Fatalf(Greet() = %q; want %q, res, hello world) 执行测试： # 单独执行 TestMockGreet➜ 01-deadcode git:(master) ✗ go test -v -run TestMockGreet=== RUN TestMockGreet--- PASS: TestMockGreet (0.00s)PASSok xgo-explore/01-deadcode 0.103s# 单独执行 TestOriginGreet➜ 01-deadcode git:(master) ✗ go test -v -run TestOriginGreet=== RUN TestOriginGreet--- PASS: TestOriginGreet (0.00s)PASSok xgo-explore/01-deadcode 0.102s# 一起执行➜ 01-deadcode git:(master) ✗ go test -v -run $Test$=== RUN TestMockGreet--- PASS: TestMockGreet (0.00s)=== RUN TestOriginGreet greet_test.go:20: Greet() = mock world; want hello world--- FAIL: TestOriginGreet (0.00s)FAILexit status 1FAIL xgo-explore/01-deadcode 0.102s 我们会发现单独执行都是 ok 的，不过一起执行的话 TestOriginGreet 就失败了，这是因为先执行了 TestMockGreet，这个时候已经往 mockFunc 中注册了 mock 函数了，所以 TessOriginGreet 就执行失败了。 这里需要在协程层面上做 mock 隔离，xgo 的思路是在编译时注入 getg() 函数来获取当前协程信息从而实现在注册 mock 函数时进行协程隔离。本文将聚焦在 xgo 的核心原理 代码重写 上，故暂时不考虑这一块。 Ok，那么短短几行代码，我们就将 xgo 的最核心思想给展示出来了。可以看到，xgo 的核心思想是往源代码中加入 合法的 Go 代码，所以不涉及指令重写，故而只要你的机器能执行 Go 程序，天然就支持 mock 功能，这就天然达到了架构无关的兼容性了。同时我们也使用了 sync.Map 来保证了并发安全。 第 2 步：死代码拦截器 ➜ 02-deadcode-interceptor git:(master) tree.├── greet.go├── greet_test.go└── mock.go 在第 1 步中，这段代码我觉得有点冗长了： fun, ok := mockFuncs.Load(Greet)if ok f, ok := fun.(func(s string) string) if ok return f(s) 参考 xgo 的函数签名，我们对其进行优化，在 mock.go 中加入一个 丐版拦截器： // mock.gofunc InterceptMock(funcName string, arg string, result *string) bool fn, ok := mockFuncs.Load(funcName)\tif ok f, ok := fn.(func(s string) string) if ok *result = f(arg) return true return false 对应 greet.go 中 Greet 函数就修改为： func Greet(s string) (res string) if InterceptMock(Greet, s, res) return res return hello + s 这看起来就清爽多了。再次执行测试代码，一样是可以通过的。 ➜ 02-deadcode-interceptor git:(master) go test -v -run TestOriginGreet=== RUN TestOriginGreet--- PASS: TestOriginGreet (0.00s)PASSok xgo-explore/02-deadcode-interceptor 0.331s➜ 02-deadcode-interceptor git:(master) go test -v -run TestMockGreet=== RUN TestMockGreet--- PASS: TestMockGreet (0.00s)PASSok xgo-explore/02-deadcode-interceptor 0.103s 第 3 步：toolexec 初探 ➜ 03-toolexec-static git:(master) tree.├── cmd│ └── mytool│ └── mytool.go├── greet.go├── main.go├── mock.go└── script.sh 这里 mock.go 没有任何变化。我们期望使用 -toolexec 来修改源代码，以实现 mock 无源代码侵入的特性，所以我们在 greet.to 中将 Greet 函数恢复为只关注实际功能的样子： func Greet(s string) (res string) return hello + s 同时为了更好地测试使用 -toolexec 编译后的运行结果，这里将 greet_test.go 删除了并新增了 main.go 文件，内容如下： func main() res := Greet(world)\tif res != hello world log.Fatalf(Greet() = %q; want %q, res, hello world) RegisterMockFunc(Greet, func(s string) string return mock + s\t)\tres = Greet(world)\tif res != mock world log.Fatalf(Greet() = %q; want %q, res, mock world) log.Println(run successfully) 那么 -toolexec 要执行的命令怎么实现呢？在 Google 搜索 go toolexec 你会看到官方给出的一个案例：toolexec.txt。 核心部分在最下面，参考这个示例，我们来实现自己的 toolexec： mkdir -p cmd/mytooltouch cmd/mytool/mytool.go 在mytool.go 中，我们先写这么点代码，看一下会输出什么。 func main() tool, args := os.Args[1], os.Args[2:]\tif len(args) 0 args[0] == -V=full // dont do anything to infuence the version full output. else if len(args) 0 fmt.Printf(tool: %s , tool) fmt.Printf(args: %v , args) // 继续执行之前的命令\tcmd := exec.Command(tool, args...)\tcmd.Stdout = os.Stdout\tcmd.Stderr = os.Stderr\tif err := cmd.Run(); err != nil log.Fatalf(run command error: %v , err) 这里我们企图输出执行的工具 tool 及传给它的参数 args。由于 -V=full 的作用是在终端输出版本信息，所以我们要跳过它，避免产生干扰。输出日志后，我们暂且先继续执行原始的命令，不对编译过程做其他的干扰。 Ok，现在就来看看这个 -toolexec 到底做了什么，在 03-toolexec-static 目录下执行以下命令： # 清除缓存，一直使用最新的编译结果go clean -cache -modcache -i -r# 编译 mytoolgo build ./cmd/mytool# 编译业务程序go build -toolexec=./mytool -o main 因为这几个命令经常会用到，所以我们可以将其封装到 script.sh 文件中： touch script.shchmod +x script.sh 内容如下： #!/bin/bashgo clean -cache -modcache -i -rgo build ./cmd/mytoolgo build -toolexec=./mytool -o main 执行上述命令后，可以看到以下输出： ➜ 03-toolexec-static git:(master) ./script.sh# xgo-explore/03-toolexec-statictool: /opt/homebrew/Cellar/go/1.22.3/libexec/pkg/tool/darwin_arm64/compileargs: [-o $WORK/b001/_pkg_.a -trimpath $WORK/b001= -p main -lang=go1.22 -complete -buildid PcS9clqF_ny_Ds5N0i_s/PcS9clqF_ny_Ds5N0i_s -goversion go1.22.3 -c=4 -shared -nolocalimports -importcfg $WORK/b001/importcfg -pack ./greet.go ./main.go ./mock.go]# xgo-explore/03-toolexec-statictool: /opt/homebrew/Cellar/go/1.22.3/libexec/pkg/tool/darwin_arm64/linkargs: [-o $WORK/b001/exe/a.out -importcfg $WORK/b001/importcfg.link -buildmode=pie -buildid=KgnnCoU_6enHkOm-T62Z/PcS9clqF_ny_Ds5N0i_s/H80dtgGZw1L8mTtVqJBf/KgnnCoU_6enHkOm-T62Z -extld=cc $WORK/b001/_pkg_.a] 可以看到执行了 compile 和 link 两个工具，compile 是编译过程，将生成 .out 文件，而 link 是将多个 .out 文件链接成一个可执行文件。这是很经典的编译过程，如果对 Go 语言的编译过程感兴趣，也可以参考官方的 Go Compile Readme，或者笔者撰写的 Go1.21.0 程序编译过程。 这里我们需要重点关注的是 compile 命令，它是负责编译源代码的，涉及到的源代码文件会通过 -pack ./greet.go ./main.go ./mock.go 传递给 compile 命令。 结合 -toolexec 的帮助信息： -toolexec cmd args a program to use to invoke toolchain programs like vet and asm. For example, instead of running asm, the go command will run cmd args /path/to/asm arguments for asm. The TOOLEXEC_IMPORTPATH environment variable will be set, matching go list -f .ImportPath for the package being built. 我们只需要在执行 compile 命令之前，在 cmd args 这个环节，进行 代码重写 就可以实现我们想要的功能了。 我们现在是要对 greet.go 里面的 Greet 函数进行重写，先看看之前的代码： package mainfunc Greet(s string) (res string) return hello + s 重写后的代码应该跟我们之前 第 2 步 是一样的： package mainfunc Greet(s string) (res string) if InterceptMock(Greet, s, res) return res return hello + s 这里有 n 多种方式可以做到，现在笔者决定使用最暴力的方式，直接临时创建一个包含这段代码的文件 tmp.go，并替换掉传给 compile 的参数，即将 -pack ./greet.go ./main.go ./mock.go 替换为 -pack tmp.go ./main.go ./mock.go 综上，cmd/mytool/mytool/go 实现的代码如下： func main() tool, args := os.Args[1], os.Args[2:]\tif len(args) 0 args[0] == -V=full // dont do anything to infuence the version full output. else if len(args) 0 if filepath.Base(tool) == compile index := findGreetFile(args) if index -1 f, err := os.Create(tmp.go) if err != nil log.Fatalf(create tmp.go error: %v , err) defer f.Close() defer os.Remove(tmp.go) _, _ = f.WriteString(newCode) args[index] = tmp.go fmt.Printf(tool: %s , tool) fmt.Printf(args: %v , args) // 继续执行之前的命令\tcmd := exec.Command(tool, args...)\tcmd.Stdout = os.Stdout\tcmd.Stderr = os.Stderr\tif err := cmd.Run(); err != nil log.Fatalf(run command error: %v , err)\tfunc findGreetFile(args []string) int for i, arg := range args if strings.Contains(arg, greet.go) return i return -1var newCode = `package mainfunc Greet(s string) (res string) if InterceptMock(Greet, s, res) return res return hello + s` 这里我先使用 findGreetFile 来查找 greet.go 文件所处的参数位置，如果找到了，则生成新的 tmp.go 文件，并替换参数，最后在 本次 compile 命令执行完毕后，删除 tmp.go，“毁尸灭迹”。 执行 ./script.sh 重新编译： ➜ 03-toolexec-static git:(master) ✗ ./script.sh# xgo-explore/03-toolexec-statictool: /opt/homebrew/Cellar/go/1.22.3/libexec/pkg/tool/darwin_arm64/compileargs: [-o $WORK/b001/_pkg_.a -trimpath $WORK/b001= -p main -lang=go1.22 -complete -buildid PcS9clqF_ny_Ds5N0i_s/PcS9clqF_ny_Ds5N0i_s -goversion go1.22.3 -c=4 -shared -nolocalimports -importcfg $WORK/b001/importcfg -pack tmp.go ./main.go ./mock.go]# xgo-explore/03-toolexec-statictool: /opt/homebrew/Cellar/go/1.22.3/libexec/pkg/tool/darwin_arm64/linkargs: [-o $WORK/b001/exe/a.out -importcfg $WORK/b001/importcfg.link -buildmode=pie -buildid=KgnnCoU_6enHkOm-T62Z/PcS9clqF_ny_Ds5N0i_s/H80dtgGZw1L8mTtVqJBf/KgnnCoU_6enHkOm-T62Z -extld=cc $WORK/b001/_pkg_.a] 输出的结果中可以看到已经将 compile 的参数替换为 -pack tmp.go ./main.go ./mock.go 了。 现在我们来执行生成的程序文件，可以看到是执行成功的。 ➜ 03-toolexec-static git:(master) ✗ ./main2024/05/23 17:53:52 run successfully 如果我们不使用 -toolexec，是执行不成功的： ➜ 03-toolexec-static git:(master) ✗ go clean -cache -modcache -i -r➜ 03-toolexec-static git:(master) ✗ go build -o main➜ 03-toolexec-static git:(master) ✗ ./main2024/05/23 17:54:33 Greet() = hello world; want mock world 第 4 步：使用 AST 在函数前插入代码 ➜ 04-toolexec-ast git:(master) ✗ tree.├── cmd│ └── mytool│ └── mytool.go├── greet.go├── main.go├── mock.go└── script.sh 暴力替换源代码文件的方式可能是不太优雅哈，假如我们的 greet.go 内容改成下面这样： package mainfunc Greet(s string) (res string) return hello + sfunc Greet2(s string) (res string) return hello 2 + s 如果我们想对 Greet2 也进行 代码重写，那就需要修改前面 newCode 字段的内容，而且它是写死的，确实不太优雅。现在我们正式来面对这件事，对比修改后的函数： func Greet(s string) (res string) if InterceptMock(Greet, s, res) return res return hello + s 其实就是在每个函数前加上这么一段： if InterceptMock(Greet, s, res) return res 了解过编译原理的读者应该可以想到，我们可以通过操作源代码的 AST 结构，往函数的开头插入这段代码即可。如果我们先不考虑参数和返回值的话，那这段代码我们需要替换的地方就是函数名称了，所以它的结构如下： if InterceptMock($funcName, s, res) return res 这里我们需要用到几个标准库工具： go/ast: 包定义了 Go 编程语言的抽象语法树（AST），核心有以下几种类型： File: 表示一个 Go 源文件。 Decl: 表示一个声明，包括函数声明、变量声明、类型声明等。 Stmt: 表示一个语句。 Expr: 表示一个表达式。 go/token: 定义了处理 Go 源代码的词法元素的基础设施，包括位置、标记和标识符等。这个包提供了用于管理源代码位置的信息，可以帮助定位代码中的特定部分。 go/parser: 将一个 .go 文件以解析成 AST 结构。 go/printer: 提供了将 AST 格式化并输出为 Go 源码的功能 修改后的 cmd/mytool/mytool.go 代码如下： func main() tool, args := os.Args[1], os.Args[2:]\tif len(args) 0 args[0] == -V=full // dont do anything to infuence the version full output. else if len(args) 0 if filepath.Base(tool) == compile index := findGreetFile(args) if index -1 filename := args[index] f, err := os.Create(tmp.go) defer f.Close() defer os.Remove(tmp.go) if err != nil log.Fatalf(create tmp.go error: %v , err) _, _ = f.WriteString(insertCode(filename)) args[index] = tmp.go fmt.Printf(tool: %s , tool) fmt.Printf(args: %v , args) // 继续执行之前的命令\tcmd := exec.Command(tool, args...)\tcmd.Stdout = os.Stdout\tcmd.Stderr = os.Stderr\tif err := cmd.Run(); err != nil log.Fatalf(run command error: %v , err)\tfunc findGreetFile(args []string) int for i, arg := range args if strings.Contains(arg, greet.go) return i return -1func insertCode(filename string) string fset := token.NewFileSet()\tfast, err := parser.ParseFile(fset, filename, nil, parser.AllErrors)\tif err != nil log.Fatalf(parse file error: %v , err) for _, decl := range fast.Decls fun, ok := decl.(*ast.FuncDecl) if !ok continue f, err := os.Create(tmp2.go) if err != nil log.Fatalf(create tmp2.go error: %v , err) _, _ = f.WriteString(fmt.Sprintf(newCodeFormat, fun.Name.Name)) f.Close() tmpFset := token.NewFileSet() tmpF, err := parser.ParseFile(tmpFset, tmp2.go, nil, parser.AllErrors) if err != nil log.Fatalf(parse tmp2.go error: %v , err) fun.Body.List = append(tmpF.Decls[0].(*ast.FuncDecl).Body.List, fun.Body.List...) os.Remove(tmp2.go) var buf bytes.Buffer\tprinter.Fprint(buf, fset, fast)\tfmt.Println(buf.String())\treturn buf.String()var newCodeFormat = `package mainfunc TmpFunc() if InterceptMock(%s, s, res) return res ` 核心的修改在于 insertCode 函数： 使用 parser.ParseFile 将源代码文件解析成 AST 结构； 遍历 AST 结构，找到所有的声明（Decl）结构，并使用 decl(.ast.FuncDecl) 找到所有的函数； FuncDecl struct Doc *CommentGroup // associated documentation; or nil Recv *FieldList // receiver (methods); or nil (functions) Name *Ident // function/method name Type *FuncType // function signature: type and value parameters, results, and position of func keyword Body *BlockStmt // function body; or nil for external (non-Go) functionBlockStmt struct Lbrace token.Pos // position of List []Stmt Rbrace token.Pos // position of , if any (may be absent due to syntax error) 查看 ast.FuncDecl 的结构后，可以得出下一步就是往 FuncDecl.Body.List 列表前面插入一些 Stmt； 笔者没找到类似 parseStmt 方法，所以取了个巧，我定义了一段代码的 format，里面的 %s 会使用 fun.Name.Name 获取函数名并进行替换。 var newCodeFormat = `package mainfunc TmpFunc() if InterceptMock(%s, s, res) return res ` 创建一个临时文件 tmp2.go 并写入格式化后的代码，然后再次调用 parser.ParseFile 得到解析这段代码的抽象语法树结构 tmpF 了； 然后通过 tmpF.Decls[0].(*ast.FuncDecl).Body.List 就可以得到 TmpFunc 中的语句 Stmt 了； 将其加在源代码函数的前面即可：fun.Body.List = append(tmpF.Decls[0].(*ast.FuncDecl).Body.List, fun.Body.List...)； 然后再使用 go/printer 将修改后的 AST 输出为新文件内容。 通过上述步骤，我们就可以为 greet.go 中的每个函数前面都插入打桩代码了。 修改 main.go 里面的内容，加入对 Greet2 的测试： func main() res := Greet(world)\tif res != hello world log.Fatalf(Greet() = %q; want %q, res, hello world) RegisterMockFunc(Greet, func(s string) string return mock + s\t)\tres = Greet(world)\tif res != mock world log.Fatalf(Greet() = %q; want %q, res, mock world) log.Println(run greet 1 successfully)\tRegisterMockFunc(Greet2, func(s string) string return mock 2 + s\t)\tres = Greet2(world)\tif res != mock 2 world log.Fatalf(Greet2() = %q; want %q, res, mock 2 world) log.Println(run greet 2 successfully) 执行脚本： ./script.sh 输出应该还是跟之前是一样的，我们运行生成的可执行函数，得到如下结果那就说明我们又成功进了一步了~ ➜ 04-toolexec-ast git:(master) ✗ ./main2024/05/23 20:03:22 run greet 1 successfully2024/05/23 20:03:22 run greet 2 successfully 第 5 步：使用 reflect 反射动态获取参数和返回值名称 ➜ 05-toolexec-general git:(master) ✗ tree.├── cmd│ └── mytool│ └── mytool.go├── greet.go├── main.go├── mock.go└── script.sh 接下来我们来处理函数签名中的参数和返回值部分，我们的样板代码中，写死了参数的名称和返回值的名称，现在我们需要来动态获取函数参数的名称和返回值的名称，如果返回值没有名称，那我们还需要手动设置名称。 我们将 greet.to 修改为以下内容： func Greet(s string) (res string) return hello + sfunc Greet2(s2 string) (res2 string) return hello 2 + s2func Greet3(s3 string) string return hello 3 + s3 函数的信息当然都在前面获得的 ast.FuncDecl 结构中，再次观察其结构： FuncDecl struct Doc *CommentGroup // associated documentation; or nil Recv *FieldList // receiver (methods); or nil (functions) Name *Ident // function/method name Type *FuncType // function signature: type and value parameters, results, and position of func keyword Body *BlockStmt // function body; or nil for external (non-Go) function 通过注释就可以知道 Type 字段就包含了参数和返回值的相关信息，查看 FuncType 结构，如下： FuncType struct Func token.Pos // position of func keyword (token.NoPos if there is no func) TypeParams *FieldList // type parameters; or nil Params *FieldList // (incoming) parameters; non-nil Results *FieldList // (outgoing) results; or nil Params：函数参数 Results：函数返回值 查看 FieldList 结构，可知参数列表和返回值列表都在相应的 List 字段中，而其中的 Names 字段就是参数的名称了。 type FieldList struct Opening token.Pos // position of opening parenthesis/brace/bracket, if any\tList []*Field // field list; or nil\tClosing token.Pos // position of closing parenthesis/brace/bracket, if anytype Field struct Doc *CommentGroup // associated documentation; or nil\tNames []*Ident // field/method/(type) parameter names; or nil\tType Expr // field/method/parameter type; or nil\tTag *BasicLit // field tag; or nil\tComment *CommentGroup // line comments; or nil 补充一下，这里为什么 Names 类型是 []*Ident 呢？因为函数有以下的命名方式： func hello(s1, s2 string) (r1, r1 string) 那么在当下，只有 1 个参数和只有 1 个返回值的情况下，我们就可以通过 fun.Type.Params.List[0].Names[0].Name 来获取参数名称，也可以通过 fun.Type.Results.List[0].Names 来获取返回值名称，如果返回值没有名称，那我们就为其设置名称 __xgo_res_1 并写回源 AST 结构。这样就都有名称，就很好处理了。 经上分析， cmd/mytool/mytool.go 中我们只需要修改 insertCode 部分，修改的结果如下： func insertCode(filename string) string fset := token.NewFileSet()\tfast, err := parser.ParseFile(fset, filename, nil, parser.AllErrors)\tif err != nil log.Fatalf(parse file error: %v , err) for _, decl := range fast.Decls fun, ok := decl.(*ast.FuncDecl) if !ok continue f, err := os.Create(tmp.go) if err != nil log.Fatalf(create tmp.go error: %v , err) _, _ = f.WriteString(newCode(fun)) f.Close() tmpFset := token.NewFileSet() tmpF, err := parser.ParseFile(tmpFset, tmp.go, nil, parser.AllErrors) if err != nil log.Fatalf(parse tmp.go error: %v , err) fun.Body.List = append(tmpF.Decls[0].(*ast.FuncDecl).Body.List, fun.Body.List...) os.Remove(tmp.go) var buf bytes.Buffer\tprinter.Fprint(buf, fset, fast)\tfmt.Println(buf.String())\treturn buf.String()func newCode(fun *ast.FuncDecl) string /* Doc:nil Names:[s] Type:string Tag:nil Comment:nil Doc:nil Names:[res] Type:string Tag:nil Comment:nil Doc:nil Names:[s2] Type:string Tag:nil Comment:nil Doc:nil Names:[res2] Type:string Tag:nil Comment:nil Doc:nil Names:[s3] Type:string Tag:nil Comment:nil Doc:nil Names:[] Type:string Tag:nil Comment:nil\t*/\t// 函数名称\tfuncName := fun.Name.Name\t// 参数列表\targName := fun.Type.Params.List[0].Names[0].Name\t// 返回值列表\tresNames := fun.Type.Results.List[0].Names\tif len(resNames) == 0 resNames = append(resNames, ast.IdentName: _xgo_res_1) fun.Type.Results.List[0].Names = resNames resName := resNames[0].Name\treturn fmt.Sprintf(newCodeFormat, funcName, argName, resName, resName)var newCodeFormat = `package mainfunc TmpFunc() if InterceptMock(%s, %s, %s) return %s ` 现在我们就可以动态获取参数名称和返回值名称了。 修改我们的 main.go，以测试所有的情况： func main() res := Greet(world)\tif res != hello world log.Fatalf(Greet() = %q; want %q, res, hello world) RegisterMockFunc(Greet, func(s string) string return mock + s\t)\tres = Greet(world)\tif res != mock world log.Fatalf(Greet() = %q; want %q, res, mock world) log.Println(run greet 1 successfully)\tRegisterMockFunc(Greet2, func(s string) string return mock 2 + s\t)\tres = Greet2(world)\tif res != mock 2 world log.Fatalf(Greet2() = %q; want %q, res, mock 2 world) log.Println(run greet 2 successfully)\tRegisterMockFunc(Greet3, func(s string) string return mock 3 + s\t)\tres = Greet3(world)\tif res != mock 3 world log.Fatalf(Greet3() = %q; want %q, res, mock 3 world) log.Println(run greet 3 successfully) 执行编译脚本： ./script.sh 执行编译产生的可执行程序，输出如下就说明我们又成功进了一大步~ ➜ 05-toolexec-general git:(master) ✗ ./main2024/05/23 20:15:08 run greet 1 successfully2024/05/23 20:15:08 run greet 2 successfully2024/05/23 20:15:08 run greet 3 successfully 第 6 步：支持多参数和多返回值 ➜ 06-toolexec-multi git:(master) ✗ tree.├── cmd│ └── mytool│ └── mytool.go├── greet.go├── main.go├── mock.go└── script.sh 本文的最后一步，我们来面对一下多参数和多返回值的问题。假设我们又如下函数： func Pair1(s1, s2 string) (res string) return pair 1 + s1 + + s2 这个时候我们 代码重写 后应该长什么样子呢？可以是下面这样的： func Pair1(s1, s2 string) (res string) if InterceptMock(Pair1, s1, s2, res) return res return pair 1 + s1 + + s2 按照这个思路，下面这个函数呢？ func Pair2(s1, s2 string) (res1, res2 string) return pair 1 + s1, pair 2 + s2 那就是这样的？ func Pair2(s1, s2 string) (res1, res2 string) if InterceptMock(Pair2, s1, s2, res1, res2) return res1, res2 return pair 1 + s1, pair 2 + s2 这种思路当然也能实现，换一种更优雅的思路呢？既然是一个列表，那么就可以用切片来承载，也就是可以是这样的： func Pair2(s1, s2 string) (res1, res2 string) if InterceptMock(Pair2, []interfaces1, s2, []interfaceres1, res2) return res1, res2 return pair 1 + s1, pair 2 + s2 那我们就可以抽象出插入代码的模板了： if InterceptMock($funcName, []interface$paramList, []interface$returnListWith) return $returnListWithout 为了实现这个，我们需要先修改一下 mock.go 中的 InterceptMock 函数： func InterceptMock(funcName string, args []interface, results []interface) bool mockFn, ok := mockFuncs.Load(funcName)\tif !ok return false in := make([]reflect.Value, len(args))\tfor i, arg := range args in[i] = reflect.ValueOf(arg) mockFnValue := reflect.ValueOf(mockFn)\tout := mockFnValue.Call(in)\tif len(out) != len(results) panic(mock function return value number is not equal to results number) for i, result := range results reflect.ValueOf(result).Elem().Set(out[i]) return true 拦截器的具体实现如下： 判断是否注册了 mock 函数，没有则直接返回； 将所有参数都放到 []refect.Value 中； 通过反射 refect.ValueOf 获取 mockFn 的值； 调用 mockFnValue.Call() 来执行函数，并返回结果列表； 遍历传进来的返回值引用列表，调用 reflect.ValueOf(result).Elem().Set(out[i]) 将返回值设置回去。 现在我们来修改我们的 -toolexec 工具，来根据函数的 AST 结构，获取参数列表和返回值列表，生成代插入的模板代码，并将其插入到每个函数的开头。这次在 cmd/mytool/mytool.go 中，我们只需修改 newCode 函数： func insertCode(filename string) string fset := token.NewFileSet()\tfast, err := parser.ParseFile(fset, filename, nil, parser.AllErrors)\tif err != nil log.Fatalf(parse file error: %v , err) for _, decl := range fast.Decls fun, ok := decl.(*ast.FuncDecl) if !ok continue f, err := os.Create(tmp.go) if err != nil log.Fatalf(create tmp.go error: %v , err) _, _ = f.WriteString(newCode(fun)) f.Close() tmpFset := token.NewFileSet() tmpF, err := parser.ParseFile(tmpFset, tmp.go, nil, parser.AllErrors) if err != nil log.Fatalf(parse tmp.go error: %v , err) fun.Body.List = append(tmpF.Decls[0].(*ast.FuncDecl).Body.List, fun.Body.List...) os.Remove(tmp.go) var buf bytes.Buffer\tprinter.Fprint(buf, fset, fast)\tfmt.Println(buf.String())\treturn buf.String()func newCode(fun *ast.FuncDecl) string // 函数名称\tfuncName := fun.Name.Name\t// 参数列表\targs := make([]string, 0)\tfor _, arg := range fun.Type.Params.List for _, name := range arg.Names args = append(args, name.Name) // 返回值列表\treturns := make([]string, 0)\treturnRefs := make([]string, 0)\treturnNames := fun.Type.Results.List[0].Names\tif len(returnNames) == 0 for i := 0; i fun.Type.Results.NumFields(); i++ fun.Type.Results.List[0].Names = append(fun.Type.Results.List[0].Names, ast.IdentName: fmt.Sprintf(_xgo_res_%d, i+1)) for _, re := range fun.Type.Results.List[0].Names returns = append(returns, re.Name) returnRefs = append(returnRefs, +re.Name) return fmt.Sprintf(newCodeFormat, funcName, strings.Join(args, ,), strings.Join(returnRefs, ,), strings.Join(returns, ,))var newCodeFormat = `package mainfunc TmpFunc() if InterceptMock(%s, []interface%s, []interface%s) return %s\t` 思路跟之前第 5 步大同小异，不过是用遍历的方式来支持多个参数和多个返回值罢了。 现在我们为 greet.go 添加更多的测试函数，代码如下： func Greet(s string) (res string) return hello + sfunc Greet2(s2 string) (res2 string) return hello 2 + s2func Greet3(s3 string) string return hello 3 + s3func Pair1(s1, s2 string) (res string) return pair 1 + s1 + + s2func Pair2(s1, s2 string) (res1, res2 string) return pair 1 + s1, pair 2 + s2func Other(i int, s string, f float64) string return fmt.Sprintf(int: %d, string: %s, float: %f, i, s, f) 为了测试，我们再次修改 main.go，使其覆盖所有的情况： func main() RegisterMockFunc(Other, func(i int, s string, f float64) string return fmt.Sprintf(mock %d %s %.2f, i, s, f)\t)\tres := Other(1, hello, 3.14)\tif res != mock 1 hello 3.14 log.Fatalf(Other() = %q; want %q, res, mock 1 hello 3.14) log.Println(run other successfully)\tRegisterMockFunc(Pair1, func(s1, s2 string) string return mock 1 + s1 + + s2\t)\tres = Pair1(hello, world)\tif res != mock 1 hello world log.Fatalf(Pair1() = %q; want %q, res, mock 1 hello world) log.Println(run pair1 successfully)\tRegisterMockFunc(Pair2, func(s1, s2 string) (string, string) return mock 2 + s1, mock 2 + s2\t)\tres1, res2 := Pair2(hello, world)\tif res1 != mock 2 hello || res2 != mock 2 world log.Fatalf(Pair2() = %q, %q; want %q, %q, res1, res2, mock 2 hello, mock 2 world) log.Println(run pair2 successfully)\tres = Greet(world)\tif res != hello world log.Fatalf(Greet() = %q; want %q, res, hello world) RegisterMockFunc(Greet, func(s string) string return mock + s\t)\tres = Greet(world)\tif res != mock world log.Fatalf(Greet() = %q; want %q, res, mock world) log.Println(run greet 1 successfully)\tRegisterMockFunc(Greet2, func(s string) string return mock 2 + s\t)\tres = Greet2(world)\tif res != mock 2 world log.Fatalf(Greet2() = %q; want %q, res, mock 2 world) log.Println(run greet 2 successfully)\tRegisterMockFunc(Greet3, func(s string) string return mock 3 + s\t)\tres = Greet3(world)\tif res != mock 3 world log.Fatalf(Greet3() = %q; want %q, res, mock 3 world) log.Println(run greet 3 successfully) 编译代码： ./script.sh 执行生成的可执行程序，如果有以下输出，那我们就又成功进了一大大步了~ ➜ 06-toolexec-multi git:(master) ✗ ./main2024/05/23 20:31:10 run other successfully2024/05/23 20:31:10 run pair1 successfully2024/05/23 20:31:10 run pair2 successfully2024/05/23 20:31:10 run greet 1 successfully2024/05/23 20:31:10 run greet 2 successfully2024/05/23 20:31:10 run greet 3 successfully 更进一步 通过上面 6 个简单的小阶段，我们就已经把 xgo 最最核心的功能给实现了，在一些小场景下还勉强能用？🤡 我们来看看包含测试代码和样例函数，总共用了多少代码： ➜ 06-toolexec-multi git:(master) ✗ tokei .=============================================================================== Language Files Lines Code Comments Blanks=============================================================================== Go 4 281 224 11 46 Shell 1 5 3 1 1=============================================================================== Total 5 286 227 12 47=============================================================================== 短短 224 行代码，这是一个非常了不起的成就！ 当然，优秀的读者肯定可以发现我们这个 丐版 xgo 有太多的不足和缺陷了。这是必然的，我们来看看 xgo 截止 1.0.37 版本，总共有多少行代码： ➜ xgo git:(master) tokei .=============================================================================== Language Files Lines Code Comments Blanks=============================================================================== BASH 1 104 81 11 12 CSS 1 153 118 5 30 Go 369 33232 26836 2588 3808 JavaScript 1 170 146 10 14 JSON 2 435 435 0 0 PowerShell 1 28 16 3 9 Shell 3 288 251 4 33 SVG 1 41 41 0 0 Plain Text 7 192 0 174 18------------------------------------------------------------------------------- HTML 1 19 16 3 0 |- JavaScript 1 6 6 0 0 (Total) 25 22 3 0------------------------------------------------------------------------------- Markdown 17 1455 0 1083 372 |- Go 8 820 635 72 113 |- JSON 1 80 80 0 0 (Total) 2355 715 1155 485=============================================================================== Total 404 36117 27940 3881 4296=============================================================================== 光 Go 代码就有 26836 行了。所以可知 xgo 的作者是做了很多的付出和努力的。不过我们用了不到百分之一的代码量，就将 xgo 最核心的原理展示得淋漓尽致了，感兴趣的读者可以进一步阅读 xgo 的源码，可以进一步探索如何抽象出更通用更简洁更易扩展的 interceptor，如何支持协程隔离，如何优化依赖管理，以及如何实现其他的 trace、coverage 功能。再次为 xgo 打 call 👏！ 参考 xgo repo xgo: 基于代码重写实现 Monkey Patch 和 Trace go compile README xgo: 在 go 中使用-toolexec 实现猴子补丁","tags":["Go","单元测试","开源项目"],"categories":["Go","开源项目"]},{"title":"Kafka 负载均衡挑战及解决思路","path":"/2024/05/20/kafka-load-balance/","content":"本文转载自 Agoda Engineering，介绍了在实际应用中，如何应对 Kafka 负载均衡所遇到的各种挑战，并提出相应的解决思路。本文简要阐述了 Kafka 的并行性机制、常用的分区策略以及在实际操作中遇到的异构硬件、不均匀工作负载等问题。通过深入分析这些挑战，并提供具体的解决方案，本文旨在帮助读者更好地理解和应用 Kafka 的负载均衡技术，从而提高系统的整体性能和稳定性。 以下大部分内容翻译自原文 how-we-solve-load-balancing-challenges-in-apache-kafka，并已获得原作者同意。 思维导图 Kafka 并行性 Kafka 通过分区来实现并行性，如下图所示，生产者（Producer）产生的消息会按照一定的分区策略分配到多个分区（Partition）中，消费组中的每个消费者会分别负责消费其中的若干个分区。 分区策略： 轮询（Round Robin）：默认情况下，Kafka 使用轮询策略将消息均匀地分配到所有分区。 哈希（Key Hashing）：如果消息有分区键，Kafka 会对键进行哈希计算，将消息分配到特定的分区。 自定义分区策略：开发者可以实现自定义的分区器（Partitioner）逻辑，以满足特定需求。 如果要使用轮询或者哈希策略来达到“负载均衡”的目的，那么需要满足以下 2 个假设： 消费者拥有相同的处理能力， 消息的工作量相等。 然而，在实践中，这些假设往往不成立。 现实挑战 1. 异构硬件 不同代的服务器硬件性能不同，导致处理速率存在差异。例如，使用不同代硬件进行处理的基准显示性能存在显着差异： 2. 每条 Kafka 消息的工作负载不均匀 下图显示了在一个时间窗口内到达的 12 条消息。在这里，生产者向该主题中的六个分区中的每一个发布两条消息。因此，每个 worker 消耗来自 2 个分区的数据，这意味着每个 worker 需要处理 4 条消息。 不同的消息可能需要不同的处理步骤集。例如，处理消息可能涉及调用第三方 HTTP 端点，并且不同的响应大小或延迟可能会影响处理速率。此外，对于涉及数据库操作的应用程序，其数据库查询的延迟可能会根据查询参数而波动，从而导致处理速率发生变化。 3. 过度配置问题 由于工作负载和处理效率不同，为了达到系统吞吐量的需求，可能会出现过度配置问题，从而导致资源浪费。 假设我们的高吞吐量和低吞吐量的处理速率分别为 20 msg/s 和 10 msg/s（根据表 1 中的数据进行简化）。使用两个较快的处理器和一个较慢的处理器，我们预计总容量为 20+20+10 = 50 条消息/秒。但是，当保持消息的循环分配时，我们无法达到此容量。下图显示了如果流量持续达到每秒 50 条消息时会发生什么情况。 从这个例子中我们可以看到，我们的处理器服务一次最多只能接受 30 条消息，以防止滞后并确保及时传递更新。 在这种情况下，要实际每秒处理 50 条消息，我们必须总共扩展到 5 台机器，以保证及时处理所有消息。由于这种不适当的分配逻辑（66.7％的过度配置），我们会向该系统过度配置额外的两台机器。 为了每秒处理 50 条消息，我们需要扩展到五台机器以确保及时处理所有消息。由于这种不适当的分配逻辑（66.7% 的过度配置），这会导致向该系统过度配置两台额外的机器。 静态解决方案 1. 在相同的 Pod（机器）上部署 考虑控制服务部署中使用的硬件类型以缓解问题。如果您在虚拟机上部署服务并拥有充足的资源和性能相同的硬件，则此方法是可行的。 然而，由于成本效益和灵活性下降，在私有云环境中通常不建议采用这种策略，主要是因为同时升级所有现有硬件可能具有挑战性。如果它非常适合您的情况，则可以使用Kubernetes 关联性将 Pod 分配给某些类型的节点。 2. 加权负载均衡 如果容量是可预测的并且大部分时间保持静态，则为不同的消费者分配不同的权重可以帮助最大限度地利用可用资源。例如，在为表现较好的消费者赋予更高的权重后，我们可以将更多流量路由给这些消费者。 动态解决方案 虽然我们可以估计消息的容量和工作负载来设计静态规则来确定加权负载平衡策略，但由于以下几个因素，这种方法在实际生产环境中可能并不总是可行： 消息的工作负载并不统一，这使得估计机器容量变得困难。 依赖关系（例如网络和第三方连接）不稳定，有时会导致实际处理中的容量发生变化。 该系统经常添加新功能，增加额外的维护工作以保持权重更新。 为了解决这些问题，我们可以动态监控每个分区中的当前滞后并根据当前流量状况做出相应响应。 有 2 种思路： 生产者角度：使用自定义算法根据滞后的消息数量来确定每个分区的流量，这种生产者称为滞后感知生产者（Lag-aware Producer）。 消费者角度：这些消费者旨在监控当前滞后的消息数量，并可以在必要时取消订阅以触发负载重新平衡。通常，可以采用自定义的重新平衡策略来调整分区分配。这种消费者称为滞后感知消费者（Lag-aware Comsumer）。 1. 从生产者角度出发 如此图所示，生产者可以使用自定义算法根据滞后确定每个分区的流量。为了减少对 Kafka 代理的调用次数，系统可以维护一个内部延迟缓存，而不是在发布每条消息之前调用 Kafka 代理。 使用滞后数据，定制的算法被设计为向经历高滞后的分区发布更少的流量，向低滞后的分区发布更多流量，以平衡每个分区上的工作负载。当滞后平衡且稳定时，此方法应确保消息的均匀分布。 不适用情况： 纯消费者应用程序：您的应用程序不控制消息生成。 **多个消费者组：**当生成的消息被多个消费者组消费时，生产者可能会为其他消费者组产生不必要的倾斜负载，因为滞后只是特定于一个消费者组的信息。 相同队列长度算法 该算法将每个分区滞后视为处理的队列大小。获取滞后信息后，它会发布适当数量的消息以填充短队列。此方法更适合由于异构硬件而导致的倾斜滞后分布，其中高性能 Pod（机器）在大多数情况下能够更快地处理。 异常值检测算法 该算法利用统计方法来确定所有分区的上离群值，并暂时停止那些慢速离群值的发布过程。在原文章中，针对 Agoda 的特定需求，他们提出了 IQR（四分位距）和 STD（标准差）异常值检测算法。算法流程图如下所示。 慢速分区：（已关闭）由于存在延迟，这些分区的消息生成已停止。 好的分区：（打开）照常发布并均匀分发到所有好的分区。 OK 分区：（观察/半开放）为了提高性能不佳的机器的性能，当系统尝试将慢速分区提升为良好分区时，会添加一个观察期。通过仅生成一小部分消息并进行观察，可以将该观察阶段优化为“半开放”状态。当滞后获取间隔相对较长时，半开放是有益的，因为它可以防止消费者延迟等待传入消息而更新的滞后数据尚未查询的情况。 2. 从消费者角度出发 这里 Adoga 提出的思路是：遇到高延迟的实例可以主动取消订阅主题以触发重新平衡。在重新平衡期间，可以使用自定义的分配器来平衡所有消费者实例之间的分区。 触发重新平衡的成本非常昂贵，因为急切的重新平衡会停止消费者组中的所有处理。Kafka 2.4中引入的增量协作再平衡协议已经最大限度地减少了性能影响，允许更频繁的再平衡以更好地分配每个分区上的负载。 为了增强重新分配的灵活性，分区的数量应该大于 worker 的数量。这一比率应根据应用程序而有所不同，并假设一个工作线程至少可以处理来自一个分区的负载以避免饥饿。 总结 本文从 Kafka 并行性的一般实现出发，探讨了 Kafka 实现负载均衡在现实实践中可能遇到的各种挑战，并从静态调整和动态调整两个方面给出了解决思路，特别注重讨论了动态调整策略，并分别从生产者和消费者的角度提出了解决方案。 总之，通过在 Kafka 中实现负载均衡，可以有效地将工作负载分配到可用资源之间，从而显著提高服务性能。具体的算法和策略需要根据实际情况进行选择和调整。","tags":["Kafka","中间件","消息队列"],"categories":["Kafka"]},{"title":"学习记录：用 Go 自制解释器 Monkey","path":"/2024/05/12/monkey-language/","content":"词法分析 TDD：测试驱动开发 先写测试用例，再进行词法分析逻辑的完善。 语法分析 递归下降语法分析伪代码 function parseProgram() program = newProgramASTNode() advanceTokens() for (currentToken() != EOF_TOKEN) statement = null if (currentToken() == LET_TOKEN) statement = parseLetStatement() else if (currentToken() == RETURN_TOKEN) statement = parseReturnStatement() else if (currentToken() == IF_TOKEN) statement = parseIfStatement() if (statement != null) program.Statements.push(statement) advanceTokens() return programfunction parseLetStatement() advanceTokens() identifier = parseIdentifier() advanceTokens() if currentToken() != EQUAL_TOKEN parseError(no equal sign!) return null advanceTokens() value = parseExpression() variableStatement = newVariableStatementASTNode() variableStatement.identifier = identifier variableStatement.value = value return variableStatementfunction parseIdentifier() identifier = newIdentifierASTNode() identifier.token = currentToken() return identifierfunction parseExpression() if (currentToken() == INTEGER_TOKEN) if (nextToken() == PLUS_TOKEN) return parseOperatorExpression() else if (nextToken() == SEMICOLON_TOKEN) return parseIntegerLiteral() else if (currentToken() == LEFT_PAREN) return parseGroupedExpression() // [...]function parseOperatorExpression() operatorExpression = newOperatorExpression() operatorExpression.left = parseIntegerLiteral() operatorExpression.operator = currentToken() operatorExpression.right = parseExpression() return operatorExpression() let x=5 return 5 普拉特解析","tags":["Go","编译原理"],"categories":["Go","Go 实战"]},{"title":"时间处理基础：Rust 的 chrono 库教程","path":"/2024/05/11/rust-crate-chrono/","content":"在开发过程中，我们经常有对时间和日期处理的需求。不论是日历应用、日程安排、还是时间戳记录，准确的时间数据处理都是必不可少的。Rust 社区提供的 chrono 库以其强大的功能和灵活的接口，在 Rust 开发者中广受欢迎。本文将简单介绍 chrono 库，展示如何利用它来精确处理和转换时间和日期，帮助你在任何 Rust 项目中都能高效地管理时间。 版本 chrono: 0.4.38 结论先行 时间相关概念 概念 理解 UNIX 时间戳（UNIX Timestamp） 也称为 POSIX 时间或 Epoch 时间，是自 1970 年 1 月 1 日（UTC 时区）以来经过的秒数，不计入闰秒。这是一种非常通用的时间表示方法，在编程中广泛使用，因为它可以简化时间差的计算。 UTC（协调世界时） 全称为协调世界时（Coordinated Universal Time），是目前国际上广泛采用的时间标准。它基本上与格林威治平均时（GMT）相同，但在技术上更加精确，因为它使用原子钟来保持时间准确。世界各地的时间都是以 UTC 为基础，加上或减去一定的小时数来定义的。 时区（Time Zone） 时区是地球上划分的标准时间区域。由于地球自西向东旋转，每向东移动一定角度，当地的太阳时间就会相应地提前。世界被分成了 24 个时区，每个时区通常相差一小时。时区允许地区内的人们能在大致相同的时间内，经历类似的日夜更替模式。 UTC+8 UTC+8 是 UTC 时间加上 8 小时的时间区。中国大陆就是位于这个时区。例如，当 UTC 时间为 00:00 时，UTC+8 的时间就是 08:00。 chrono 关键类型 类型 含义 适用场景 DateTimeTz 一个带有时区的日期和时间类型，其中 Tz 是实现了 TimeZone 特质的类型，如 Utc 和 Local 。这意味着 DateTime 考虑了时区的影响，可以表示全球任意地点的精确时间。 广泛用于需要考虑时区转换的场景，如存储用户的本地时间或在不同地区之间转换时间。 NaiveDateTime 一个“天真的”日期和时间，即不包含任何时区信息的日期和时间。这种类型仅仅表示一个日历日期和一天中的时间，而没有任何关于地理或政治时区的数据。 对于一些时区不重要的场景非常有用，比如记录电影的发行日期或历史事件的日期。 NaiveDate 仅表示一个日历日期，不包括时间或时区信息。 它用于处理只需要日期而不关心具体时间的场景，如生日、节日等。 NaiveTime 是一个只表示一天中时间的类型，它不包含日期或时区信息。 这个类型适用于需要处理具体某个时间点（如开会时间、日常活动的开始时间）但不需要日期数据的情景。 chrono 时区类型 chrono 支持多种时区类型，方便进行全球时间的转换和计算： Utc: 用于处理协调世界时。 Local: 代表服务器或用户的本地时区。 FixedOffset: 允许定义任意的小时和分钟偏移量，适合固定偏移的时间计算。 常用功能 获取当前时间 let local_datetime: DateTimeLocal = Local::now();let utc_datetime: DateTimeUtc = Utc::now(); DateTime 转 String println!(, local_datetime.to_rfc2822()); // Sun, 12 May 2024 00:15:55 +0800println!(, local_datetime.to_rfc3339()); // 2024-05-12T00:15:55.325058+08:00println!(, local_datetime.to_string()); // 2024-05-12 00:15:55.325058 +08:00println!(, local_datetime.format(%Y-%m-%d %H:%M:%S)) // 2024-05-12 00:15:55 String 转 DateTime 字符串带时区信息，使用 DateTime::parse_from_str(s, f)。 let format_withzone = %Y-%m-%d %H:%M:%S %z;let datetime_withzone_str = 2024-01-01 00:00:00 +08:00;let local_datetime = DateTime::parse_from_str(datetime_withzone_str, format_withzone).unwrap(); 字符串无时区信息，使用 NaiveDateTime::parse_from_str(s, f)。 let format = %Y-%m-%d %H:%M:%S;let datetime_str = 2024-01-01 00:00:00;let local_datetime = NaiveDateTime::parse_from_str(datetime_str, format) .unwrap() .and_local_timezone(Local) // 转为带时区的 DateTime .unwrap(); DateTime 转 timestamp let local_datetime = Local::now();println!(seconds: , local_datetime.timestamp()); // 1715444324println!(millis: , local_datetime.timestamp_millis()); // 1715444338610println!(micros: , local_datetime.timestamp_micros()); // 1715444338610873println!(nacos: , local_datetime.timestamp_nanos_opt().unwrap()); // 1715444338610873000 timestamp 转 DateTime let utc_datetime: DateTimeUtc = DateTime::from_timestamp(1704139200, 0).unwrap(); // 默认是 Utclet local_datetime: DateTimeLocal = DateTime::from_timestamp(1704139200, 0).unwrap().into(); // 使用 into() 转为 Local 时区转换 use chrono::DateTime, FixedOffset, Utc;fn main() let utc_date_time: DateTimeUtc = Utc::now(); let fixed_offset = FixedOffset::east(8 * 3600); // 转为 utc+8 东八区 let local_date_time = utc_date_time.with_timezone(fixed_offset); println!(Local time in UTC+8: , local_date_time); 时间计算 时间加减： use chrono::Duration, Local;let now = Local::now();let yesterday = now - Duration::hours(24); 时间间隔： use chrono::Duration, Local;let now = Local::now();let yesterday = now - Duration::hours(24);let hour_interval = (now - yesterday).num_hours(); 总结 通过本文的详细介绍和实用示例，我们了解了如何使用 Rust 的 chrono 库来精确处理时间和日期。chrono 不仅支持复杂的时区计算和全球时间管理，还提供了方便的日期时间解析和格式化工具，以及灵活的时间运算功能。掌握了这些技能后，你将能够在任何需要精确时间数据处理的 Rust 应用中，提供稳定和高效的解决方案。 时间是每个程序的基石，而 chrono 就是那把能够操纵时间的魔杖。 希望本文能对你有帮助，peace! enjoy coding~ 参考： chrono crate rust-working-with-date-and-time 作图： https://excalidraw.com/","tags":["Rust"],"categories":["Rust","Rust 常用库"]},{"title":"epoll","path":"/2024/04/28/epoll/","content":"前言 epoll 是一种 I/O 多路复用技术，主要用于高性能的网络服务器中，特别是在处理大量并发连接时。它是 Linux 特有的，自 Linux 内核 2.5.44 版本引入，并在后续版本中不断优化。epoll 能够帮助服务器高效地管理数以千计的客户端连接，是 select 和 poll 方法的现代替代品。 本文不对 epoll 的源码进行分析，仅做原理上的总结，方便快速查阅回顾。各大论坛很多大佬都对 epoll 的源码进行了详尽的分析，感兴趣的读者可以看「参考」篇章。 主要特点 效率高: 相较于 select 和 poll，epoll 可以更高效地处理大量的并发连接。select 和 poll 的效率随着监视的文件描述符数量增加而线性下降，而 epoll 则不会因为监视的文件描述符数量增加而显著降低效率。 扩展性好: epoll 使用一种称为事件通知的机制，只会处理那些真正发生了事件的文件描述符。这意味着系统不必重新检查所有文件描述符，从而大大减少了不必要的 CPU 开销。 支持边缘触发和水平触发: epoll 支持 Edge Triggered 和水平触发 Level Triggered 两种模式。边缘触发模式只在文件描述符状态改变时才通知应用程序，适用于非阻塞 I/O；而水平触发模式则在有事件可读或可写时都会通知应用程序，更容易使用但效率略低。 结论先行 工作原理 epoll 的工作可以分为三个主要步骤： 创建 epoll 实例: 使用 epoll_create 函数创建一个 epoll 实例。 添加/修改/删除文件描述符: 使用 epoll_ctl 函数将新的文件描述符添加到 epoll 实例中，或者修改、删除已存在的文件描述符。这些操作与文件描述符的数量无关，因此执行速度非常快。 等待事件发生: 使用 epoll_wait 函数等待事件的发生。这个函数可以同时监控多个文件描述符，当指定的文件描述符上发生了注册的事件时，函数返回，并告知哪些文件描述符上发生了事件。 ET LT 在 epoll 中，边缘触发（ET, Edge Triggered）和水平触发（LT, Level Triggered）是两种不同的事件通知方式，它们定义了操作系统如何通知应用程序文件描述符上的 I/O 事件。 这两种模式的主要区别在于何时以及如何多次通知应用程序关于某个文件描述符的事件。 水平触发（Level Triggered） 定义: 在水平触发模式下，只要文件描述符上有未处理的 I/O 事件存在，epoll_wait 就会通知应用程序。这意味着，如果数据可读取但未被完全读取，epoll_wait 会在下次调用时再次返回该文件描述符。 行为: 这种模式更容易编程，因为应用程序可以不用担心在一个操作中处理所有数据。如果数据还在，epoll_wait 会继续通知你。 适用场景: 更适合那些简单的应用或者对实时性要求不是非常高的应用，因为它简化了处理逻辑。 边缘触发（Edge Triggered） 定义: 在边缘触发模式下，只有状态变化时（例如从无数据到有数据），epoll_wait 才会通知应用程序。一旦通知了应用程序某事件发生，除非有新的数据到达或状态再次发生变化，否则不会再次通知应用程序该事件。 行为: 这要求应用程序必须立即处理所有事件，因为之后不会再收到关于这些事件的通知。这意味着应用程序必须循环读取或写入，直到数据被完全处理完，以确保不遗漏任何事件。 适用场景: 适合需要高性能的场景，因为它减少了事件处理的次数，但要求程序必须更加小心地管理 I/O 操作。 比较和选择 性能: 边缘触发通常提供更高的性能，因为它减少了系统调用的次数和不必要的事件处理。 编程复杂性: 边缘触发模式编程比水平触发复杂，因为需要确保每次事件被彻底处理，并且更容易遇到如“惊群效应”（多个进程或线程被同一个事件唤醒）等问题。 可靠性: 水平触发因为其简单的行为模式，在可靠性处理上更为直接和容易。 通常，选择哪种模式取决于应用的具体需求、预期的负载以及开发者对事件处理逻辑的控制程度。高性能服务器通常选择边缘触发模式，以最大化其效率，而简单的或者低负载应用可能会更倾向于使用水平触发，以简化开发和调试过程。 数据结构 epoll 使用 2 种关键的数据结构来维护和跟踪文件描述符（FD）和事件： 红黑树（Red-Black Tree）: 用于存储所有注册的文件描述符及其事件。红黑树是一种自平衡二叉搜索树，能够在对数时间内完成插入、删除和查找操作，这使得管理大量文件描述符变得高效。 就绪列表（Ready List）: 当事件发生（如可读、可写等）并被内核检测到时，相应的 FD 会被添加到一个就绪列表中。这个列表仅包含实际有事件发生的文件描述符，从而减少了 epoll_wait 调用的处理时间。 工作细节 通过调用 epoll_create() 函数创建并初始化一个 eventpoll 对象。 通过调用 epoll_ctl() 函数把被监听的文件句柄 (如 socket 句柄) 封装成 epitem 对象并且添加到 eventpoll 对象的红黑树中进行管理。 通过调用 epoll_wait() 函数等待被监听的文件状态发生改变。 当被监听的文件状态发生改变时（如 socket 接收到数据），会把文件句柄对应 epitem 对象添加到 eventpoll 对象的就绪队列 rdllist 中。并且把就绪队列的文件列表复制到 epoll_wait() 函数的 events 参数中。 唤醒调用 epoll_wait() 函数被阻塞（睡眠）的进程。 事件监听 内核中的事件监听和回调机制是通过高效的事件驱动模型实现的，而不是简单的循环检查（如在用户空间中的轮询）。这种机制利用了现代操作系统的中断和回调系统，以及针对异步事件的优化处理策略。 以下是这个过程的详细解释： 1. 中断和中断处理 在硬件层面，大多数 I/O 操作（如网络通信、磁盘 I/O）都是通过中断驱动的。当一个 I/O 设备准备好数据或需要服务时，它会产生一个中断信号，这个信号被发送到 CPU。CPU 响应中断，并执行一个预定的中断处理程序（Interrupt Service Routine, ISR），该程序是由设备的驱动程序提供的。 2. 事件和回调 在 ISR 中，与设备相关的事件（例如网络包的接收、硬盘读取完成）会被检测到，并且可以在此阶段调用特定的回调函数。这些回调函数是在设备驱动或相关的内核模块中定义的，用来通知内核其他部分或者相关的进程有关事件的发生。 3. 文件描述符的回调机制 对于 epoll 等 I/O 多路复用技术，内核为每个文件描述符维护了一个事件处理机制。当文件描述符被创建时，相关的设备或资源会注册一组回调函数，这些函数会在特定的操作（如读、写、错误）上被触发。例如，一个网络套接字可能会在数据到达时触发一个“可读”事件的回调。 4. epoll 的事件绑定 当一个文件描述符被加入到 epoll 监听队列中，epoll 会利用这些回调来获得事件通知。epoll 操作相关的代码会将一个额外的回调函数绑定到这些文件描述符上。当文件描述符的状态改变时（如数据可读），这个回调函数将被触发，然后它会将相应的文件描述符标记为“就绪”，并放入 epoll 的就绪队列。 5. 事件通知和唤醒 当 epoll_wait 被调用且有事件就绪时，内核会检查就绪队列，并将这些事件传递给等待的进程。如果没有事件就绪，进程将被挂起直到有事件发生。事件的发生会触发内核调度程序唤醒相应的进程。 6. 效率和性能 这种基于中断的事件通知机制意味着内核不需要不断循环检查每个文件描述符的状态，从而极大地提高了效率。事件只有在实际发生时才被处理，且处理通常是由硬件中断直接触发的，这使得整个系统更加响应快速，减少了无效的 CPU 使用。 这种设计使得 Linux 内核在处理大量并发 I/O 操作时能够保持高效和稳定，适合构建高性能的网络服务和应用。 中断 中断机制是计算机硬件和操作系统核心功能之一，它允许外设或硬件异步地通知 CPU 需要处理某些事件。中断机制的实现并不依赖于类似于 for 循环的轮询检查，而是建立在更为直接和高效的硬件和处理器架构支持之上。 当 CPU 接收到中断信号时，它是通过一套内建于硬件的协调机制来识别和响应中断的。这个过程涉及硬件电路设计、处理器架构和操作系统的中断管理功能。 以下是 CPU 如何知道有中断发生，并且如何处理这一中断的详细步骤： 中断信号的检测和响应 中断请求线（IRQ）：外部设备通过连接到处理器的一个特定的硬件线路（IRQ）发送中断信号。这个线路直接与处理器内的中断控制单元（Interrupt Controller）相连。 中断控制器：大多数现代计算机系统使用一个或多个中断控制器来管理中断信号。中断控制器的任务是接收来自各种外部设备的中断请求，并将这些请求优先级排序后发送给 CPU。 中断向量：当中断控制器接收到一个中断信号后，它会根据中断源确定一个中断向量。这个向量是一个数字，指向中断向量表中对应的入口，该入口包含了处理该中断的中断服务例程（ISR）的地址。 CPU 如何处理中断 当前指令的完成：当 CPU 接收到中断控制器发出的中断信号时，它首先会完成当前执行的指令。这是为了保证程序的状态能够正确保存，从而在中断处理完毕后可以无缝地恢复执行。 保存上下文：一旦当前指令执行完毕，CPU 会自动保存当前的程序状态，包括程序计数器（PC）、寄存器和其他必要的状态信息。这些信息通常被推送到当前的栈上。 跳转到 ISR：CPU 使用中断向量来访问中断向量表，找到与中断号对应的中断服务例程（ISR）的地址，并跳转到该地址开始执行 ISR。这个过程是自动的，由处理器的内部机制控制。 执行 ISR：中断服务例程会执行必要的操作来处理中断，比如读取数据缓冲区、清除设备状态或发送信号等。 恢复上下文并返回：一旦 ISR 执行完成，处理器会从栈上恢复之前保存的程序状态，并将控制权返回到被中断的程序，继续执行。 硬件支持 这一过程大量依赖于处理器的硬件支持，如中断向量表通常是固定在处理器的特定内存地址上的。此外，现代处理器如 x86 架构还提供了更高级的功能，比如支持多重中断控制器和高级可编程中断控制器（APIC）等。 这种基于硬件的中断响应机制允许 CPU 快速有效地处理各种外部事件，确保系统的响应性和稳定性。 参考 图解 | 深入揭秘 epoll 是如何实现 IO 多路复用的！ 一图总结 epoll 的总体工作流程 scalable-io-events-vs-multithreading-based Epoll 实现原理 网络编程之 epoll 源码深度剖析","tags":["epoll","网络编程","非阻塞 I/0"],"categories":["计算机基础","计算机网络"]},{"title":"Rust 实战丨并发构建倒排索引","path":"/2024/04/23/rust-action-inverted-index-concurrency/","content":"引言 继上篇 Rust 实战丨倒排索引，本篇我们将参考《Rust 程序设计（第二版）》中并发编程篇章来实现高并发构建倒排索引。 本篇主要分为以下几个部分： 功能展示：展示我们最终实现的 2 个工具的效果（构建索引、搜索功能） 阅读源码：阅读书中源码的实现，理清大体思路。 构建索引：实战构建索引的每个具体环节，并对核心逻辑进行解释和阐述缘由。 搜索功能：这是书中未曾提供的功能，笔者根据自身理解，对齐上篇提供的功能，实现了一个搜索功能。 能学到： Rust 各种迭代器的使用 Rust 文件常用操作 Rust 字符串常用操作 Rust channel 实战 Rust 并发编程 多路合并文件实际应用 使用 byteorder 进行位操作 使用 clap 进行 CLI 开发 终端高亮输出 深入理解倒排索引高性能的核心细节 阅读建议 本篇内容较为冗长，涉及到的细节讲解可能比较啰嗦，推荐直接阅读源码，然后对不理解的地方再来本篇对应的章节进行阅读。 完成源码位于：https://github.com/hedon-rust-road/inverted-index-concurrency 版本声明 Rust: 1.76 byteordrr: 1.5.0 clap: 4.5.0 运行环境：macbookPro Apple M2 Max 功能展示 create.rs Usage: create [OPTIONS] FILENAMES...Arguments: FILENAMES...Options: -s, --single-threaded Default false -h, --help Print help 指定文件目录，构建索引，可以使用 -s 使用单线程构建，默认使用并发构建。 执行示例如下： ➜ inverted-index-concurrency git:(master) ✗ cargo run --bin create ./texts Finished dev [unoptimized + debuginfo] target(s) in 0.08s Running `/Users/wangjiahan/rust-target/debug/create ./texts`indexed document 0:./texts/text1.txt, 22 bytes, 5 wordsindexed document 1:./texts/text3.txt, 27 bytes, 5 wordsindexed document 2:./texts/text2.txt, 39 bytes, 6 wordsword count: 16351 bytes main, 736 bytes totalwrote file ./tmp00000001.dat search.rs Usage: search --index-file INDEX_FILE --term TERMOptions: -i, --index-file INDEX_FILE Specify index file path -t, --term TERM Specify search term -h, --help Print help 指定索引文件和搜索词来进行搜索。 执行示例如下： 阅读源码 书中的源码位于：fingertips 第一部分我们先来阅读源码，书中展示了这样一张图： 从这张图我们大概可以猜想本案例中构建并发索引的过程可能是： 读取文件内容； 根据文件内容构建索引； 多个索引进行合并； 将索引写入文件； 多个索引文件进行合并。 按照这个思路的指引，我们打开源码，从 main.rs 的 main() 出发： fn main() let mut single_threaded = false; let mut filenames = vec![]; // 命令行参数解析 let mut ap = ArgumentParser::new(); ap.set_description(Make an inverted index for searching documents.); ap.refer(mut single_threaded).add_option( [-1, --single-threaded], StoreTrue, Do all the work on a single thread., ); ap.refer(mut filenames).add_argument( filenames, Collect, Names of files/directories to index. \\ For directories, all .txt files immediately \\ under the directory are indexed., ); ap.parse_args_or_exit(); // 构建索引 match run(filenames, single_threaded) Ok(()) = Err(err) = println!(error: , err), 解析命令行参数，这里使用 argparse 这个比较古老的 crate 来解析，现在一般是使用 clap。 single_threaded: 是否使用单线程，默认是多线程。 filenames: 指定的文本文件或目录。 run 函数执行构建索引。 看一下 run： /// Generate an index for a bunch of text files.fn run(filenames: VecString, single_threaded: bool) - io::Result() let output_dir = PathBuf::from(.); let documents = expand_filename_arguments(filenames)?; if single_threaded run_single_threaded(documents, output_dir) else run_pipeline(documents, output_dir) 单线程：run_single_threaded 多线程：run_pipeline 先从简单看，单线程，忽略掉源码中定义的特殊数据结构，可以发现跟我们上篇介绍的简单版倒排索引思路基本是一致的，只不过本案例中数据是从文件中读，最后又会将索引写入到文件中。 fn run_single_threaded(documents: VecPathBuf, output_dir: PathBuf) - io::Result() let mut accumulated_index = InMemoryIndex::new(); let mut merge = FileMerge::new(output_dir); let mut tmp_dir = TmpDir::new(output_dir); // 迭代每个文本文件 for (doc_id, filename) in documents.into_iter().enumerate() // 打开文件，并将内容读取到 `text` 上 let mut f = File::open(filename)?; let mut text = String::new(); f.read_to_string(mut text)?; // 构建索引 let index = InMemoryIndex::from_single_document(doc_id, text); accumulated_index.merge(index); if accumulated_index.is_large() // 当索引足够大的时候，将其写到文件中 let file = write_index_to_tmp_file(accumulated_index, mut tmp_dir)?; merge.add_file(file)?; accumulated_index = InMemoryIndex::new(); // 将最后一个索引写入到文件中 if !accumulated_index.is_empty() let file = write_index_to_tmp_file(accumulated_index, mut tmp_dir)?; merge.add_file(file)?; merge.finish() 再来看本文的重头戏，多线程： fn run_pipeline(documents: VecPathBuf, output_dir: PathBuf) - io::Result() // 将构建索引分为 5 个过程 let (texts, h1) = start_file_reader_thread(documents); let (pints, h2) = start_file_indexing_thread(texts); let (gallons, h3) = start_in_memory_merge_thread(pints); let (files, h4) = start_index_writer_thread(gallons, output_dir); let result = merge_index_files(files, output_dir); // 等待所有线程执行完毕 let r1 = h1.join().unwrap(); h2.join().unwrap(); h3.join().unwrap(); let r4 = h4.join().unwrap(); r1?; r4?; result 首先将索引构建分成 5 个阶段： 1. start_file_reader_thread 就是从文件中读取文本信息，并将其扔进 ReceiverString channel 中，传到下一个阶段。 fn start_file_reader_thread( documents: VecPathBuf,) - (ReceiverString, JoinHandleio::Result()) let (sender, receiver) = channel(); let handle = spawn(move || for filename in documents let mut f = File::open(filename)?; let mut text = String::new(); // 读取文件内容 f.read_to_string(mut text)?; if sender.send(text).is_err() break; Ok(()) ); (receiver, handle) 2. start_file_indexing_thread 从第 1 步传过来的文本信息中调用 InMemoryIndex::from_single_document 构建索引。 fn start_file_indexing_thread( texts: ReceiverString,) - (ReceiverInMemoryIndex, JoinHandle()) let (sender, receiver) = channel(); let handle = spawn(move || for (doc_id, text) in texts.into_iter().enumerate() // 构建索引 let index = InMemoryIndex::from_single_document(doc_id, text); if sender.send(index).is_err() break; ); (receiver, handle) 3. start_in_memory_merge_thread 将第 2 步构建的单一索引进行合并，并将合并后的索引传到下一个阶段。 fn start_in_memory_merge_thread( file_indexes: ReceiverInMemoryIndex,) - (ReceiverInMemoryIndex, JoinHandle()) let (sender, receiver) = channel(); let handle = spawn(move || let mut accumulated_index = InMemoryIndex::new(); for fi in file_indexes // 将索引进行合并 accumulated_index.merge(fi); if accumulated_index.is_large() // 如果索引大小到达阈值，则传到下一阶段 if sender.send(accumulated_index).is_err() return; accumulated_index = InMemoryIndex::new(); if !accumulated_index.is_empty() let _ = sender.send(accumulated_index); ); (receiver, handle) 4. start_index_writer_thread 将第 3 步传来的内存索引写入到临时文件中。 fn start_index_writer_thread( big_indexes: ReceiverInMemoryIndex, output_dir: Path,) - (ReceiverPathBuf, JoinHandleio::Result()) let (sender, receiver) = channel(); let mut tmp_dir = TmpDir::new(output_dir); let handle = spawn(move || for index in big_indexes // 将索引写入临时文件中 let file = write_index_to_tmp_file(index, mut tmp_dir)?; if sender.send(file).is_err() break; Ok(()) ); (receiver, handle) 5. merge_index_files 将临时文件进行合并，生成最终的索引文件。 fn merge_index_files(files: ReceiverPathBuf, output_dir: Path) - io::Result() let mut merge = FileMerge::new(output_dir); for file in files merge.add_file(file)?; merge.finish() 这 5 个步骤跟书中给出的示意图基本一致，我们再来看 run_pipeline 是如何合并并行的： // 使用 join() 等待所有线程完成let r1 = h1.join().unwrap();h2.join().unwrap();h3.join().unwrap();let r4 = h4.join().unwrap();// 阶段 2 和阶段 3 都是纯内存操作，不会有错误// 阶段 1 是读文件，阶段 4 是写文件，所以有可能会报错r1?;r4?; 源码阅读部分差不多就到这了，大的思想架构你应该都能 Get 到了，其中每个数据结构的具体实现细节，我们在后面的实战中进行拆解。 构建索引 代码结构 书中源码代码结构如下所示： ➜ fingertips git:(master) ✗ tree.├── Cargo.lock├── Cargo.toml├── LICENSE-MIT├── README.md├── src│ ├── index.rs│ ├── main.rs│ ├── merge.rs│ ├── read.rs│ ├── tmp.rs│ └── write.rs 书中给出的源码并没有实现使用构建好的索引文件进行搜索的功能，笔者将在此基础上实现该功能，所以对代码结构进行了简单的调整： ➜ inverted_index git:(master) ✗ tree.├── Cargo.lock├── Cargo.toml├── index.bat├── src│ ├── bin│ │ ├── create.rs│ │ └── search.rs│ ├── index.rs│ ├── lib.rs│ ├── merge.rs│ ├── read.rs│ ├── tmp.rs│ └── write.rs└── texts ├── text1.txt ├── text2.txt └── text3.txt 可以看到我将核心代码从 bin 改成了 lib ，这是为了支持我后面要实现的两个 bin: create: 构建索引，基本上就是源代码中的 main.rs search: 基于生成的索引文件实现搜索功能 texts 是我提供的文本文件样例。 src 目录中的代码阅读顺序及功能划分如下： index: 定义了内存索引数据结构 InMemoryIndex，实现了从文件内容中构建内存索引的基本逻辑，也实现了从索引文件重建内存索引的功能。 tmp: 定义了临时目录数据结构 TmpDir，用于存放临时索引文件。 write: 定义了索引文件写入器 IndexFileWriter，实现了将 InMemoryIndex 写入文件中的逻辑。 merge: 定义了文件合并器 FileMerge，用于合并 TmpDir 的所有索引文件。 read: 定义了索引文件读取器 IndexFileWrite，实现了解析索引文件的逻辑。 项目准备 cargo new --lib inverted_index_concurrency Cargo.toml [package]name = inverted-index-concurrencyversion = 0.1.0edition = 2021license = mitauthors = [hedon]description = a tool to concurrently build an inverted index.[[bin]]name=createpath=src/bin/create.rs[[bin]]name=searchpath=src/bin/search.rs[dependencies]byteorder = 1.5.0clap = version = 4.5.4, features = [derive] lib.rs pub mod index;pub mod merge;pub mod read;pub mod tmp;pub mod write; 在 lib.rs 中我们将这 5 个 mod 公开出去，这样就可以给 bin 目录中的 crate.rs 和 search.rs 使用了。 index.rs 完整源码：index.rs 第一部分是内存索引的构建。 tokenize 我们先定义一个分词函数： fn tokenize(text: str) - Vec(str, usize, usize) let mut res = Vec::new(); let mut token_start = None; for (idx, ch) in text.char_indices() match (ch.is_alphanumeric(), token_start) (true, None) = token_start = Some(idx), // 每个单词的开始 (false, Some(start)) = // 每个单词的结尾 res.push((text[start..idx], start, idx - 1)); token_start = None _ = if let Some(start) = token_start res.push((text[start..], start, text.len() - 1)) res 这个分词函数跟书中源码提供的不一样，为了实现文本高亮，我们需要记录每个分词在原文本中的起始位置和结束位置。它的核心逻辑如下： 通过 char_indices() 获取 text 的字符迭代器，这是一种懒加载的方法，避免一次性将所有 char 加载到内存中。 匹配 (ch.is_alphanumeric(), token_start)： 如果是 (true, None) 则表示这是一个单词的开始，我们纪录其开始的位置 Some(idx)； 如果是 (false, Some(idx)) 则表示这是一个单词的结束，我们将其加入到 res 中，并记录起始位置和结束位置。 其他情况，不做处理，要么是非法字符，要么是处于单词中间。 从这个简单的理解中，你应该可以感受到 Rust 中 match pattern 的强大和便捷了，666 👍🏻 struct: InMemoryIndex 在 index.rs 中，我们定义了三个数据结构： pub struct InMemoryIndex pub word_count: usize, pub terms: HashMapString, VecHit, pub docs: HashMapusize, Document,pub struct Document pub id: u32, pub path: PathBuf,pub type Hit = Vecu8; Document: 文档封装。 id: 文档 id，唯一标识符。 path: 源文件路径。 Hit: 它是一个字节数组，我们按照小端序进行存储，它的存储结构如下： [0…3] 存储一个 HITS_SEPERATOR = -1，表示一个 Hit 的开始。 [4…7] 存储一个 u32 的 document_id。 后面每 8 个 u8 会存在一个 u32 的 start_pos 和一个 u32 的 end_pos。 InMemoryIndex: 内存索引。 word_count: 包含的单词（word/term）个数，记录它是为了判断索引是否过大，以便对索引进行分片存储。 terms: 存储 word 到 Hits 的映射，每个 word 是一个搜索项。 docs: 存储了 document_id 到文档的映射，用于查询原始文档信息。 接下来我们来为 InMemoryIndex 实现一系列方法，因为我们期望使用小端序存储 Hit 中的数据，所以我们需要引入 byteorder 这个 crate: cargo add byteorder 具体实现可参考源码，核心逻辑是 from_single_document 和 merge。 from_single_document from_single_document 的核心逻辑在这一段，它其实跟我们之前实现的简易版倒排索引很相似： for (token, start_pos, end_pos) in tokens.iter() let hits = index.terms.entry(token.to_string()).or_insert_with(|| let mut hits = Vec::with_capacity(4 + 4 + 4 + 4); hits.write_i32::LittleEndian(Self::HITS_SEPERATOR) .unwrap(); hits.write_u32::LittleEndian(document_id).unwrap(); vec![hits] ); hits[0].write_u32::LittleEndian(*start_pos as u32).unwrap(); hits[0].write_u32::LittleEndian(*end_pos as u32).unwrap(); index.word_count += 1; 遍历每个 token 和它在文本中的位置。 对于每个 token，尝试在索引的 map 中查找一个现有的条目。如果不存在，则创建一个新的 Hit 记录，并初始化它： 创建一个新的 Hit 向量，预留 24 字节的容量，这是因为至少要存储 1 个分隔符、1 个 document_id、1 个 start_pos 和 1 个 end_pos。 首先写入 HITS_SEPERATOR 和 document_id（使用小端序）。 向对应的 Hit 向量中添加当前单词的位置。 累加处理的单词总数到 index.word_count。 这里给个示例，希望可以帮助你理解 InMemoryIndex 的内存结构： InMemoryIndex│├── word_count: usize│├── terms: HashMapString, VecHit│ ││ ├── Key: example (String)│ │ └── Value: VecHit│ │ ├── [HITS_SEPERATOR, Document ID: 1, Positions: [10, 19, 30, 39]] (Hit)│ │ └── [HITS_SEPERATOR, Document ID: 2, Positions: [15, 25]] (Hit)│ ││ └── Key: test│ └── Value: VecHit│ └── [HITS_SEPERATOR, Document ID: 1, Positions: [20, 24, 50, 69]] (Hit)│└── docs: HashMapu32, Document ├── Key: 1 (u32) │ └── Value: Document id: 1, path: path/to/file1.txt └── Key: 2 └── Value: Document id: 2, path: path/to/file2.txt merge merge 是用于合并多个 InMemoryIndex，起到批处理的目的。 pub fn merge(mut self, other: InMemoryIndex) for (term, hits) in other.terms self.terms.entry(term).or_default().extend(hits) self.word_count += other.word_count; self.docs.extend(other.docs); 实现完了 InMemoryIndex 后，我们就可以先来完成 create.rs 的 run_pipeline 的前 3 个阶段了。 step1: start_file_reader_thread 读取文件信息：我们需要在独立的线程中依次打开给定的文件列表，并将文件内容读取到一个 String 中，并利用 channel 传送出去。 fn start_file_reader_thread( documents: VecPathBuf,) - (Receiver(PathBuf, String), JoinHandleio::Result()) let (sender, receiver) = channel(); let handler = spawn(move || for filename in documents let mut f = File::open(filename.clone())?; let mut text = String::new(); f.read_to_string(mut text)?; if sender.send((filename, text)).is_err() break; Ok(()) ); (receiver, handler) step2: start_file_indexing_thread 构建索引：通过 channel 从第 1 阶段中获取文档文本信息，通过 from_single_document 构建索引 InMemoryIndex 后，将索引通过 channel 传送出去。 fn start_file_indexing_thread( docs: Receiver(PathBuf, String),) - (ReceiverInMemoryIndex, JoinHandle()) let (sender, receiver) = channel(); let handler = spawn(move || for (doc_id, (path, text)) in docs.into_iter().enumerate() let index = InMemoryIndex::from_single_document(doc_id as u32, path, text); if sender.send(index).is_err() break; ); (receiver, handler) step3: start_in_memory_merge_thread 合并索引：通过 channel 从第 2 阶段中获得构建的 InMemoryIndex 并将其合并成大索引，然后通过 channel 传送出去。 fn start_in_memory_merge_thread( indexes: ReceiverInMemoryIndex,) - (ReceiverInMemoryIndex, JoinHandle()) let (sender, receiver) = channel(); let handle = spawn(move || let mut accumulated_index = InMemoryIndex::new(); for i in indexes accumulated_index.merge(i); if accumulated_index.is_large() if sender.send(accumulated_index).is_err() return; accumulated_index = InMemoryIndex::new(); if !accumulated_index.is_empty() let _ = sender.send(accumulated_index); ); (receiver, handle) 补充：为什么采用这种“复杂”的方式来存储数据呢？可否使用 JSON 或者 Protobuf 呢？ 选择如何组织和存储数据，特别是在实现一个搜索引擎或数据库索引时，是一个关键决策，这会直接影响到程序的性能、可维护性以及扩展性。在这些情况下，使用像 byteorder 这样的低级数据格式存储索引信息可能比使用 JSON 或 Protobuf 等高级格式更有优势。读写速度：二进制格式：直接操作二进制格式通常比解析文本或半结构化的数据格式（如 JSON）要快，因为它减少了解析时间和内存使用。在二进制格式中，数据通常是紧密打包的，没有额外的格式标记（如 JSON 中的花括号和逗号），这减少了磁盘 I/O 需求。文本/半结构化格式：例如 JSON，每次读取时都需要解析文本，转换数据类型，这会增加 CPU 的负担，尤其是在大规模数据处理时。空间效率：二进制格式：使用最少的字节表示数据，例如使用定长的整数存储文档 ID 和位置索引，不仅节省空间，还能提高缓存利用率。文本/半结构化格式：文本格式需要存储额外的字符来标识数据（例如引号和键名），这增加了存储需求。适用场景：二进制格式：非常适合需要高性能和大数据处理的后端系统，如搜索引擎和数据库索引。这种格式可以有效地支持快速的数据读取和写入，特别是在资源受限的环境中（如嵌入式系统或低延迟应用）。JSON/Protobuf：更适合需要跨平台兼容性和易于调试的应用场景。例如，在 Web 应用中使用 JSON 作为数据交换格式，可以简化前后端的集成和测试。 tmp.rs 完成内存索引的构建后，我们需要将构建过程中产生的大索引先临时落盘，后面再进行合并。为了临时存储这些数据文件，我们需要将他们放在一个临时目录中，为此，我们定义了 TmpDir 数据结构： #[derive(Clone)]pub struct TmpDir dir: PathBuf, n: usize, dir: 目录 n: 自增器，用于区分临时文件命名 接下来为 TmpDir 实现 2 个方法： impl TmpDir pub fn newP: AsRefPath(dir: P) - TmpDir TmpDir dir: dir.as_ref().to_owned(), n: 1, pub fn create(mut self) - io::Result(PathBuf, BufWriterFile) let mut r#try = 1; loop let filename = self .dir .join(PathBuf::from(format!(tmp:08x.dat, self.n))); self.n += 1; match fs::OpenOptions::new() .write(true) .create_new(true) .open(filename) Ok(f) = return Ok((filename, BufWriter::new(f))), Err(exc) = if r#try 999 exc.kind() == io::ErrorKind::AlreadyExists // keep going else return Err(exc); r#try += 1; new 方法是 TmpDir 的构造函数，其中我们将 n 设置为 1，即文件名从 1 开始生成。dir.as_ref().to_owned() 接受一个可能是任何类型的路径，将其标准化为一个 Path 类型的引用，然后再复制这个引用，创建一个完全独立的、拥有所有权的 PathBuf 对象， create 方法是在 TmpDir 目录下创建一个临时文件。 write.rs 完整源码：write.rs 准备好内存索引和临时文件，那我们就需要实现将内存索引写入到文件中的功能了。 struct: InMemoryIndex 我们先来分析一下如何将 InMemoryIndex 落盘。首先 InMemoryIndex 的结构如下： pub struct InMemoryIndex pub word_count: usize, pub terms: HashMapString, VecHit, pub docs: HashMapu32, Document,pub struct Document pub id: u32, pub path: PathBuf, 其中 word_count 不需要存储，我们可以计算出来。那我们就需要存储索引 map 和文档原数据 docs。为了能精确定位到各个数据，我们需要： terms: 写入 VecHit docs: 写入 docs 中的每个 Document 写入 id 写入 path 大小 写入 path 而为了快速定位到每个 term 和 doc 的位置，我们需要下面几个值，这几个值将组合起来辅助我们快速定位 terms 或 docs，我们后面会将其称为 Entry，它包含以下几个值： term: 索引单词。为了统一，如果 term 为空，则表示当前表示的是 doc，否则为 terms。 df: term 的出现次数。为了统一，如果 df 为 0，则表示当前表示的是 doc，否则为 terms。 offset: 对应的 terms 或 docs 在文件中的偏移。 nbytes: 对应的 terms 或 docs 的总长度。 所以文件的内存结构大概如下： 文件区域 描述 指向内容 头部 （8 字节） 包含一个指向目录表开始位置的偏移量。 header 主条目 这些条目按顺序紧密存储，没有额外的元数据。这部分包含实际的数据条目。 terms + docs 目录表 存储在文件的最后，包括每个条目的术语信息、文档频率、偏移和大小。 entries 示意图如下： 为此我们定义了 IndexFileWriter，它专门用于将 InMemoryIndex 写入到临时文件中，定义如下： /// A structure to manage writing to an index file efficiently.pub struct IndexFileWriter offset: u64, writer: BufWriterFile, contents_buf: Vecu8, offset: 用于追踪文件中当前的写入位置。 writer: 一个缓冲写入器，它包装了一个文件，用于输出操作。 contents_buf: 一个向量，用来存储内容条目，在全部写入文件之前暂存在这个缓冲区。 接下来我们为 IndexFileWriter 实现几个方法： new: 这是一个构造函数，它初始化文件并设置初始偏移量。在文件的开始处写入一个占位符作为头部，这个头部最终会存储主数据区的大小。 write_document: 用于将一个文档以二进制格式写入到文件中，同时更新偏移量。 write_main: 这个方法接受一段数据，并将它写入文件中，同时更新偏移量。 write_contents_entry: 将一个内容 Entry 追加到内部的缓冲区中。Entry 包括一个术语、文档频率、术语数据的起始偏移和大小，它用于快速定位 terms 或 docs。 finish: 完成文件写入过程，将内部缓冲区的内容写入文件，并更新文件头部的主数据大小。 new 我们先来看构造方法： pub fn new(mut f: BufWriterFile) - io::ResultIndexFileWriter const HEADER_SIZE: u64 = 8; f.write_u64::LittleEndian(0)?; // content start Ok(IndexFileWriter offset: HEADER_SIZE, writer: f, contents_buf: vec![], ) new 分为以下几步： 定义头部大小：const HEADER_SIZE: u64 = 8;：定义一个常量 HEADER_SIZE，其值为 8 字节，这表示文件头部的大小。这个头部将用于后续在文件的开始处写入主数据区的起始位置。 写入头部占位符：f.write_u64::LittleEndian(0)?;：在文件的开始处写入一个 8 字节的占位符，这个值是以小端字节序（LittleEndian）存储的。初始时这里写入的是 0，意味着“主数据区的起始位置未知”，这个值在后续的 finish 函数中会被更新。 返回一个新的 IndexFileWriter 实例：Ok(IndexFileWriter offset: HEADER_SIZE, writer: f, contents_buf: vec![], )：构造并返回一个 IndexFileWriter 实例。这个实例的 offset 字段被初始化为 HEADER_SIZE（8 字节），表示实际数据将从文件的第 17 个字节开始写入。writer 字段就是传入的文件写入器，contents_buf 是一个新的空向量，用于临时存储内容条目数据。 为什么这样设计？ 这个实现方式有几个设计上的考虑：预留头部空间：通过在文件开始处预留 8 字节空间来存储主数据区的大小，这样做可以在数据写入完成后，方便地回填这个信息。这是文件格式设计中常见的做法，允许读取者快速定位主数据区和内容索引区。使用小端字节序：小端字节序是一种在二进制文件中常用的字节序，尤其是在 Windows 平台下。使用小端字节序可以提高文件的兼容性，并且对于多数处理器架构来说，小端字节序的读写操作更为高效。灵活的数据写入：通过将 writer 和 contents_buf 组合使用，这个结构体可以灵活地处理不同的数据写入需求。writer 直接写入文件，适合连续大块数据的写入；而 contents_buf 用于聚集多个小片段的数据，可以在最后统一写入，减少磁盘操作次数。总的来说，这个构造函数的实现为高效和灵活的文件写操作提供了良好的基础，同时通过合理的错误处理和数据组织方式，确保了程序的健壮性和高性能。 write_main Hit 本身就是一个 Vecu8， 将其写入文件很简单，调用 write_all，即可，我们为其封装 write_main 方法： pub fn write_main(mut self, buf: [u8]) - io::Result() self.writer.write_all(buf)?; self.offset += buf.len() as u64; Ok(()) write_document 为了将 Docuemnt 本以二进制结构写入到文件中，我们需要拆分成几个部分： 文件 id 文件路径大小 文件路径 为此我们为 IndexFileWriter 封装了 write_document： pub fn write_document(mut self, doc: Document) - io::Result() self.writer.write_u32::LittleEndian(doc.id)?; self.writer .write_u64::LittleEndian(doc.path.as_os_str().len() as u64)?; self.writer.write_all(doc.path.as_os_str().as_bytes())?; self.offset += 4 + 8 + doc.path.as_os_str().len() as u64; Ok(()) write_contents_entry Entry 的数据量一般较小，我们会先写入缓冲中，后面再一次性刷盘，为此我们为 IndexFileWriter 封装了 write_contents_entry： /// Appends a content entry to the internal buffer.////// # Arguments/// * `term` - The term associated with the entry/// * `df` - Document frequency for the term/// * `offset` - Offset where the term data starts in the file/// * `nbytes` - Number of bytes of the term datapub fn write_contents_entry(mut self, term: String, df: u32, offset: u64, nbytes: u64) self.contents_buf.write_u64::LittleEndian(offset).unwrap(); self.contents_buf.write_u64::LittleEndian(nbytes).unwrap(); self.contents_buf.write_u32::LittleEndian(df).unwrap(); let bytes = term.bytes(); self.contents_buf .write_u32::LittleEndian(bytes.len() as u32) .unwrap(); self.contents_buf.extend(bytes); finish 刷盘的过程我们封装在 finish 中： pub fn finish(mut self) - io::Result() let contents_start = self.offset; self.writer.write_all(self.contents_buf)?; self.writer.seek(SeekFrom::Start(0))?; self.writer.write_u64::LittleEndian(contents_start)?; Ok(()) write_index_to_tmp_file 综合下来，我们就可以实现最核心的函数 write_index_to_tmp_file 了： pub fn write_index_to_tmp_file(index: InMemoryIndex, tmp_dir: mut TmpDir) - io::ResultPathBuf let (filename, f) = tmp_dir.create()?; let mut writer = IndexFileWriter::new(f)?; let mut index_as_vec: Vec_ = index.terms.into_iter().collect(); index_as_vec.sort_by(|(a, _), (b, _)| a.cmp(b)); for (term, hits) in index_as_vec let df = hits.len() as u32; let start = writer.offset; for buffer in hits writer.write_main(buffer)?; let stop = writer.offset; writer.write_contents_entry(term, df, start, stop - start); // if term == df == 0 type = document for (_, doc) in index.docs let start = writer.offset; writer.write_document(doc)?; let stop = writer.offset; writer.write_contents_entry(.to_string(), 0, start, stop - start) writer.finish()?; println!(wrote file :?, filename); Ok(filename) 我们在临时目录中创建一个临时文件，并初始化 IndexFileWriter； 将索引的 terms 转换成一个向量并按照键排序； 对于每个 term，计算文档频率（df），记录开始和结束位置，然后调用 write_main 方法将数据写入文件，然后使用 write_contents_entry 方法写入 Entry 的元数据到目录表； 对于 index.docs 中的每个文档，计算起止位置，并使用一个特殊的条目（空字符串作为条目名和 0 作为文档频率）标记在文件中； 最后我们使用 finish 将缓存中所有的 Entry 刷盘，并设置 entries 的起始位置。 文件的内存结构如上面给出的图一样，这里我们可以再看一次： step4: start_index_writer_thread 实现了将内存索引写入到文件的功能后，我们就可以继续在 create.rs 中实现下一个流程了： fn start_index_writer_thread( big_indexes: ReceiverInMemoryIndex, output_dir: Path,) - (ReceiverPathBuf, JoinHandleio::Result()) let (sender, receiver) = channel(); let mut tmp_dir = TmpDir::new(output_dir); let handle = spawn(move || for i in big_indexes println!(word count: , i.word_count); let file = write_index_to_tmp_file(i, mut tmp_dir)?; if sender.send(file).is_err() break; Ok(()) ); (receiver, handle) 在 start_index_writer_thread 流程中，我们将构建好的内存索引一个个写入到文件中，并将生成的文件句柄传入下一个流程。 merge.rs 完整源码：merge.rs 前面 start_index_writer_thread 是将一个个 InMemoryIndex 写入到 TmpDir 临时目录中。现在我们要将这些临时文件合并成一个最终的索引文件，以优化查询效率和节省存储空间。 srtuct: FileMerge 我们定义一下结构： pub struct FileMerge output_dir: PathBuf, tmp_dir: TmpDir, stacks: VecVecPathBuf, output_dir: 用于存储最终合并文件的输出目录。 tmp_dir: 前面 tmp.rs 定义的结构，用于管理合并过程中产生的临时文件。 stacks: 这是一个二维向量，每个内部向量代表一个合并“层”，存储了该层待合并的文件路径。 关于 stacks，再多说两点： 多级合并策略: FileMerge 使用一个多层合并策略，这种策略在处理大量文件时尤为有效。基本思想是，当一层的文件数量达到一个预设的阈值（NSTREAMS）时，这些文件会被合并成一个新的文件，新文件则被推送到上一层。这种层级式的处理方式可以显著减少最终合并步骤需要处理的文件数量，从而优化性能。 动态扩展：使用 VecVecPathBuf 允许动态地添加新的合并层，这在处理不确定数量的文件时非常有用。向量的灵活性意味着无需预先知道将处理多少文件，它可以根据实际需要进行扩展。 接下来我们会为 FileMerge 实现 2 个方法： add_file: 添加一个文件到合并栈中，并使用多级合并策略进行合并。 finish: 执行最后的合并操作，生成最终的索引文件，输出到 output_dir 中。 add_file 首先我们来看add_file，它的实现如下： pub fn add_file(mut self, mut file: PathBuf) - io::Result() // 从第一层开始检查 let mut level = 0; // 使用循环来处理文件的添加和可能的合并。 loop // 如果当前的 level （层级）不存在于 stacks 中， // 就在 stacks 中添加一个新的空向量。 // 这是为了存放该层级的文件。 if level == self.stacks.len() self.stacks.push(vec![]); // 将当前的文件添加到对应层级的向量中。 self.stacks[level].push(file); // 如果这个级别的堆栈已满，就合并这个级别的文件。 // 如果没满，则不进行合并，直接退出。 if self.stacks[level].len() NSTREAMS break; // 创建一个新文件来存储合并结果，并更新堆栈。 let (filename, out) = self.tmp_dir.create()?; // 初始化一个空的 to_merge 向量， // 然后使用 mem::swap 交换当前层级的文件列表和这个空向量， // 这样 to_merge 向量就包含了需要合并的文件， // 而当前层级变为空，可以用来存放新的合并文件。 let mut to_merge = vec![]; mem::swap(mut self.stacks[level], mut to_merge); // 调用 merge_streams 函数将 to_merge 中的文件合并到新创建的文件中。 merge_streams(to_merge, out)?; // 将合并后得到的新文件路径赋值给 file 变量，用于下一轮循环。 file = filename; // level 加一，表示移动到下一个层级。 level += 1; Ok(()) 这个方法通过层级的方式管理文件合并，每个层级可以有多个文件，但数量上限为 NSTREAMS。如果某层满了，就将该层的文件合并成一个新文件，并将这个新文件移动到上一层继续参与合并。这种设计有效地将多个文件逐步合并成一个文件，同时控制内存和 I/O 资源的使用。 其中 merge_streams 就是具体的合并过程，它的实现如下： fn merge_streams(files: VecPathBuf, out: BufWriterFile) - io::Result() // 从索引文件中构建 IndexFileReader 列表 let mut streams: VecIndexFileReader = files .into_iter() .map(|p| IndexFileReader::open_and_delete(p, true)) .collect::io::Result_()?; // 针对输出文件生成一个 IndexFileWriter 用于写入索引信息 let mut output = IndexFileWriter::new(out)?; // 用于记录当前写入的位置（或者数据偏移量）。 let mut point: u64 = 0; // 记录还有数据未处理的文件流数量，用 peek() 方法检查。 let mut count = streams.iter().filter(|s| s.peek().is_some()).count(); // 只要 count 大于0，表示还有文件未完全处理，就继续循环。 while count 0 let mut term = None; let mut nbytes = 0; let mut df = 0; // 这段代码通过遍历每个文件流，使用 peek() 方法预览每个文件的当前数据条目 for s in streams match s.peek() None = Some(entry) = // term 是空的，则说明这是表示 doc 的 entry。 // 直接退出 for 循环，因为 doc 的 entry 没有顺序且唯一，不会进行累加。 if entry.term.is_empty() term = Some(entry.term.clone()); nbytes = entry.nbytes; df = entry.df; break; // term 不是空的，则说明这是表示 terms 的 entry。 // 选择词条最小的一个（字典序），并且累加其出现的频次和字节大小。 // 这是多路归并的核心，确保输出文件是有序的。 if term.is_none() || entry.term *term.as_ref().unwrap() term = Some(entry.term.clone()); nbytes = entry.nbytes; df = entry.df else if entry.term == *term.as_ref().unwrap() nbytes += entry.nbytes; df += entry.df let term = term.expect(bug in algorithm); // 对于每个文件流，如果当前数据条目与选择的 term 相同， // 则将该条目写入输出文件，并更新该流的读取位置。 for s in mut streams if s.is_at(term) s.move_entry_to(mut output)?; if s.peek().is_none() count -= 1; if term.is_empty() break; output.write_contents_entry(term, df, point, nbytes); point += nbytes Ok(()) 这里涉及到了一个新的结构 IndexFileReader，它是索引文件的读取器，我们将在 read.rs 中实现它。这里先不展开，你只需要知道： IndexFileReader::open_and_delete(p, true): 打开一个索引文件，并根据传入的参数判断是否要删除这个文件，在合并过程中，因为都是临时文件，所以我们会指定为删除文件。但是在后面从索引文件中重建 InMemoryIndex 的时候，我们不希望删除原始的索引文件。 s.peek(): 查看下一个 Entry，它的返回值是 OptionEntry。 s.move_entry_to(mut output): 将 s.peek() 指向的 Entry 写入到 output 文件中，并移动到一下 Entry。 总结下来，这个函数实现多路归并的核心部分，它将多个索引文件合并成一个单一的有序文件。 finish 我们再来看 FileMerge 的另外一个方法 finish： pub fn finish(mut self) - io::Result() // 初始化一个临时向量 tmp，用来暂存需要合并的文件路径。 // 这个向量的容量设置为 NSTREAMS，这是预先定义的常量，表示一次可以合并的最大文件数。 let mut tmp = Vec::with_capacity(NSTREAMS); // 方法遍历 self.stacks 中的每个堆栈。每个堆栈代表一个合并层级，包含若干待合并的文件。 for stack in self.stacks // 对于每个堆栈，方法使用 .into_iter().rev() 迭代器反向遍历文件， // 以确保按正确的顺序处理（先进后出）。 for file in stack.into_iter().rev() // 将文件逐个添加到 tmp 向量中。 tmp.push(file); // 当 tmp 的长度达到 NSTREAMS 时， // 调用 merge_reversed 函数进行合并。 if tmp.len() == NSTREAMS merge_reversed(mut tmp, mut self.tmp_dir)?; // 对于剩余文件进行最终的合并。 if tmp.len() 1 merge_reversed(mut tmp, mut self.tmp_dir)?; // 最后应该只有一个最终文件 assert!(tmp.len() == 1); match tmp.pop() // 对文件进行重命名 Some(last_file) = fs::rename(last_file, self.output_dir.join(MERGED_FILENAME)), None = Err(io::Error::new( io::ErrorKind::Other, no ducuments were parsed or none contained any words, )), 这里涉及到了另外一个函数 merge_reversed： fn merge_reversed(filenames: mut VecPathBuf, tmp_dir: mut TmpDir) - io::Result() filenames.reverse(); let (merge_filename, out) = tmp_dir.create()?; let mut to_merge = Vec::with_capacity(NSTREAMS); mem::swap(filenames, mut to_merge); merge_streams(to_merge, out)?; filenames.push(merge_filename); Ok(()) 它其实就是将 filenames 翻转，清空并将内容转移到 to_merge，然后调用 merge_streams 合并，并将合并后的文件重新放回被清空的 filenames，也就是我们在 finish 中声明的 tmp 变量。 为什么这里需要翻转 filenames？ 假设 NSTREAMS = 3，我们执行 add_file，从 file1 到 file8，那么过程如下：ActionStack 0Stack 1NotesAdd file1file1Add file2file1, file2Add file3file1, file2, file3Merge S1(empty)merge1merge1 is the result of merging file1-file3Add file4file4merge1Add file5file4, file5merge1Add file6file4, file5, file6merge1Merge S2(empty)merge1, merge2merge2 is the result of merging file4-file6Add file7file7merge1, merge2Add file8file7, file8merge1, merge2Trigger merge because 8 files are reached最后我们获得的结果是：stack0stack1file7, file8merge1, merge2按照文件的添加顺序，我们期望在 finish 中合并的顺序应该是：merge1, merge2, file7, file8。所以我们遍历 stacks 的时候，从第 1 层开始遍历的话，我们就需要反向遍历 rev()，这个时候我们组成的 tmp 就是：file8, file7, merge2, merge1。最后我们传入 merge_reversed 的时候，再进行 reverse()，就可以获得我们期望的顺序 merge1, merge2, file7, file8。 回过头来，我们总结一下 finish：这个方法通过多级合并的方式，逐层处理并最终合并所有文件到一个文件。这个方法确保在多个文件频繁合并的环境中，能有效地管理和减少临时存储使用，并保持合并操作的效率。通过最后的重命名操作，它还处理了文件的最终存放，确保合并结果的正确性和可用性。 实现了 merge.rs 的相关内容，我们就可以来实现 create.rs 中的最后一步了。 step5: merge_index_files 我们将第 4 阶段构建的临时文件合并成一个最终的索引文件并输出到 output_dir 目录中。 fn merge_index_files(files: ReceiverPathBuf, output_dir: Path) - io::Result() let mut merge = FileMerge::new(output_dir); for file in files merge.add_file(file)?; merge.finish() run_pipeline 至此，我们就完成了并发构建倒排索引的 5 个步骤了，对其进行组织，就可以实现我们的并发构建函数 run_pipeline： fn run_pipeline(documents: VecPathBuf, output_dir: PathBuf) - io::Result() // Launch all five stages of the pipeline. let (texts, h1) = start_file_reader_thread(documents); let (pints, h2) = start_file_indexing_thread(texts); let (gallons, h3) = start_in_memory_merge_thread(pints); let (files, h4) = start_index_writer_thread(gallons, output_dir); let result = merge_index_files(files, output_dir); // Wait for threads to finish, holding on to any errors that they encounter. let r1 = h1.join().unwrap(); h2.join().unwrap(); h3.join().unwrap(); let r4 = h4.join().unwrap(); // Return the first error encountered, if any. // (As it happens, h2 and h3 cant fail: those threads // are pure in-memory data processing.) r1?; r4?; result read.rs 完整源码：read.rs 在 merge.rs 中，我们还剩最后一个结构没有解析，那就是 IndexFileReader，它是索引文件的读取器。 struct: IndexFileReader pub struct IndexFileReader pub terms_docs: BufReaderFile, entries: BufReaderFile, next: OptionEntry,pub struct Entry pub term: String, pub df: u32, pub offset: u64, pub nbytes: u64, 我们在 IndexFileReader 结构体中定义两个 BufReaderFile ，这是为了有效管理和操作索引文件中的不同数据段。具体来说，这种设计使得代码能够更加灵活和高效地处理索引文件中的“主数据区”和“内容表区”。 即用来分别处理下图的 termsdoc 和 entries 两个区域： 这有几个好处： 独立的文件指针：每个 BufReaderFile 维护自己的文件读取位置（文件指针）。这意味着读取或搜索内容表时，不会影响主数据区的文件指针，反之亦然。这样可以避免频繁地重新定位文件指针，提高文件操作的效率。 缓冲读取：BufReader 提供了缓冲读取功能，可以减少直接对硬盘的读取次数，从而优化读取性能。对于需要频繁读取小块数据的索引操作，使用缓冲读取可以显著提高效率。 并行操作：在多线程环境中，可能需要同时读取主数据区和内容表区。使用两个独立的 BufReader 实例可以简化并行读取的管理，每个读取操作都可以在不干扰另一个操作的情况下独立进行。 Entry 就是我们在 write.rs 中 write_contents_entry 时传入的参数，这里我们将其封装成一个 struct，再次回顾下这几个字段的含义： term: 索引单词。为了统一，如果 term 为空，则表示当前表示的是 doc，否则为 terms。 df: term 的出现次数。为了统一，如果 df 为 0，则表示当前表示的是 doc，否则为 terms。 offset: 对应的 terms 或 docs 在文件中的偏移。 nbytes: 对应的 terms 或 docs 的总长度。 read_entry 这里我们重点解释一下 read_entry 方法，其他的都比较简单，请在源码中查找。 fn read_entry(f: mut BufReaderFile) - io::ResultOptionEntry // 获取偏移值 let offset = match f.read_u64::LittleEndian() Ok(value) = value, Err(err) = if err.kind() == io::ErrorKind::UnexpectedEof return Ok(None); else return Err(err); ; // 读取 nbytes let nbytes = f.read_u64::LittleEndian()?; // 读取 df let df = f.read_u32::LittleEndian()?; // 读取 term_len，并初始化一块内存 bytes 用来读取完整的 term let term_len = f.read_u32::LittleEndian()? as usize; let mut bytes = vec![0; term_len]; f.read_exact(mut bytes)?; let term = match String::from_utf8(bytes) Ok(s) = s, Err(_) = return Err(io::Error::new(io::ErrorKind::Other, unicode fail)), ; // 返回构建的 Entry Ok(Some(Entry term, df, offset, nbytes, )) 结合下面这张图，很容易理解 read_entry 就是前面 write_contents_entry 的逆向过程。 create.rs 完整源码：create.rs 至此，我们就分析完并发构建索引的整个过程了，在 create.rs 中，我们使用 clap 命令解析框架来构建一个 CLI 工具用以支持构建索引，我们同时支持单线程构建和并发构建，具体可看完整源码。 如果对 clap 不熟悉的读者，可参考：深入探索 Rust 的 clap 库：命令行解析的艺术 #[derive(Parser)]struct Opts #[arg(short, long, default_value_t = false, help = Default false)] single_threaded: bool, #[arg(required = true)] filenames: VecString,fn main() let opts = Opts::parse(); match run(opts.filenames, opts.single_threaded) Ok(()) = Err(err) = println!(error: , err), 搜索功能 在《Rust 程序设计（第二版）》中，作者并没有实现搜索功能，笔者对其进行扩展，目标是对标我们前篇所构建的 Rust 实战丨倒排索引。这个搜索功能，会根据现有的索引文件重建内存索引 InMemoryIndex，支持指定 term 进行搜索，并将包含这个 term 的文件在响应的位置中进行高亮显示并输出到终端。 search.rs 完整源码：search.rs 程序入口如下所示，比较简单，就不赘述了。 #[derive(Parser)]struct Opts #[arg(short, long, required = true, help = Specify index file path)] index_file: String, #[arg(short, long, required = true, help = Specify search term)] term: String,fn main() - io::Result() let opts = Opts::parse(); let index = InMemoryIndex::from_index_file(opts.index_file)?; index.search(opts.term)?; Ok(()) 这里有 2 个核心逻辑： InMemoryIndex::from_index_file: 根据索引文件重建内存索引。 index.search(term): 搜索。 index.rs 我们在 index.rs 中为 InMemoryIndex 实现上述 2 个方法。 from_index_file pub fn from_index_fileP: AsRefPath(filename: P) - io::ResultInMemoryIndex let mut index = InMemoryIndex::new(); // 获取 IndexFileReader let mut reader = IndexFileReader::open_and_delete(filename, false)?; // 依次解析每个 Entry while let Some(entry) = reader.iter_next_entry() if entry.term.is_empty() entry.df == 0 // 当前 Entry 指向的是一个 Document。 // 通过 terms_docs 读取 Document 所在位置并进行解析。 reader.terms_docs.seek(io::SeekFrom::Start(entry.offset))?; let doc_id = reader.terms_docs.read_u32::LittleEndian()?; let path_len = reader.terms_docs.read_u64::LittleEndian()?; let mut path = vec![0u8; path_len as usize]; reader.terms_docs.read_exact(mut path)?; index.docs.insert( doc_id, Document id: doc_id, path: vec_to_pathbuf(path), , ); else // 当前 Entry 指向的是一个 terms。 // 通过 terms_docs 读取 terms 所在位置并进行解析。 let mut hits = vec![]; reader.terms_docs.seek(io::SeekFrom::Start(entry.offset))?; let mut data = vec![0u8; entry.nbytes as usize]; reader.terms_docs.read_exact(mut data)?; let mut cursor = Cursor::new(data); let mut i = entry.df; let mut has_hit = false; let mut quit = false; while i 0 !quit let mut hit = Vec::with_capacity(4 + 4 + 4); // cannot use vec![0;12] loop if let Ok(item) = cursor.read_i32::LittleEndian() // the start of next hit if item == Self::HITS_SEPERATOR has_hit hits.push(hit); i -= 1; index.word_count -= 2; hit = Vec::with_capacity(4 + 4 + 4); has_hit = true; hit.write_u32::LittleEndian(item as u32).unwrap(); index.word_count += 1; else quit = true; if !hit.is_empty() hits.push(hit); index.word_count -= 2; break; index.terms.insert(entry.term, hits); index.word_count /= 2; Ok(index) search pub fn search(self, term: str) - io::Result() // 获取 term 出现的位置 let m: OptionVecVecu8 = self.terms.get(term); if m.is_none() println!(can not found in all documents, term); return Ok(()); let hits = m.unwrap(); // 遍历每个出现的位置 for hit in hits let mut cursor = Cursor::new(hit); let _ = cursor.read_i32::LittleEndian().unwrap(); // 获取文档原始信息 let document_id = cursor.read_u32::LittleEndian().unwrap(); let doc = self.docs.get(document_id); if doc.is_none() println!(cannot found document , document_id); continue; let doc = doc.unwrap(); // hits 存储的内容：[HITS_SEPERATOR, document_id, start_pos1, end_pos1, ...] // 解析 term 出现在 doc 中的每个位置 let mut poss = Vec::with_capacity(hits.len() / 4); let mut pos = TokenPos::default(); let mut has_pos = false; while let Ok(p) = cursor.read_u32::LittleEndian() if !has_pos pos.start_pos = p; has_pos = true; else pos.end_pos = p; poss.push(pos); pos = TokenPos::default(); has_pos = false; // 对每个出现的位置进行高亮处理 let result = highlight_file(doc.path.clone(), mut poss)?; // 输出高亮后的结果 println!( :?: , doc.path, result); Ok(()) 至此，我们就实现了高并发构建索引和根据索引进行搜索的功能，本篇某些部分可能比较复杂，篇幅也比较冗长，笔者在阅读书中原实现的时候，也是获益颇丰，想不到一个简单的倒排索引竟涉及这么多的处理细节。也希望本篇文章能对感兴趣的读者有些许帮助。 peace! enjoy coding~ 绘图工具 https://excalidraw.com/ 参考资料 维基百科·倒排索引 Rust 程序设计（第二版）","tags":["Rust","倒排索引","并发编程","通道"],"categories":["Rust","Rust 实战"]},{"title":"Rust 实战丨倒排索引","path":"/2024/04/15/rust-action-inverted-index-demo/","content":"引言 倒排索引（Inverted Index）是一种索引数据结构，用于存储某个单词（词项）在一组文档中的所有出现情况的映射。它是搜索引擎执行快速全文搜索的核心技术，也广泛用于数据库中进行文本搜索。我们熟知的 ElasticSearch 最核心底层原理便就是倒排索引。 倒排索引的基本原理是将文档中的词汇进行反转，形成倒排列表。 在倒排列表中，每个词汇都对应一个文档标识符的列表，这些标识符指明了该词汇出现在哪些文档中。 通过查询倒排列表，可以快速地找到包含特定词汇的文档。 本文将使用 Rust 语言来实现一个简单的倒排索引，包括倒排索引的构建和搜索过程。在下一篇文章中，笔者会基于《Rust 程序设计（第二版）》并发编程篇章，解读该书作者是如何基于 Rust 通道实现更优秀、更高性能的倒排索引。 可以学到 倒排索引的原理、优势和使用 常用 crate：colored、regex Rust HashMap Rust 迭代器 开发思路 一个简单的倒排索引开发思路大概如上图所示： 读取文档 分词 构建每个词到每个文档的映射 开发过程 完整源码位于：inverted_index。 最终效果 fn main() let mut index = InvertedIndex::new(); index.add(1, Rust is safe and fast.); index.add(2, Rust is a systems programming language.); index.add(3, Programming in Rust is fun.); // query Rust let results = index.query(Rust); for result in results println!(, result); println!(); // query Programming let results = index.query(Programming); for result in results println!(, result); 执行： cargo run 输出： 版本声明 [package]name = inverted_indexversion = 0.1.0edition = 2021[dependencies]colored = 2.1.0regex = 1.10.4 项目准备 首先我们创建项目： cargo new inverted_index 准备依赖： cargo add regexcargo add colored colored: 终端高亮，后面我们将实现搜索词的高亮显示，使结果更美观。 regex: 正则库，用于实现不区分大小写替换匹配到的搜索词。 实现过程 首先我们定义两个数据结构： struct Document id: usize, content: String,struct InvertedIndex indexes: HashMapString, Vecusize, documents: HashMapusize, Document,impl InvertedIndex fn new() - InvertedIndex InvertedIndex indexes: HashMap::new(), documents: HashMap::new(), Document: 封装原始文档 IndexedIndex: 我们将构建的倒排索引 接下来我们要实现 2 个辅助函数，一个是 tokenize，用于将原始的文档信息拆分成独立的词（word/term），另一个是 hightlight，用于将匹配到的文本进行替换，使其在中断可以以紫色输出。 tokenize 实现如下： fn tokenize(text: str) - Vecstr text.split(|ch: char| !ch.is_alphanumeric()) .filter(|c| !c.is_empty()) .collect()#[test]fn tokenize_test() assert_eq!( tokenize(This is hedons tokenize function.), vec![This, is, hedon, s, tokenize, function] ) highlight 实现如下： fn highlight(term: str, content: str) - String let regex = Regex::new(format!(r(?i), term)).unwrap(); let highlighted_content = regex .replace_all(content, |caps: regex::Captures| caps[0].to_string().purple().to_string() ) .to_string(); highlighted_content#[test]fn highlight_test() assert_eq!( highlight(programming, I like programming with Rust Programming), I like \\u1b[35mprogramming\\u1b[0m with Rust \\u1b[35mProgramming\\u1b[0m ); 现在我们可以为 InvertedIndex 实现构建索引的方法 add 了，它会接收原始文档，对其进行分词，并将记录每个分词和文档 id 的映射。 impl InvertedIndex fn add(mut self, doc_id: usize, content: str) let content_lowercase = content.to_lowercase(); let words = tokenize(content_lowercase); for word in words self.indexes .entry(word.to_string()) .or_insert(vec![]) .push(doc_id) self.documents.insert( doc_id, Document id: doc_id, content: content.to_string(), , ); 然后我们再实现对应的根据分词 term 搜索原始文档的方法： impl InvertedIndex fn query(self, term: str) - VecString let term_lowercase = term.to_lowercase(); if let Some(doc_ids) = self.indexes.get(term_lowercase) doc_ids .iter() .filter_map(|doc_id| self.documents .get(doc_id) .map(|doc| highlight(term_lowercase, doc.content)) ) .collect() else Vec::new() 这样一个简单的倒排索引构建和搜索功能就完成了，具体的执行效果你可以回到前面的「最终效果」进行查阅。 总结预告 本文实现的倒排索引虽然非常简单，但是也基本体现了倒排索引的最核心思想和应用方式了。在《Rust 程序设计（第二版）》的并发编程篇章中，该书提出了使用通道 channel 来并发构建倒排索引，同时给出了更加丰富和优雅的实现。在下篇文章中，笔者将阅读这部分的源码，解析并重现当中的实战过程，并进行适当扩展。 peace! enjoy coding~ 绘图工具 https://excalidraw.com/ 参考资料 维基百科·倒排索引 Rust 程序设计（第二版）","tags":["Rust","倒排索引"],"categories":["Rust","Rust 实战"]},{"title":"深入浅出 Go 语言的 defer 机制","path":"/2024/03/28/go-defer/","content":"Go 语言以其简洁的语法和强大的并发支持而闻名。在这些特性中，defer 语句是 Go 语言提供的一项独特功能，它允许我们推迟函数的执行直到包含它的函数即将返回。这个简单而强大的机制不仅可以帮助我们处理资源释放和错误处理，还能让代码更加简洁和安全。本文将深入浅出地介绍 defer 的工作原理，探究其背后的机制，并通过丰富的案例来展示它的实际应用。 笔者本来以为 Go 语言的 defer 其实东西不多，就是类似于“栈”的操作罢了，无非就是用于释放资源、后进先出而已。但是最近在阅读完《深入理解 Go 语言》、《Go 底层原理剖析》和《Go 语言设计与实现》中关于 defer 的篇章。发现其中隐含的道道和坑还是比较有意思的，特此整理这篇文章，希望能对 Go defer 原理感兴趣的读者带来一些帮助。 本文具体会包含以下内容： defer 机制简介：介绍 defer 关键字的基本概念和它在 Go 语言中的作用。 defer 的工作原理：深入探讨 defer 在函数执行结束时如何工作的细节。 defer 的执行顺序：解释 defer 语句是如何按照后进先出（LIFO）的顺序执行的。 参数预计算和值传递：讨论 defer 语句中参数是如何被预先计算和传递的。 环境变量和闭包：探讨 defer 如何与闭包一起工作，以及如何捕获和影响环境变量。 defer 与错误处理：说明如何利用 defer 和 recover 进行错误处理和异常捕获。 defer 的实现细节：深入分析 defer 的不同实现策略，包括堆上分配、栈上分配和开放编码。 版本声明 Go1.22 思维导图 核心要点 对于后面将要分析的各种各样的情况，在分析的时候只要遵循以下几个核心点，基本上就不会跑偏： 延迟执行：在函数结束时执行，包括正常返回或遭遇 panic。 栈式执行顺序：后定义的 defer 先执行（LIFO）。 参数预计算：defer 语句定义时即计算并固定参数值。 值传递原则：defer 拷贝参数，使用定义时的值。 环境变量捕获：在 defer 中可以跟一个闭包，闭包可以捕获环境变量，当然这包括具名返回值。 特别说明的是，虽然我们通常将 defer 想象为使用栈进行管理，但是实际实现上，defer 并不都是存放在栈上的，我们后面会具体分析到。这种实现细节通常对于编写正确的 Go 代码并不重要，但了解这一点对于深入理解语言内部机制可能是有帮助的。 基本用法 在 Go 语言中，defer 语句通常用于确保一个函数调用在程序执行结束时发生，常见的用例包括文件关闭、锁释放、资源回收等。 func readFile(filename string) error f, err := os.Open(filename) if err != nil return err // 确保文件在函数返回时关闭 defer f.Close() // ... 处理文件 ... return nil 在上面的例子中，defer f.Close() 保证了无论 readFile 函数如何返回（正常返回或发生错误），f.Close() 都会被调用，从而避免了资源泄露。 执行顺序 defer 的执行顺序是先进后出，即“栈”操作。这里借用刘丹冰老师的一张图来演示这个过程： 我们可以通过以下代码进行验证： func func1() fmt.Println(func1...)func func2() fmt.Println(func2...)func func3() fmt.Println(func3...)func main() defer func1()\tdefer func2()\tdefer func3() 输出如下： func3...func2...func1... 参数求值与陷阱 关于 defer 参数这一块，是一个比较容易出错的地方。我们先来看一个例子，你可以分析下它的输出会是什么？ func printI(i int) fmt.Println(printI i:, i)func main() i := 10\tdefer printI(i * 10)\ti = i + 1\tfmt.Println(main i:, i) 按照我们之前总结的核心点：参数预计算：defer 语句定义时即计算并固定参数值。具体来说，在把 defer 压入“栈”时，会同时压入函数地址和函数形参，也就是会在这个时候就把参数先算好。所以在执行到第 7 行代码的时候，就会把 i*10 算好，然后同 printI 一同压入到延迟执行栈中。 所以最后的结果就是： main i: 11printI i: 100 关于参数值传递，笔者这里再举两个例子进行比较，体会后你应该就理解了。 第一个例子中，defer 后面参数是指针，本质上值传递，但是拷贝的是指针，所以在 defer 中修改的东西，最后会反馈到指针指向的对象，所以对 testUser 的返回值是有影响的。 type User struct\tname stringfunc testUser() *User user := User\tuser.name = name-1\tdefer func(u *User) u.name = name-defer\t(user)\tuser.name = name-2\treturn userfunc main() user := testUser()\tfmt.Println(user)// name-defer 第二个例子中，我们传入的就是结构体示例本身了，因为值传递，即拷贝了一份新的 user，所以闭包内的修改对外面是不产生影响的。 type User struct name stringfunc testUser() User user := User\tuser.name = name-1\tdefer func(u User) u.name = name-defer\t(user)\tuser.name = name-2\treturn userfunc main() user := testUser()\tfmt.Println(user)// name-2 环境变量捕获 将上面的一个例子进行简单修改，会输出什么呢？ func printI(i int) fmt.Println(printI i:, i)func main() i := 10\tdefer func() printI(i * 10)\t()\ti = i + 1\tfmt.Println(main i:, i) 这个时候其实没有参数，所以会直接将下面闭包压入延迟栈中。 func() printI(i * 10) 而闭包是可以捕获环境变量的，所以在 main return 后，defer 可以捕获到 i 的值，为更新后的 i+1，最后再进行 printI(i * 10)。 所以输出结果是： main i: 11printI i: 110 所以说，defer 后面的闭包，是可以捕获环境变量的，如果这个变量是返回值的话，那么理所应当也是可以对其产生作用的，如： func getI() (i int) i = 1\tdefer func() i *= 10\t()\treturn 20func main() fmt.Println(getI()) 这段代码中，getI 的返回值是有名字的 i，getI 执行了 return 20，其实就是将 i 设置为 20，所以在执行到 defer 闭包的时候，捕获到了 i=20，并将其进行了修改。所以最终输出： 200 错误处理与 defer 我们都知道 Go 程序中遇到 panic 就会中断后面的执行流程直接返回，这个时候我们可以在 defer 中结合 recover 来捕获这个 panic，从而保护程序不崩溃。 如： func panicAndRecover() defer func() if err := recover(); err != nil fmt.Println(err) ()\tfmt.Println(函数中正常流程)\tpanic(出现异常)\tfmt.Println(panic 后的语句永远执行不到)func main() panicAndRecover()\tfmt.Println(正常回到 main)// 函数中正常流程// 出现异常// 正常回到 main 更进一步，如果我们在 defer 中也有 panic 呢？请思考下列代码： func panicAndRecover() defer func() fmt.Println(第 1 个入栈的 defer) if err := recover(); err != nil fmt.Println(最终捕获的 panic:, err) ()\tdefer func() fmt.Println(第 2 个入栈的 defer) panic(第 2 个入栈的 defer 发生 panic)\t()\tfmt.Println(panicAndRecover 函数中正常流程)\tpanic(panicAndRecover 出现异常)\tfmt.Println(panic 后的语句永远执行不到)func main() panicAndRecover()\tfmt.Println(正常回到 main) 上述代码中，我们在 panicAndRecover 强行抛出 panic，由于 defer 先进后出，所以我们会先执行第 2 个 defer，其中也发生了 panic，我们在第 1 个 defer 中对 panic 进行 recover，最终的现象是只捕获到了后面抛出的 panic： panicAndRecover 函数中正常流程第 2 个入栈的 defer第 1 个入栈的 defer最终捕获的 panic: 第 2 个入栈的 defer 发生 panic正常回到 main 这是为什么呢？ 在 Go 语言中，panic 函数实际上是创建了一个 panic 对象，并抛出这个对象。 当一个 panic 发生并开始向上传播时，Go 运行时会检查每个 defer。如果 defer 中包含 recover 调用，并且它被执行，那么 recover 会捕获当前的 panic，并且防止它继续向上传播。如果 defer 中再次发生 panic，那么原来的 panic 就不会被 recover 捕获，因为 defer 函数已经退出了。在这种情况下，新的 panic 会导致程序崩溃，因为没有更多的 defer 函数去 recover 这个新的 panic。 这说明了 Go 程序中不允许同时有多个活跃的 panic 存在，这个设计确保了在任何给定的时刻，只有一个 panic 能够被处理。这样做有几个原因： 简化错误处理： 如果同时存在多个 panic，就会变得非常复杂去确定如何处理它们，尤其是在它们之间存在依赖关系的时候。一个 panic 应该表示一个不可恢复的错误，如果有多个这样的错误同时存在，程序的状态可能会变得非常不确定。 保持一致性： panic 通常表示程序中出现了严重错误，可能会破坏程序的一致性或安全性。如果允许多个 panic 同时存在，就很难保证程序状态的一致性，因为不同的 panic 可能需要回退不同的操作。 避免资源泄漏： defer 语句用于确保资源被释放，例如文件和锁。如果在处理一个 panic 的过程中，又发生了另一个 panic，可能会导致 defer 语句中剩余的清理代码无法执行，从而引起资源泄漏。 控制流程清晰： panic 和 recover 的设计使得错误的控制流程清晰且可预测。一旦一个 panic 被 recover 捕获，程序可以选择是否继续执行，或者是通过重新 panic 来终止程序。这种决策过程在多个 panic 情况下会变得复杂且难以管理。 因此，在 Go 的设计中，不允许同时存在多个活跃的 panic。一旦发生 panic，它必须被 recover 处理，否则程序将会终止。这确保了错误处理的清晰性和程序的稳定性。 defer 放在哪 defer 实际上不一定是放在栈上的，截止 Go1.22，defer 其实用 3 种分配策略： 堆上分配 栈上分配 开放编码 执行机制 在 ssa.go 文件中，我们可以找到 state.stmt()，这个函数是负责在 Go 程序编译过程中中间代码生成阶段时对不同语句的处理过程，其中对于 ODEFER 即 defer 语句的处理逻辑如下： // stmt converts the statement n to SSA and adds it to s.func (s *state) stmt(n ir.Node) s.stmtList(n.Init())\tswitch n.Op() case ir.ODEFER: n := n.(*ir.GoDeferStmt) if base.Debug.Defer 0 var defertype string if s.hasOpenDefers defertype = open-coded else if n.Esc() == ir.EscNever defertype = stack-allocated else defertype = heap-allocated base.WarnfAt(n.Pos(), %s defer, defertype) ... 可以看到，总共有 3 种分配策略： open-coded: s.hasOpenDefers == true stack-allocated: n.Esc() == ir.EscNever heap-allocated: 默认 默认是堆分配，在 Go1.13 以前，也只有堆分配这一种策略，不过该实现的性能较差。Go 语言在 1.13 中引入栈上分配的结构体，减少了 30% 的额外开销，并在 1.14 中引入了基于开放编码的 defer，使得该关键字的额外开销几乎可以忽略不计。 本文中不对具体的分配机制进行分析，这一块会比较复杂，笔者本身也不是很感兴趣，便决定对此不过分深究，感兴趣的读者推荐详细阅读《Go 语言设计与实现》中关于 defer 关键字的分析：https://draveness.me/golang/docs/part2-foundation/ch05-keyword/golang-defer/。 本文只讨论什么情况下会使用什么分配策略。由于堆分配是默认的，我们就不作分析了，具体来看看 s.hasOpenDefers == true 和 n.Esc() == ir.EscNever 什么时候会成立。 栈上分配 我们先来看栈上分配，要满足栈上分配，则需要满足 n.Esc() == ir.EscNever。 const (\tEscUnknown = iota\tEscNone // Does not escape to heap, result, or parameters.\tEscHeap // Reachable from the heap\tEscNever // By construction will not escape.) 当 n 的逃逸分析结果是 ir.EscNever，则表明该 defer 语句从不逃逸（不会在函数调用结束后仍然被引用），这种情况下 defer 将被分配到栈上（stack-allocated）。否则，如果 defer 逃逸了，就会被分配到堆上（heap-allocated）。 那 defer 语句什么时候会逃逸呢？ 在 Go 中，一个变量的逃逸意味着它的生命周期超出了当前函数的范围。在函数内定义的变量通常分配在栈上，而在堆上分配内存需要更复杂的管理。在一些情况下，编译器可能会选择将变量分配在堆上，这种情况下我们称之为逃逸。 对于 defer 语句，如果它引用了函数外的变量，这个 defer 就会逃逸。例如： var x = 10func someFunction() defer func() fmt.Println(x) // 这里引用了外部变量 x () 在这个例子中，defer 函数内部引用了 x 这个外部变量，因此 defer 语句需要确保 x 在 defer 函数执行时仍然有效。为了满足这个条件，编译器可能会将 x 分配在堆上，而不是栈上。 开放编码 先给结论，在开发过程中，要使用开放编码策略，你只需要关注以下 4 点即可： 函数的 defer 数量不能超过 8 个； 函数的 defer 关键字不能在循环中执行； 函数的 defer 中不能发生逃逸； 函数的 return 语句与 defer 语句的乘积小于或者等于 15 个； Ok，下面是具体的分析过程。 借助 Goland 的能力，将鼠标光标放在 s.hasOpenDefers 上，按住 Command 加点击鼠标，可以看到该属性的使用情况： 可以看到该属性的判断逻辑都在 ssa.go 文件中的 buildssa() 函数中。去掉一些无关的代码，核心逻辑如下： // buildssa builds an SSA function for fn.// worker indicates which of the backend workers is doing the processing.func buildssa(fn *ir.Func, worker int) *ssa.Func ... // ①\ts.hasOpenDefers = base.Flag.N == 0 s.hasdefer !s.curfn.OpenCodedDeferDisallowed()\tswitch // ②\tcase base.Debug.NoOpenDefer != 0: s.hasOpenDefers = false\tcase s.hasOpenDefers (base.Ctxt.Flag_shared || base.Ctxt.Flag_dynlink) base.Ctxt.Arch.Name == 386: // ③ // Dont support open-coded defers for 386 ONLY when using shared // libraries, because there is extra code (added by rewriteToUseGot()) // preceding the deferreturn/ret code that we dont track correctly. s.hasOpenDefers = false // ④\tif s.hasOpenDefers len(s.curfn.Exit) 0 // Skip doing open defers if there is any extra exit code (likely // race detection), since we will not generate that code in the // case of the extra deferreturn/ret segment. s.hasOpenDefers = false // ⑤\tif s.hasOpenDefers // Similarly, skip if there are any heap-allocated result // parameters that need to be copied back to their stack slots. for _, f := range s.curfn.Type().Results().FieldSlice() if !f.Nname.(*ir.Name).OnStack() s.hasOpenDefers = false break // ⑥\tif s.hasOpenDefers s.curfn.NumReturns*s.curfn.NumDefers 15 // Since we are generating defer calls at every exit for // open-coded defers, skip doing open-coded defers if there are // too many returns (especially if there are multiple defers). // Open-coded defers are most important for improving performance // for smaller functions (which dont have many returns). s.hasOpenDefers = false ...\treturn s.f 可以看到总共有 6 个条件，我已在注释中进行标注，我们来进行逐一分析： ① base.Flag.N == 0 s.hasdefer !s.curfn.OpenCodedDeferDisallowed() 如果base.Flag.N 等于 0 且当前函数有延迟调用且没有禁止开放式延迟，那么设置s.hasOpenDefers为true。 在 Go 编译器中，-N标志通常用于禁用优化。在这段代码中，如果base.Flag.N等于 0，意味着没有禁用优化，因此编译器可能会尝试使用更高级的优化技术，比如开放式延迟（open-coded defers）。 OpenCodedDeferDisallowed() 即禁用开放编码，它的实现如下： const funcOpenCodedDeferDisallowed // cant do open-coded defersfunc (f *Func) OpenCodedDeferDisallowed() bool return f.flagsfuncOpenCodedDeferDisallowed != 0 按住 Command 后点击 funcOpenCodedDeferDisallowed 可以看到只有 funcOpenCodedDeferDisallowed(b) 可以修改它的值。 我们来看看哪个地方会调用 funcOpenCodedDeferDisallowed()，并将 funcOpenCodedDeferDisallowed 设置为 true： 调用它的地方在 stmt.go 文件中的 walkStmt() 函数，具体如下： // The max number of defers in a function using open-coded defers. We enforce this// limit because the deferBits bitmask is currently a single byte (to minimize code size)const maxOpenDefers = 8// The result of walkStmt MUST be assigned back to n, e.g.////\tn.Left = walkStmt(n.Left)func walkStmt(n ir.Node) ir.Node ...\tswitch n.Op() ... case ir.ODEFER: n := n.(*ir.GoDeferStmt) ir.CurFunc.SetHasDefer(true) ir.CurFunc.NumDefers++ if ir.CurFunc.NumDefers maxOpenDefers // Dont allow open-coded defers if there are more than // 8 defers in the function, since we use a single // byte to record active defers. ir.CurFunc.SetOpenCodedDeferDisallowed(true) if n.Esc() != ir.EscNever // If n.Esc is not EscNever, then this defer occurs in a loop, // so open-coded defers cannot be used in this function. ir.CurFunc.SetOpenCodedDeferDisallowed(true) fallthrough ... ... 第一点是：当前函数中 defer 个数超过 8 的话，则禁用开放编码。 第二点是当 n.Esc() != ir.EscNever 使，就禁用开放编码。这个要求跟前面分析的“栈上分配”要求是一样的。 这里再补充一点：什么时候 n.Esc() 会被设置为 ir.EscNever 呢？ 这里面核心点是第一个，它对应的代码如下： func (e *escape) goDeferStmt(n *ir.GoDeferStmt) k := e.heapHole()\tif n.Op() == ir.ODEFER e.loopDepth == 1 ... n.SetEsc(ir.EscNever) ... e.loopDepth == 1 时就设置，换言之，defer 不在循环中的时候，才允许开放编码。 总而言之，第 ① 个条件约束了要采用 open-coded 开放编码策略的 3 个条件： 函数中 defer 个数不能超过 8； defer 不能在循环中； defer 不能发生逃逸。 ② base.Debug.NoOpenDefer != 0 如果base.Debug.NoOpenDefer不为 0，那么禁用开放式延迟。 NoOpenDefer int `help:disable open-coded defers concurrent:ok` ③ (base.Ctxt.Flag_shared || base.Ctxt.Flag_dynlink) base.Ctxt.Arch.Name == “386” 如果当前架构是386，并且使用共享库或动态链接，那么不支持开放式延迟，因为存在一些额外的代码（由rewriteToUseGot()添加）可能无法正确追踪。 ④ len(s.curfn.Exit) 如果存在任何额外的退出代码（比如可能是竞态检测相关的代码），则跳过开放式延迟。 ⑤ !f.Nname.(*ir.Name).OnStack() 如果有任何堆分配的结果参数需要复制回它们的栈槽，也跳过开放式延迟。 ⑥ s.curfn.NumReturns*s.curfn.NumDefers 15 如果函数的返回数乘以延迟调用数大于 15，考虑到每个退出点都要生成延迟调用，并且开放式延迟对于小函数（没有多个返回）的性能提升最为重要，所以在这种情况下也不使用开放式延迟。 堆上分配 当不满足开放编码和栈上分配的时候，默认就是堆上分配（heap-allocated），性能最差，这里不做分析。 以上就是本文关于 Go 语言中 defer 关键字的具体分析，Happy Coding! Peace~ 参考 深入理解 Go 语言 Go 语言底层原理剖析 Go 语言设计与实现 ChatGPT4","tags":["Go"],"categories":["Go"]},{"title":"深入 Go 语言核心：结构体的全方位解析","path":"/2024/03/09/go-struct/","content":"Go 语言，作为一种高效、静态类型的编程语言，自其问世以来便以其并发处理能力和简洁的语法结构广受开发者欢迎。虽然 Go 不是传统意义上的面向对象语言，它却以独特的方式支持面向对象编程的核心概念，其中结构体扮演了非常关键的角色。 结构体在 Go 语言中是一种复合数据类型，允许我们将不同类型的数据聚合到一起。它不仅提高了数据管理的效率和逻辑清晰度，还是 Go 语言中实现面向对象编程思想如封装、组合等概念的基石。了解和掌握结构体的使用，对于深入理解 Go 语言的特性和编写高效、可维护的 Go 代码至关重要。 本文将带您全面深入地探索 Go 语言中结构体的各个方面，从基本定义、初始化和使用，到高级特性如结构体的组合、方法定义、内存对齐等，每一个细节都将一一展开。无论您是 Go 语言的新手，还是有一定经验的开发者，相信本文都能为您提供有价值的见解和帮助。让我们一起探索 Go 结构体的奥秘，揭开其背后的原理，优化我们的代码结构，提升编程效率。 版本声明 Go 1.22.1 gopkg.in/yaml.v3 v3.0.1 os: m2max 全文概览 1. 结构体的基本使用 1.1 定义结构体 结构体类型的定义形式如下： type T struct Field T1, Field T2, .... FieldN Tn, 比如： type Person struct Name string Age int ExtraInfo map[string]interface 结构体内部，也可以内嵌匿名结构体，如： type Person struct Name string Age int School struct Name string Address string Phone string 但是！注意，如果 Person 中包含了 Person 呢？ type Person struct person Person 这里会报错：不允许引用自身。 ./main.go:5:6: invalid recursive type: Person refers to itself 这是因为 Go 语言在编译时需要知道每个类型的确切大小，以便正确地分配内存。但在这个定义中，因为 Person 包含自身，编译器无法确定 Person 的大小，因此会报错。 如果你需要在一个结构体中引用相同类型的数据，你应该使用指针。指针的大小是固定的，因此编译器可以确定结构体的大小。 type Person struct person *Person 1.2 初始化结构体 假设我们有以下结构体： type Person struct Name string\tAge int\tExtraInfo map[string]interface 可以有以下几种初始化： // 逐个字段赋值，顺序不重要，也可以只赋值部分字段person1 := Person Age: 18, Name: hedon, ExtraInfo: make(map[string]interface),fmt.Println(person1) // hedon 18 map[]// 可以不指定字段，严格按照顺序person2 := Personhedon2, 19, make(map[string]interface)fmt.Println(person2) // hedon2 19 map[]// 默认初始化，则结构体中的每个字段都会被默认赋予其对应类型的“零值”var person3 Personfmt.Println(person3) // 0 map[]fmt.Println(person3.ExtraInfo == nil) // true// 也可以使用 new() 或 来初始化并返回指针person3 := new(Person)fmt.Println(person3) // 0 map[] 1.3 空结构体 有一种特殊的结构体，它一个字段都没有，我们称之为“空结构体”： type Empty struct 空结构体非常特殊，它不占据任何空间！你可以自己验证一下： type Empty structfunc main() fmt.Println(the size of empty:, unsafe.Sizeof(Empty)) // the size of empty: 0 而且，所有空结构体的地址都一样： type Empty structtype Empty1 structfunc main() e := Empty\te1 := Empty1\tfmt.Printf(the address of empty: %p , e) // the address of empty: 0x10460f520\tfmt.Printf(the address of empty1: %p , e1) // the address of empty1: 0x10460f520 这是因为 Go 语言为所有大小为 0 的变量都指向了同一个值： // base address for all 0-byte allocationsvar zerobase uintptr 好处就是减少了内存的浪费。典型的用法就是我们可以使用 map 来实现 Set，这样就只花费了存储键的空间，而值不占用任何空间。 type Set = map[string]struct 1.4 访问和修改结构体 结构体属性的可见性跟 Go 包的可见性规则一样：大写对包外可见，小写仅包内可见。 使用 . 访问和修改结构体中的属性。 Go 语言中只有“值传递”，所以如果你要将结构体示例传入一个 func 进行修改，则需要传入其引用。 type Person struct Name string\tAge intfunc main() p := PersonName: hedon, Age: 18\tUpdatePersonName(p)\tfmt.Println(1:, p)\tUpdatePersonNameWithRef(p)\tfmt.Println(2:, p)func UpdatePersonName(p Person) p.Name = hedon-1func UpdatePersonNameWithRef(p *Person) p.Name = hedon-2 输出： 1: hedon 182: hedon-2 18 2. 结构体的高级特性 2.1 结构体组合 在 Go 语言中，倡导的是“组合优于继承”的哲学，即倡导使用组合而不是继承来实现代码的复用。该理念鼓励开发者通过组合和接口来构建灵活、可维护的代码，而不是依赖于更严格、更易出错的继承关系。这种方式促进了代码的解耦，增强了代码的灵活性和可重用性，同时也使得代码更加清晰和易于理解。 在 Go 中，组合是通过将一个或多个类型（通常是结构体）嵌入到另一个结构体中来实现的。这使得嵌入的类型的方法被“提升”到包含它的结构体中，允许你调用这些方法就像它们是外部结构体的一部分一样。 type Engine struct Power intfunc (e *Engine) Start() // 启动引擎的逻辑type Car struct Engine // 通过组合的方式嵌入 Engine// 现在 Car 可以直接调用 Start 方法car := CarEnginePower: 100car.Start() // 调用的是 Engine 的 Start 方法 2.2 结构体的方法 假设我们定义了一个结构体 Person： type Person struct Name string 在 Go 中，你可以为结构体的值或指针实现特定的方法： func(p Person) SetName(name string) string p.Name = name func(p *Person) SetName(name string) string p.Name = name 这两者最核心的区别是：当你为结构体的指针类型定义方法时，该方法会在原始结构体实例上操作。这意味着方法内部对结构体的任何修改都会影响到原始结构体。 所以这两段代码的输出是不一样的： func main() p := PersonName: hedon\tp.SetName(new_name)\tfmt.Println(p.Name) // name_namefunc (p *Person) SetName(name string) p.Name = name func main() p := PersonName: hedon\tp.SetName(new_name)\tfmt.Println(p.Name) // hedonfunc (p Person) SetName(name string) p.Name = name 但是这里我想再补充两个小点。请先思考一下下面这两段代码是否可以编译通过？如果可以输出是什么？ func main() p := PersonName: hedon\tp.SetName(new_name)\tfmt.Println(person name after set:, p.Name)\tpt := reflect.TypeOf(p)\tfmt.Println(the number of persons method: , pt.NumMethod())\tp2 := Person\tpt = reflect.TypeOf(p2)\tfmt.Println(the number of persons method: , pt.NumMethod())func (p *Person) SetName(name string) p.Name = name func main() p := PersonName: hedon\tp.SetName(new_name)\tfmt.Println(person name after set:, p.Name)\tpt := reflect.TypeOf(p)\tfmt.Println(the number of persons method: , pt.NumMethod())\tp2 := Person\tpt = reflect.TypeOf(p2)\tfmt.Println(the number of persons method: , pt.NumMethod())func (p Person) SetName(name string) p.Name = name 很明显这两段代码的唯一区别就是，第一段代码我们是为 *Person 实现了 SetName 方法，而第二段代码我们是为 Person 实现了 SetName 方法。两段代码我们都打印了调用 SetName 后 p.name 的值，以及利用方式分别获取 Person 和 *Person 实现的方法个数。 第一段代码的输出如下： person name after set: new_namethe number of persons method: 0the number of persons method: 1 第二段代码的输出如下： person name after set: hedonthe number of persons method: 1the number of persons method: 1 这里我们可以得出 2 个结论： ① 结构体的修改依赖于方法接收器的类型： 当方法的接收器为值类型（Person）时，对结构体的修改不会影响原始结构体实例，因为方法作用于结构体的副本上。 当方法的接收器为指针类型（*Person）时，对结构体的修改会影响原始结构体实例，因为方法作用于结构体的引用上。 ② 方法集依赖于接收器的类型： 为值类型（Person）实现的方法，既属于值类型也属于指针类型（*Person）的方法集。 为指针类型（*Person）实现的方法，只属于指针类型的方法集。 对于 ②，我们可以通过 Plan9 汇编代码一探究竟。 我们为第一段代码执行以下命令： go build -gcflags -S main.go 在输出的最上面，可以看到只有 main.(*Person).GetName。 # command-line-argumentsmain.main STEXT size=128 args=0x0 locals=0x48 funcid=0x0 align=0x0 ...main.(*Person).GetName STEXT size=16 args=0x8 locals=0x0 funcid=0x0 align=0x0 leaf ... 我们再来为第二段代码执行相同的命令。可以在输出的最上面，看到不仅有 main.Person.GetName，还可以发现编译器自动帮我们生成了 main.(*Person).GetName。 # command-line-argumentsmain.main STEXT size=480 args=0x0 locals=0xe8 funcid=0x0 align=0x0\t...main.Person.SetName STEXT size=16 args=0x28 locals=0x0 funcid=0x0 align=0x0 leaf ...main.(*Person).SetName STEXT dupok size=128 args=0x18 locals=0x8 funcid=0x16 align=0x0\t... 对于 ②，笔者其实有一个不太理解的地方，比如下面这段代码： func main() p := PersonName: hedon\tp.SetName(new_name)\tfmt.Println(person name after set:, p.Name) // hedonfunc (p Person) SetName(name string) p.Name = name 这里 p 是引用类型，下面实现的是 Person.SetName，按照我们上面的结论，编译器会自动帮我们实现 (*Person).SetName。按照这种思路，输出 new_name 也是解释得通的。因为既然我们声明的是一个引用类型，那么 p 完全可以去调用自动生成的 (*Person).SetName。但是最终的结果还是输出 hedon，所以这里编译器自动帮我们将 p 进行解引用，然后调用了 Person.SetName。 这是比较困扰笔者的一个地方，欢迎评论区讨论~ 可能编译器还是更希望对于开发者来说“所见即所得”，既然开发者实现的是 Person.SetName，那么对于开发者来说，应该就是希望不影响原始结构体的值，所以编译器还是选择遵循这种“意愿”，不乱操作。 2.3 结构体比较 Go 允许直接比较两个结构体实例，但有一定的限制： 可比较性：只有当结构体中的所有字段都是可比较的时，结构体才是可比较的。基本数据类型（如 int、string 等）是可比较的，但切片、映射、函数等类型不可比较。 相等性检测：当两个结构体的对应字段都相等时，这两个结构体被认为是相等的。可以使用 == 和 != 操作符来进行比较。 下面这段示例，p3==p4 返回了 true，这符合我们上面总结的结论。p1==p2 返回了 false，因为这其实不是结构体之间的比较了，这是指针的比较了。 p1 := PersonName: hedon, Age: 18p2 := PersonName: hedon, Age: 18fmt.Println(p1 == p2) // falsep3 := PersonName: hedon, Age: 18p4 := PersonName: hedon, Age: 18fmt.Println(p3 == p4) // true 结构体的比较只支持 == 和 !=，不支持 和 等其他运算符的比较。而 Go 语言又不支持比较符重载。所以如果你要比较两个结构体的大小，那么只能自行封装类型 compare 的函数。在这我们排序结构体数组或切片的时候，经常使用到，比如我们希望按 Age 字段从小到大排序： sort.Slice(persons, func(i, j int) bool return persons[i].Age persons[j].Age) 2.4 结构体复制 在 Go 中，结构体也是值类型，这意味着当它们被赋值给新的变量或作为函数参数传递时，实际上是进行了一次深拷贝： 值复制：当将一个结构体赋值给一个新变量时，新变量会获得原始结构体的一个副本，它们在内存中占有不同的位置。 独立性：因为是深拷贝，所以原始结构体和副本结构体是完全独立的；修改其中一个不会影响另一个。 type Point struct X, Y intoriginal := Point1, 2copy := originalcopy.X = 3fmt.Println(original) // 1, 2fmt.Println(copy) // 3, 2 3. 结构体与接口 在 Go 语言中，如果一个类型实现了接口中所有的方法，则这个类型就实现了该接口。关于接口部分的知识点，比如接口定义、多态和断言等，本文就不赘述了。 在这里我主要想从另外一个角度继续来验证前面我们总结的：为值类型（Person）实现的方法，既属于值类型也属于指针类型（*Person）的方法集。 请看这段代码： package mainimport fmttype Person interface GetName() stringtype Man struct Name stringfunc (m Man) GetName() string return m.Namefunc PrintPersonName(p Person) fmt.Println(p.GetName())func main() m1 := ManName: hedon1\tPrintPersonName(m1)\tm2 := ManName: hedon2\tPrintPersonName(m2) 这段代码我们定义了 Person 接口，它只有一个方法 GetName。然后我们定义了一个结构体 Man，并为它的值类型实现了 Person 接口。通过我们上面的结论，这里 Man 和 *Man 其实都实现了 Person 接口，所以上面的代码是可以编译通过的。 如果改成为指针类型实现接口呢？你可以试一下~ func (m *Man) GetName() string return m.Name 4. 泛型结构体 Go 语言在其 1.18 版本中引入了泛型支持，这包括了对泛型结构体的支持。通过使用泛型，你可以创建更灵活和可重用的数据结构和函数。 type Container[T any] struct items []T 可以看到 Go 语言用 [] 来实现泛型，而不像其他语言一样用 ，真是喜欢搞特殊啊 🤡，又丑又容易跟 map 和 slice 混淆。 5. 结构体的标签（Tag） 在结构体字段后面，我们可以用 `` 来指定标签，这允许我们对结构体定制化一些常用操作，最经典的就是序列化与反序列化。 5.1 序列化与反序列化 对于常见的数据结构，如 json、yaml、xml 或 toml，我们都可以通过在结构体中指定标签，然后使用对应解析库进行序列化和反序列化。比如： package mainimport (\tencoding/json\tfmt)type Person struct Name string `json:name`\tAge int `json:age`func main() p := PersonName: hedon, Age: 18\tbs, _ := json.Marshal(p) // 序列化\tfmt.Println(string(bs)) // name:hedon,age:18\tnewP := Person\t_ = json.Unmarshal(bs, newP) // 反序列化\tfmt.Println(newP) // hedon 18 在笔者的实践过程中，在结构体组合的场景下，不同数据格式的解析会有一些小差别，这在实战过程中你需要重点关注和验证。比如 json 和 yaml 就会有一些不同。 比如说我这里定义了下面 2 个结构体，其中 Person 组合了 School： type Person struct Name string `json:name yaml:name`\tAge int `json:age yaml:age`\tSchooltype School struct SchoolName string `json:school_name yaml:school_name`\tSchoolAddress string `json:school_address json:school_address` 它们都加上了 json 和 yaml 标签，对于 json 类型，你可以用标准库的 encoding/json 来进行序列化和反序列化，而 yaml 你可以使用第三方库：go-yaml。 先来看系列化结果： func main() p := PersonName: hedon, Age: 18, School: SchoolSchoolName: nb_school, SchoolAddress: a_good_school_place\tbs, _ := json.Marshal(p)\tfmt.Println(json: , string(bs))\tbs, _ = yaml.Marshal(p)\tfmt.Println(yaml: , string(bs)) 输出如下： json: name:hedon,age:18,school_name:nb_school,school_address:a_good_school_placeyaml: name: hedon age: 18 school: school_name: nb_school school_address: a_good_school_place 通过观察你可以发现哈，在 json 中，组合的时候（没有给 School 加标签）直接将 School 平铺在 Person 中，所以在序列化的结果中，找不到 school: 。而在 yaml 中，并不是直接平铺的。 这个区别在你解析配置文件的时候尤其重要，如果不注意，那么可能会导致配置解析失败。 我准备了 4 个配置文件，分别是： // person1.json name: hedon_json, age: 18, school: school_name: nb_json_school, school_address: a_good_place_in_json # person1.yamlname: hedon_yamlage: 18school: school_name: nb_yaml_school school_address: a_good_price_in_yaml // person2.json name: hedon_json, age: 18, school_name: nb_json_school, school_address: a_good_place_in_json # person2.yamlname: hedon_yamlage: 18school_name: nb_yaml_schoolschool_address: a_good_price_in_yaml 解析代码如下： func main() filenames := []stringperson1.json, person1.yaml, person2.json, person2.yaml\tfor i, fn := range filenames bs := readFileIntoBytes(fn) p := Person if i%2 == 0 _ = json.Unmarshal(bs, p) else _ = yaml.Unmarshal(bs, p) fmt.Printf(%s - %v , fn, p)\tfunc readFileIntoBytes(filename string) []byte f, err := os.Open(filename)\tif err != nil panic(err) bs, _ := io.ReadAll(f)\treturn bs 输出： person1.json - hedon_json 18 person1.yaml - hedon_yaml 18 nb_yaml_school a_good_price_in_yamlperson2.json - hedon_json 18 nb_json_school a_good_place_in_jsonperson2.yaml - hedon_yaml 18 如果给 School 字段加上 json tag 的话，结果又是不同： type Person struct Name string `json:name yaml:name`\tAge int `json:age yaml:age`\tSchool `json:school yaml:school` 输出： person1.json - hedon_json 18 nb_json_school a_good_place_in_jsonperson1.yaml - hedon_yaml 18 nb_yaml_school a_good_price_in_yamlperson2.json - hedon_json 18 person2.yaml - hedon_yaml 18 可以看到受影响的只有 json。 到这里我们可以总结：在组合场景下，如果不明确指定 tag，yaml 解析期望字段是嵌套的，而 json 解析期望字段是平铺的。 5.2 自定义 Tag 在 Go 中，你可以为结构体字段定义任意的标签。这些标签在编译时会被存储，并且可以在运行时通过反射（reflection）来访问。 假设我们定义一个名为 check 的标签，它用于我们对结构体字段的检查，假设我们这个标签支持以下功能： check:strnoempty: 字符串不可以为空。 假如加入 check 标签的 Person 结构体如下： type Person struct Name string `check:strnoempty` 我们来为 check 实现解析函数： func CheckPerson(p Person) error pt := reflect.TypeOf(p)\tpv := reflect.ValueOf(p)\tfor i := 0; i pt.NumField(); i++ field := pt.Field(i) tagValue := field.Tag.Get(check) if tagValue == continue if field.Type.Kind() == reflect.String tagValue == strnoempty if err := checkStrNoEmpty(field.Name, pv.Field(i).Interface()); err != nil return err return nilfunc checkStrNoEmpty(fieldName string, v any) error s, ok := v.(string)\tif !ok return fmt.Errorf(%v is not string, v) if s == return fmt.Errorf([check] %s should not be empty, fieldName) return nil 测试如下： func main() p1 := Person\tp2 := PersonName: hedon\tfmt.Println(CheckPerson(p1)) // [check] Name should not be empty\tfmt.Println(CheckPerson(p2)) // nil 6. 结构体内存对齐 在本小节中，我们将探讨 Go 语言结构体的内存结构和对齐策略。 6.1 问题引出 思考下面这段代码的输出： type S1 struct num2 int8\tnum1 int16\tflag booltype S2 struct num1 int8\tflag bool\tnum2 int16func main() fmt.Println(unsafe.Sizeof(S1))\tfmt.Println(unsafe.Sizeof(S2)) 为什么仅是字段顺序不同，S1 和 S2 的大小就不一样了？ 我们可以写个简单的程序来输出 S1 和 S2 的内存结构： func main() s1 := S1\ts2 := S2\tfmt.Print(s1: )\tprintMemory(s1)\tfmt.Print(s2: )\tprintMemory(s2)func printMemory(a any) t := reflect.TypeOf(a)\tmem := make([]int, int(t.Size()))\tfor i := 0; i t.NumField(); i++ field := t.Field(i) offset := int(field.Offset) size := int(field.Type.Size()) for j := 0; j size; j++ mem[j+offset] = i + 1 fmt.Println(mem) 输出： s1: [1 0 2 2 3 0]s2: [1 2 3 3] 其中 1、2、3 分别替代结构体中的第 1/2/3 个字段所占用的内存。这里可以看到 s1 的长度是 6 字节，而 s2 是 4 字节。这里 s1 比 s2 多出的 2 个字节就是这两个填充的 0。这而 2 个字节的填充，就是为了内存对齐。 6.2 内存对齐 如上分析，s1 的内存结构如下： 如果没有内存对齐呢？s1 的结构可能如下： 如果是 16 位系统的话，那么没有内存对齐的情况下，要访问 s1.num2 字段，就需要跨过 2 个系统字长的内存，效率就低了。具体来说，内存对齐是计算机内存分配的一种优化方式，用于确保数据结构的存储按照特定的字节边界对齐。这种对齐是为了提高计算机处理数据的效率。 6.3 对齐系数 对齐系数：变量的内存地址必须被对齐系数整除。 unsafe.Alignof(): 可以查看值在内存中的对齐系数。 6.4 基本类型对齐 fmt.Printf(bool size: %d, align: %d , unsafe.Sizeof(bool(true)), unsafe.Alignof(bool(true)))fmt.Printf(byte size: %d, align: %d , unsafe.Sizeof(byte(0)), unsafe.Alignof(byte(0)))fmt.Printf(int8 size: %d, align: %d , unsafe.Sizeof(int8(0)), unsafe.Alignof(int8(0)))fmt.Printf(int16 size: %d, align: %d , unsafe.Sizeof(int16(0)), unsafe.Alignof(int16(0)))fmt.Printf(int32 size: %d, align: %d , unsafe.Sizeof(int32(0)), unsafe.Alignof(int32(0)))fmt.Printf(int64 size: %d, align: %d , unsafe.Sizeof(int64(0)), unsafe.Alignof(int64(0))) 输出： bool size: 1, align: 1byte size: 1, align: 1int8 size: 1, align: 1int16 size: 2, align: 2int32 size: 4, align: 4int64 size: 8, align: 8 结论：基本类型的对齐系数跟它的长度一致。 6.5 结构体内部对齐 结构体内存对齐分为内部对齐和结构体之间对齐。 我们先来看结构体内部对齐： 指的是结构体内部成员的相对位置（偏移量）； 每个成员的偏移量是 自身大小 和 对齐系数 的较小值的倍数 type Demo struct a bool b string c int16 假如我们定义了上面的结构体 Demo，如果在 64 位系统上（字长为 8 字节）通过上面的规则，可以判断出：（单位为字节） a: size=1, align=1 b: size=16, align=8 c: size=2, align=2 当然我们也可以通过程序输出来验证： type Demo struct a bool // size=1, align=1\tb string // size=16, align=8\tc int16 // size=2, align=2func main() d := Demo\tfmt.Printf(a: size=%d, align=%d , unsafe.Sizeof(d.a), unsafe.Alignof(d.a))\tfmt.Printf(b: size=%d, align=%d , unsafe.Sizeof(d.b), unsafe.Alignof(d.b))\tfmt.Printf(c: size=%d, align=%d , unsafe.Sizeof(d.c), unsafe.Alignof(d.c))\tprintMemory(d)func printMemory(a any) t := reflect.TypeOf(a)\tmem := make([]int, int(t.Size()))\tfor i := 0; i t.NumField(); i++ field := t.Field(i) offset := int(field.Offset) size := int(field.Type.Size()) for j := 0; j size; j++ mem[j+offset] = i + 1 fmt.Println(mem) 输出： a: size=1, align=1b: size=16, align=8c: size=2, align=2[1 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 0 0 0 0 0 0] 6.6 结构体长度填充 上面 Demo 结构体最后还填了 6 个字节的 0，这就是结构体长度填充： 结构体通过填充长度，来对齐系统字长。 结构体长度是 最大成员长度 和 系统字长 较小值的整数倍。 我的系统环境是 m2max，系统字长是 8 字节，Demo 最大成员长度是 b string，即 16 个字节，所以 Demo 的长度应该是 8 的倍数，所以最后填充了 6 个字节的 0。 6.7 结构体之间对齐 结构体之间对齐，是为了确定结构体的第一个成员变量的内存地址，以让后面的成员地址都合法。 结构体的对齐系数是 其成员的最大对齐系数； 6.8 空结构体对齐 前面我们专门讨论了空结构体 struct，它们的内存地址统一指向 zerobase，而且内存长度为 0。这也导致了它的内存对齐规则，有一些不同。具体可以分为以下 4 个情况。 6.8.1 空结构体单独存在 空结构体单独存在时，其内存地址为 zerobase，不额外分配内存。 6.8.2 空结构体在结构体最前 空结构体是结构体第一个字段时，它的地址跟结构体本身及结构体第 2 个字段一样，不占据内存空间。 type TestEmpty struct empty struct\ta bool\tb stringfunc main() te := TestEmpty\tfmt.Printf(address of te: %p , te)\tfmt.Printf(address of te.empty: %p , (te.empty))\tfmt.Printf(address of te.a: %p , (te.a))\tfmt.Printf(empty: size=%d, align=%d , unsafe.Sizeof(te.empty), unsafe.Alignof(te.empty))\tfmt.Printf(a: size=%d, align=%d , unsafe.Sizeof(te.a), unsafe.Alignof(te.a))\tfmt.Printf(b: size=%d, align=%d , unsafe.Sizeof(te.b), unsafe.Alignof(te.b))\tprintMemory(te) 输出： address of te: 0x140000ba000address of te.empty: 0x140000ba000address of te.a: 0x140000ba000empty: size=0, align=1a: size=1, align=1b: size=16, align=8[2 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3] 6.8.3 空结构体在结构体中间 空结构体出现在结构体中时，地址跟随前一个变量。 type TestEmpty struct a bool\tempty struct\tb stringfunc main() te := TestEmpty\tfmt.Printf(address of te: %p , te)\tfmt.Printf(address of te.a: %p , (te.a))\tfmt.Printf(address of te.empty: %p , (te.empty))\tfmt.Printf(a: size=%d, align=%d , unsafe.Sizeof(te.a), unsafe.Alignof(te.a))\tfmt.Printf(empty: size=%d, align=%d , unsafe.Sizeof(te.empty), unsafe.Alignof(te.empty))\tfmt.Printf(b: size=%d, align=%d , unsafe.Sizeof(te.b), unsafe.Alignof(te.b))\tprintMemory(te) 输出： address of te: 0x14000128000address of te.a: 0x14000128000address of te.empty: 0x14000128001a: size=1, align=1empty: size=0, align=1b: size=16, align=8[1 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3] 6.8.4 空结构体在结构体最后 空结构体出现在结构体最后，如果开启了一个新的系统字长，则需要补零，防止与其他结构体混用地址。 type TestEmpty struct a bool\tb string\tempty structfunc main() te := TestEmpty\tfmt.Printf(address of te: %p , te)\tfmt.Printf(address of te.a: %p , (te.a))\tfmt.Printf(address of te.empty: %p , (te.empty))\tfmt.Printf(a: size=%d, align=%d , unsafe.Sizeof(te.a), unsafe.Alignof(te.a))\tfmt.Printf(b: size=%d, align=%d , unsafe.Sizeof(te.b), unsafe.Alignof(te.b))\tfmt.Printf(empty: size=%d, align=%d , unsafe.Sizeof(te.empty), unsafe.Alignof(te.empty))\tprintMemory(te) 输出： address of te: 0x1400006a020address of te.a: 0x1400006a020address of te.empty: 0x1400006a038a: size=1, align=1b: size=16, align=8empty: size=0, align=1[1 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0] 6.9 使用 fieldalignment -fix 工具优化结构体内存对齐 还记得我们最开始提出的问题吗？ type S1 struct num2 int8\tnum1 int16\tflag booltype S2 struct num1 int8\tflag bool\tnum2 int16func main() fmt.Println(unsafe.Sizeof(S1))\tfmt.Println(unsafe.Sizeof(S2)) S1 和 S2 提供的程序功能是一样的，但是 S1 却比 S2 花费了更多的内存空间。所以有时候我们可以通过仅仅调整结构体内部字段的顺序就减少不少的内存空间消耗。在这个时候 fieldalignment 可以帮助我们自动检测并优化。 你可以运行下面命令安装 fieldalignment 命令： go install golang.org/x/tools/go/analysis/passes/fieldalignment/cmd/fieldalignment@latest 然后在项目根目录下运行下面命令，对我们的代码进行检查： go vet -vettool=$(which fieldalignment) ./... 这里会输出： ./main.go:9:9: struct of size 6 could be 4 这个时候可以执行 fieldalignment -fix 目录|文件 ，它会自动帮我们的代码进行修复，但是强烈建议你在运行之前，备份你的代码，因为注释会被删除！ fieldalignment -fix ./... 输出： /Users/hedon/GolandProjects/learn-go-struct/main.go:9:9: struct of size 6 could be 4 这个时候 S1 已经被优化好了： type S1 struct num1 int16\tnum2 int8\tflag bool","tags":["Go"],"categories":["Go"]},{"title":"Rust 实战丨HTTPie","path":"/2024/03/06/rust-action-httpie/","content":"概述 之前学习过《陈天·Rust 编程第一课 - 04｜get hands dirty：来写个实用的 CLI 小工具》，学的时候迷迷糊糊。后来在系统学习完 Rust 后，重新回过头来看这个实战小案例，基本上都能掌握，并且有了一些新的理解。所以我决定以一个 Rust 初学者的角度，并以最新版本的 Rust（1.7.6）和 clap（4.5.1）来重新实现这个案例，期望能对 Rust 感兴趣的初学者提供一些帮助。 本文将实现的应用叫 HTTPie，HTTPie 是一个用 Python 编写的命令行 HTTP 客户端，其目标是使 CLI 与 web 服务的交互尽可能愉快。它被设计为一个 curl 和 wget 的替代品，提供易于使用的界面和一些用户友好的功能，如 JSON 支持、语法高亮和插件。它对于测试、调试和通常与 HTTP 服务器或 RESTful API 进行交云的开发人员来说非常有用。 HTTPie 的一些关键特性包括： JSON 支持：默认情况下，HTTPie 会自动发送 JSON，并且可以轻松地通过命令行发送 JSON 请求体。 语法高亮：它会为 HTTP 响应输出提供语法高亮显示，使得结果更加易于阅读。 插件：HTTPie 支持插件，允许扩展其核心功能。 表单和文件上传：可以很容易地通过表单上传文件。 自定义 HTTP 方法和头部：可以发送任何 HTTP 方法的请求，自定义请求头部。 HTTPS、代理和身份验证支持：支持 HTTPS 请求、使用代理以及多种 HTTP 身份验证机制。 流式上传和下载：支持大文件的流式上传和下载。 会话支持：可以保存和重用常用的请求和集合。 本文我们将实现其中的 1、2 和 5。我们会支持发送 GET 和 POST 请求，其中 POST 支持设置请求头和 JSON 数据。 在本文中，你可以学习到： 如何用 clap 解析命令行参数。 如何用 tokio 进行异步编程。 如何用 reqwest 发送 HTTP 请求。 如何用 colored 在终端输出带颜色的内容。 如何用 jsonxf 美化 json 字符串。 如何用 anyhow 配合 ? 进行错误传播。 如何使用 HTTPie 来进行 HTTP 接口测试。 在进行实际开发之前，推荐你先了解一下： https://hedon.top/2024/03/02/rust-crate-reqwest/https://hedon.top/2024/03/02/rust-crate-reqwest/ https://hedon.top/2024/03/05/rust-crate-anyhow/https://hedon.top/2024/03/05/rust-crate-anyhow/ https://hedon.top/2024/03/02/rust-crate-clap/https://hedon.top/2024/03/02/rust-crate-clap/ 本文完整代码： https://github.com/hedon-rust-road/httpiehttps://github.com/hedon-rust-road/httpie 开发思路 HTTP 协议 回顾一下 HTTP 协议的请求体和响应体结构。 请求结构： 响应结构： 命令分析 在本文中，我们就实现 HTTPie cli 官方的这个示例：即允许指定请求方法、携带 headers 和 json 数据发送请求。 我们来拆解一下，这个命令可以分为以下几个部分： httpie METHOD URL [headers | params]... METHOD: 请求方法，本案例中，我们仅支持 GET 和 POST。 URL: 请求地址。 HEADERS: 请求头，格式为 h1:v1。 PARAMS: 请求参数，格式为 k1=v1，最终以 json 结构发送。 效果展示 ➜ httpie git:(master) ✗ ./Httpie --help Usage: Httpie COMMANDCommands: get post help Print this message or the help of the given subcommand(s)Options: -h, --help Print help -V, --version Print version 其中 post 子命令： Usage: Httpie post URL BODY...Arguments: URL Specify the url you wanna request to BODY... Set the request body. Examples: headers: header1:value1 params: key1=value1Options: -h, --help Print help 请求示例： 思路梳理 第 1 步：解析命令行参数 本案例中 httpie 支持 2 个子命令： get 支持 url 参数 post 支持 url、body 参数，因为其中 headers 和 params 是变长的，我们统一用 VecString 类型的 body 来接收，然后用 : 和 = 来区分它们。 第 2 步：发送请求 使用 reqwest 创建 http client； 设置 url； 设置 method； 设置 headers； 设置 params； 发送请求； 获取响应体。 第 3 步：打印响应 打印 http version 和 status，并使用 colored 赋予蓝色； 打印 response headers，并使用 colored 赋予绿色； 确定 content-type，如果是 json，我们就用 jsonxf 美化 json 串并使用 colored 赋予蓝绿色输出，如果是其他类型，这里我们就输出原文即可。 实战过程 1. 创建项目 cargo new httpie 2. 添加依赖 [package]name = httpieversion = 0.1.0edition = 2021[dependencies]anyhow = 1.0.80clap = version = 4.5.1, features = [derive] colored = 2.1.0jsonxf = 1.1.1mime = 0.3.17reqwest = version = 0.11.24, features = [json] tokio = version = 1.36.0, features = [rt, rt-multi-thread, macros] anyhow: 用于简化异常处理。 clap: 解析命令行参数。 colored: 为终端输出内容赋予颜色。 jsonxf: 美化 json 串。 mime: 提供了各种 Media Type 的类型封装。 reqwest: http 客户端。 tokio: 异步库，本案例种我们使用 reqwest 的异步功能。 3. 完整源码 // src/main.rs 为减小篇幅，省略了单元测试，读者可自行补充。use std::collections::HashMap;use reqwest::Client, header, Response;use std::str::FromStr;use anyhow::anyhow;use clap::Args, Parser, Subcommand;use colored::Colorize;use mime::Mime;use reqwest::header::HeaderMap, HeaderName, HeaderValue;use reqwest::Url;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Httpie #[command(subcommand)] methods: Method,#[derive(Subcommand)]enum Method Get(Get), Post(Post)#[derive(Args)]struct Get #[arg(value_parser = parse_url)] url: String,#[derive(Args)]struct Post /// Specify the url you wanna request to. #[arg(value_parser = parse_url)] url: String, /// Set the request body. /// Examples: /// headers: /// header1:value1 /// params: /// key1=value1 #[arg(required = true, value_parser = parse_kv_pairs)] body: VecKvPair#[derive(Debug, Clone)]struct KvPair k: String, v: String, t: KvPairType,#[derive(Debug,Clone)]enum KvPairType Header, Param,impl FromStr for KvPair type Err = anyhow::Error; fn from_str(s: str) - ResultSelf, Self::Err let pair_type: KvPairType; let split_char = if s.contains(:) pair_type = KvPairType::Header; : else pair_type = KvPairType::Param; = ; let mut split = s.split(split_char); let err = || anyhow!(format!(failed to parse pairs ,s)); Ok(Self k: (split.next().ok_or_else(err)?).to_string(), v: (split.next().ok_or_else(err)?).to_string(), t: pair_type, ) fn parse_url(s: str) - anyhow::ResultString let _url: Url = s.parse()?; Ok(s.into())fn parse_kv_pairs(s: str) - anyhow::ResultKvPair Ok(s.parse()?)async fn get(client: Client, args: Get) - anyhow::Result() let resp = client.get(args.url).send().await?; Ok(print_resp(resp).await?)async fn post(client: Client, args: Post) - anyhow::Result() let mut body = HashMap::new(); let mut header_map = HeaderMap::new(); for pair in args.body.iter() match pair.t KvPairType::Param = body.insert(pair.k, pair.v); KvPairType::Header = if let Ok(name) = HeaderName::from_str(pair.k.as_str()) if let Ok(value) = HeaderValue::from_str(pair.v.as_str()) header_map.insert(name,value); else println!(Invalid header value for key: , pair.v); else println!(Invalid header key: , pair.k); let resp = client.post(args.url) .headers(header_map) .json(body).send().await?; Ok(print_resp(resp).await?)async fn print_resp(resp: Response) - anyhow::Result() print_status(resp); print_headers(resp); let mime = get_content_type(resp); let body = resp.text().await?; print_body(mime, body); Ok(())fn print_status(resp: Response) let status = format!(:? , resp.version(), resp.status()).blue(); println!( , status);fn print_headers(resp: Response) for (k,v) in resp.headers() println!(: :?, k.to_string().green(), v); print!( );fn print_body(mime: OptionMime, resp: String) match mime Some(v) = if v == mime::APPLICATION_JSON println!(, jsonxf::pretty_print(resp).unwrap().cyan()) _ = print!(, resp), fn get_content_type(resp: Response) - OptionMime resp.headers() .get(header::CONTENT_TYPE) .map(|v|v.to_str().unwrap().parse().unwrap())#[tokio::main]async fn main() - anyhow::Result() let httpie = Httpie::parse(); let client = Client::new(); let result = match httpie.methods Method::Get(ref args) = get(client, args).await?, Method::Post(ref args) = post(client, args).await?, ; Ok(result) 可以看到，即使算上 use 部分，总代码也不过160 行左右，Rust 的 clap 库在 CLI 开发上确实 yyds！ 接下来我们来一一拆解这部分的代码，其中关于 clap 的部分我不会过多展开，刚兴趣的读者可以参阅：深入探索 Rust 的 clap 库：命令行解析的艺术。 3.1 命令行解析 我们先从 main() 开始： #[tokio::main]async fn main() - anyhow::Result() let httpie = Httpie::parse(); let client = Client::new(); let result = match httpie.methods Method::Get(ref args) = get(client, args).await?, Method::Post(ref args) = post(client, args).await?, ; Ok(result) 我们希望使用 clap 的异步功能，所以使用了 async 关键字，同时加上了 tokio 提供的属性宏 #[tokio::main]，用于设置异步环境。为了能够使用 ? 快速传播错误，我们设置返回值为 anyhow::Result()，本项目中我们不对错误进行过多处理，所以这种方式可以大大简化我们的错误处理过程。 main() 中我们使用 Httpie::parse() 解析命令行中的参数，使用 Client::new() 创建一个 http client，根据解析到的命令行参数，我们匹配子命令 methods，分别调用 get() 和 post() 来发送 GET 和 POST 请求。 Httpie 的定义如下： #[derive(Parser)]#[command(version, author, about, long_about = None)]struct Httpie #[command(subcommand)] methods: Method, #[derive(Parser)] 是一个过程宏（procedural macro），用于自动为结构体实现 clap::Parser trait。这使得该结构体可以用来解析命令行参数。 在 Httpie 中我们定义了子命令 Method： #[derive(Subcommand)]enum Method Get(Get), Post(Post) #[derive(Subcommand)] 属性宏会自动为枚举派生一些代码，以便它可以作为子命令来解析命令行参数。目前支持 Get 和 Post 两个子命令，它们分别接收 Get 和 Post 参数： #[derive(Args)]struct Get #[arg(value_parser = parse_url)] url: String,#[derive(Args)]struct Post #[arg(value_parser = parse_url)] url: String, #[arg(value_parser = parse_kv_pairs)] body: VecKvPair #[derive(Args)] 属性宏表明当前 struct 是命令的参数，其中 Get 仅支持 url 参数，Post 支持 url 和 body 参数。 url 参数我们使用 parse_url 函数来进行解析： use reqwest::Url;fn parse_url(s: str) - anyhow::ResultString let _url: Url = s.parse()?; Ok(s.into()) 这里 reqwest::Url 已经实现了 FromStr trait，所以这里我们可以直接调用 s.parse() 来解析 url。 而 body，因为我们期望 CLI 使用起来像： httpie url header1:value1 param1=v1 body 就是 header1:value1 param1=v1，一对 kv 就代表着一个 header 或者 param，用 : 和 = 来区分。因为 kv 对的个数的变长的，所以我们使用 VecKvPair 来接收 body 这个参数，并使用 parse_kv_pairs 来解析 kv 对。 KvPair 是我们自定义的类型： #[derive(Debug, Clone)]struct KvPair k: String, v: String, t: KvPairType,#[derive(Debug,Clone)]enum KvPairType Header, Param, parse_kv_pairs 的实现如下： fn parse_kv_pairs(s: str) - anyhow::ResultKvPair Ok(s.parse()?) 在这里，你可以在 parse_kv_pairs() 函数中，对 s 进行解析并返回 anyhow::ResultKvPair。不过，更优雅，更统一的方式是什么呢？就是像 reqwest::Url 一样，为 KvPair 实现 FromStr trait，这样就可以直接调用 s.parse() 来进行解析了。 impl FromStr for KvPair type Err = anyhow::Error; fn from_str(s: str) - ResultSelf, Self::Err ... 3.2 发送请求 参数解析完，就到了发送请求的地方了，这里使用 reqwest crate 就非常方便了，这里就不赘述了，具体可以参考：Rust reqwest 简明教程。 async fn get(client: Client, args: Get) - anyhow::Result() ... async fn post(client: Client, args: Post) - anyhow::Result() ... 3.3 打印响应 响应分为 3 个部分： print_status() print_headers() print_body() async fn print_resp(resp: Response) - anyhow::Result() print_status(resp); print_headers(resp); let mime = get_content_type(resp); let body = resp.text().await?; print_body(mime, body); Ok(()) print_status() 比较简单，就是打印 HTTP 版本和响应状态码，然后我们使用 colored crate 的 blue() 使其在终端以蓝色输出。 fn print_status(resp: Response) let status = format!(:? , resp.version(), resp.status()).blue(); println!( , status); print_headers() 中，我们使用 green() 使 header_name 在终端以绿色输出。 fn print_headers(resp: Response) for (k,v) in resp.headers() println!(: :?, k.to_string().green(), v); print!( ); 响应体的格式（Media Type）有很多，本案例中我们仅支持 application/json，所以在 print_body() 之前，我们需要先读取 response header 中的 content-type： fn get_content_type(resp: Response) - OptionMime resp.headers() .get(header::CONTENT_TYPE) .map(|v|v.to_str().unwrap().parse().unwrap()) 在 print_resp() 中，对于 application/json，我们使用 jsonxf crate 对进行美化，并使用 cyan() 使其在终端以蓝绿色输出。对于其他类型，我们姑且照原文输出。 fn print_body(mime: OptionMime, resp: String) match mime Some(v) = if v == mime::APPLICATION_JSON println!(, jsonxf::pretty_print(resp).unwrap().cyan()) _ = print!(, resp), 总结 在本文中，我们深入探讨了如何使用 Rust 语言来实现一个类似于 HTTPie 的命令行工具。这个过程包括了对 HTTP 协议的理解、命令行参数的解析、HTTP 客户端的创建和请求发送，以及对响应的处理和展示。通过本文，读者不仅能够获得一个实用的命令行工具，还能够学习到如何使用 Rust 的库来构建实际的应用程序，包括 clap、reqwest、tokio 和 colored 等。此外，文章也说明了在 Rust 中进行异步编程和错误处理的一些常见模式。尽管示例代码的错误处理较为简单，但它提供了一个良好的起点，开发者可以在此基础上进行扩展和改进，以适应更复杂的应用场景。","tags":["Rust"],"categories":["Rust","Rust 实战"]},{"title":"Rust anyhow 简明教程","path":"/2024/03/05/rust-crate-anyhow/","content":"anyhow 是 Rust 中的一个库，旨在提供灵活的、具体的错误处理能力，建立在 std::error::Error 基础上。它主要用于那些需要简单错误处理的应用程序和原型开发中，尤其是在错误类型不需要被严格区分的场景下。 以下是 anyhow 的几个关键特性： 易用性: anyhow 提供了一个 Error 类型，这个类型可以包含任何实现了 std::error::Error 的错误。这意味着你可以使用 anyhow::Error 来包装几乎所有类型的错误，无需担心具体的错误类型。 简洁的错误链: anyhow 支持通过 ? 操作符来传播错误，同时保留错误发生的上下文。这让错误处理更加直观，同时还能保留错误链，便于调试。 便于调试: anyhow 支持通过 :# 格式化指示符来打印错误及其所有相关的上下文和原因，这使得调试复杂的错误链变得更加简单。 无需关心错误类型: 在很多情况下，特别是在应用程序的顶层，你可能不需要关心错误的具体类型，只需要知道出错了并且能够将错误信息传递给用户或日志。anyhow 让这一过程变得简单，因为它可以包装任何错误，而不需要显式地指定错误类型。 使用 anyhow 的典型场景包括快速原型开发、应用程序顶层的错误处理，或者在库中作为返回错误类型的一个简便选择，尤其是在库的使用者不需要关心具体错误类型的时候。 anyhow::Error anyhow::Error 是 anyhow 库定义的一个错误类型。它是一个包装器（wrapper）类型，可以包含任何实现了 std::error::Error trait 的错误类型。这意味着你可以将几乎所有的错误转换为 anyhow::Error 类型，从而在函数之间传递，而不需要在意具体的错误类型。这在快速原型开发或应用程序顶层错误处理中特别有用，因为它简化了错误处理的逻辑。 它的定义如下： #[cfg_attr(not(doc), repr(transparent))]pub struct Error inner: OwnErrorImpl, 其中核心是 ErrorImpl： #[repr(C)]pub(crate) struct ErrorImplE = () vtable: static ErrorVTable, backtrace: OptionBacktrace, // NOTE: Dont use directly. Use only through vtable. Erased type may have // different alignment. _object: E, ErrorImpl 是一个内部结构体，用于实现 anyhow::Error 类型的具体功能。它包含了三个主要字段： vtable 是一个指向静态虚拟表的指针，用于动态派发错误相关的方法。 backtrace 是一个可选的回溯（Backtrace）类型，用于存储错误发生时的调用栈信息。 _object 字段用于存储具体的错误对象，其类型在编译时被擦除以提供类型安全的动态错误处理。 这种设计允许 anyhow 错误封装并表示各种不同的错误类型，同时提供了方法动态派发和回溯功能，以便于错误调试。 anyhow::Error 可以包含任何实现了 std::error::Error trait 的错误类型，这里因为下面的 impl： implE StdError for ErrorImplEwhere E: StdError, fn source(self) - Option(dyn StdError + static) unsafe ErrorImpl::error(self.erase()).source() #[cfg(error_generic_member_access)] fn providea(a self, request: mut Requesta) unsafe ErrorImpl::provide(self.erase(), request) anyhow::Result anyhow::Result 是一个别名（type alias），它是 std::result::ResultT, anyhow::Error 的简写。在使用 anyhow 库进行错误处理时，你会频繁地看到这个类型。它基本上是标准的 Result 类型，但错误类型被固定为 anyhow::Error。这使得你可以很容易地在函数之间传递错误，而不需要声明具体的错误类型。 pub type ResultT, E = Error = core::result::ResultT, E; 使用 anyhow::Result 的好处在于它提供了一种统一的方式来处理错误。你可以使用 ? 操作符来传播错误，同时保留错误的上下文信息和回溯。这极大地简化了错误处理代码，尤其是在多个可能产生不同错误类型的操作链中。 3 个核心使用技巧 使用 ResultT, anyhow::Error 或者 anyhow::ResultT 作为返回值，然后利用 ? 语法糖无脑传播报错。 使用 with_context(f) 来附加错误信息。 使用 downcast 反解具体的错误类型。 实战案例 下面我们用一个案例来体会 anyhow 的使用方式： 我们的需求是：打开一个文件，解析文件中的数据并进行大写化，然后输出处理后的数据。 use anyhow::Result, Context;use std::fs, io;// 1. 读取文件、解析数据和执行数据操作都可能出现错误，// 所以我们需要返回 Result 来兼容异常情况。// 这里我们使用 anyhow::Result 来简化和传播错误。fn read_and_process_file(file_path: str) - Result() // 尝试读取文件 let data = fs::read_to_string(file_path) // 2. 使用 with_context 来附加错误信息，然后利用 ? 语法糖传播错误。 .with_context(||format!(failed to read file ``, file_path))?; // 解析数据 let processed_data = parse_data(data) .with_context(||format!(failed to parse data from file ``, file_path))?; // 执行数据操作 perform_some_operation(processed_data) .with_context(|| failed to perform operation based on file data)?; Ok(())fn parse_data(data: str) - ResultString Ok(data.to_uppercase())fn perform_some_operation(data: String) - Result() println!(processed data: , data); Ok(())fn main() let file_path = ./anyhow.txt; // 执行处理逻辑 let res = read_and_process_file(file_path); // 处理结果 match res Ok(_) = println!(successfully!), Err(e) = // 3. 使用 downcast 来反解出实际的错误实例，本案例中可能出现的异常是 io::Error。 if let Some(my_error) = e.downcast_ref::io::Error() println!(has io error: :#, my_error); else println!(unknown error: :?, e);","tags":["Rust"],"categories":["Rust","Rust 常用库"]},{"title":"深入探索 Rust 的 clap 库：命令行解析的艺术","path":"/2024/03/02/rust-crate-clap/","content":"版本声明 Rust: 1.76 clap: 4.5.1 clap_complete 4.5.1 rpassword: 7.3.1 结论先行 本文将从 CLI（Command Line Interface）命令行工具的概述讲起，介绍一个优秀的命令行工具应该具备的功能和特性。然后介绍 Rust 中一个非常优秀的命令行解析工具 clap 经典使用方法，并利用 clap 实现一个类似于 curl 的工具 httpie。文章最后还将 clap 于 Go 语言中同样优秀的命令行解析工具 cobra 进行一个简单对比，便于读者进一步体会 clap 的简洁和优秀。 本文将包含以下几个部分： CLI 概述：从 CLI 的基本概念出发，介绍优秀命令行工具应该具备的功能特性，并以 curl 作为经典范例进行说明。 详细介绍 clap：基于 clap 官方文档，分别详细介绍 clap 以 derive 和 builder 两个方式构建 cli 的常用方法。 实战 httpie：参考陈天老师的《Rust 编程第一课》，用最新的 clap 版本（1.7.6）实现 httpie 工具。 对比 cobra：从设计理念和目标、功能特点、使用场景等方面简要对比 clap 和 Go 流行的命令行解析库 cobra。 特此声明，本文包含 AI 辅助生成内容，如有错误遗漏之处，敬请指出。 CLI 概述 CLI（Command Line Interface，命令行界面）是一种允许用户通过文本命令与计算机程序或操作系统进行交互的接口。与图形用户界面（GUI，Graphical User Interface）相比，CLI 不提供图形元素，如按钮或图标，而是依赖于文本输入。用户通过键盘输入特定的命令行指令，命令行界面解释这些指令并执行相应的操作。 一款优秀的 CLI 工具应该具备以下的功能和特性，以提升用户体验和效率： 一个优秀的命令行工具（CLI, Command Line Interface）应该具备以下功能和特性，以提升用户体验和效率： 直观易用： 简洁的命令语法：命令和参数的设计应直观易懂，方便用户记忆和使用。 自动补全：支持命令和参数的自动补全功能，提高用户输入效率。 命令别名：提供常用命令的简短别名，减少输入的工作量。 强大的帮助系统： 详细的帮助文档：每个命令和参数都应有清晰的说明文档。 示例使用方式：提供常见的使用示例，帮助用户快速理解和应用。 内置帮助命令：通过如--help或-h参数轻松访问帮助信息。 错误处理与反馈： 清晰的错误信息：出现错误时，提供明确、具体的错误信息，帮助用户快速定位问题。 建议和解决方案：在可能的情况下，给出错误解决的建议或自动修复选项。 高效的执行和输出： 快速响应：命令执行应迅速，减少用户等待时间。 格式化的输出：提供易于阅读和解析的输出格式，如表格、JSON 或 XML 等。 输出过滤和排序：允许用户根据需要过滤和排序输出结果，提高信息的查找效率。 跨平台兼容： 多平台支持：能够在不同的操作系统上运行，如 Windows、macOS、Linux 等。 环境适应性：自动适应不同的终端环境和字符编码，确保输出显示正确。 安全性： 安全的默认设置：默认配置应强调安全，避免暴露敏感信息。 数据加密：在处理敏感信息（如密码）时，应使用加密手段保护数据安全。 版本管理： 版本控制：提供命令查看工具版本，支持多版本共存或升级。 向后兼容：新版本应尽量保持与旧版本的兼容性，避免破坏用户现有的工作流程。 这些特性不仅能够提高用户的工作效率，还能增强用户体验，使命令行工具更加强大和易用。 下面我们以 curl 为例，看看优秀的 CLI 工具大概长什么样子。 curl 是一种命令行工具和库，用于传输数据。它支持多种协议，包括 HTTP、HTTPS、FTP、FTPS、SCP、SFTP、TFTP、TELNET、DICT、LDAP、LDAPS、IMAP、POP3、SMTP 和 RTSP 等。curl 是一个非常强大和灵活的工具，广泛应用于自动化脚本、系统测试、数据收集和许多其他用途。 进入终端，我们可以用下面命令查看 curl 的说明文档： ➜ ~ curl --helpUsage: curl [options...] url -d, --data data HTTP POST data -f, --fail Fail fast with no output on HTTP errors -h, --help category Get help for commands -i, --include Include protocol response headers in the output -o, --output file Write to file instead of stdout -O, --remote-name Write output to a file named as the remote file -s, --silent Silent mode -T, --upload-file file Transfer local FILE to destination -u, --user user:password Server user and password -A, --user-agent name Send User-Agent name to server -v, --verbose Make the operation more talkative -V, --version Show version number and quitThis is not the full help, this menu is stripped into categories.Use --help category to get an overview of all categories.For all options use the manual or --help all. 使用示例： 下载文件：curl -O http://example.com/file.txt 发送 POST 请求：curl -d param1=value1param2=value2 http://example.com/resource 使用 HTTPS 并忽略证书验证：curl -k https://example.com 使用基本认证：curl -u username:password http://example.com curl 的这些特性使其成为开发者、系统管理员和自动化脚本中广泛使用的工具之一。 clap 概述 clap，代表 Command Line Argument Parser，是一个旨在创建直观、易用且功能强大的命令行界面的 Rust 库。截至目前（2024.2），clap 已经发展到了 4.5.1 版本，它通过简化命令行参数的处理，让开发者能更专注于应用逻辑的构建。 clap 之所以在 Rust 社区如此流行，得益于以下几个优点： 1. 易于使用 clap 的设计理念是让命令行参数的解析变得简单而直观。即使是没有经验的开发者也能快速上手，通过几行代码就能实现复杂的命令行参数解析。 2. 功能丰富 clap 提供了广泛的功能来满足各种命令行解析需求，包括但不限于： 自动生成的帮助信息：clap 能根据定义的参数自动生成帮助信息，包括参数的说明、类型、默认值等。 强大的错误提示：当用户输入无效的命令行参数时，clap 会提供清晰且有用的错误提示，帮助用户快速定位问题。 参数验证：开发者可以为参数设定验证规则，确保输入的参数符合预期。 复杂的命令结构：支持子命令的嵌套，允许构建复杂的命令行应用结构。 自定义派生：通过 clap 的派生宏，可以简化命令行解析器的定义，使代码更加清晰。 3. 高度可定制 clap 允许开发者高度定制命令行解析的行为和外观，包括自定义帮助信息的格式、控制错误消息的显示方式等。这种灵活性意味着你可以根据应用程序的需求调整 clap 的行为。 4. 性能优异 尽管 clap 功能强大，但它仍然非常注重性能。clap 经过优化，以尽可能少的性能开销处理命令行参数。 5. 活跃的社区支持 clap 有一个非常活跃的社区，在 GitHub 上不断有新的贡献者加入。这意味着 clap 不断地得到改进和更新，同时也有大量的社区资源可供参考。 Derive vs Builder (1) 初探 clap 提供了 2 种构建命令行的方式，分别为 Derive 和 Builder。顾名思义，Derive 就是利用宏强大的功能来构建命令行，而 Builder 则采用构建者模式链式构建命令行工具。 在这里我们先给出示例来直观感受这 2 种构建方式的不同： Derive: #[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli /// Specify your name name: String, /// Specify your age optionally #[arg(short, long)] age: Optioni8,fn main() let cli = Cli::parse(); println!(name: , cli.name); println!(age: :?, cli.age); Builder: fn main() let matches = Command::new(myapp) .version(1.0.0) .author(hedon) .about(this is the short about) .long_about(this is the long about) .arg(arg!([NAME]).required(true).help(Specify your name)) .arg(arg!(-a --age AGE) .value_parser(clap::value_parser!(u8)) .help(Specify your age optionally)) .get_matches(); println!(name: :?, matches.get_one::String(NAME)); println!(age: :?, matches.get_one::u8(age)); 这 2 个程序都实现了相同的功能，使用 --help ，输出的内容大致都如下： Usage: derive [OPTIONS] NAMEArguments: NAME Specify your nameOptions: -a, --age AGE Specify your age optionally -h, --help Print help 通过观察，可以发现 Derive 模式下，宏中的每一个属性，如 version、author 等，都对应到 Builder 模式下一个同名的函数。 下面我们将从**「应用配置」、「参数类型」和「参数校验」**三个方面，分别介绍 clap 中 Derive 和 Builder 两种模式构建 CLI 的常用方法。 特别说明：后续的例子均在 examples 目录下实现，故编译和执行命令都包含 example。 目录结构大概如下： ➜ learn-clap git:(master) ✗ tree .├── Cargo.lock├── Cargo.toml├── examples│ ├── optional.rs├── src│ └── main.rs└── target └── release └── examples └── optional Derive 要使用 clap 的 Derive 模式，需要： cargo add clap --features derive 1. 应用配置 我们需要定义一个 strut 来表示我们的 application，利用它来承载应用的参数： /// The example of clap derive#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli /// Specify your name name: String, /// Specify your age optionally #[arg(short, long)] age: Optioni8,fn main() let cli = Cli::parse(); println!(name: , cli.name); println!(age: :?, cli.age); #[derive(Parser)] 是一个过程宏（procedural macro），用于自动为结构体实现 clap::Parser trait。这使得该结构体可以用来解析命令行参数。 使用 #[derive(Parser)]，你可以简化命令行解析的代码，因为 clap 会根据结构体的字段自动生成命令行解析的逻辑。 每个字段都对应一个命令行参数，字段的类型和属性用来决定参数的解析方式和验证规则。 #[command(version, about, long_about = None)] 属性用于为整个命令行程序提供元信息，它支持以下几个元素： #[arg(short, long)] 属性用于配置命令参数的元信息，它支持以下几个属性： 属性 方法 默认值/行为 备注 id Arg::id field’s name 当属性不存在时，使用字段名 value_parser Arg::value_parser auto-select based on field type 当属性不存在时，会基于字段类型自动选择实现 action Arg::action auto-select based on field type 当属性不存在时，会基于字段类型自动选择动作 help Arg::help Doc comment summary 当属性不存在时，使用文档注释摘要 long_help Arg::long_help Doc comment with blank line, else nothing 当属性不存在时，使用文档注释，如果有空行 verbatim_doc_comment Minimizes preprocessing - 将文档注释转换为 help/long_help 时最小化预处理 short Arg::short no short set 当属性不存在时，没有短名称设置 long Arg::long no long set 当属性不存在时，没有长名称设置 env Arg::env no env set 当属性不存在时，没有环境变量设置 from_global Read Arg::global - 无论在哪个子命令中，都读取 Arg::global 参数 value_enum Parse with ValueEnum - 使用 ValueEnum 解析值 skip Ignore this field fills the field with Default::default() 忽略此字段，用 expr 或 Default::default() 填充 default_value Arg::default_value Arg::required(false) 设置默认值，并将 Arg 设置为非必须 default_value_t Arg::default_value Arg::required(false) 要求 std::fmt::Display 与 Arg::value_parser 相匹配 default_values_t Arg::default_values Arg::required(false) 要求字段类型为 VecT，T 实现 std::fmt::Display default_value_os_t Arg::default_value_os Arg::required(false) 要求 std::convert::IntoOsString default_values_os_t Arg::default_values_os Arg::required(false) 要求字段类型为 VecT，T 实现std::convert::IntoOsString 2. 参数类型 2.1 Arguments Options 从上面这个输出样例中： the example of clap deriveUsage: derive [OPTIONS] NAMEArguments: NAME Specify your nameOptions: -a, --age AGE Specify your age optionally -h, --help Print help 可以看到跟在命令后面有 2 中参数类型： Arguments: 直接在命令后面指定值，如 cmd hedon，有严格的顺序要求。 Options: 需要用 -short 或 --long 来指定是哪个参数，无严格的顺序要求。 它们的定义区别就是是否使用了 #[arg]： Options: 指定了 short 或 long。 Arguments: 没有 short 和 long。 #[derive(Parser)]struct Cli /// 会被解析成 [NAME] name: String, /// 会被解析成 -a AGE #[arg(short, long)] age: u8, 2.2 可选参数 可以使用 Option 来实现可选参数： use clap::Parser;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli name: OptionString, #[arg(short, long)] age: Optionu8,fn main() let cli = Cli::parse(); println!(name: :?, cli.name); println!(age: :?, cli.age); 编译： cargo build --example optional --release 执行： /target/release/examples/optional --help 输出： this is the about from Cargo.tomlUsage: optional [OPTIONS] [NAME]Arguments: [NAME] Options: -a, --age AGE -h, --help Print help -V, --version Print version 测试： ➜ learn-clap git:(master) ✗ ./target/release/examples/optional name: Noneage: None➜ learn-clap git:(master) ✗ ./target/release/examples/optional -a 1 name: Noneage: Some(1)➜ learn-clap git:(master) ✗ ./target/release/examples/optional hedon name: Some(hedon)age: None➜ learn-clap git:(master) ✗ ./target/release/examples/optional hedon -a 18name: Some(hedon)age: Some(18) 2.3 枚举参数 可以使用 enum 搭配 value_enum 来实现多选一参数，并限制可选参数的取值。 use clap::Parser, ValueEnum;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli /// Choose the program mode run in #[arg(value_enum)] mode: Mode,#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, ValueEnum)]enum Mode /// run in fast mode Fast, /// run in slow mode Slow,fn main() let cli = Cli::parse(); match cli.mode Mode::Fast = println!(fast!!!!!), Mode::Slow = println!(slow......), 输出： Usage: enum MODEArguments: MODE Choose the program mode run in Possible values: - fast: run in fast mode - slow: run in slow modeOptions: -h, --help Print help (see a summary with -h) -V, --version Print version 2.4 累计参数 累积参数允许用户通过重复指定同一个标志（例如 -d）来累加值或效果，通常用于控制命令行应用的详细级别（verbosity level）或其他需要根据次数变化的行为。 在很多命令行工具中，累积参数常见于控制日志输出的详细程度。例如，一个 -v（verbose）标志可能每被指定一次，就增加一层详细级别。所以，-vvv（等价于 -v -v -v） 会比单个 -v 提供更多的详细信息。 在 clap 中可以通过 clap::ArgAction::Count 来实现这种累积参数。 use clap::Parser;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli #[arg(short, long, action = clap::ArgAction::Count)] verbose: u8,fn main() let cli = Cli::parse(); println!(verbose: , cli.verbose); 输出： ➜ learn-clap git:(master) ✗ ./target/release/examples/accurate --helpthis is the about from Cargo.tomlUsage: accurate [OPTIONS]Options: -v, --verbose... -h, --help Print help -V, --version Print version➜ learn-clap git:(master) ✗ ./target/release/examples/accurate -v verbose: 1➜ learn-clap git:(master) ✗ ./target/release/examples/accurate -vvvvverbose: 4 2.5 变长参数 有时候我们希望接收变长参数，比如说： del file1 file2 file3 这个时候可以使用 Vec 来实现。 use clap::Parser;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli files: VecString,fn main() let cli = Cli::parse(); println!(files: :?, cli.files); 输出： ➜ learn-clap git:(master) ✗ ./target/release/examples/var_length --helpthis is the about from Cargo.tomlUsage: var_length [FILES]...Arguments: [FILES]... Options: -h, --help Print help -V, --version Print version➜ learn-clap git:(master) ✗ ./target/release/examples/var_length files: []➜ learn-clap git:(master) ✗ ./target/release/examples/var_length file1 files: [file1]➜ learn-clap git:(master) ✗ ./target/release/examples/var_length file1 file2files: [file1, file2]➜ learn-clap git:(master) ✗ ./target/release/examples/var_length file1 file2 file3files: [file1, file2, file3] 2.6 标志参数 对于标志参数，只要指定类型为 bool，就可以自动实现了。 use clap::Parser;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli #[arg(short, long)] verbose: bool,fn main() let cli = Cli::parse(); println!(verbose: , cli.verbose); 输出： ➜ learn-clap git:(master) ✗ ./target/release/examples/flag --helpUsage: flag [OPTIONS]Options: -v, --verbose -h, --help Print help -V, --version Print version➜ learn-clap git:(master) ✗ ./target/release/examples/flag verbose: false➜ learn-clap git:(master) ✗ ./target/release/examples/flag -v verbose: true 2.7 子命令 在更复杂的命令行工具中，除了主命令，还有子命令，甚至子命令下面还有子命令，其实就是一颗命令树。 在 clap 中可以使用 #[command(subcommand)] 搭配 #[derive(Subcommand)] 实现子命令功能。 use clap::Parser, Subcommand;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli #[command(subcommand)] test: OptionTest,#[derive(Subcommand)]enum Test /// Add a number Add #[arg(short, long)] num: u16, , /// Sub a number Sub #[arg(short, long)] num: u16, fn main() let cli = Cli::parse(); if let Some(test) = cli.test match test Test::Add num = println!(test add num: :?, num), Test::Sub num = println!(test sub num: :?, num), 输出： ➜ learn-clap git:(master) ✗ ./target/release/examples/subcommand --help this is the about from Cargo.tomlUsage: subcommand [COMMAND]Commands: add Add a number sub Sub a number help Print this message or the help of the given subcommand(s)Options: -h, --help Print help -V, --version Print version➜ learn-clap git:(master) ✗ ./target/release/examples/subcommand add --helpAdd a numberUsage: subcommand add --num NUMOptions: -n, --num NUM -h, --help Print help➜ learn-clap git:(master) ✗ ./target/release/examples/subcommand add -n 1 test add num: 1➜ learn-clap git:(master) ✗ ./target/release/examples/subcommand sub -n 2test sub num: 2 3. 参数校验 3.1 类型校验 可以发现，使用 Derive 模式的时候，我们在参数后面指定参数类型的时候，clap 就会对我们输入参数进行类型检查，不匹配的时候会输出丰富的报错信息和指导建议。 error: invalid value xxxx for --num NUM: invalid digit found in stringFor more information, try --help. 默认支持： 原生类型：bool, String, OsString, PathBuf、usize、isize 范围数据：u8, i8, u16, i16, u32, i32, u64, i64 实现了 ValueEnum 的 enum 类型 实现了 FromOsString、FromOsStr 、FromStr 的类型 这是因为他们都实现了 TypedValueParser trait，你自定义的类型也可以实现这个 triat，这样就可以自动进行类型校验了。 clap 还提供了一些更加严格的参数校验功能。👇🏻 3.2 枚举校验 对于实现 ValueEnum 的枚举类型，如果输入的值不是枚举中定义的，则 clap 会报错并提示可选值。 我们复用上面介绍「多选一参数」的代码： use clap::Parser, ValueEnum;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli /// Choose the program mode run in #[arg(value_enum)] mode: Mode,#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, ValueEnum)]enum Mode /// run in fast mode Fast, /// run in slow mode Slow,fn main() let cli = Cli::parse(); match cli.mode Mode::Fast = println!(fast!!!!!), Mode::Slow = println!(slow......), 使用错误的值进行尝试： ➜ learn-clap git:(master) ✗ ./target/release/examples/enum xxxx error: invalid value xxxx for MODE [possible values: fast, slow]For more information, try --help. 3.3 范围校验 如果你想要实现数字类型范围限制的话，比如端口号参数的范围应该是 [1, 65535]，那可以使用 value_parser! = clap::value_parser!(u16).range(1..) 来实现这个功能： use clap::Parser;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli #[arg(short, long, value_parser = clap::value_parser!(u16).range(1..))] port: u16,fn main() let cli = Cli::parse(); println!(port: :?, cli.port); 输出： ➜ learn-clap git:(master) ✗ ./target/release/examples/range --help this is the about from Cargo.tomlUsage: range --port PORTOptions: -p, --port PORT -h, --help Print help -V, --version Print version ➜ learn-clap git:(master) ✗ ./target/release/examples/range -p 0 error: invalid value 0 for --port PORT: 0 is not in 1..=65535For more information, try --help.➜ learn-clap git:(master) ✗ ./target/release/examples/range -p 11111111error: invalid value 11111111 for --port PORT: 11111111 is not in 1..=65535For more information, try --help.➜ learn-clap git:(master) ✗ ./target/release/examples/range -p 1111 port: 1111 在这个例子中，value_parser = clap::value_parser!(u16).range(1..) 的含义可以分为两部分解释： 1. clap::value_parser!(u16) 这部分使用 value_parser! 宏为命令行参数指定了 u16 类型的解析器。这意味着输入的参数值会被尝试解析为无符号 16 位整数（u16）。如果输入不能被成功解析为 u16 类型（例如，输入是非数字字符串或者数字过大/过小而不符合 u16 的范围），clap 会报错并提示用户输入有效的参数值。 2. .range(1…) 这部分进一步限制了参数值的有效范围。.range(1..) 指定了参数值必须大于或等于 1（包含 1），但没有上限。换句话说，任何小于 1 的值都将被认为是无效的，clap 会因此报错并要求用户输入一个符合范围要求的值。这在需要限定参数值为正数时非常有用。 结合起来，value_parser = clap::value_parser!(u16).range(1..) 创建了一个规则，要求命令行参数必须是一个大于或等于 1 的 u16 类型的数值。这在很多场景下都非常有用，比如当你需要用户指定一个正数端口号时。 在 RustRover 中，你可以在 Builder 模式，通过在 clap::value_parser!() 中指定其他的类型，然后输入 . 获得其他类型的内置校验规则。 3.4 自定义校验 对于更复杂的规则，clap 还支持自定义校验规则。比如上面对 port 的校验，也可以自己实现。 use std::ops::RangeInclusive;use clap::Parser;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli #[arg(short, long, value_parser = parse_port)] port: u16,const PORT_RANGE: RangeInclusiveusize = 1..=65535;fn parse_port(s: str) - Resultu16, String let port: usize = s .parse() .map_err(|_| format!(`s` isnt a port number`))?; if PORT_RANGE.contains(port) Ok(port as u16) else Err(format!( port not in range -, PORT_RANGE.start(), PORT_RANGE.end(), )) fn main() let cli = Cli::parse(); println!(port: :?, cli.port); 在代码中，我们直接使用 value_parser = parse_port 来指定自定义的校验规则。 我们自定义的校验规则为： fn parse_port(s: str) - Resultu16, String 它需要满足： 入参是 str 出参是 Result参数类型, String 可以测试输出： ➜ learn-clap git:(master) ✗ ./target/release/examples/custom --helpthis is the about from Cargo.tomlUsage: custom --port PORTOptions: -p, --port PORT -h, --help Print help -V, --version Print version ➜ learn-clap git:(master) ✗ ./target/release/examples/custom -p xxxerror: invalid value xxx for --port PORT: `xxx` isnt a port number`For more information, try --help.➜ learn-clap git:(master) ✗ ./target/release/examples/custom -p 0 error: invalid value 0 for --port PORT: port not in range 1-65535For more information, try --help.➜ learn-clap git:(master) ✗ ./target/release/examples/custom -p 9527port: 9527 3.5 关联参数 有时候参数直接还有关联关系，比如说： 依赖：必须存在 -a 参数，-b 参数才有意义，即要使用 -b 参数时，必须指定 -a 参数。 互斥：-a 和 -b 只能同时存在一个。 可以使用 requires 实现依赖关系： use clap::Parser;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli #[arg(short, long)] a: OptionString, #[arg(short, long,requires = a)] b: OptionString,fn main() let cli = Cli::parse(); println!(a: :?, cli.a); println!(b: :?, cli.b); 上述代码中，我们在参数 b 中加入了 requires = a，表示要使用 b 参数必须要有 a 参数。 输出： ➜ learn-clap git:(master) ✗ ./target/release/examples/relation a: Noneb: None➜ learn-clap git:(master) ✗ ./target/release/examples/relation -b 1 error: the following required arguments were not provided: --a AUsage: relation --a A --b BFor more information, try --help.➜ learn-clap git:(master) ✗ ./target/release/examples/relation -a 1a: Some(1)b: None➜ learn-clap git:(master) ✗ ./target/release/examples/relation -a 1 -b 2a: Some(1)b: Some(2) 可以使用 #[group(required = true, mutiple = false)] 来实现互斥关系： use clap::Args, Parser;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli #[command(flatten)] args: Only,#[derive(Args, Debug)]#[group(required = true, multiple = false)]struct Only #[arg(long)] a: OptionString, #[arg(long)] b: OptionString, #[arg(long)] c: OptionString, #[arg(long)] d: OptionString,fn main() let cli = Cli::parse(); println!(only: :?, cli.args) #[command(flattern)] 直接将结构体里面的参数平铺。 #[group] 用于将一组参数归为一个组，required = true 表示必须提供该 group 中的参数，multiple = false 表示只能有一个参数被提供。 测试输出如下： ➜ learn-clap git:(master) ✗ ./target/release/examples/only_one --helpthis is the about from Cargo.tomlUsage: only_one --a A|--b B|--c C|--d DOptions: --a A --b B --c C --d D -h, --help Print help -V, --version Print version ➜ learn-clap git:(master) ✗ ./target/release/examples/only_one error: the following required arguments were not provided: --a A|--b B|--c C|--d DUsage: only_one --a A|--b B|--c C|--d DFor more information, try --help.➜ learn-clap git:(master) ✗ ./target/release/examples/only_one --a 1 only: Only a: Some(1), b: None, c: None, d: None ➜ learn-clap git:(master) ✗ ./target/release/examples/only_one --a 1 --b 2error: the argument --a A cannot be used with --b BUsage: only_one --a A|--b B|--c C|--d DFor more information, try --help.➜ learn-clap git:(master) ✗ ./target/release/examples/only_one --b 2 only: Only a: None, b: Some(2), c: None, d: None Builder 使用 clap 的 Builder 模式，一般情况下不需要额外引入其他的 features： cargo add clap 但是如果要使用 command! 来构建应用的话，需要引入 cargo 这个 features： cargo add clap --features cargo 1. 应用配置 在 Builder 模式下，你可以使用 command!() 或 Command::new(appname) 来构建一个命令行应用，其中 command!() 默认将 appname 设置应用名称，而 Command::new() 必须显示指定 appname。 use clap::arg, Arg, Command, command, value_parser;fn main() // let matches = command!() let matches = Command::new(MyApp) // Application configuration .version(1.0.0) .author(hedon) .about(This the intro of the cli application) // Application args .arg(arg!([NAME]).help(Specify your name)) .arg( Arg::new(age).short(a).long(age).value_parser(value_parser!(u8)) ) .get_matches(); // Read and parse command args if let Some(name) = matches.get_one::String(NAME) println!(Value for name: name); if let Some(age) = matches.get_one::u8(age) println!(Value for age: age); 这段代码分为以下几个部分： 1. 创建命令行应用实例： let matches = Command::new(MyApp) 这里使用 Command::new 方法创建了一个新的命令行应用实例，命名为 MyApp。 2. 配置应用： .version(1.0.0).author(hedon).about(This the intro of the cli application) 接下来，使用链式调用方法配置应用的版本号为 1.0.0，作者为 hedon，并添加了一个简短的描述。 这里等价于 Builder 模式下的： #[command(version, author, about)] 3. 添加命令行参数： .arg(arg!([NAME]).help(Specify your name)).arg( Arg::new(age).short(a).long(age).value_parser(value_parser!(u8))) 这部分代码添加了两个命令行参数： .arg(arg!([NAME]).required(true).help(Specify your name)) 使用 arg! 宏添加了一个名为 NAME 的必需参数，并提供了一些帮助信息。 .arg(Arg::new(age).short('a').long(age).value_parser(value_parser!(u8))) 创建了另一个参数 age，可以通过 -a 或 --age 来指定。这个参数使用了 value_parser 宏来指明它的值应被解析为 u8 类型的数字。 4. 解析命令行参数： .get_matches(); 使用 .get_matches() 方法来解析命令行参数并将结果存储在 matches 变量中。 5. 读取并打印参数值： if let Some(name) = matches.get_one::String(NAME) println!(Value for name: name);if let Some(age) = matches.get_one::u8(age) println!(Value for age: age); 最后，使用 matches.get_one::T(arg_name) 方法尝试获取指定名称的参数值。如果成功找到，则将其打印出来。这里分别尝试获取 NAME 和 age 参数的值，并使用 println! 宏将它们打印到控制台。 使用 -- help 测试输出如下： This the intro of the cli applicationUsage: app2 [OPTIONS] [NAME]Arguments: [NAME] Specify your nameOptions: -a, --age AGE -h, --help Print help -V, --version Print version 你可以将其与「Derive - 应用配置」进行比较，应该很容易找到它们之间的对应关系。 在 Derive 中 #[command] 和 #[arg] 支持的属性，都可以在 Builder 中找到对应的同名的函数，这里就不赘述了。 2. 参数类型 在 Builder 模式中，配置参数有两种方式： arg!([-short] [–long] id) Args::new(“id”).short(‘s’).long(“long”) 2.1 Arguments Options Arguments: [NAME] Specify your nameOptions: -a, --age AGE Argument: 不包含 -short 和 --long。 Options: 包含 -short 或 --long。 .arg(arg!([NAME]).help(Specify your name)).arg(arg!(-a --age AGE).value_parser(value_parser!(u16))) 2.2 可选参数 根据约定， 表示必须，而 [] 表示可选： .arg(arg!(NAME) // 必须.arg(arg!([ADDRESS])) // 可选 你也可以使用 .required(bool) 函数明确指出是否必须： .arg(arg!(NAME).required(true)) .required() 的优先级高于 和 []，但是建议你在构建的时候还是遵循约定。 2.3 枚举参数 第 1 种：在 value_parser() 中直接指定可选的枚举参数 .arg(arg!(MODE).value_parser([fast, slow])) 第 2 种：使用枚举，但是枚举需要实现 ValueEnum trait 这里又有 2 种方式，你可以向 Derive 一样引入 derive features，然后直接 #[derive(ValueElem)] 使用默认实现，也可以手动实现。我更倾向于前者。 use clap::arg, command, value_parser, ValueEnum;fn main() let matches = command!() // .arg(arg!(MODE).value_parser([fast, slow])) .arg( arg!(MODE).value_parser(value_parser!(Mode)).required(true) ) .get_matches(); match matches.get_one::Mode(MODE) .expect(Mode is required and parsing will fail if its missing) Mode::Fast = println!(fast), Mode::Slow = println!(slow), #[derive(Copy, Clone, Ord, PartialOrd, Eq, PartialEq, ValueEnum)]enum Mode /// Run in fast mode Fast, /// Run in slow mode Slow, 2.4 累计参数 使用 clap::ArgAction::Count 设置参数为累计参数，然后使用 get_count(id) 获取参数的值： use clap::arg, command;fn main() let matches = command!() .arg(arg!(-v --verbose...).action(clap::ArgAction::Count)) .get_matches(); println!(v count: :?, matches.get_count(verbose)); 这里要注意，arg!() 中参数的定义，也要符合累计参数的格式 -short --long...。 2.5 变长参数 使用 clap::ArgAction::Append 设置参数为变长参数，然后使用 get_many::类型(id) 获取参数的值： use clap::arg, Command;fn main() let matches = Command::new(append-application) .arg(arg!([FILES]...).action(clap::ArgAction::Append)) .get_matches(); let files = matches .get_many::String(FILES) .unwrap_or_default() .map(|v|v.as_str()) .collect::Vec_(); println!(files: :?, files); 这里要注意，arg!() 中参数的定义，也要符合变长参数的格式 [arg]|arg...。 2.6 标志参数 使用 clap::ArgAction::SetTrue 或 clap::ArgAction::SetFalse 设置参数为标志参数，然后使用 get_flag() 获取参数的值： use clap::arg, command;fn main() let matches = command!() .arg(arg!(-d --debug).action(clap::ArgAction::SetTrue)) .arg(arg!(-v --verbose).action(clap::ArgAction::SetFalse)) .get_matches(); println!(debug: :?, matches.get_flag(debug)); println!(verbose: :?, matches.get_flag(verbose)) 其中： clap::ArgAction::SetTrue : 设置参数的话，则为 true，否则 false（默认）。 clap::ArgAction::SetFalse : 设置参数的话，则为 false，否则 true（默认）。 测试： ➜ learn-clap-builder git:(master) ✗ ./target/release/examples/flag debug: falseverbose: true➜ learn-clap-builder git:(master) ✗ ./target/release/examples/flag -d debug: trueverbose: true➜ learn-clap-builder git:(master) ✗ ./target/release/examples/flag -v debug: falseverbose: false 2.7 子命令 可以使用 subcommand(sub_cmd) 和 subcommand([sub_cmd1, sub_cmd2]) 来添加子命令，解析的时候使用 matches.subcommand() 匹配子命令，再按照之前的规则解析子命令中对应的参数即可。 use clap::arg, Command, value_parser;fn main() let matches = Command::new(myapp) .subcommands([ Command::new(add) .arg(arg!(NUM).value_parser(value_parser!(i16))), Command::new(sub) .arg(arg!(NUM).value_parser(value_parser!(i16))), ]) .get_matches(); match matches.subcommand() Some((add, add_cmd)) = println!( myapp add was used, num is: :?, add_cmd.get_one::i16(NUM), ), Some((sub, sub_cmd)) = println!( myapp sub was used, num is: :?, sub_cmd.get_one::i16(NUM), ), _ = unreachable!() 3. 参数校验 3.1 类型校验 使用 value_parser!() 在括号中指定类型，clap 就会自动帮我们对参数进行类型校验，当然你在获取参数值 get_one::类型() 的时候，类型要对上，否则会 panic。 默认支持： 原生类型：bool, String, OsString, PathBuf、usize、isize 范围数据：u8, i8, u16, i16, u32, i32, u64, i64 实现了 ValueEnum 的 enum 类型 实现了 FromOsString、FromOsStr 、FromStr 的类型 3.2 枚举校验 2.3 中枚举参数的说明中，已经体现了枚举校验的功能了，这里不赘述。 3.3 范围校验 对于上述提到的「范围数据」，可以使用 value_parser!(类型).range() 进行范围校验。 arg!(PORT) .value_parser(value_parser!(u16).range(1..)) 3.4 自定义校验 value_parser() 中也可以传自定义的校验函数，该函数的签名需要满足的条件跟我们在介绍 Derive 时一样。 use std::ops::RangeInclusive;use clap::arg, command;fn main() let matches = command!() .arg(arg!(PORT).value_parser(port_in_range)) .get_matches(); println!(port: :?, matches.get_one::u16(PORT))const PORT_RANGE: RangeInclusiveusize = RangeInclusive::new(1, 65535);fn port_in_range(s: str) - Resultu16, String let port: usize = s .parse() .map_err(|_|format!(`s` is not a port number))?; if PORT_RANGE.contains(port) Ok(port as u16) else Err(format!( port not in range -, PORT_RANGE.start(), PORT_RANGE.end(), )) 3.5 关联参数 **依赖关系：**使用 requires(id | group) 排斥关系：使用 group().multiple(false).required(true) .group( ArgGroup::new(vers) // 表示 set-ver, major, minor, patch 必须有一个且只能有一个存在 .multiple(false) .required(true) .args([set-ver, major, minor, patch]),).arg( arg!([INPUT_FILE] some regular input) .value_parser(value_parser!(PathBuf)) .group(input),).arg( arg!(config: -c CONFIG) .value_parser(value_parser!(PathBuf)) // 表示 -c 需要有 group 为 input 的命令存在才可以使用 .requires(input),) Derive vs Builder (2) 对比 clap + rpassword 实现加密输入 对于密码、密钥等关键信息的输入，为了信息安全，我们一般会使用加密输出，clap 本身不支持加密输入功能。若你有这方面的需求，可以使用 rpassword crate 辅助完成。 示例： use clap::Parser;use rpassword::read_password;#[derive(Parser)]#[command(version, author, about, long_about = None)]struct Cli #[arg(short, long)] username: String, #[arg(short, long, required = true)] password: bool,fn main() let cli = Cli::parse(); let password = if cli.password // Prompt user to enter password read_password().expect(Failed to read password) else .to_string() ; // Use username and password to do something println!(username: , password: , cli.username, password); clap_complete 实现自动补全 要实现自动补全，需要在 .zshrc 或 .bashrc 等 SHELL 文件中加入命令自动补全脚本。这时候可以使用 clap_complete 来实现这个功能。 下面的示例目录结构如下： ├── Cargo.lock├── Cargo.toml├── build.rs└── src ├── cli.rs └── main.rs 首先我们需要引入 clap 和 clap_complete crate，其中 clap_complete 只需在 build 环境下即可，所以我们的 Cargo.tmol 如下： [package]name = myappversion = 0.1.0edition = 2021build = build.rs[dependencies]clap = version = 4.5.1 dirs = 5.0.1[build-dependencies]clap = version = 4.5.1clap_complete = 4.5.1 我们先在 src/cli.rs 中实现一个简单的命令行程序 myapp： use clap::Arg, ArgAction, Command;pub fn build_cli() - Command Command::new(myapp) .about(Tests completions) .arg(Arg::new(file) .help(some input file)) .subcommand(Command::new(test) .about(tests things) .arg(Arg::new(case) .long(case) .action(ArgAction::Set) .help(the case to test))) 我们主要是演示这个自动补全功能，为了省事，src/main.rs 中就不实现具体逻辑了： mod cli;fn main() let _m = cli::build_cli().get_matches(); 接着，我们在项目根目录下实现 build.rs，它将为我们指定的命令生成自动补全脚本： touch build.rs use clap_complete::generate_to, shells::Bash;use std::env;use std::io::Error;include!(src/cli.rs);fn main() - Result(), Error let outdir = match env::var_os(OUT_DIR) None = return Ok(()), Some(outdir) = outdir, ; let mut cmd = build_cli(); let path = generate_to( Bash, mut cmd, // We need to specify what generator to use myapp, // We need to specify the bin name manually outdir, // We need to specify where to write to )?; println!(cargo:warning=completion file is generated: path:?); Ok(()) 你需要把其中的 myapp 替换为你的命令。 执行构建命令： cargo build 可以看到输出： warning: myapp@0.1.0: completion file is generated: /Users/hedon/RustroverProjects/learn-clap-complete/target/debug/build/myapp-42e401d08c044ca3/out/myapp.bash Finished dev [unoptimized + debuginfo] target(s) in 1.90s 这里会输出生成脚本所在的位置，我这里是 /Users/hedon/RustroverProjects/learn-clap-complete/target/debug/build/myapp-42e401d08c044ca3/out/myapp.bash。 我的终端使用的是 zsh： ➜ echo $SHELL /bin/zsh 所以我需要将这个文件的内容加到 ~/.zshrc 文件的末尾： cat /Users/hedon/RustroverProjects/learn-clap-complete/target/debug/build/myapp-42e401d08c044ca3/out/myapp.bash ~/.zshrc 重新加载配置文件： source ~/.zshrc 这个时候你使用 myapp 命令的时候，按 tap 键，就有自动补全了： ➜ ./target/debug/myapp --help -h \\[file\\] help test HTTPie 由于篇幅原因，实战 HTTPie 部分请看：Rust 实战丨HTTPie 与 Go 语言 cobra 比较 Go 的 cobra 也是用于构建命令行应用程序的库，它在 Go 语言生态中非常受欢迎。 为了直观展示这 2 个库构建命令行应用程序的区别，我们来设计一个简单的命令行程序，用 clap 和 cobra 分别实现，以展示如何用这两个库实现相同的功能。 让我们创建一个 CLI 程序，它有一个 greet 子命令，接受一个 -n 或 --name 参数，并打印出一条欢迎信息。 Rust clap 实现 use clap:: Parser, Subcommand;#[derive(Parser)]#[command(bin_name = greet_app)]struct Cli #[command(subcommand)] sub: OptionSub,#[derive(Subcommand)]enum Sub Greet #[arg(short, long)] name: String, fn main() let cli = Cli::parse(); if let Some(sub) = cli.sub match sub Sub::Greetname = println!(greeting: :?, name), Go cobra 实现 package mainimport (\tfmt\tos\tgithub.com/spf13/cobra)var rootCmd = cobra.Command\tUse: greet_app,\tShort: A simple greeting application,\tLong: `This is a simple greeting application with a greet command.`,var greetCmd = cobra.Command\tUse: greet,\tShort: Greets a user,\tLong: `Prints a greeting message for the specified user.`,\tRun: func(cmd *cobra.Command, args []string) name, _ := cmd.Flags().GetString(name) fmt.Printf(Hello, %s! , name)\t,func init() rootCmd.AddCommand(greetCmd)\tgreetCmd.Flags().StringP(name, n, , Sets the name to greet)\tgreetCmd.MarkFlagRequired(name)func main() if err := rootCmd.Execute(); err != nil fmt.Println(err) os.Exit(1) 输出： This is a simple greeting application with a greet command.Usage: greet_app [command]Available Commands: completion Generate the autocompletion script for the specified shell greet Greets a user help Help about any commandFlags: -h, --help help for greet_appUse greet_app [command] --help for more information about a command. 对比 设计哲学和易用性 clap: 使用 Rust 的宏来提供强大的编译时功能，如参数解析、验证等。 利用 Rust 的类型安全特性，减少运行时错误。 支持通过派生宏自动从结构体生成命令行解析代码，简化开发流程。 cobra: 采用更传统的命令式编程模型，直观且易于上手。 通过组合命令对象来构建复杂的命令行应用。 提供了一套完整的生成工具来创建命令和配置，促进了开发速度。 功能和特性 clap: 自动生成帮助信息、版本信息等。 支持多级子命令。 支持自定义验证器和复杂的参数关系（如互斥、依赖等）。 cobra: 支持自动生成帮助文档。 内置命令自动补全脚本生成功能。 支持持久化命令行标志到配置文件。 通过插件支持增加额外的子命令。 能够轻松地与其他 Go 库集成，如 Viper 用于配置管理。 性能 clap: 由于 Rust 的编译时优化，clap 在解析命令行参数时通常会有更好的性能。 更少的运行时开销，尤其是在处理大量复杂命令行参数时。 cobra: 性能对于大多数命令行应用来说已经足够，但可能不如 clap 优化。 Go 的运行时可能会引入额外的开销，尤其是在并发处理时。","tags":["Rust","clap"],"categories":["Rust","Rust 常用库"]},{"title":"Rust reqwest 简明教程","path":"/2024/03/02/rust-crate-reqwest/","content":"概述 reqwest 是 Rust 中一个非常流行和强大的 HTTP 客户端库，它提供了一种简单的方式来发送 HTTP 请求并处理响应。reqwest 支持阻塞和非阻塞（异步）请求，使其适合于各种不同的应用场景。在这篇博文中，我们将详细介绍如何使用 reqwest 发送各种 HTTP 请求，并处理返回的响应。 开始之前 在开始编写代码之前，你需要在你的 Rust 项目中添加 reqwest 依赖。打开你的 Cargo.toml 文件，并添加以下内容： [dependencies]reqwest = version = 0.12.4, features = [json] tokio = version = 1, features = [full] serde = version = 1.0.197, features = [derive] serde_json = 1.0.114 这里我们还添加了其他几个依赖： tokio: 在后面的示例中，我们将使用 reqwest 的异步功能。 serde: 用于数据解析，在示例中，我们会演示 json 数据的解析。 serde_json: 便于使用 json! 宏快速构建 json 数据。 发送 GET 请求 发送一个 GET 请求是最基本的 HTTP 操作。以下是如何使用 reqwest 发送 GET 请求并设置请求头的示例： use reqwest::header;#[tokio::main]async fn main() - Result(), reqwest::Error let params = [(key1, value1), (key2, values)]; let client = reqwest::Client::new(); let body = client .get(http://httpbin.org/get) // set query params .form(params) // set request headers .header(header::USER_AGENT, My Rust Program) .header(header::CONTENT_TYPE, application/json) .send() .await? .text() .await?; println!(body = :?, body); Ok(()) 在这个例子中，我们使用 reqwest::get 函数发送一个 GET 请求到 “https://httpbin.org/get”，并通过 text 方法获取响应的文本内容。 发送 POST - text 请求 use reqwest::Client;#[tokio::main]async fn main() - Result(), reqwest::Error let client = Client::new(); let res = client.post(http://httpbin.org/post) .body(the exact body that is sent) .send() .await? .text() .await?; println!(body: :?, res); Ok(()) 发送 POST - form 请求 #[tokio::main]async fn main() - Result(), reqwest::Error let params = [(key1, value1), (key2, values)]; let client = reqwest::Client::new(); let res = client.post(http://httpbin.org/post) .form(params) .send() .await? .text() .await?; println!(body: :?, res); Ok(()) 发送 POST - json 请求 发送 POST 请求通常用于向服务器提交数据。以下是如何使用 reqwest 发送包含 JSON 数据的 POST 请求的示例： use reqwest;use serde_json::json;#[tokio::main]async fn main() - Result(), reqwest::Error let client = reqwest::Client::new(); let res = client.post(https://httpbin.org/post) .json(json!(key: value)) .send() .await?; let body = res.text().await?; println!(Body: , body); Ok(()) 这里我们使用 Client::post 方法创建一个 POST 请求，并通过 json 方法设置 JSON 负载。然后，我们调用 send 方法发送请求。 处理 JSON 响应 use reqwest;use serde::Deserialize;#[derive(Deserialize)]struct Ip origin: String,#[tokio::main]async fn main() - Result(), reqwest::Error let ip: Ip = reqwest::get(https://httpbin.org/ip) .await? .json() .await?; println!(IP: , ip.origin); Ok(()) 在这个示例中，我们定义了一个 Ip 结构体来表示 JSON 响应，然后使用 json 方法将响应反序列化为 Ip 类型。 总结 reqwest 库为 Rust 提供了一个功能丰富而灵活的 HTTP 客户端，适用于各种网络编程任务。无论是简单的数据获取还是复杂的 API 交互，reqwest 都能帮助你以简洁的 Rust 代码完成任务。希望这篇博文能帮助你开始使用 reqwest 来开发网络相关的 Rust 应用！","tags":["Rust"],"categories":["Rust","Rust 常用库"]},{"title":"深入浅出 Go 语言的 GPM 模型（Go1.21）","path":"/2024/01/20/go-gpm/","content":"引言 在现代软件开发中，有效地利用并发是提高应用性能和响应速度的关键。随着多核处理器的普及，编程语言和框架如何高效、简便地支持并发编程，成为了软件工程师们评估和选择工具时的一个重要考量。在这方面，Go 语言凭借其创新的并发模型—GPM（Goroutine, P, M）—在众多编程语言中脱颖而出，为开发者提供了强大的工具，以简单、高效的方式实现并发。 自从 2009 年首次发布以来，Go 语言就以其出色的性能、简洁的语法和对并发的原生支持赢得了广泛的关注。尤其是其并发模型，被设计为能够充分利用现代多核处理器的能力，同时隐藏底层的线程管理和同步复杂性，让开发者能够以更直观、更高级的抽象来构建并发程序。GPM 模型，作为 Go 语言并发编程的核心，通过 Goroutine、P（processor）、M（machine）三者的协同工作，实现了一种高效且易于管理的并发机制。 本文将基于 Go1.21 深入浅出地探讨 Go 语言的 GPM 模型，主要分为几个部分： 首先从其设计理念出发，详细解析 Goroutine、P 和 M 三者的角色、工作原理及其相互之间的交互方式。 然后引入几个关键问题，我们会从结论上先总结 GPM 的核心要点，内容包括协程调度循环、调度策略和调度时机。 接着我们会深入源码，去一步步洞察 Go 语言设计者是如何实现 GPM 模型中的各个要点的，这个过程会比较繁琐，但其实也比较有趣，感兴趣的读者可以阅读这一块，若只是想对 GPM 模型有个大概了解，那么停留在上一步也足矣了。 最后我们基于前面的分析，总结 G、P、M 三大组件在 Go 程序运行过程中的状态流转图。 通过对 GPM 模型的探讨，我们不仅能够理解 Go 语言如何在众多现代编程语言中以其并发编程能力脱颖而出，还能够洞察其设计背后的智慧，以及这一模型如何随着 Go 语言版本的迭代而不断进化和优化。无论你是对 Go 语言充满好奇的新手，还是希望深化理解其并发模型的经验开发者，本文都将为你提供宝贵的视角和深刻的洞见。 结论先行 GPM 调度原理图 Goroutine 底层结构 调度器 P 底层结构 GPM 调度循环 GPM 协程调度优先级与顺序 寻找可执行 G 过程 协程切换时机 GPM 模型 1. 概览 这里有一张很流行的 Goroutine 调度原理图： 代号 名称 定义位置 作用 Sched 调度器 proc.c 维护有存储 M 和 G 的队列以及调度器的一些状态信息等。 M Machine 系统线程 runtime.h 它由操作系统管理的，Goroutine 就是跑在 M 之上的；M 是一个很大的结构，里面维护小对象内存 cache（mcache）、当前执行的 Goroutine、随机数发生器等等非常多的信息。 P Processor 处理器 runtime.h 它的主要用途就是用来执行 Goroutine 的，它维护了一个 Goroutine 队列，即 runqueue。Processor 是让我们从 N:1 调度到 M:N 调度的重要部分。所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS（可配置）个。 G Goroutine 实现的核心结构 runtime.h 它包含了栈，指令指针，以及其他对调度 Goroutine 很重要的信息，例如其阻塞的 channel。 Global Queue 全局队列 proc.h 存放等待运行的 G。全局队列可能被任意的 P 加锁去获取里面的 G。 P Local Queue P 的本地队列 proc.h 同全局队列类似，存放的也是等待运行的 G，但存放的数据有限，不会超过 256 个。新建 G 时，G 会优先加入本地队列。如果队列满了，则会把本地队列中一半的 G 以及新 G 一起移动到全局队列。 通过这个原理图我们知道 Go 语言的 GPM 模型的作用非常简单，它就是一个“精打细算”的工具。以前单进程无法充分利用 CPU 资源，所以引入了多进程。又因为进程拥有的资源太多，其创建、切换和销毁都会占用很长时间，所以引入了更小粒度的线程。随着计算机科学的进步，现在看来，线程拥有的资源也是“比较多”的，所以线程的创建、切换和销毁代价也是“相对大”的。所以很多编程语言就引入了协程这个概念，其核心目的就是应用层自己抽象一个比线程更小粒度的调度单元，应用层结合操作系统的多线程能力，自己来管理“调度单元”的创建、切换和销毁，从而尽可能减少由线程切换带来的开销，以做到更轻量级的并发。 不同的编程语言可能有不同的实现，而关键就在于如何让调度更快、开销更小。这便是我们本文要探讨的主要内容。 Go 语言的实现 线程想运行任务就得获取 P，从 P 的本地队列获取 G，当 P 的本地队列为空时，M 会尝试从全局队列获得一批 G 放到 P 的本地队列，或者从其他 P 的本地队列中“偷”一半 G 放到自己的本地队列。然后 M 运行 G，G 执行之后，再从 P 获取下一个 G，如此不断重复下去。 在进入更加具体深入的讨论之前，我们需要重点思考以下几个问题： G 我们可以随便创建，可能有成千上万个，那 P 和 M 有多少个呢？ P 和 M 什么时候被创建呢？ 操作系统只知道线程，所以实际上还是线程在执行任务，那么 G 是如何调度到线程上并执行的呢？ 如何防止协程饥饿？ 如何减少频繁地创建和销毁线程？ 多个线程从全局队列拿 G 如何解决并发问题？又如何减少这种数据竞争呢？ 在整个 Go 调度协程的过程中，G、P、M 有哪些状态？它们又是如何轮转的呢？ 如果你对这几个问题有兴趣，请继续阅读下文。 2. P 和 M 的个数问题 P 的数量由启动时环境变量 $GOMAXPROCS 或者程序中 runtime.GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 GOMAXPROCS 个 Goroutine 在同时运行。 M 的数量由 Go 语言本身的限制决定，Go 程序启动时会设置 M 的最大数量为 10000 个，但是内核很难支持这么多的线程数，所以这个限制可以忽略。可以使用 runtime.SetMaxThreads() 设置 M 的最大数量。 3. P 和 M 何时被创建 P 的创建时机在确定了 P 的最大数量 n 后，runtime 会根据这个数量创建 n 个 P。 M 创建的时机是在当没有足够的 M 来关联 P 并运行其中可运行的 G 的时候，如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，如果没有空闲的 M，就会去创建新的 M。 4. 调度循环 在讨论 G 是如何被调度到 M 去执行的时候，我们需要先介绍 GPM 模型中两个比较特殊的角色：m0 和 g0。 4.1 m0 定义：m0 是 Go 程序启动时创建的第一个 M。它是由 Go 运行时系统直接从操作系统线程创建的，不是从线程池中获取的。 作用：m0 负责初始化和启动 Go 运行时环境，包括创建调度器、分配第一个 P（p0），并创建其他系统级别的资源。在程序的整个生命周期中，m0 会继续存在，即使它可能不执行任何 Go 代码。 特点：m0 不同于其他 M，因为它不是从线程池中获取的。它可能没有绑定任何 P，除非程序中只有一个 P（即 GOMAXPROCS 设置为 1）。 4.2 g0 定义：g0 是每个 M 的特殊 Goroutine，它不执行任何实际的 Go 代码。每个 M 在创建时都会分配一个 g0。 作用：g0 主要用于执行调度器代码和进行系统调用。当 M 需要执行这些非用户代码时，会切换到 g0 的栈上运行。 特点：g0 拥有自己的栈，这个栈用于存放调度器函数和系统调用的数据。这意味着当执行这些操作时，不会影响当前运行的用户 Goroutine 的栈。 4.3 协程栈切换 g0 是 M 中负责调度其他 g 的协程，所以一个 M 中的协程调度其实就是在 g 和 g0 之间不断切换： 大致过程如下： 当 M 执行一个 G（用户 Goroutine）时，它使用 G 的栈来运行用户代码。 当需要执行系统调用或调度器相关的代码时，M 会切换到 g0。g0 拥有自己的栈，专门用于执行系统调用和调度器代码，这样可以避免污染用户 Goroutine 的栈空间。在 g0 上，M 可以执行如内存分配、调度决策、处理 Goroutine 的创建和销毁等操作。 完成系统调用或调度器任务后，M 会切换回之前的 G，继续执行用户代码。这个过程会从 g0 的栈切换回 G 的栈。 详细细节我们留到后面的源码分析揭晓。 5. 调度策略 5.1 获取本地运行队列 P 会优先尝试从自己的本地队列中寻找就绪的 G，它一般会优先调度最近加入的。 因为这个时候可能由其他 P 来窃取 G，所以这里是需要同步机制的，Go 采用原子操作来降低同步开销。 本地队列 G 的个数不超过 256 个，如果在创建 G 的时候本地队列满了，会将本地队列中 1/2 的 G 连同新创建的 G 一起放入全局队列中。 5.2 获取全局运行队列 P 会优先本地队列，然后才全局队列，这有个好处： 如果只有全局队列，那么所有的 P 都需要去竞争全局队列中的 G，这个时候需要上锁，且数据竞争会比较激烈，性能较差。 通过每个 P 维护一个自己的本地队列可以减少并发冲突，如果实在需要去全局队列拿 G，也可以一次性拿多个，大大减少了并发冲突的情况发生。 但这又带来了一个问题，全局队列中协程的饥饿问题，因为 P 会优先调度最近加入到自己本地队列中的 G，那可能会一直有新的 G 被创建，导致全局队列中的 G 没有机会被调度到。Go 的解决思路是： P 每调度 61 次后，就会从全局队列中获取一个 G 来运行。 5.3 获取准备就绪的网络协程 如果本地队列和全局队列都找不到就绪的 G 可以执行的话。调度会通过 runtime.netpoll 获取可以运行的网络协程。 Go 语言的网络模型是对不同操作系统平台上 I/O 多路复用技术的封装。 当 Goroutine 在进行网络 I/O 时，它会被挂起，线程会去执行其他 Goroutine。一旦 I/O 操作完成，该 Goroutine 会被唤醒并重新排队等待执行。 5.4 系统调用 当一个 Goroutine 执行系统调用时，它可能会被阻塞，这时它的执行线程（M）可能会释放当前绑定的处理器（P），以便其他 Goroutine 可以在该 P 上运行。 5.5 协程窃取 空闲的 M 如果绑定了 P，那么它的 P 会一直尝试从其他 P 的队列中窃取 Goroutine，以平衡负载和避免空闲。这个时候为了让每个 P 都有可能被窃取，Go 没有直接顺序遍历 P 列表，而是采用了一种相对随机的方式去遍历 P 列表，直到找到可以运行的协程就返回。M 不断寻找可执行 G 的这段期间，它被称为自旋线程。 所以为减少创建、切换和销毁线程的开销，Go 做了至少两点努力： 偷取（Work Stealing）机制 当本线程无可运行的 G 时，它所绑定的 P 会尝试从其他线程绑定的 P 窃取 G，而不是销毁线程。 移交（Hand Off）机制 当本线程因为 G 进行系统调用而阻塞时，线程会释放绑定的 P，把 P 移交给其他空闲的线程执行。 6. 调度时机 Go 语言的调度器结合了抢占式调度和协作式调度，以下是 Go 中这两种调度方式的具体实现和特性： 6.1 协作式调度（Cooperative Scheduling） 阻塞操作： 当 Goroutine 执行阻塞操作（如通道操作、等待锁、系统调用等）时，它会主动放弃 CPU 控制权，允许调度器切换到其他 Goroutine。 显式调度： Goroutine 显式请求 runtime.Gosched() 调用，调度器进行调度。 这个时候回从当前协程切换到 g0 协程，取消 G 与 M 之间的绑定关系，把 G 放入全局队列中。 6.2 抢占式调度（Preemptive Scheduling） 基于时间的抢占： 从 Go 1.14 开始，调度器引入了基于时间的抢占机制。如果一个 Goroutine 运行时间超过 10 毫秒，或者在系统调用中超过了 20 微妙，调度器会在安全点（如函数调用、循环迭代、阻塞操作等）尝试暂停该 Goroutine。 这种抢占不依赖于 Goroutine 的显式放弃控制，而是由调度器主动触发。 安全点的选择旨在减少对 Goroutine 执行的干扰，同时确保调度的公平性和响应性。 基于信号的抢占： 当程序在执行过程中既无法主动挂起，也不能进行系统调用，且无法进行函数调用时，就可以使用信号来调度。 信号其实就是线程信号，在操作系统中有很多基于信号的底层通信方式（SIGPIPE / SIGURG / SIGHUP），而我们的线程可以注册对应信号的处理函数。 当线程接收到抢占信号时，会进入一个专门的信号处理器。这个处理器会检查是否处于安全点，如果是，则暂停当前 Goroutine 并进行上下文切换。 源码分析 前面我们对 Go 语言的 GPM 模型在基本概念、调度循环、调度策略和调度时机各个方面都进行了详细的阐述。如果读者只是想简单了解一下 GPM 模型的一些概念和设计思想，那么阅读到这里就基本足够了。如果对其源码实现有兴趣的话，那么请继续往下阅读~ 接下来我们会从以下几个方面来对 Go 语言的 GPM 模型进行源码分析： G、P、M 在 Go 语言中的表示。 G 的创建过程。 g 和 g0 的切换过程。 GPM 的调度机制。 1. G 的底层结构 G 在 Go 里面就是 runtime2.go 里面定义的 g 结构体： type g struct // 栈参数。\t// stack 描述实际的栈内存：[stack.lo, stack.hi)。\t// stackguard0 是在 Go 栈增长序言中比较的栈指针。\t// 通常是 stack.lo+StackGuard，但可以是 StackPreempt 来触发抢占。\t// stackguard1 是在 C 栈增长序言中比较的栈指针。\t// 在 g0 和 gsignal 栈上是 stack.lo+StackGuard。\t// 在其他 goroutine 栈上是 ~0，以触发对 morestackc 的调用（并崩溃）。\tstack stack // 运行时/CGO 已知的偏移\tstackguard0 uintptr // liblink 已知的偏移\tstackguard1 uintptr // liblink 已知的偏移\t_panic *_panic // 最内层的 panic - liblink 已知的偏移\t_defer *_defer // 最内层的 defer\tm *m // 当前 m；arm liblink 已知的偏移\tsched gobuf // 当前协程的运行现场\tsyscallsp uintptr // 如果 status==Gsyscall, syscallsp = sched.sp 在 gc 期间使用\tsyscallpc uintptr // 如果 status==Gsyscall, syscallpc = sched.pc 在 gc 期间使用\tstktopsp uintptr // 栈顶的预期 sp，用于回溯检查\t// param 是一个通用的指针参数字段，用于在特定上下文中传递值，\t// 其他存储参数的方式难以找到。目前有三种用途：\t// 1. 当通道操作唤醒一个阻塞的 goroutine 时，它将 param 设置为\t// 指向已完成阻塞操作的 sudog。\t// 2. 由 gcAssistAlloc1 使用，以向其调用者信号，表明 goroutine 完成了 GC 周期。\t// 以任何其他方式这样做是不安全的，因为此时 goroutine 的栈可能已经移动。\t// 3. 由 debugCallWrap 使用，以将参数传递给新的 goroutine，因为在运行时分配闭包是被禁止的。\tparam unsafe.Pointer\tatomicstatus atomic.Uint32\tstackLock uint32 // sigprof/scang 锁；TODO: 合并到 atomicstatus\tgoid uint64\tschedlink guintptr\twaitsince int64 // g 变为阻塞的大致时间\twaitreason waitReason // 如果 status==Gwaiting\tpreempt bool // 抢占信号，复制 stackguard0 = stackpreempt\tpreemptStop bool // 在抢占时转换为 _Gpreempted；否则，只是取消调度\tpreemptShrink bool // 在同步安全点缩小栈\t// asyncSafePoint 设置为 true 表示 g 在异步安全点停止。\t// 这意味着栈上有没有精确指针信息的帧。\tasyncSafePoint bool\tpaniconfault bool // 在意外的故障地址上触发 panic（而不是崩溃）\tgcscandone bool // g 已扫描栈；由 _Gscan 位在状态中保护\tthrowsplit bool // 必须不分割栈\t// activeStackChans 表示有未锁定的通道指向这个 goroutine 的栈。\t// 如果为 true，栈复制需要获取通道锁来保护这些栈区域。\tactiveStackChans bool\t// parkingOnChan 表示 goroutine 即将在 chansend 或 chanrecv 上停车。\t// 用于标记栈缩小的不安全点。\tparkingOnChan atomic.Bool\traceignore int8 // 忽略竞态检测事件\ttracking bool // 是否跟踪此 G 以获取调度延迟统计\ttrackingSeq uint8 // 用于决定是否跟踪此 G\ttrackingStamp int64 // G 最后开始被跟踪的时间戳\trunnableTime int64 // 可运行时间，运行时清除，仅在跟踪时使用\tlockedm muintptr\tsig uint32\twritebuf []byte\tsigcode0 uintptr\tsigcode1 uintptr\tsigpc uintptr\tparentGoid uint64 // 创建此 goroutine 的 goroutine 的 goid\tgopc uintptr // 创建此 goroutine 的 go 语句的 pc\tancestors *[]ancestorInfo // 创建此 goroutine 的祖先 goroutine 的信息（仅在 debug.tracebackancestors 使用）\tstartpc uintptr // goroutine 函数的 pc\tracectx uintptr\twaiting *sudog // 此 g 正在等待的 sudog 结构（具有有效的 elem 指针）；按锁顺序\tcgoCtxt []uintptr // cgo 回溯上下文\tlabels unsafe.Pointer // 分析器标签\ttimer *timer // 缓存的计时器，用于 time.Sleep\tselectDone atomic.Uint32 // 我们是否参与 select 并且有人赢得了竞赛？\t// goroutineProfiled 指示当前 goroutine 的栈状态 // 是否已经被记录在进行中的 goroutine 性能分析中。\tgoroutineProfiled goroutineProfileStateHolder\t// 每个 G 的追踪状态。\ttrace gTraceState\t// 每个 G 的 GC 状态\t// gcAssistBytes 是此 G 的 GC 协助信用，以分配的字节为单位。\t// 如果为正，则 G 有信用分配 gcAssistBytes 字节而不协助。\t// 如果为负，则 G 必须通过执行扫描工作来纠正这一点。\t// 我们以字节为单位跟踪这一点，以便在 malloc 热路径中快速更新和检查债务。\t// 协助比率决定了这如何对应于扫描工作债务。\tgcAssistBytes int64 可以看到 g 结构字段非常多，这个结构体的设计反映了 Go 语言对并发和协程管理的底层机制，包括栈管理、调度、垃圾回收、异常处理等多个方面。通过这种抽象，Go 语言能够有效地管理成千上万的 goroutine，使得并发编程变得更加简单和高效。 这里我们只关注 GPM 模型相关的内容，需要重点关心以下几个字段： type g struct stack stack // 当前协程的协程栈\tm *m // 当前线程\tsched gobuf // 保存协程的运行现场\tatomicstatus atomic.Uint32 // 协程状态\tgoid uint64 // 协程ID 1.1 协程栈 stack 其中 stack 结构如下，它存储了协程栈的低地址和高地址。 type stack struct lo uintptr // 栈的低地址\thi uintptr // 栈的高地址 1.2 线程抽象 m 而 m 就是 Go 语言对操作系统线程的抽象，这不是实际的线程，这只是 Go 语言对线程相关信息的抽象，以方便更好地调度协程。 type m struct g0 *g // g0 协程，Go 中的主协程\tcurg *g // 现在正在运行的协程\tid int64 // 线程ID\tmOS // 当前操作系统对线程的额外描述信息\t... m 结构体包含了许多字段，这些字段涉及到线程管理、调度、信号处理、系统调用、锁管理等多个方面。这个结构体是 Go 并发模型的核心部分之一，它与 g（goroutine）和 p（processor）结构体一起，构成了 Go 的调度系统的基础。通过这种设计，Go 能够有效地在多个操作系统线程之间调度成千上万的 goroutine，实现高效的并发执行。 1.3 协程上下文 gobuf gobuf 结构体在 Go 语言的运行时系统中用于保存 Goroutine 的执行上下文，特别是在调度和系统调用中。这个结构体保存了足够的信息以便在 Goroutine 被暂停后能够恢复执行。 下面是对 gobuf 结构体中各个字段的解释： type gobuf struct // sp, pc 和 g 的偏移量是已知的（在 libmach 中硬编码）。\t//\t// ctxt 在 GC 方面比较特殊：它可能是一个堆分配的 funcval，\t// 因此 GC 需要跟踪它，但它需要在汇编中设置和清除，\t// 在那里实现写屏障比较困难。然而，ctxt 实际上是一个保存的、活跃的寄存器，\t// 我们只在真实寄存器和 gobuf 之间交换它。因此，我们在栈扫描期间将其视为根，\t// 这意味着保存和恢复它的汇编不需要写屏障。它仍然被类型化为指针，\t// 以便任何其他从 Go 进行的写操作都会获得写屏障。\tsp uintptr // 栈指针\tpc uintptr // 程序计数器\tg guintptr // 指向当前 goroutine 的指针\tctxt unsafe.Pointer // 上下文，用于保存额外的状态或信息\tret uintptr // 用于保存函数返回值\tlr uintptr // 链接寄存器（在某些架构中用于函数调用）\tbp uintptr // 基指针（在启用帧指针的架构中使用） 我们重点需要关注 2 个字段： sp：栈指针，表示当前协程运行到栈中的哪个位置了。 pc：程序计数器，表示当前协程运行到哪一行代码了。 1.4 协程状态 atomicstatus 我记得在 Go1.16 版本中，这个字段的类型还是 uint32： atomicstatus uint32 现在 Go1.21 版本中，已经用了原子操作来减少并发冲突了： atomicstatus atomic.Uint32 可以看到 Go 的底层也是随着版本更新不断优化中的。 runtime2.go 定义了 G 的各种状态，如： _Gidle (0): 表示 G 刚刚被分配，尚未初始化。 _Grunnable (1): 表示 G 在运行队列上。它当前没有执行用户代码。栈不被该 goroutine 拥有。 … 后面我们会给出 G 状态的流转图。 1.5 举个例子 假设我们现在有以下 Go 代码：main() 调用 do1()，do1() 调用 do2()，do2() 调用 do3()。 func do3() fmt.Println(here is do3)func do2() do3() //\t---------------func do1() do2()func main() do1() 那么当这段程序运行到第 6 行的时候，它的底层结构大概如下图所示： 至于为什么这里有个 goexit()，其实就是为了可以跳回到 g0 协程，后面我们会具体分析到。 2. P 的底层结构 P 的本质是 runtime2.go 里面定义的 p 结构体： type p struct id int32 // P 的唯一标识符 status uint32 // P 的状态，如 pidle/prunning/... link puintptr // P 链接 schedtick uint32 // 每次调度器调用时递增 syscalltick uint32 // 每次系统调用时递增 sysmontick sysmontick // sysmon 观察到的最后一个 tick m muintptr // 关联的 M 的反向链接（如果空闲则为 nil） mcache *mcache // M 缓存 pcache pageCache // 页面缓存 raceprocctx uintptr // 用于竞态检测的上下文 // 延迟结构体池 deferpool []*_defer deferpoolbuf [32]*_defer // Goroutine ID 缓存，减少对 runtime·sched.goidgen 的访问 goidcache uint64 goidcacheend uint64 // 可运行 goroutine 队列，无锁访问 runqhead uint32 runqtail uint32 runq [256]guintptr runnext guintptr // 下一个要运行的 G // 空闲 G 的列表（状态 == Gdead） gFree struct gList n int32 // sudog 缓存 sudogcache []*sudog sudogbuf [128]*sudog // 堆上 mspan 对象的缓存 mspancache struct len int buf [128]*mspan // pinner 对象的缓存 pinnerCache *pinner // P 状态跟踪 trace pTraceState // 每个 P 的持久分配，避免互斥 palloc persistentAlloc // 定时器相关字段 timer0When atomic.Int64 timerModifiedEarliest atomic.Int64 timersLock mutex timers []*timer numTimers atomic.Uint32 deletedTimers atomic.Uint32 timerRaceCtx uintptr // GC 相关字段 gcAssistTime int64 gcFractionalMarkTime int64 gcw gcWork wbBuf wbBuf // 指示是否在下一个安全点运行特定的函数 runSafePointFn uint32 // 指示当前 P 是否正在写入任何统计数据。 // 偶数时表示没有写入，奇数时表示正在写入。 statsSeq atomic.Uint32 // 指示当前的 P 应该尽快进入调度器，无论其上运行的是哪个 G。 // 这是实现抢占式调度的一部分，允许调度器在必要时中断长时间运行的 goroutine， // 以便其他 goroutine 有机会运行。 preempt bool // 记录页面分配、释放和清理跟踪信息的缓冲区。 pageTraceBuf pageTraceBuf p 结构体在 Go 语言的运行时系统中代表了一个处理器（processor），它是调度器的核心组成部分。每个 p 负责管理一组 goroutine 的运行。这个结构体包含了许多字段，涉及到 goroutine 的调度、内存分配、垃圾回收和其他系统级别的操作。 我们重点关注以下几个字段： type p struct m muintptr // 当前负责的线程 // 本地可运行的协程的队列，可无锁访问\trunqhead uint32 // 队头\trunqtail uint32 // 队尾\trunq [256]guintptr // 长度为 256\trunnext guintptr // 下一个可用的协程的指针 // 抢占标识，指示当前的 P 应该尽快进入调度器，无论其上运行的是哪个 G。 preempt bool 3. Goroutine 的创建 Go 并发能力的优秀之处，就在于它启动一个新的协程实在是太方便了： go func() ... () 那么底层究竟做了什么呢？ 3.1 newproc() Goroutine 通过 proc.go 中的 newproc() 创建： func newproc(fn *funcval) gp := getg() pc := getcallerpc() systemstack(func() newg := newproc1(fn, gp, pc) pp := getg().m.p.ptr() runqput(pp, newg, true) if mainStarted wakep() ) 获取当前 goroutine 和调用者 PC: getg() 获取当前正在执行的 goroutine，getcallerpc() 获取调用者的程序计数器地址。 在系统栈上执行 newproc1: systemstack 确保 newproc1 在系统栈上执行，而不是当前 goroutine 的栈。这是因为新的 goroutine 可能需要更多的栈空间。 创建新的 goroutine: newproc1 被调用来实际创建新的 goroutine。 将新的 goroutine 放入运行队列: runqput 将新创建的 goroutine 放入运行队列。 唤醒处理器: 如果主函数已经开始执行，wakep 用于唤醒一个空闲的 P 来运行新的 goroutine。 3.2 newproc1() func newproc1(fn *funcval, callergp *g, callerpc uintptr) *g // ... (省略了错误检查和获取 M 的代码) // 尝试从 P 的空闲列表获取一个 G，如果没有则创建一个新的 newg := gfget(pp) if newg == nil newg = malg(stackMin) casgstatus(newg, _Gidle, _Gdead) allgadd(newg) // 设置新 G 的栈 totalSize := uintptr(4*goarch.PtrSize + sys.MinFrameSize) totalSize = alignUp(totalSize, sys.StackAlign) sp := newg.stack.hi - totalSize spArg := sp // 清空并设置新 G 的调度器相关字段 memclrNoHeapPointers(unsafe.Pointer(newg.sched), unsafe.Sizeof(newg.sched)) newg.sched.sp = sp newg.stktopsp = sp newg.sched.pc = abi.FuncPCABI0(goexit) + sys.PCQuantum newg.sched.g = guintptr(unsafe.Pointer(newg)) // 设置新 G 的其他字段 gostartcallfn(newg.sched, fn) newg.parentGoid = callergp.goid newg.gopc = callerpc newg.startpc = fn.fn // ... (省略了跟踪和调试相关的代码) casgstatus(newg, _Gdead, _Grunnable) return newg 创建或获取一个新的 goroutine: gfget 尝试从 P 的空闲列表中获取一个 goroutine，如果没有可用的，则通过 malg 分配一个新的。 初始化 goroutine 的栈和调度器: 设置新 goroutine 的栈、程序计数器、调用函数等。这里有个非常核心的点 newg.sched.pc = abi.FuncPCABI0(goexit) + sys.PCQuantum，我们前面留了个疑问，协程栈顶的 goexit 是哪里来的，就是这里来的。这里设置新 goroutine 的程序计数器（pc）指向 goexit 函数。goexit 是每个 goroutine 在退出时必须调用的函数，用于执行清理工作并切换到 g0 栈。 设置父 goroutine ID 和创建点: 记录创建这个新 goroutine 的父 goroutine 的 ID 和 go 语句的位置。 更改 goroutine 状态: 将新 goroutine 的状态从 _Gdead 改为 _Grunnable，使其准备好被调度。 返回新的 goroutine: 函数返回新创建的 goroutine。 3.3 runqput() // runqput tries to put g on the local runnable queue.// If next is false, runqput adds g to the tail of the runnable queue.// If next is true, runqput puts g in the pp.runnext slot.// If the run queue is full, runnext puts g on the global queue.// Executed only by the owner P.func runqput(pp *p, gp *g, next bool) if randomizeScheduler next fastrandn(2) == 0 next = false if next retryNext: oldnext := pp.runnext if !pp.runnext.cas(oldnext, guintptr(unsafe.Pointer(gp))) goto retryNext if oldnext == 0 return gp = oldnext.ptr()\tretry:\th := atomic.LoadAcq(pp.runqhead) t := pp.runqtail\tif t-h uint32(len(pp.runq)) pp.runq[t%uint32(len(pp.runq))].set(gp) atomic.StoreRel(pp.runqtail, t+1) return if runqputslow(pp, gp, h, t) return goto retry 随机调度器：如果启用了调度器的随机化（randomizeScheduler），并且 next 为 true（newproc 调用的时候永远都是传的 true），则有一半的概率将 next 设置为 false。这有助于防止调度器的行为过于可预测。 处理 runnext 槽：如果 next 为 true，函数尝试将 gp 放入 pp.runnext 槽。如果该槽已被占用，则将原有的 goroutine 移动到常规运行队列，并重试将新的 gp 放入 runnext。 放入本地运行队列：如果 next 为 false 或 runnext 槽已满，函数尝试将 gp 放入本地运行队列的尾部。如果队列未满，gp 将被成功添加。 处理队列满的情况：如果本地运行队列已满，runqputslow 被调用，尝试将 gp 连同自己队列中一半的 g 放入全局运行队列。如果这也失败了，函数会重试将 gp 放入本地队列。 原子操作：函数使用原子操作来加载和存储队列头（runqhead）和尾（runqtail）指针，以确保多线程环境下的数据一致性和线程安全。 3.4 runqputslow() runqputslow 函数处理本地运行队列满的情况，将 goroutine 批量转移到全局队列。这个函数通过原子操作和锁来确保操作的原子性和线程安全。随机化调度器的使用增加了调度的随机性和公平性。 // Put g and a batch of work from local runnable queue on global queue.// Executed only by the owner P.func runqputslow(pp *p, gp *g, h, t uint32) bool // 从 pp 的本地队列中获取一半的 goroutine var batch [len(pp.runq)/2 + 1]*g\tn := t - h\tn = n / 2\tif n != uint32(len(pp.runq)/2) throw(runqputslow: queue is not full) for i := uint32(0); i n; i++ batch[i] = pp.runq[(h+i)%uint32(len(pp.runq))].ptr() if !atomic.CasRel(pp.runqhead, h, h+n) return false batch[n] = gp // 随机打乱 goroutine 的顺序，以增加调度的随机性\tif randomizeScheduler for i := uint32(1); i = n; i++ j := fastrandn(i + 1) batch[i], batch[j] = batch[j], batch[i] // 串成队列\tfor i := uint32(0); i n; i++ batch[i].schedlink.set(batch[i+1]) var q gQueue\tq.head.set(batch[0])\tq.tail.set(batch[n])\t// 放入全局队列中\tlock(sched.lock)\tglobrunqputbatch(q, int32(n+1))\tunlock(sched.lock)\treturn true 创建批处理数组：函数首先创建一个 batch 数组，用于存储从本地队列中取出的 goroutine。 从本地队列中获取一批 goroutine：函数计算出要从本地队列中取出多少个 goroutine（通常是队列长度的一半），并将它们添加到 batch 数组中。 原子操作更新队列头部：使用原子操作 atomic.CasRel 更新本地运行队列的头部索引，这是一个释放（release）操作，确保之前的读取操作完成。 将当前 goroutine 添加到批处理中：将传入的 gp 添加到 batch 数组的末尾。 随机化调度器：如果启用了随机调度器，函数会随机打乱 batch 数组中的 goroutine 顺序，以增加调度的随机性。 链接 goroutine：将 batch 数组中的 goroutine 链接起来，形成一个队列。 准备全局队列：创建一个 gQueue 结构，并设置其头部和尾部指向 batch 数组中的第一个和最后一个 goroutine。 将批处理放入全局队列：加锁访问全局调度器的锁，然后将整个 batch 队列放入全局运行队列。 4. 调度过程 schedule() Go 的调度器核心执行逻辑都在 proc.go 的 schedule() 函数中。我们先不探讨过多的细节，我们先把整个大体脉络理清楚再说。 简化后的 schedule() 如下： func schedule() // 获取当前正在执行的 M\tmp := getg().m ... // 查找一个可运行的 G，会阻塞住直到返回。\tgp, inheritTime, tryWakeP := findRunnable() ...\t// 执行 g\texecute(gp, inheritTime) execute() 执行 g，它简化后如下： func execute(gp *g, inheritTime bool) mp := getg().m\t..\tgogo(gp.sched) 它调用了 gogo()： func gogo(buf *gobuf) 一般这种格式说明函数是用汇编实现的，我们在 Goland 上可以双击 shift 然后搜索 runtime·gogo： 不同的平台有不同的实现，但是核心逻辑都是一样的， 它直接操作处理器的寄存器和栈，以实现从一个 goroutine 切换到另一个 goroutine 的功能。 我们后面的发内心会发现 goexit() 最终会调用 schedule()。 这就串起来了，Go 程序启动后会创建 m0 和 g0，所以第一个schedule() 是 g0 调用的，最后通过 gogo 切换到用户协程 g 上面执行业务方法，完事后 g 通过 goexit 回到 schedule()，以此循环反复下去。 现在我们可以来总结一下 GPM 调度循环的过程，大概如下图表示： 下面我们再对这个过程中的关键函数进行细致分析： schedule()：调度入口。 findRunnable()：寻找可执行的 G。 execute()：执行 G。 gogo()：切换协程栈 g0 到 g。 goexit()：退出 g 协程，切换回 g0 栈。 4.1 schedule() func schedule() // 获取当前正在执行的 M\tmp := getg().m // 有锁的话抛出异常，避免该情况下调度出现死锁或其他问题\tif mp.locks != 0 throw(schedule: holding locks) // M 被锁定了特定的 G，这个时候直接执行这个锁定的 G。\tif mp.lockedg != 0 stoplockedm() execute(mp.lockedg.ptr(), false) // Never returns. // CGO 调用需要 g0 栈，所以这个时候不继续调度了，抛出异常。\tif mp.incgo throw(schedule: in cgo)\ttop:\tpp := mp.p.ptr()\tpp.preempt = false\t// 安全点检查：如果当前 M 在自旋的话，应该是没有可执行 G 的。\tif mp.spinning (pp.runnext != 0 || pp.runqhead != pp.runqtail) throw(schedule: spinning with local work) // 查找一个可运行的 G，会阻塞住直到返回。\tgp, inheritTime, tryWakeP := findRunnable() // 调试的时候系统会处于“冻结”状态， // 这里故意通过两次 lock 引入死锁使当前 M 陷入无限等待， // 以在调试时保持当前的调度器和运行时状态不变。\tif debug.dontfreezetheworld 0 freezing.Load() lock(deadlock) lock(deadlock) // 如果当前 M 之前是自旋的，但是现在要准备执行 G 了，那就不是自旋了。\tif mp.spinning resetspinning() // 当用户级调度被禁用时，采用双重检查后如果确实被禁用了， // 那么就把当前 g 放在 sched.disable.runnable 列表中， // 等待调度重启启用时再处理。 // 在 gc 的时候会出现这种情况： // gcStart() - schedEnableUser(false) // gcMarkDone() - schedEnableUser(true)\tif sched.disable.user !schedEnabled(gp) lock(sched.lock) if schedEnabled(gp) unlock(sched.lock) else sched.disable.runnable.pushBack(gp) sched.disable.n++ unlock(sched.lock) goto top // 检查是否需要唤醒一个 P。 // 如果返回的 g 比较特殊，比如要负责 gc，那么这个值会是 true。\tif tryWakeP wakep() // 如果 g 已经绑定了 M，则直接启动该 M 去执行 g。\tif gp.lockedm != 0 startlockedm(gp) goto top // 执行 g\texecute(gp, inheritTime) schedule() 函数是 Go 调度器的核心，负责管理 goroutine 的执行。它包括多个步骤，如检查当前 M 的状态，处理特殊情况（如 goroutine 被锁定到特定的 M，或者 M 正在执行 CGO 调用），以及选择和执行可运行的 goroutine。 4.2 findRunnable() // Finds a runnable goroutine to execute.// Tries to steal from other Ps, get g from local or global queue, poll network.// tryWakeP indicates that the returned goroutine is not normal (GC worker, trace reader) so the caller should try to wake a P.func findRunnable() (gp *g, inheritTime, tryWakeP bool) 通过注释就可以知道这个函数的作用：寻找一个可执行的 goroutine： 尝试从其他 P 窃取 g、从本地获取 g、从全局队列获取 g、从网络轮询器获取 g； 如果是一个特殊的 g，如要负责 gc 或 trace，那么会将 tryWakeP 置为 true，表示调度器需要尝试唤醒或启动一个新的 P 来运行这个 g，以确保了即使在系统负载较低时，这些特殊的g 也能得到及时处理。 我们只关心它的核心部分： func findRunnable() (gp *g, inheritTime, tryWakeP bool) // 获取当前 M\tmp := getg().mtop: // 获取 M 绑定的 P\tpp := mp.p.ptr()\t// 1. 每 61 次循环调度，就会去全局队列中获取一个 g 来执行\tif pp.schedtick%61 == 0 sched.runqsize 0 lock(sched.lock) gp := globrunqget(pp, 1) unlock(sched.lock) if gp != nil return gp, false, false // 2. 从本地队列中获取 g\tif gp, inheritTime := runqget(pp); gp != nil return gp, inheritTime, false // 3. 从全局队列中获取 g\tif sched.runqsize != 0 lock(sched.lock) gp := globrunqget(pp, 0) unlock(sched.lock) if gp != nil return gp, false, false // 4. 从网络轮询器中获取 g\tif netpollinited() netpollWaiters.Load() 0 sched.lastpoll.Load() != 0 if list := netpoll(0); !list.empty() // non-blocking gp := list.pop() injectglist(list) casgstatus(gp, _Gwaiting, _Grunnable) if traceEnabled() traceGoUnpark(gp, 0) return gp, false, false // 5. 自旋，从其他 P 窃取 g // mp.spinning 这个条件检查当前 M（操作系统线程）是否应该进入自旋状态。 // 自旋状态意味着 M 会积极地寻找工作，而不是休眠。 // 2*sched.nmspinning.Load() gomaxprocs-sched.npidle.Load() // 这个条件确保系统中自旋的 M 的数量不会超过一定比例。 // 这是为了防止在低并发情况下过多的 CPU 使用。\tif mp.spinning || 2*sched.nmspinning.Load() gomaxprocs-sched.npidle.Load() if !mp.spinning mp.becomeSpinning() gp, inheritTime, tnow, w, newWork := stealWork(now) if gp != nil return gp, inheritTime, false if newWork goto top now = tnow if w != 0 (pollUntil == 0 || w pollUntil) pollUntil = w ...\tgoto top 这个过程涉及到几个重要的函数： globrunqget()：从全局队列中寻找可运行的 G。 runqget()：从本地队列中寻找可运行的 G。 netpoll()：寻找可以运行的网络协程。 stealWork()：从其他 P 窃取可运行的 G。 4.3 globrunqget() func globrunqget(pp *p, max int32) *g // 抢全局列表的锁 assertLockHeld(sched.lock) // 如果为空则直接返回 if sched.runqsize == 0 return nil // 确定 n 的大小，即要从全局队列中获取的 g 的个数。 // 这里会结合入参 max 对边界值进行判断，以获得一个合理的 n。 // 一次性最多拿 len(pp.runq)/2 个 g。 n := sched.runqsize/gomaxprocs + 1 if n sched.runqsize n = sched.runqsize if max 0 n max n = max if n int32(len(pp.runq))/2 n = int32(len(pp.runq)) / 2 sched.runqsize -= n // 通过 pop() 从全局队列中弹出 g gp := sched.runq.pop() n-- for ; n 0; n-- gp1 := sched.runq.pop() // 将 g 放入 pp 的本地队列中 // runqput 在前面创建协程的地方已经介绍过了，这里不赘述。 runqput(pp, gp1, false) return gp 4.4 runqget() func runqget(pp *p) (gp *g, inheritTime bool) // runnext 的 g 会优先执行\tnext := pp.runnext\tif next != 0 pp.runnext.cas(next, 0) return next.ptr(), true for // 原子操作获取队头指针 h := atomic.LoadAcq(pp.runqhead) t := pp.runqtail if t == h return nil, false // 从队头获取 g，并通过原子操作更新队头（即抢这个 g） gp := pp.runq[h%uint32(len(pp.runq))].ptr() if atomic.CasRel(pp.runqhead, h, h+1) return gp, false runqget() 函数用于从本地运行队列中获取一个可运行的 goroutine。这个函数只能由拥有该队列的处理器（P）执行。下面是对这个函数的详细解释： 1. 检查 runnext： runnext 是一个特殊的字段，用于存储下一个要运行的 goroutine。如果 runnext 非零，并且能成功通过原子操作（CAS）将其设置为零，则直接返回这个 goroutine。 如果成功获取 runnext 指向的 goroutine，inheritTime 被设置为 true，表示这个 goroutine 应该继承当前时间片的剩余时间。 如果没成功，意味着 runnext 的这个 g 已经被其他 P 给抢了，因为我们可以发现本 P 只可能将其设置为 0，只有其他 P 才会将其设置以为非 0。 2. 从本地队列中获取 goroutine： 使用原子操作加载 runqhead（队列头指针），runqtail（队列尾指针）。 如果 runqhead 等于 runqtail，表示队列为空，返回 nil。 否则，从队列中获取 runqhead 指向的 goroutine，并尝试通过原子操作（CAS）更新 runqhead。 如果更新成功，返回获取到的 goroutine，inheritTime 被设置为 false，表示这个 goroutine 应该开始一个新的时间片。 两个问题： 1. 为什么获取 runqhead 需要上锁，获取 runqtail 就不需要？ 单一生产者：每个本地运行队列只有一个生产者，即与之关联的当前 P。只有这个 P 可以向队列尾部添加新的 goroutine。由于不存在多个生产者的并发写入问题，因此不需要锁来保护队尾。 2. inheritTime 有什么用？ inheritTime 的主要作用是决定新调度的 goroutine 是否应该立即开始一个新的时间片，或者继续使用当前时间片的剩余部分。这在以下两种情况下尤为重要： 继承时间片 (inheritTime == true)：当 runqget 从 runnext 字段获取 goroutine 时，这个 goroutine 被认为是特别优先的，因此它继承了当前时间片的剩余时间。这通常发生在 goroutine 通过特定的同步机制（如通道操作）被明确唤醒时。 开始新的时间片 (inheritTime == false)：当 runqget 从本地运行队列中正常获取 goroutine 时，这个 goroutine 将开始一个全新的时间片。这确保了调度的公平性，使得每个 goroutine 都有机会在给定的时间片内运行。 4.5 netpoll() netpoll() 函数是 Go 语言运行时网络轮询机制的一部分，用于检查网络连接是否准备好进行非阻塞 I/O 操作。这个函数返回一组已经变为可运行状态的 goroutine，这些 goroutine 之前可能因等待网络 I/O 而被挂起。 这里涉及到 Go 语言网络编程原理，在本文中不细究，就简单带过了。 func netpoll(delay int64) gList // 检查轮询器是否初始化。\tif kq == -1 return gList // 设置轮询超时。\tvar tp *timespec\tvar ts timespec\tif delay 0 tp = nil else if delay == 0 tp = ts else ts.setNsec(delay) if ts.tv_sec 1e6 ts.tv_sec = 1e6 tp = ts // 使用 kevent 进行轮询操作，结果放在 events 中。\tvar events [64]keventtretry:\tn := kevent(kq, nil, 0, events[0], int32(len(events)), tp)\tif n 0 if n != -_EINTR println(runtime: kevent on fd, kq, failed with, -n) throw(runtime: netpoll failed) if delay 0 return gList goto retry // 遍历 events 处理轮询事件。\tvar toRun gList\tfor i := 0; i int(n); i++ ev := events[i] // netpollBreakRd 用于唤醒轮询，即唤醒等待中的 goroutine。 if uintptr(ev.ident) == netpollBreakRd if ev.filter != _EVFILT_READ println(runtime: netpoll: break fd ready for, ev.filter) throw(runtime: netpoll: break fd ready for something unexpected) if delay != 0 var tmp [16]byte read(int32(netpollBreakRd), noescape(unsafe.Pointer(tmp[0])), int32(len(tmp))) netpollWakeSig.Store(0) continue // 根据轮询事件的类型（读或写），唤醒相应等待网络 I/O 的 groutine。 var mode int32 switch ev.filter case _EVFILT_READ: mode += r if ev.flags_EV_EOF != 0 mode += w case _EVFILT_WRITE: mode += w if mode != 0 var pd *pollDesc var tag uintptr if goarch.PtrSize == 4 pd = (*pollDesc)(unsafe.Pointer(ev.udata)) tag = 0 else tp := taggedPointer(uintptr(unsafe.Pointer(ev.udata))) pd = (*pollDesc)(tp.pointer()) tag = tp.tag() if pd.fdseq.Load() != tag continue pd.setEventErr(ev.flags == _EV_ERROR, tag) // 标记 goroutine 可执行。 netpollready(toRun, pd, mode) // 返回可运行的 goroutine 列表。\treturn toRun 4.6 stealWork() stealWork() 函数用于尝试从其他处理器（P）窃取可运行的 goroutine 或定时器。 func stealWork(now int64) (gp *g, inheritTime bool, rnow, pollUntil int64, newWork bool) // 获取当前 M 绑定的 P。\tpp := getg().m.p.ptr()\tranTimer := false // 尝试 4 次。\tconst stealTries = 4\tfor i := 0; i stealTries; i++ // 前 3 次尝试窃取 g。 // 第 4 次尝试窃取 timer，并且尝试获取其他 P 的 runnext 中的 g。 stealTimersOrRunNextG := i == stealTries-1 // 随机选一个 P。 for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() // 如果系统正在 GC，则可以直接返回 true，因为可能要负责 gc 了，有事干了。 if sched.gcwaiting.Load() return nil, false, now, pollUntil, true // 获取选中的 P，如果是当前 P 则直接 continue，重试。 p2 := allp[enum.position()] if pp == p2 continue // 第 4 次尝试去窃取 p2 的 timer。 if stealTimersOrRunNextG timerpMask.read(enum.position()) // 检查并可能执行 timer。 tnow, w, ran := checkTimers(p2, now) now = tnow if w != 0 (pollUntil == 0 || w pollUntil) pollUntil = w // 如果执行了 timer，则检查本地队列是否有 g 可以运行， // 因为 timer 会唤醒被挂起的 g。 if ran if gp, inheritTime := runqget(pp); gp != nil return gp, inheritTime, now, pollUntil, ranTimer ranTimer = true // 前 3 次尝试或者第 4 次尝试没有窃取到 timer 的时候， // 就从其他非空闲 P 的本地队列中尝试窃取 g。 if !idlepMask.read(enum.position()) // 如果 stealTimersOrRunNextG 为 true， // 那么会在窃取的时候，尝试窃取 p2 的 runnext。 if gp := runqsteal(pp, p2, stealTimersOrRunNextG); gp != nil return gp, false, now, pollUntil, ranTimer return nil, false, now, pollUntil, ranTimer 阅读源码的好处这就体现了，所有人都告诉我们 P 找不到可运行 G 的时候就会去窃取其他 P 的 G，但没人告诉我们，在这个过程还可能会去窃取其他 P 的 timer 和 runnext。 所谓 timer，即定时器，用于在指定的时间后执行某些操作。这些操作通常包括唤醒等待特定时间的 goroutine，或执行与时间相关的任务。定时器在 Go 的并发模型中扮演着重要的角色，特别是在涉及到时间延迟或周期性任务的场景中。在调度器层面，定时器的管理对于确保及时响应时间相关的事件和维持高效的调度至关重要。通过合理地处理定时器事件，Go 能够在保持高并发性的同时，有效地管理时间延迟和周期性任务。 在 Go 语言的调度器中，跨 P 的定时器窃取是一种优化机制，它有 2 个好处： 保持处理器活跃：当一个 P 没有足够的本地工作时，它可以尝试从其他 P 窃取定时器任务。这样做可以保持该 P 活跃，避免它进入休眠状态，从而提高整体系统的效率。 平衡系统负载：在多核系统中，不同的 P 可能会有不同的负载。跨 P 的定时器窃取有助于在 P 之间平衡负载，特别是在一些 P 非常忙碌而其他 P 相对空闲的情况下。 好的，回过头来，为什么我们会说窃取的时候会从队头窃取呢？为什么是窃取 p2 一半的 g 呢？这个过程就在 runqsteal() 中： func runqsteal(pp, p2 *p, stealRunNextG bool) *g t := pp.runqtail // 从 p2 中获取 n 个 g。\tn := runqgrab(p2, pp.runq, t, stealRunNextG)\tif n == 0 return nil // 返回第 1 个 g，因为它可以直接执行了。\tn--\tgp := pp.runq[(t+n)%uint32(len(pp.runq))].ptr()\tif n == 0 return gp // 如果还有剩下的 g，那么就加入到本地队列中。 // 这里可以看到是从队头加入的，所以需要使用原子操作获取队头。\th := atomic.LoadAcq(pp.runqhead)\tif t-h+n = uint32(len(pp.runq)) throw(runqsteal: runq overflow) atomic.StoreRel(pp.runqtail, t+n)\treturn gp runqgrab() 是窃取 n 个 g 的过程： func runqgrab(pp *p, batch *[256]guintptr, batchHead uint32, stealRunNextG bool) uint32 // 使用无限循环来尝试窃取工作，直到成功或确定没有可窃取的工作。\tfor h := atomic.LoadAcq(pp.runqhead) t := atomic.LoadAcq(pp.runqtail) n := t - h // 这里可以看到，要窃取的个数，就是 pp 本地队列中 g 个数的一半 n = n - n/2 // 如果 n 为 0，且 stealRunNextG == true， // 那么就尝试窃取 pp 的 runnext 中的 g。 if n == 0 if stealRunNextG if next := pp.runnext; next != 0 if !pp.runnext.cas(next, 0) continue batch[batchHead%uint32(len(batch))] = next return 1 return 0 // 如果 n 不为队列长度的一半，则说明队列发生了变化， // 这个时候重新尝试窃取。 if n uint32(len(pp.runq)/2) continue // 将要窃取的 g 从 pp.runq 中转移到 batch 中。 for i := uint32(0); i n; i++ g := pp.runq[(h+i)%uint32(len(pp.runq))] batch[(batchHead+i)%uint32(len(batch))] = g // 使用原子操作尝试更新 pp 的队列头部，即将 g 从 pp.runq 中移除。 if atomic.CasRel(pp.runqhead, h, h+n) return n findRunnable() 的全部过程我们总算是梳理完了，这个过程确实非常精彩，Go 调度器在提高调度性能、确保调度的公平性、平衡系统负载、降低同步开销、减少资源再分配等方面都做了很多的努力，这才让 Go 语言的并发又强大又易用。 下面是对 findRunnable() 一个简单的总结： 4.7 execute() findRunnable() 之后就是 execute()，它的核心过程如下（有删减）： func execute(gp *g, inheritTime bool) mp := getg().m\t// 将 g0 d 线程信息复制到即将要调用的协程 gp 中。\tmp.curg = gp\tgp.m = mp // 修改 gp 的状态为 _Grunning，即运行中。\tcasgstatus(gp, _Grunnable, _Grunning)\tgp.waitsince = 0 // 标记为非抢占\tgp.preempt = false // 用于栈保护，检测栈溢出\tgp.stackguard0 = gp.stack.lo + stackGuard // gogo 会完成 g0 到 g 的协程栈的切换，并从 gp.sched 开始执行。 // sched 字段我们前面介绍过，它是 gobuf 结构体，存储了 sp 和 pc。\tgogo(gp.sched) 所以 execute() 的工作非常简单，其实就是将 g0 的线程信息复制到 gp 上，并修改状态和一些元数据，核心部分其实在 gogo() 中。 4.8 gogo() 前面我们说过，gogo() 会完成 g0 栈到 g 栈的切换，且在不同平台下有不同的视线，这里我们以 asm_arm64.s 为代表来看一下 gogo() 的汇编实现： TEXT runtime·gogo(SB), NOSPLIT|NOFRAME, $0-8\tMOVD\tbuf+0(FP), R5\tMOVD\tgobuf_g(R5), R6\tMOVD\t0(R6), R4\t// make sure g != nil\tB\tgogo(SB)TEXT gogo(SB), NOSPLIT|NOFRAME, $0\tMOVD\tR6, g\tBL\truntime·save_g(SB)\tMOVD\tgobuf_sp(R5), R0\tMOVD\tR0, RSP\tMOVD\tgobuf_bp(R5), R29\tMOVD\tgobuf_lr(R5), LR\tMOVD\tgobuf_ret(R5), R0\tMOVD\tgobuf_ctxt(R5), R26\tMOVD\t$0, gobuf_sp(R5)\tMOVD\t$0, gobuf_bp(R5)\tMOVD\t$0, gobuf_ret(R5)\tMOVD\t$0, gobuf_lr(R5)\tMOVD\t$0, gobuf_ctxt(R5)\tCMP\tZR, ZR // set condition codes for == test, needed by stack split\tMOVD\tgobuf_pc(R5), R6\tB\t(R6) 具体过程如下： runtime·gogo 函数：这个函数用于设置新的 goroutine 上下文。它接收一个指向 gobuf 结构的指针（buf+0(FP)），该结构包含了 goroutine 的上下文信息。 加载 gobuf 并检查 g：加载 gobuf 结构，并检查 g 是否为 nil。 跳转到 gogo：执行无条件跳转到 gogo 函数。 gogo 函数：这个函数实际上完成了上下文切换。 设置当前 goroutine：将 R6 寄存器中的值（新的 goroutine）设置为当前 goroutine。 保存当前 goroutine：调用 runtime·save_g 保存当前 goroutine 的状态。 恢复栈指针和其他寄存器：从 gobuf 结构中恢复栈指针（RSP）、基指针（R29）、链接寄存器（LR）、返回值（R0）和上下文（R26）。 清空 gobuf 结构：将 gobuf 结构中的字段清零。 准备跳转到新的程序计数器位置：从 gobuf 中加载新的程序计数器地址（gobuf_pc(R5)）到 R6。 跳转执行：通过 B (R6) 跳转到新的程序计数器地址，继续执行新 goroutine 的代码。 这段汇编代码是 Go 运行时中处理 goroutine 上下文切换的关键部分。它直接操作处理器的寄存器和栈，以实现从一个 goroutine 切换到另一个 goroutine 的功能。 在 execute() 中是这么调用 gogo() 的： gogo(gp.sched) 所以完成栈的切换后会从 gp.sched 开始，执行代码，前面我们介绍过 sched 是一个 gobuf 结构体： type gobuf struct sp uintptr\tpc uintptr\tg guintptr\tctxt unsafe.Pointer\tret uintptr\tlr uintptr\tbp uintptr 所以会从 pc 处开始执行业务代码，前面在 newproc() 的时候，我们提过一行代码： newg.sched.pc = abi.FuncPCABI0(goexit) + sys.PCQuantum 这行代码的作用，是在协程创建的时候插入一个 goexit 函数的地址，因为这个时候 g 刚创建，所以其实就是往协程栈顶插入了 goexit 的地址。所以当 g 执行完业务代码后，当栈中元素不断弹出后，最终就会弹出 goexit 的地址，然后执行 goexit() 函数，退出当前 g，切换回 g0。 4.9 goexit() goexit 定义在 runtime/stubs.go 中： // goexit is the return stub at the top of every goroutine call stack.// Each goroutine stack is constructed as if goexit called the// goroutines entry point function, so that when the entry point// function returns, it will return to goexit, which will call goexit1// to perform the actual exit.//// This function must never be called directly. Call goexit1 instead.// gentraceback assumes that goexit terminates the stack. A direct// call on the stack will cause gentraceback to stop walking the stack// prematurely and if there is leftover state it may panic.func goexit(neverCallThisFunction) 通过注释我们可以得到 2 个信息： goexit 的位于每个 goroutine 调用栈的顶部。每个 goroutine 的栈被构造得好像 goexit 调用了 goroutine 的入口函数。这意味着当入口函数返回时，它实际上返回到 goexit。 不要直接调用 goexit，应该调用 goexit1。 goexit1 位于 runtime/proc.go 中： // Finishes execution of the current goroutine.func goexit1() if raceenabled racegoend() if traceEnabled() traceGoEnd() mcall(goexit0) 好吧，它调用了 goexit0，原来这才是真正的退出入口，它也位于 runtime/proc.go 中： func goexit0(gp *g) // 获取当前的 M 和 P\tmp := getg().m\tpp := mp.p.ptr() // 修改 gp 的状态为 _Gdead，标志它的终止\tcasgstatus(gp, _Grunning, _Gdead) // 标记 gc 的栈内存是可以进行 gc 扫描的\tgcController.addScannableStack(pp, -int64(gp.stack.hi-gp.stack.lo))\t// 如果 gp 是系统 goroutine，则将系统 goroutine 的计数减少 if isSystemGoroutine(gp, false) sched.ngsys.Add(-1) // 清理 gp 的状态\tgp.m = nil\tlocked := gp.lockedm != 0\tgp.lockedm = 0\tmp.lockedg = 0\tgp.preemptStop = false\tgp.paniconfault = false\tgp._defer = nil gp._panic = nil\tgp.writebuf = nil\tgp.waitreason = waitReasonZero\tgp.param = nil\tgp.labels = nil\tgp.timer = nil // 如果启用了垃圾回收（GC）并且 gp.gcAssistBytes 大于 0， // 则将辅助信用归还给全局池。这有助于更好地控制垃圾回收进程。\tif gcBlackenEnabled != 0 gp.gcAssistBytes 0 assistWorkPerByte := gcController.assistWorkPerByte.Load() scanCredit := int64(assistWorkPerByte * float64(gp.gcAssistBytes)) gcController.bgScanCredit.Add(scanCredit) gp.gcAssistBytes = 0 // 将当前 g 从 P 的运行队列中移除\tdropg() // WebAssembly 平台特殊处理\tif GOARCH == wasm gfput(pp, gp) schedule() // 将 gp 放回处理器的可用队列中，这样可以复用 g\tgfput(pp, gp) // 如果 goroutine 被绑定到当前线程上， // 那可能是在做系统调用，cgo 调用或其他特殊任务， // 那么就需要切到 g0，让 g0 来完成后面的调度。 if locked // 如果 goroutine 在终止前曾锁定当前线程， // 则根据不同的操作系统执行不同的处理。 // 在大多数操作系统上，会跳转到 mstart 函数，释放 P 并退出线程。 // 但在 Plan 9 操作系统上，会清除 lockedExt。 if GOOS != plan9 // See golang.org/issue/22227. gogo(mp.g0.sched) else mp.lockedExt = 0 // 继续调度 // 如果执行了 gogo，那就是 g0 在调度。 // 如果没有执行 gogo，那就是 gp 在调度。\tschedule() 到这里我们就完成了对 GPM 调度循环的全过程源码分析了，你可以回到 [4. 调度过程 schedule()](##4. 调度过程 schedule()) 看一下我总结的那张图，这回你应该会有更加深入的理解了。 5. 协程切换 如果要一个协程要一直到执行完毕才退出的话，那很可能会造成其他协程饥饿的问题。所以 Go 其实会在一些特殊的时机对协程进行切换，这个过程有抢占式调度，也有协作式的调度。 协程切换的时候，最核心的就是要保存当前协程的现场，以方便回到该协程的时候继续执行剩下的内容。大致过程如下： 有哪些时机会触发切换呢，这里我直接给出结论： 基于协作的抢占式调度 主动挂起：runtime.gopark() 系统调用结束时：exitsyscall() 函数跳转时：morestack() 基于信号的抢占式调度 信号调度：doSigPreempt() 5.1 主动挂起 runtime.gopack() 这个函数位于 runtime/proc.go 中： func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceReason traceBlockReason, traceskip int) if reason != waitReasonSleep checkTimeouts() mp := acquirem()\tgp := mp.curg\tstatus := readgstatus(gp)\tif status != _Grunning status != _Gscanrunning throw(gopark: bad g status) mp.waitlock = lock\tmp.waitunlockf = unlockf\tgp.waitreason = reason\tmp.waitTraceBlockReason = traceReason\tmp.waitTraceSkip = traceskip\treleasem(mp)\tmcall(park_m) gopark 函数的主要目的是使 G 进入休眠状态，等待被唤醒。 最后它调用了 mcall()： // mcall switches from the g to the g0 stack and invokes fn(g)// mcall 切换到 g0，并执行 fn。func mcall(fn func(*g)) 所以这里切换回 g0，并执行了 pack_m： func park_m(gp *g) ...\tschedule() pack_m() 其实就是调用了 schedule() 去进行下一轮调度，这就完成了协程的切换。 当协程被阻塞的时候，就会去调用 runtime.gopark() 主动让出 CPU，切回 g0，等待被唤醒，以此保证最大化利用 CPU 资源。比如以下几种情况： 休眠 channel 通道阻塞 网络 I/O 阻塞 因为执行垃圾回收而暂停 5.2 系统调用结束时 exitsyscall() Go 通过 entersyscall() 进行系统调用，完事后会执行 exitsyscall()，它也位于 runtime/proc.go 中： func exitsyscall() ...\tmcall(exitsyscall0) 其实它最终也是调用 mcall() 切换到 g0， 我们不难猜出，它这里让 g0 去执行 exitsyscall0 函数，做完系统调用的善后后，肯定还是会执行 schedule() 函数进行协程调度。 func exitsyscall0(gp *g) ...\tschedule() 5.3 函数跳转时 morestack() 因为函数跳转意味着“压栈”，函数跳转时都会调用这个方法，它的本意在于检查当前协程栈空间是否有足够内存，如果不够就要扩大该栈空间。 为了让每个协程都有执行的机会，并且最大化利用 CPU 资源，Go 语言在初始化时会启动一个特殊的线程来执行系统监控任务，系统监控在一个独立的 M 上运行，不用绑定逻辑处理器 P。当系统监控到协程运行超过 10ms，就将 g.stackguard0 置为 stackPreempt（该值是一个抢占标志）。 const forcePreemptNS = 10 * 1000 * 1000 // 10msfunc retake(now int64) uint32 // 遍历所有的 P\tfor i := 0; i len(allp); i++ pp := allp[i] pd := pp.sysmontick s := pp.status sysretake := false if s == _Prunning || s == _Psyscall t := int64(pp.schedtick) if int64(pd.schedtick) != t pd.schedtick = uint32(t) pd.schedwhen = now else if pd.schedwhen+forcePreemptNS = now // 如果 G 运行时间过长，超过了 forcePreemptNS(10ms)， // 则标记抢占 preemptone(pp) sysretake = true if s == _Psyscall // 如果是系统调用，且已经超过了一个系统监控的 tick(20us)， // 则从系统调用中抢占 p。 t := int64(pp.syscalltick) if !sysretake int64(pd.syscalltick) != t pd.syscalltick = uint32(t) pd.syscallwhen = now continue ... // 标记抢占func preemptone(pp *p) bool mp := pp.m.ptr()\tgp := mp.curg\tgp.preempt = true\tgp.stackguard0 = stackPreempt\treturn true 巧的就是，Go 设计者，让程序在执行 morestack() 函数时顺便判断一下 g 中的 stackguard 是否已经被置为抢占 stackPreempt，如果的确被标记抢占，就回到 schedule() 方法，并将当前协程放回队列中。 morestack 是汇编实现： TEXT runtime·morestack(SB),NOSPLIT|NOFRAME,$0-0\t...\tBL\truntime·newstack(SB) 它最终会调用 newstack()： func newstack() thisg := getg() gp := thisg.m.curg // 1. 判断 gp.stackguard0 是否被标记为抢占 stackguard0 := atomic.Loaduintptr(gp.stackguard0)\tpreempt := stackguard0 == stackPreempt // 2. 如果被标记位抢占，调用 gopreempt_m() if preempt // 3. 最终会去调用 schedule() 去调新的协程执行 gopreempt_m(gp) // never return\tfunc gopreempt_m(gp *g) if traceEnabled() traceGoPreempt() goschedImpl(gp)func goschedImpl(gp *g) ...\tschedule() 5.4 信号调度 doSigPreempt() 当程序在执行过程中既无法主动挂起，也不能进行系统调用，且无法进行函数调用时，就可以使用信号来调度。 信号其实就是线程信号，在操作系统中有很多基于信号的底层通信方式（SIGPIPE / SIGURG / SIGHUP），而我们的线程可以注册对应信号的处理函数。 Go 中是注册了 SIGURG 信号的处理函数 doSigPreempt()，在 GC 工作时，向目标线程发送信号。线程收到信号后，会触发调度。 doSigPreempt 位于 runtime.signal_unix.go 中： func doSigPreempt(gp *g, ctxt *sigctxt) // 检查此 g 是否要被抢占并且安全抢占\tif wantAsyncPreempt(gp) if ok, newpc := isAsyncSafePoint(gp, ctxt.sigpc(), ctxt.sigsp(), ctxt.siglr()); ok // 2. 调整程序计数器 PC 并异步调用 asyncPreempt ctxt.pushCall(abi.FuncPCABI0(asyncPreempt), newpc) 其中 asyncPreempt 的实现如下： func asyncPreempt()// func asyncPreempt2() gp := getg()\tgp.asyncSafePoint = true // if gp.preemptStop mcall(preemptPark) else mcall(gopreempt_m) gp.asyncSafePoint = false asyncPreempt 是汇编实现，最终是调的 asyncPreempt2，它会调用 mcall 切回 g0，并执行 preemptPark 或 gopreempt_m， gopreempt_m 就是前面 morestack 最后调的！不出意外，preemptPack 最后肯定还是调的 schedule()。 func preemptPark(gp *g) ...\tschedule() 5.5 runtime.Gosched() 在我们实际编程中，你可以通过显式调用 runtime.Gosched() 来主动让出 CPU，促进 Go 的下一轮调度，我们来看它的具体实现，肯定还是调的 schedule()，没有意外！ func Gosched() checkTimeouts()\tmcall(gosched_m)func gosched_m(gp *g) if traceEnabled() traceGoSched() goschedImpl(gp)func goschedImpl(gp *g) status := readgstatus(gp)\tif status^_Gscan != _Grunning dumpgstatus(gp) throw(bad g status) casgstatus(gp, _Grunning, _Grunnable)\tdropg()\tlock(sched.lock)\tglobrunqput(gp)\tunlock(sched.lock)\tschedule() 5.6 总结 Go 语言为了确保 P 不会因为 G 运行时间过长或系统调用阻塞时间过长而导致性能下降。它会尝试进行协程切换，以确保任务可以适时地被分配和执行。这有助于保持Go程序的并发性能和响应性。而协程切换的方式有基于协作的抢占式调度（主动挂起 runtime.gopark()，系统调用结束时exitsyscall()，函数跳转时 morestack()），也有基于信号的抢占式调度 doSigPreempt()，他们都无一例外的最终调用了 schedule()。 所以总结下来其实还是这张图： G、P、M 状态流转 经过我们前面的分析，你可以自行整理 G、P、M 状态的流转，这里我给出几张图供你参考： 总结 以上便是对 Go 语言 GPM 模型的全部分享啦！GPM 模型使得 Go 语言能够并发执行成千上万个协程。 为了减少线程“相对昂贵”的切换代价，Go 引入了 GPM，将大量的 Goroutine 分配到少量的系统线程上去执行，并利用多核并行，实现更强大的并发。 为了减小并发冲突，Go 在全局队列的基础上引入了本地队列。 为了避免协程饥饿，Go 又引入了多种协程调度的策略。 为了避免协程阻塞浪费 CPU，Go 引入了多种协程切换的方式。 Go 语言设计者进行了如此复杂的调度器实现，最终交付给 Gopher 的，仅仅是一个 go 关键字这么简单，真的是大道至简，这也是充分印证了那句话：“Go 为并发而生”。 希望本文能对你有所帮助，enjoy~ happy coding~ 参考 深入理解 Go 语言 Go 语言底层原理剖析 深入 Go 底层原理 ChatGPT4 作图工具 excalidraw whimsical","tags":["Go"],"categories":["Go"]},{"title":"Rust 实战丨绘制曼德博集","path":"/2024/01/17/rust-action-mandelbrot/","content":"曼德博集 曼德博集其实是一个“没什么用”的发现。 曼德博集（Mandelbrot Set）是一种在复平面上形成独特且复杂图案的点的集合。这个集合是以数学家本华·曼德博（Benoit Mandelbrot）的名字命名的，他在研究复杂结构和混沌理论时发现了这个集合。曼德博集是分形几何的一个经典例子，显示了一个简单的数学公式如何能产生无限复杂和美丽的图案。 曼德博集的定义相对简单。对于每一个复数 $c$，我们考虑以下迭代序列： $$ Z_{n+1} = z_n^2 + c ;;\\ 其中 ;; (z_0 = 0) $$ 曼德博集合由那些使得上述序列不趋于无限大的复数 $c$ 组成。在复平面上，这些点形成了一种独特的图案，通常以一种美丽且艺术的方式呈现。这个图案的边界非常复杂，包含了无限的细节和自相似的结构。这意味着无论你放大图案的哪一部分，你都会发现越来越精细的结构，这些结构在形式上与整体图案相似。 曼德博集合不仅在数学上有意义，也在艺术和科学中有广泛的应用，尤其是在研究混沌理论和复杂系统时。 具体可以看 维基百科-曼德博集 bilibili - 2000亿倍放大曼德博集 目标功能 最终我们将实现一个命令行工具，它会根据我们输入的参数生成曼德博集图，使用如下： ./mandelbrot FILE PIXELS UPPERLEFT LOWERRIGHT FILE: 曼德博集图生成的图片路经。 PIXELS: 图片分辨率，如 4x3。 UPPERLEFT: 指定在复平面中图片覆盖的左上角，如 4.0,3.0。 LOWERRIGHT: 制定在复平面中图片覆盖的右下角。 所以我们最终会根据指定的图片范围，截取 PIXELS 分辨率大小的曼德博集图： 基于以上目标，我们拆分成几个问题： 如何表示复数？ 如何解析分辨率和坐标？ 如何将图上像素映射到复数？ 如何生成曼德博集图？即如何找到那些符合曼德博集的点，并将其进行着色标注？ 如何写入图片文件？ 如何渲染曼德博集？ 如何解析命令行参数？ 如何并发写入图片文件？ 能学到什么 曼德博集是什么？ Rust 中的复数的原理与应用。 Rust 泛型初探。 Rust 中的 Option 和 Result 初探。 Rust 并发初探。 Rust 中如何解析命令行参数？ Rust 如何写入图像文件？ Rust 如何写测试用例？ Rust 实用 crate num、image、crossbeam。 版本 [package]name = mandelbrotversion = 0.1.0edition = 2021[dependencies]image = version = 0.13.0, features = [default, png]num = 0.4.1crossbeam = 0.8rayon = 1.10.0 完整代码：https://github.com/hedon954/mandelbrot/blob/master/src/main.rs 编码实现 0. 创建项目 cargo new mandelbrot cd mandelbrot 1. 复数表示 使用复数，我们需要引入一个 crete：num： cargo add num 其中定义了一个复数类型 Complex： pub struct ComplexT /// 复数的实部 pub re: T, /// 复数的虚部 pub im: T, 这里 T 是 Rust 中的泛型功能，表示任意类型 T，确定好这个结构体的 T 的类型后，其中的属性 re 和 im 的类型也就随之确定了。 2. 解析分辨率和坐标 分辨率格式为：4000x3000 坐标格式为：-1.0,2.0 2.1 解析数对 我们要做的就是，将分辨率拆成 (4000,3000)，将坐标拆为 (-1.0, 2.0)。这里： 带解析的元素 s 是一个字符串 str。 分隔符 separator 是一个字符 char。 返回值是一个元组 (T, T)，其中 T 这里可以是 u64/f32 等数字，它们都需要能从字符串转化而来，即 T:FromStr。 因为解析可能出错，所以我们使用 Option 来承载。 /// 把字符串 `s`（形如 `400×600` 或 ``1.0,0.5）解析成一个坐标对////// 具体来说，`s` 应该具有leftsepright的格式，其中sep是由`separator`/// 参数给出的字符，而left和right是可以被 `T:from_str` 解析的字符串。/// `separator` 必须是 ASCII 字符////// 如果 `s` 具有正确的格式，就返回 `Some(x,y)`，否则返回 `None`fn parse_pairT: FromStr(s: str, separator: char) - Option(T, T) match s.find(separator) None = None, Some(index) = match (T::from_str(s[..index]), T::from_str(s[index + 1..])) (Ok(l), Ok(r)) = Some((l, r)), _ = None, , 我们可以写几个测试用例来验证一下这个函数的正确性，这里我们用到 #[test] 和 assert_eq!： #[test]fn test_parse_pair() assert_eq!(parse_pair::i32(, ,), None); assert_eq!(parse_pair::i32(10,, ,), None); assert_eq!(parse_pair::i32(,10, ,), None); assert_eq!(parse_pair::i32(10,20, ,), Some((10, 20))); assert_eq!(parse_pair::i32(10,20xy, ,), None); assert_eq!(parse_pair::f64(0.5x, x), None); assert_eq!(parse_pair::f64(0.5x1.5, x), Some((0.5, 1.5))); 2.2 转为复数 我们需要的参数 upper_left 和 lower_right 都是复平面中的一个点，所以从字符串中将数对解析完毕后，我们将其赋值到复数的实部和虚部，转为复数实例。 // 把一对用逗号隔开的浮点数解析为复数fn parse_complex(s: str) - OptionComplexf64 match parse_pair(s, ,) Some((re, im)) = Some(Complex re, im ), None = None, 3. 将像素点映射成复数 第 2 步我们其实确定了两件事： 确定截取曼德博集的哪一部分。 要在这个部分中画多少个点。 这一步我们需要把 x 点转为复数，即确定它的横坐标和纵坐标。这部分可能需要发挥一下你的几何数学能力了（🤡🤡🤡）。 /// 给定输出图像重像素的行和列，返回复平面中对应的坐标////// `pixed` 是表示给图片中特定像素的 (column, row) 二元组。/// `upper_left` 参数和 `lower_right` 参数是在复平面中表示指定图像覆盖范围的点。fn pixed_to_point( /* ·-------------------- bounds.0 re 丨 丨 丨 bounds.1 im */ bounds: (usize, usize), pixed: (usize, usize), upper_left: Complexf64, lower_right: Complexf64,) - Complexf64 let (width, height) = ( lower_right.re - upper_left.re, // 右-左 upper_left.im - lower_right.im, // 上-下 ); Complex re: upper_left.re + pixed.0 as f64 * width / bounds.0 as f64, im: upper_left.im - pixed.1 as f64 * height / bounds.1 as f64, #[test]fn test_pixed_to_point() assert_eq!( pixed_to_point( (100, 200), (25, 175), Complex re: -1.0, im: 1.0 , Complex re: 1.0, im: -1.0 ), Complex re: -0.5, im: -0.75, ); 4. 寻找曼德博集点 什么是曼德博集点？看看上面的定义：曼德博集合由那些使得上述序列不趋于无限大的复数 $c$ 组成。 现在我们可以来表示上述的公式 $Z_{n+1} = z_n^2 + c$ 了： fn complex_square_add_loop(c: Complexf64) let mut z = Complex re: 0.0, im: 0.0 ; loop z = z * z + c 其中我们将泛型结构体 Complex 的 T 确定为 f64，并使用 loop 关键字进行无限循环。 所以我们的目标是什么？找到令 z 不会“飞到”无穷远的 c。 由于复数 $c$ 具有实部 re 和虚部 im，因此可以把它们视为笛卡尔平面上某个点的 x 坐标和 y 坐标，如果 $c$ 在曼德博集中，就在其中用黑色着色，否则就用浅色。因此，对于图像中的每个像素，必须在复平面上相应点位运行前面的循环，看看它是否逃逸到无穷远还是永远绕着原点运行，并相应将其着色。 无限循环肯定是不现实的，我们总要找到退出循环的机会，有 2 个思路： 进行有限次数的迭代，这样可以获得该集合的一个不错的近似值，迭代的次数取决了精度的需要； 业界已证明，一旦 z 离开了以原点为中心的半径 2 的圆，它最终一定会“飞到”无穷远。 所以我们最终确定的函数如下，其中 norm_sqr() 会返回 z 跟复平面原点的距离的平方： /// 尝试测试 `c` 是否位于曼德博集中，使用最多 `limit` 次迭代来判定////// 如果 `c` 不是集合成员之一，则返回 `Some(i)`，其中 `i` 是 `c` 离开以原点/// 为中心的半径为 2 的圆时所需的迭代次数。如果 `c` 似乎是集群成员之一（确/// 切而言是达到了迭代次数限制但仍然无法证明 `c` 不是成员），则返回 `None`fn escape_time(c: Complexf64, limit: usize) - Optionusize let mut z = Complex re: 0.0, im: 0.0 ; for i in 0..limit if z.norm_sqr() 4.0 return Some(i); z = z * z + c None 5. 写入图片文件 我们可以使用 image 这个 crate 来写入图片文件，它支持多种格式图片的读写，并内置了多种颜色色值。 这里我们准备生成 png 图片，且需要对图片进行不同颜色的着色，所以我们引入 default 和 png 这两个 feature。 cargo add image --features default,png 5.1 创建文件 File::create() 我们可以用标准库中的 File::create(filename) 来创建一个文件，成功的话会返回一个文件句柄： let output = File::create(filename)?; 5.2 写入图片 PNGEncoder image 中提供了 PNGEncoder 用于写入 png 图片，它有两个核心方法： implW: Write PNGEncoderW /// Create a new encoder that writes its output to ```w``` pub fn new(w: W) - PNGEncoderW PNGEncoder w: w /// Encodes the image ```image``` /// that has dimensions ```width``` and ```height``` /// and ```ColorType``` ```c``` pub fn encode(self, data: [u8], width: u32, height: u32, color: ColorType) - io::Result() let (ct, bits) = color.into(); let mut encoder = png::Encoder::new(self.w, width, height); encoder.set(ct).set(bits); let mut writer = try!(encoder.write_header()); writer.write_image_data(data).map_err(|e| e.into()) new(w): 传进目标 writer，即我们上面创建的 output。 encode(): 写入图片信息，这里有几个参数： width: u32: 图片宽度。 height: u32: 图片高度。 color: ColorType: 颜色类型，可以是 RGB, Gray(8) 等。 data: [u8]: 像素色值列表，它的长度应该由上面 3 个字段共同决定，如果选取的颜色是 RGB，意味着需要 3 个 u8 才能表示一个像素点的颜色，所以长度为 width * height * 3，如果选取的颜色是 Gray(8)，那么我们用 1 个 u8 就可以表示一个像素点的灰度值，所以长度为 width * height * 1。本文中我们会采用 Gray(8) 来汇总曼德博集的黑白图。 6. 渲染曼德博集 这一步我们需要来确定上述 PNGEncoder::encode() 的 4 个参数： width: u32: 图片宽度由命令行参数中指定即可。 height: u32: 图片高度由命令行参数中指定即可。 color: ColorType: 本文我们只绘制黑白图，这里使用 ColorType::Gray(8)，它表示图像是一个灰度（单色）图像，每个像素用8位（即1个字节）来表示。在这种格式中，每个像素的灰度值范围是 0 到 255，其中 0 通常表示黑色，255 表示白色，中间值表示不同的灰度。 data: [u8]: 像素色值列表，我们需要确定 width * height 个像素的灰度值。 首先我们根据第 3 步将像素点映射成复数 $c$，然后使用第 4 步中的 escape_time() 函数来判断复数 $c$ 是否位于曼德博集中，如果是，则着黑色，即赋值 0，如果不是，则看它迭代了多少次才失败，次数越多，则越接近曼德博集，颜色越深，即越靠近 0，所以赋值 255-time。 最终我们实现的函数如下： /// 将曼德博集对应的矩形渲染到像素缓冲区中////// `bounds` 参数会给缓冲区 `pixels` 的宽度和高度，此缓冲区的每个字节都/// 包含一个灰度像素。`upper_left` 和 `lower_right` 参数分别指定了/// 复平面中对应于像素缓冲区左上角和右上角的点。fn render( pixels: mut [u8], bounds: (usize, usize), upper_left: Complexf64, lower_right: Complexf64,) assert_eq!(pixels.len(), bounds.0 * bounds.1); for raw in 0..bounds.1 for column in 0..bounds.0 let point = pixed_to_point(bounds, (column, raw), upper_left, lower_right); pixels[raw * bounds.0 + column] = match escape_time(point, 255) None = 0, Some(count) = 255 - count as u8, 7. 解析命令行参数 核心逻辑部分到这里其实就完成了，现在我们要做最后一步，就是解析命令行参数，让程序可以根据我们的要求绘制曼德博集图。 7.1 解析 std::env::args() 在 Rust 中解析命令行参数的一个常用方法是使用std::env::args函数，这个函数返回一个迭代器，它包含了命令行上传递给程序的所有参数。对于更复杂的命令行参数解析，可以使用像clap或structopt这样的第三方库，这些库提供了更高级的功能和更好的错误处理。 下面是一个使用std::env::args的基本例子： use std::env;fn main() let args: VecString = env::args().collect(); for arg in args.iter() println!(, arg); 7.2 基础版程序 到这里，我们就可以实现完整的基础版程序了。 fn main() // 读取参数 let args: VecString = env::args().collect(); // 参数个数 = 1 + 4，其中第 1 个是应用程序名 if args.len() != 5 eprintln!(Usage: FILE PIXELS UPPERLEFT LOWERRIGHT, args[0]); eprintln!( Example: mandel.png 1000x700 -1.20,0.35 -1,0.20, args[0] ); std::process::exit(1); // 解析参数 let bounds = parse_pair(args[2], x).expect(error parsing image dimensions); let upper_left = parse_complex(args[3]).expect(error parsing upper left corner point); let lower_right = parse_complex(args[4]).expect(error parsing lower right corner point); let mut pixels = vec![0; bounds.0 * bounds.1]; // 渲染曼德博集 render(mut pixels, bounds, upper_left, lower_right); // 输出图片 write_image(args[1], pixels, bounds).expect(error writing PNG file); 我们在项目根目录下编译一下程序： cargo build --release 会在 target/release 下生成可执行文件，执行： ./target/release/mandelbrot mandel.png 4000x3000 -1.20,0.35 -1,0.20 执行后你应该可以看到我们生成的曼德博集图如下： 大概是处于这个位置： 8. 并发渲染 在 macOS 或 linux 系统下，我们可以使用 time 来输出程序的执行时间： time ./target/release/mandelbrot mandel.png 4000x3000 -1.20,0.35 -1,0.20./target/release/mandelbrot mandel.png 4000x3000 -1.20,0.35 -1,0.20 3.30s user 0.01s system 98% cpu 3.341 total 笔者使用的电脑为 macbook Pro m2 max 芯片 32 G 内存 12 核，可以看到在单核模式下，差不多需要 3~4s 的时间。 几乎所有的现代机器都有多个处理器核心，而当前这个程序只使用了一个。如果可以把此工作分派个机器提供的多个处理器核心，则应该可以更快地画完图像。 为此，我们可以将图像划分成多个部分，每个处理器负责其中的一个部分，并让每个处理器为分派给它的像素着色。为简单起见，可以将其分成一些水平条带，如下图所示： crossbeam 是 Rust 中的一个并发编程工具箱，它广泛用于提供各种并发和多线程编程的组件。 crossbeam::scope 是 crossbeam 提供的一个非常有用的功能，它允许你安全地创建临时的线程，并确保这些线程在离开作用域之前结束。 这里我们引入 crossbeam： cargo add crossbeam 我们将 fn main() 中的： render(mut pixels, bounds, upper_left, lower_right); 替换成： // 使用 8 个线程来并发执行let threads = 8;// 计算每个线程负责渲染的高度，向上取整let rows_per_band = bounds.1 / threads + 1; // chunks_mut() 会返回一个迭代器，该迭代器会生成此缓冲区的可变且不可迭代的切片 let bands: Vecmut [u8] = pixels.chunks_mut(rows_per_band * bounds.0).collect(); // crossbeam::scope 确保所有子线程在作用域结束之前完成， // 这防止了悬垂指针和其他数据竞争问题。 crossbeam::scope(|spawner| // 遍历像素缓冲区的各个条带， // 这里 into_iter() 迭代器会为循环体的每次迭代赋予独占一个条带的所有权， // 确保一次只有一个线程可以写入它。 for (i, band) in bands.into_iter().enumerate() // 确定每个条带的参数 let top = rows_per_band * i; let height = band.len() / bounds.0; let band_bounds = (bounds.0, height); let band_upper_left = pixed_to_point(bounds, (0, top), upper_left, lower_right); let band_lower_right = pixed_to_point(bounds, (bounds.0, top + height), upper_left, lower_right); // 创建一个线程，渲染图像 // move 表示这个闭包会接手它所用遍历的所有权， // 所以只有此闭关，即只有此线程可以使用可变切片 band。 spawner.spawn(move |_| render(band, band_bounds, band_upper_left, band_lower_right); ); ) .unwrap(); 再次执行： time ./target/release/mandelbrot mandel.png 4000x3000 -1.20,0.35 -1,0.20./target/release/mandelbrot mandel.png 4000x3000 -1.20,0.35 -1,0.20 3.57s user 0.01s system 335% cpu 1.067 total 可以看到虽然总共使用的 CPU 时间还是 3~4s，但是整个程序的执行时间只缩短到 1s 左右了。 9. rayon 工作窃取 前面我们使用 8 个工作线程优化了曼德博集的绘制速度，大概是 4 倍的速度提升。其实这还不够快。 问题的根源在于我们没有平均分配工作量。计算图像的一个像素相当于运行一个循环。事实上，图像的浅灰色部分（循环会快速退出的地方）比黑色部分（循环会运行整整 255 次迭代的地方）渲染速度要快得多。因此，虽然我们将整个区域划分成了大小相等的水平条带，但创建了不均等的工作负载， 使用 rayon 很容易解决这个问题。我们可以为输出中的每一行像素启动一个并行任务。这会创建数百个任务，而 rayon 可以在其线程中分配这些任务。有了工作窃取机制，任务的规模是无关紧要的。rayon 会对这些工作进行平衡。 我们先引入 rayon： cargo add rayon 在 main.rs 中引入 rayon: use rayon::prelude::*; 然后 main 中并发绘制的部分替换为下面的代码： let bands: Vec(usize, mut [u8]) = pixels.chunks_mut(bounds.0).enumerate().collect();bands.into_par_iter().for_each(|(i, band)| let top = i; let band_bounds = (bounds.0, 1); let band_upper_left = pixed_to_point(bounds, (0, top), upper_left, lower_right); let band_lower_right = pixed_to_point(bounds, (bounds.0, top + 1), upper_left, lower_right); render(band, band_bounds, band_upper_left, band_lower_right);); 首先，创建 bands，也就是要传给 rayon 的任务集合。每个任务只是一个元组类型 (usize, mut [u8])：第一个是计算所需的行号，第二个是要填充的 pixels 切片。我们使用 chunks_mut 方法将图像缓冲区分成一些行，enumerate 则会给每一行添加行号，然后 collect 会将所有数值切片对放入一个向量中。（这里需要一个向量，因为 rayon 只能从数组和向量中创建并行迭代器。） 编译： cargo build --release 再次执行： time ./target/release/mandelbrot mandel.png 4000x3000 -1.20,0.35 -1,0.20./target/release/mandelbrot mandel.png 4000x3000 -1.20,0.35 -1,0.20 3.96s user 0.01s system 973% cpu 0.408 total 可以看到，这次速度提升更加明显，总共只用了 0.4s 左右的时间。 以上就是实用 Rust 绘制曼德博集实战的全部内容，enjoy，happy coding~","tags":["Rust"],"categories":["Rust","Rust 实战"]},{"title":"一文彻底掌握浮点数","path":"/2023/12/23/floating-point-number/","content":"经典问题 0.1 + 0.2 = ？ 我们写个 Go 程序来测试一下： func main() var f1 float64 = 0.1\tvar f2 float64 = 0.2\tfmt.Println(f1+f2 == 0.3)\tfmt.Println(f1 + f2) 输出： false0.30000000000000004 如此违背 “常识” 的结果，其实是因为当下计算机体系中小数的表示方式是浮点数，而计算机中对浮点数的表示并非百分百精确的，在表示和计算过程中都有可能会丢失精度。 这迫使必须深入理解浮点数在计算机中的存储方式及性质，才能正确处理关于数字的计算问题。 结论先行 定点数 要理解浮点数的第一步是考虑含有小数值的二进制数字。在这之前，我们来看看更加熟悉的十进制表示法： $$ d_md_{m-1} ··· d_1d_0 . d_{-1}d_{-2}··· d_{-n} $$ 小数点 . 左边是整数部分，右边是小数部分。其中每个十进制数 di 的取值范围是 0~9。 如十进制的 12.34 即可以表示为： $$ 1×10^1+2×10^0+3×10^{-1}+4×10^{-2} $$ 那其实二进制也是一样的道理，只不过把其中的 10 换成 2，而 di 的取值范围为 0~1。 如二进制的 101.11 可以表示为： $$ 1×2^2+0×2^1+1×2^0+1×2^{-1}+1×2^{-2} $$ 如果我们仅考虑有限长度的编码，那么十进制表示法不能准确表达像 1/3 和 5/7 这样的数。类似的，小数的二进制表示法只能表示那些能够被写成以下形式的数： $$ x × 2^y $$ 其他的值就只能近似地表示。 定点数的整数部分是小数部分的位数是固定不变的，在位数有限的情况下，定点数的取值范围和精度都比较差。于是就有了 IEEE-754 提出的浮点数表示法。 浮点数 所谓“浮点数”（Floating-point numbers），即小数点可以“浮动”，即小数点的位置不是固定的，而是可以根据数值的大小和精度需求移动的。这种表示法允许在广泛的范围内表示数值，同时保持相对恒定的精度。 在计算机中，浮点数通常遵循 IEEE-754 标准。这个标准定义了浮点数的存储和运算方式，确保了不同计算机系统之间的一致性。IEEE-754 用以下形式来表示一个数： $$ V = (-1)^s×M×2^E $$ 其中： s 符号位（Sign bit）：表示数值的正负。 M 尾数（Mantissa）：表示数值的有效数字。 E 指数（Exponent）：决定小数点的位置。 IEEE-754 将浮点数的位表示划分成三个部分，分别对各个部分进行编码，对应上面公式右边的 3 个字母： 一个单独的符号位 s 直接编码符号 s。 $k$ 位的阶码字段 $exp=e_{k-1}\\cdots e_1e_0$ 编码阶码 E。 $n$ 位小数字段 $frac=f_{n-1}\\cdots f_1f_0$ 编码尾数 M，但是编码出来的值也依赖于阶码字段的值是否等于 0。 在 IEEE-754 标准中，定义了两种精度的浮点数，分别是单精度浮点数（32 位）和双精度浮点数（64 位）。 单精度： 1 位符号位 s 8 位指数 exp 23 位尾数 frac 双精度： 1 位符号位 s 11 位指数 exp 52 位尾数 frac 根据 exp 的值，浮点数又可以分成三类： 规格化的 非规格化的 特殊的 其中第三类“特殊的”又可以根据 frac 分成两类： 无穷大 不是一个数 NaN（Not a Number） 具体如下表所示： exp frac 规格化的 ≠0 ≠ 255 f 非规格化的 0 f 特殊的 1 f - 无穷大 1 0 - NaN 1 ≠0 对于不同类型的浮点数，在计算公式 $V=(-1)^s×M×2^E$ 中，exp - E 和 frac - M 的方式有所不同。 下面我们来对这几种不同类型进行详细讨论，其中不乏有一些很有趣且充满智慧的设计理念。 特殊值 Special Values 指数部分：全为 0。 尾数部分：全为 0 则表示无穷大，不全为 0 则表示 NaN。 作用：特殊值用于表示那些无法用常规数值表示的情况，如无穷大、非数（NaN）等。这些值通常用于操作的错误或特殊情况的结果，如除以 0、无效操作等。 规格化的值 Normalize Values 指数部分：不全为 0 且不全为 1。 尾数部分：可以是任意值。 作用：用于表示大多数非零数值 在规格化值中： $E=e-bias$ $M=1+f$ 其中 e 即为 exp，，bias 是偏置量，它的值为 $2^{k-1} -1$，其中 k 为 exp 的位数，故： 在单精度中，$bias=2^{8-1}-1=2^7-1=128-1=127$ 在双精度中，$bias=2^{11-1}-1=2^{10}-1=1024-1=1023$ 其中 f 为 frac 表示的数，范围 $0≤f1$。 所以一个规格化数，具体可以表示为： $$ V=(-1)^{sign}×1.frac×2^{(exp-bias)} $$ 这里有 4 个问题： 这个 bias 是什么？ 为什么 E 要 e 去减掉一个 bias？ bias 的值是怎么定下的，如单精度为什么是 127，不是 126 或 128？ M 为什么需要 f 去加上一个 1？ 下面我们来对这 4 个问题进行一一解答。 第 1 个问题，这个 bias 是什么？ bias 是一个预设的偏移量，用于将指数部分的值偏移到全正数，从而简化处理。 第 2 个问题：为什么 E 要 e 去减去一个 bias？ 先说结论：使用 bias（偏置指数，biased exponent）可以允许浮点数以统一的方式表示，同时也使得浮点数的排序和比较变得简单。 首先指数肯定得支持正负形式的出现，那么直接使用无符号整型来表示指数肯定是不行的，因为它无法表示负指数。暂时先抛开 IEEE-754 定下的标准，我们可以尝试用补码来表示指数。 假设我们有两个 32 位的浮点数 A 和 B，并且我们假设它们的指数部分使用 8 位二进制补码表示（这与 IEEE-754 标准不同）。 A 的二进制表示：0 0000010 00000000000000000000000 B 的二进制表示：0 1111110 00000000000000000000000 在这里，第一位是符号位（0 表示正数），接下来的 8 位是以补码形式表示的指数，剩下的 23 位是尾数。 我们想要比较这两个数的大小，需要怎么做呢？ 我们先解析这 2 个数： 符号位：对于 A 和 B，符号位都是 0，表示这是两个正数。 指数部分（使用补码表示） A 的指数为 0000010，解读为正数 +2。 B 的指数为 1111110，在补码表示中，这是一个负数。先加取反后加 1 转换为正数 00000010，它表示 -2。 要比较这 2 个数： 当我们比较 A 和 B 时，首先需要考虑它们的指数。 指数 A 为 +2，而 B 为 -2。即使它们的尾数部分相同（在这个例子中都是 0），A 的实际值要大于 B，因为正指数表示的数值范围远大于负指数。 可以看出：使用补码表示指数增加了比较过程的复杂性，因为我们需要解读补码并考虑其正负。特别是在涉及到负指数的情况下，我们不能仅仅比较二进制表示的大小，而必须将补码转换为实际的数值，然后再进行比较。 现在回过头来看看 IEEE-754 的设计，假设我们有两个单精度（32 位）浮点数 A 和 B： A 的二进制表示为：0 10000010 00000000000000000000000 B 的二进制表示为：0 01111110 00000000000000000000000 解析这两个数： A：符号位为 0（正数），指数部分为 10000010（二进制，对应十进制的 130），尾数部分为全 0。 B：符号位为 0（正数），指数部分为 01111110（二进制，对应十进制的 126），尾数部分为全 0。 计算实际指数值：单精度浮点数的偏置值 bias 为 127，故： A 的实际指数 E = 130 - 127 = 3。 B 的实际指数 E = 126 - 127 = -1。 比较这两个数： 在减去 bias 后，我们可以直接比较指数部分的二进制表示来确定数值的大小。 由于 10000010（130）大于 01111110（126），因此我们可以直接得出 A 大于 B，而无需考虑负指数的复杂表示问题。 这个例子说明了通过减去偏置值，IEEE-754 标准能够简化浮点数的比较和排序操作。偏置后的指数表示方法允许计算机以统一和高效的方式处理浮点数，无论它们的实际数值大小如何。 第 3 个问题：bias 的值是怎么定下的，如单精度为什么是 127，而不是 126 或 128？ bias 值的选择，是为了平衡正负指数的表示范围，并且充分利用指数部分的存储空间。 以单精度为例，exp 占了 8 位，8 位二进制可以表示的值的范围是 $[0,255]$。如果我们选择 127 作为 bias，则存储的指数范围就是 $[-127,128]$。这样可以使得指数部分可以均匀地表示从负大数到正大数的范围（对称）。 在 IEEE-754 标准中，全 0 的指数表示为非规格化数或 0，而全 1 的指数用于表示无穷大或 NaN）。选择 127 作为 bias 可以在保留这些特殊值的同时，提供最大的有效指数范围。 第 4 个问题：M 为什么需要 f 去加上一个 1？ 在规格化数中隐含最高位 1 是为了提高尾数部分的表示效率，从而增加精度。 其实这跟科学计数法的很像的，为了确保浮点数表示的唯一性，IEEE-754 规定规格化浮点数最高位一定是非零的。如果不规定最高位非零，同一个数可以有多种不同的浮点表示，例如，在二进制中 0.5 可以表示为 $1.0×2^{-1}$，也可以表示位 $0.1×2^0$ 或 $0.01×2^1$ 等等。这种多重表示会使浮点运算变得复杂且低效。 那既然最高位总是 1，那就没必要显示存储了，还可以使尾数部分中多 1 位的存储空间，从而允许存储更多的有效数字，以提高精度。 非规格化的值 Denormalized Values 指数部分：全为 0。 尾数部分：可以是任意值。 作用： 提供表示数值 0 的方法。因为规格化中 $M≥1$，所以无法表示 0。 用于表示非常接近于 0 的数值，这些数值太小，无法用规格化格式表示。它们填补了 0 和最小规格化正数之间的间隙，提供了渐近于 0 的连续表示，防止了所谓的“下溢”。 在非规格化值中： $E=1-bias$ $M=f$ 所以一个规格化数，具体可以表示为： $$ V=(-1)^{sign}×0.frac×2^{(1-bias)} $$ 那这里又有 2 个问题了： 为什么指数部分不是 $0-bias$ 而是 $1-bias$？ 为什么 M 不需要隐含的 1 了？ 第 1 个问题：为什么指数部分不是 0-bias 而是 1-bias？ 这是一个特殊的设计，旨在使非规格化数能够平滑地连接到规格化数的最小正值。 最小的规格化数的指数为 1 - bias。为了在数值上平滑地过渡到非规格化数，非规格化数的实际指数也被设定为 1 - bias。这样，非规格化数就可以代表那些小于最小规格化正数的数值，而不会出现一个数值的“间隙”。 第 2 个问题：为什么 M 不需要隐含的 1 了？ 不包含隐含的 1 使得非规格化数能够在浮点数表示中填补 0 和最小规格化数之间的空隙，提供对极小数值的连续表示。 避免下溢：非规格化数通过允许尾数部分不以隐含的 1 开始（而是以显式的 0 开始），使得它们可以表示比最小规格化数还要小的数值。这对于避免数值下溢至 0 非常重要，尤其是在累积了多次运算后的场合。 精度牺牲：使用非规格化数的代价是牺牲了一些精度。由于没有隐含的最高位 1，非规格化数的精度较低。但这是为了在非常小的数值范围内提供数值的连续性所做的必要妥协。 总结 规格化值、非规格化值和特殊值三种类型共同构成了 IEEE-754 浮点数标准的完整表示体系，使得浮点数能够在计算机中有效低处理从非常小到非常大的数值范围，同时还能应对特殊的计算情况。 举例 参考《深入理解计算机系统》，我们以 8 位浮点数为例，其中： 1 位符号 s 4 位指数 exp 3 位尾数 frac 可以算出 $bias=2^{4-1}-1=2^3-1=8-1=7$。 其中靠近 0 的是非规格化值： 以 0 0000 001 为例： $$ V = (-1)^s×M×2^E \\ = (-1)^s×0.frac×2^{1-bias} \\ = (-1)^0×(0+(1/8))×2^{1-7} \\ = 1×1/8×2^{-6} \\ =2^{(-9)} \\ = 1/512 $$ 再往下，就是规格化值： 以 0 0110 110 为例： $$ V = (-1)^s×M×2^E \\ = (-1)^s×1.frac×2^{e-bias} \\ = (-1)^0×(1+6/8)×2^{6-7} \\ =1×14/8×2^{-1} \\ = 14/16 \\ =7/8 $$ 整型转为浮点型 下面以一个例子来直观感受一下一个整型是如何转为浮点型的。 现在我们有一个 int32 的整型 123，我们希望将其转为单精度浮点型 123.0。 1. 将整型用二进制表示出来 $$ 12345_{(10)} = 1111011_{(2)} $$ 2. 规范化表示 $$ 1111011= 1.111011×2^6 $$ 3. 计算指数 $$ exp = 6 + 127 = 133_{(10)} = 10000101_{(2)} $$ 4. 确定尾数** 这是个规范化值，所以 1.frac 的 1 省略，又因为单精度浮点数 frac 占 23 位，所以我们需要在 111011 后面再填 17 个 0，即： $$ frac = 111011 0000 0000 0000 0000 0 $$ 5. 确定符号位 $$ s = 0_{(2)} $$ 6. 组合起来 12345.0 = 0 10000101 11101100000000000000000 浮点数舍入 由于浮点数的表示具有固定的精度，在进行运算或表示时，经常会遇到无法精确表示的数值，这就需要采用舍入方法来近似表示这些数值。IEEE-754 标准定义了几种不同的舍入模式，以适应不同的计算需求。 舍入模式 最近舍入（Round to Nearest）: 这是最常用的舍入模式，也是默认的模式。 规则是向最接近的可表示值舍入。如果精确结果位于两个可表示值的中点，通常舍入到最近的偶数（即尾数的最后一位为 0）。 这种方法减少了累积误差，确保了在多次运算后的总体精度。 向零舍入（Round Toward Zero）: 这种模式总是舍入到零的方向，即舍去小数部分。 对于正数，这相当于取下限，对于负数，相当于取上限。 向上舍入（Round Up）: 无论正负，都向远离零的方向舍入。 对于正数，舍入后的值不小于原值；对于负数，舍入后的值不大于原值。 向下舍入（Round Down）: 无论正负，都向接近零的方向舍入。 对于正数，舍入后的值不大于原值；对于负数，舍入后的值不小于原值。 舍入的影响 精度损失：由于固定的尾数位数，舍入可能导致精度的损失。 舍入误差：舍入操作本身可能引入误差，这些误差在连续运算中可能会累积。 选择合适的舍入模式：不同的舍入模式适合不同的应用场景。例如，金融计算可能更倾向于使用向零舍入，而科学计算通常使用最近舍入以减少累积误差。 实例 Mode 1.40 1.60 1.50 2.50 -1.50 最近舍入 1 2 2 2 -2 向零舍入 1 1 1 2 -1 向上舍入 2 2 2 3 -1 向下舍入 1 1 1 2 -2 浮点数运算 因为浮点数本身就存在精度问题，所以浮点数运算在计算机中是一个近似过程，涉及到精确度的权衡、特殊值的处理、错误的传播，以及舍入规则的应用。 浮点数加减 浮点数加法和减法首先需要对操作数进行对齐，使得它们的指数相同。这可能涉及将尾数的二进制表示向右移位，可能导致精度损失。 然后执行加法或减法操作。 对结果进行规范化和舍入。 注意，浮点数的加减法不满足结合律、交换律和分配律，这你简单分析下应该就可以理解了，这里不赘述了。 假设我们要在单精度浮点数格式下计算： $$ 12.375 + 0.1 = ? $$ 第 1 步：转为二进制表示 其中 12.375 我们可以用二进制精确表示： $$ 12.375_{(10)} = 1100.011_{(2)} $$ 而 0.1 就比较特殊了，用二进制表示的话它会无限循环。 将十进制小数转换为二进制表示涉及到重复乘以 2 的过程，并提取每次乘法后整数部分作为二进制位。这个过程是一个不断重复的过程，直到小数部分变为 0 或开始循环。 取 0.1 的小数部分乘以 2（即 0.1 × 2 = 0.2），整数部分是 0，小数部分是 0.2。 再次取小数部分乘以 2（即 0.2 × 2 = 0.4），整数部分是 0，小数部分是 0.4。 继续这个过程，我们得到以下序列： 0.4 × 2 = 0.8 → 整数部分 0 0.8 × 2 = 1.6 → 整数部分 1 0.6 × 2 = 1.2 → 整数部分 1 0.2 × 2 = 0.4 → 整数部分 0 …（循环开始） 所以，0.1 的二进制表示开始为 0.0001100110011…，并且这个模式会无限循环下去。 第 2 步：规格化 回顾一下这张图： 所以 12.375 规格化表示为： 先规范化为 1.xxxx 形式： $1100.011_{(2)} = 1.100011 × 2^3$ 指数为：$3 + 127 = 130 = 10000010_{(2)}$ 尾数为：$10001100000000000000000（23;位，右边补;0）$ 汇总：$0;10000010;10001100000000000000000$ 而 0.1 由于无限循环，我们在单精度下只能保留 23 位，并采用最近舍入，所以 0.1 规格化表示为： 先规范为 1.xxxx 形式：$0.00011001100110011001100(循环) = 1.10011001100110011001100 × 2^-4$ 指数为：$-4 + 127 = 123 = 01111011_{(2)}$ 尾数为：$10011001100110011001100$ 汇总：$0;01111011;10011001100110011001100$ 第 3 步：对齐指数 先把 2 个浮点表示放在一起，好对比： $0;10000010;10001100000000000000000$ $0;01111011;10011001100110011001100$ 将两个数的指数对齐，较小的指数增加，同时相应地调整尾数。 这里需要调整将 0.1 的指数从 01111011 调整到 10000010，这里加了 7，所以 0.1 的尾数 1.10011001100110011001100需要右移 7 位，即：0.00000011001100110011001。 第 4 步：相加 现在两个数的指数相同了，我们可以直接把它们的尾数相加： $$ ;;;1.10001100000000000000000 \\ +;0.00000011001100110011001 \\ =;1.10001111001100110011001 $$ 第 5 步：规范化结果 这里无需规范化。 第 6 步：舍入 这里没有进位，不需要舍入。 第 7 步：浮点化表示 $$ 0;10000010;10001111001100110011001 $$ 第 8 步：转为十进制 $$ V =(-1)^s×M×2^E \\ = (-1)^s×1.frac×2^{e-bias} \\ = 1.10001111001100110011001 × 2^3 \\ = 1100.01111001100110011001_{(2)} \\ = 12.47499942779541015625_{(10)} \\ ≈ 12.475_{(10)} $$ 浮点数乘法 符号位计算：结果的符号由两个操作数的符号位决定。如果符号位相同（都是正数或都是负数），结果为正；如果符号位不同，结果为负。 指数相加：两个数的指数相加，并减去偏置值（单精度浮点数中为 127，双精度为 1023）。 尾数相乘：两个数的尾数相乘。这里的尾数包括隐含的最高位 1。 结果规范化：如果乘法的结果需要规范化（即调整为 1.xxxx 的形式），则相应调整指数。 舍入处理：如果需要，对结果进行舍入以适应目标格式。 检查溢出或下溢：如果指数超出了表示范围，则发生溢出（结果可能为无穷大或特殊值）；如果指数太小，发生下溢（结果可能为 0 或非规格化数）。 假设我们要在单精度浮点数格式下计算： $$ 2.0 × 3.0 = ? $$ 第 1 步：转为二进制表示 $$ 2.0_{(10)} = 1_{(2)} \\ 3.0_{(10)} = 11_{(2)} $$ 第 2 步：规范化 $$ 1 = 1.0 × 2^0 \\ 11 = 1.1 × 2^1 $$ 第 3 步：浮点化 $$ 2.0 = 0;00000001;00000000000000000000000 \\ 3.0 = 0;00000001;10000000000000000000000 $$ 第 4 步：乘法操作 符号位：正正得正：$0_{(2)} × 0_{(2)} = 0_{(2)}$ 指数相加并减去偏置值：$(127+1)+(127+1)-127=129$ 尾数相乘：$1.0_{(2)}×1.1_{(2)} = 1.1_{(2)}$ 第 5 步：规范化 这里无需规范化。 第 6 步：舍入 这里无需舍入。 第 7 步：浮点化结果 $$ 0;00000010;10000000000000000000000 $$ 第 8 步：转为十进制 $$ V = (-1)^s×1.frac×2^{(e-127)} \\ = 0 × 1.1 × 2^2 \\ = 110_{(2)} \\ = 6.0_{(10)} $$ 浮点数除法 浮点数除法类似于乘法，但有一些不同： 符号位计算：与乘法类似，结果的符号由两个操作数的符号位决定。 指数相减：被除数的指数减去除数的指数，再加上偏置值。 尾数相除：被除数的尾数除以除数的尾数。 结果规范化：如果必要，调整结果使其规范化。 舍入处理：如果需要，对结果进行舍入。 检查溢出或下溢：与乘法类似的检查。 假设我们要在单精度浮点数格式下计算： $$ 6.0 ÷ 3.0 =? $$ 第 1 步：转为二进制表示 $$ 6.0_{(10)} = 110_{(2)} \\ 3.0_{(10)} = 11_{(2)} $$ 第 2 步：规范化 $$ 6.0 = 110 = 1.10 × 2^2 \\ 3.0 = 11 = 1.1 × 2^1 $$ 第 3 步：浮点化 $$ 6.0 = 0;00000020;10000000000000000000000 \\ 3.0 = 0;00000001;10000000000000000000000 $$ 第 4 步：除法操作 符号位：正正得正：$0_{(2)} × 0_{(2)} = 0_{(2)}$ 指数减并加上偏置值：$(127+2)-(127+1)+127=128$ 尾数相除：$1.1_{(2)}×1.1_{(2)} = 1.0_{(2)}$ 第 5 步：规范化 这里无需规范化。 第 6 步：舍入 这里无需舍入。 第 7 步：浮点化结果 $$ 0;00000001;00000000000000000000000 $$ 第 8 步：转为十进制 $$ V = (-1)^s×1.frac×2^{(e-127)} \\ = 0 × 1.0 × 2^1 \\ = 10_{(2)} \\ = 2.0_{(10)} $$ Go 语言输出浮点数 func main() var number float32 = 12.375\tfmt.Printf(浮点数：%f , number)\tfmt.Printf(科学计数法：%e , number)\tfmt.Printf(保留 2 位小数：%.2f , number)\tbits := math.Float32bits(number)\tbitsStr := fmt.Sprintf(%.32b, bits)\tfmt.Printf(输出32位浮点表示：%s %s %s , bitsStr[:1], bitsStr[1:9], bitsStr[9:]) math/big Go 语言的 math/big 包提供了对大数的精确计算支持，这些大数的大小超出了标准整数类型（如 int64）或浮点类型（如 float64）的范围。这个包主要用于需要高精度计算的领域，如加密、科学计算等。 主要功能： 算术运算：支持基本的加、减、乘、除等算术运算。 比较操作：可以比较两个大数的大小。 位操作：对大整数进行位操作，如位移、与、或、异或等。 解析和格式化：可以从字符串解析大数，也可以将大数格式化为字符串。 示例： func main() a := big.NewFloat(math.MaxFloat64)\tb := big.NewFloat(math.MaxFloat64)\tsum := big.NewFloat(0)\tsum.Add(a, b)\tfmt.Println(a:, a)\tfmt.Println(sum:, sum)\tsum2 := big.NewFloat(0). SetPrec(15). // 设置精度，prec 越大，精度越高，计算越复杂 SetMode(big.ToZero) // 设置舍入策略\tsum2.Add(a, b)\tfmt.Println(sum2:, sum2)// a: 1.7976931348623157e+308// sum: 3.5953862697246314e+308// sum2: 3.5953e+308 注意事项： 性能考虑：由于 math/big 提供的是任意精度计算，其性能通常低于原生的固定大小数值类型。 内存使用：大数运算可能会消耗更多的内存。 方法链式调用：math/big 的许多方法返回接收者本身，支持链式调用。 参考资料 IEEE-754 深入理解计算机系统 Go 语言底层原理剖析 https://www.bilibili.com/video/BV1zK4y1j7Cn ChatGPT-4","tags":["计算机原理","浮点数"],"categories":["计算机基础"]},{"title":"Go1.21.0 程序启动过程","path":"/2023/12/07/go-start/","content":"版本说明 Go 1.21.0 操作系统：Windows11 Intel64 结论先行 开发关注版 在 Go 语言中，启动顺序通常如下： 导入包：首先，Go 编译器按照源文件中的 import 语句导入所有需要的包。 初始化常量和变量：接着，编译器会初始化包级别（全局）的常量和变量。它们的初始化顺序按照它们在源文件中出现的顺序进行。 执行 init 函数：然后，编译器会执行包级别的 init 函数。如果一个包有多个 init 函数，它们的执行顺序和它们在源文件中出现的顺序一致。 执行 main.main 函数：最后，编译器会执行 main 函数。 深入原理版 命令行参数复制：读取命令行参数，复制到 argc 和 argv。 初始化 g0 栈：g0 是运行时系统的一个特殊的 goroutine，它在程序启动时被创建，用于执行系统调用和协程调度。 runtime.check 运行时检查： 类型长度 指针操作 结构体字段偏移量 CAS atomic 操作 栈大小是否为 2 的幂次。 runtime.args 参数初始化：将 argc 和 argv 的参数赋值到 Go 的变量中。 runtime.osinit 初始化操作系统特点的设置：主要是判断系统字长和 CPU 核数。 runtime.schedinit 初始化调度器： 锁初始化 竞态检测器初始化 调度器设置，设置调度器可以管理的最大线程（M）数目 系统初始化，初始化内存管理、CPU 设置、算法等，这些都是调度器正常工作的基础 设置当前 M 的信号掩码 解析程序参数和环境变量 垃圾收集器初始化 设置 process 的数量 runtime.newproc 创建主协程 g0 并将其放入队列中等待执行。 runtime. mstart 启动调度器：初始化 m0，并调度 g0 去执行 runtime.main。 runtime.main 程序真正入口： runtime.init 启动 gc 执行用户包 init 执行用户函数 main.main 如果只是想对 Go 语言程序的启动过程有一个简单的了解，那么阅读到这里就可以结束了。 Runtime 在分析 Go 程序的启动过程之前，我们需要先了解一下 Go 中的 Runtime。所谓 Runtime，即 Go 的运行时环境，可以理解为 Java 的 JVM、JavaScript 依赖的浏览器内核。 Go 的 Runtime 是一份代码，它会随着用户程序一起打包成二进制文件，随着程序一起运行。 Runtime 具有内存管理、GC、协程、屏蔽不同操作系统调用等能力。 综上，Go 程序的运行都依赖于 Runtime 运行，所以我们在分析 Go 语言程序的启动过程的时候，首先要确定程序的入口，即 Runtime。 这部分代码位于 go 源码中 src/runtime 目录下，当你在本机安装 go 后，你可以进入相应的代码目录下，在 Windows 上，你可以在该目录下运行下面命令： dir | findstr rt0 | findstr amd 这里我们输出 go 官方为多种 amd 处理器架构的操作系统所实现的 runtime，如： -a---- 2023/8/25 23:44 754 rt0_android_amd64.s-a---- 2023/8/25 23:44 399 rt0_darwin_amd64.s-a---- 2023/8/25 23:44 448 rt0_dragonfly_amd64.s-a---- 2023/8/25 23:44 442 rt0_freebsd_amd64.s-a---- 2023/8/25 23:44 311 rt0_illumos_amd64.s-a---- 2023/8/25 23:44 425 rt0_ios_amd64.s-a---- 2023/8/25 23:44 307 rt0_linux_amd64.s-a---- 2023/8/25 23:44 309 rt0_netbsd_amd64.s-a---- 2023/8/25 23:44 311 rt0_openbsd_amd64.s-a---- 2023/8/25 23:44 481 rt0_plan9_amd64.s-a---- 2023/8/25 23:44 311 rt0_solaris_amd64.s-a---- 2023/8/25 23:44 1166 rt0_windows_amd64.s 到这里也就明白了，前面所说的 Go Runtime 能力之 “屏蔽不同操作系统调用能力” 的方式便是针对每一种操作系统单独做实现，最后在编译的时候根据操作系统选择对应的实现即可。 这里我们以 rt0_windows_amd64.s 为例，看看这个文件写了些什么： TEXT _rt0_amd64_windows(SB),NOSPLIT|NOFRAME,$-8\tJMP\t_rt0_amd64(SB) 这里我们可以看到它会直接跳到 _rt0_amd64(SB) 这里，在 Goland IDE 中，你可以双击 Shift 键打开搜索，搜索 TEXT _rt0_amd64，就可以发现这个函数位于 asm_amd64.s 文件中，查看该文件： // _rt0_amd64 is common startup code for most amd64 systems when using// internal linking. This is the entry point for the program from the// kernel for an ordinary -buildmode=exe program. The stack holds the// number of arguments and the C-style argv.TEXT _rt0_amd64(SB),NOSPLIT,$-8\tMOVQ\t0(SP), DI\t// argc\tLEAQ\t8(SP), SI\t// argv\tJMP\truntime·rt0_go(SB) 翻译一下上面的注释：_rt0_amd64 是大多数 amd64 系统在使用内部链接时的通用启动代码。这是 exe 程序从内核进入程序的入口点。堆栈保存了参数的数量和 C 语言风格的 argv。 到这里我们就可以非常确定地找到了对应操作系统的 Go 语言程序启动入口了，接下来只需要沿着该入口继续分析即可。 runtime·rt0_go 上面我们分析到 _rt0_adm64 会 JMP 到 runtime·rt0_go 执行，这个函数也位于 asm_amd64.s 文件中，通过分析这个函数，我们可以了解到 Go 语言程序的整个启动过程。 下面将对这整个函数进行一个概览，后面会对重点过程逐个详述。 TEXT runtime·rt0_go(SB),NOSPLIT|NOFRAME|TOPFRAME,$0\t// 读取命令行参数，复制参数变量 argc 和 argv 到栈上\tMOVQ\tDI, AX // argc\tMOVQ\tSI, BX // argv\tSUBQ\t$(5*8), SP ANDQ\t$~15, SP\tMOVQ\tAX, 24(SP)\tMOVQ\tBX, 32(SP)\t// 从给定的（操作系统）堆栈创建istack。\t// 这是在设置 g0 的堆栈，g0 是运行时系统的一个特殊的 goroutine。\t// 它在程序启动时被创建，用于执行系统调用和协程调度。\t// 这里只是初始化 g0 的堆栈，还没有启动 g0。\tMOVQ\t$runtime·g0(SB), DI\tLEAQ\t(-64*1024)(SP), BX\tMOVQ\tBX, g_stackguard0(DI)\tMOVQ\tBX, g_stackguard1(DI)\tMOVQ\tBX, (g_stack+stack_lo)(DI)\tMOVQ\tSP, (g_stack+stack_hi)(DI)\t// 检查 CPU 的厂商 ID：\t//\t如果没有 CPU 信息，则跳转到 nocpuinfo；\t//\t如果是 Intel 的 CPU，就设置 runtime·isIntel=1，否则跳到 notintel。\tMOVL\t$0, AX\tCPUID\tCMPL\tAX, $0\tJE\tnocpuinfo\tCMPL\tBX, $0x756E6547 // Genu\tJNE\tnotintel\tCMPL\tDX, $0x49656E69 // ineI\tJNE\tnotintel\tCMPL\tCX, $0x6C65746E // ntel\tJNE\tnotintel\tMOVB\t$1, runtime·isIntel(SB)notintel: // 加载 EXA=1 的 cpuid 标志和版本信息\tMOVL\t$1, AX\tCPUID\tMOVL\tAX, runtime·processorVersionInfo(SB)nocpuinfo: // 如果有 _cgo_init 就调用它\tMOVQ\t_cgo_init(SB), AX\tTESTQ\tAX, AX\t// 如果 _cgo_init 不存在，那么跳过后面的代码，\t// 直接进入到 needtls 进行 TLS 的初始化。\t// TLS，全称为Thread-Local Storage（线程局部存储），\t// 是操作系统提供的一种机制，允许每个线程拥有一份自己的数据副本。\t// 这些数据在同一线程的所有函数中都是可见的，但对其他线程是不可见的。\t// 这样，每个线程可以访问和修改自己的数据，而不会影响其他线程。\tJZ\tneedtls\t// 将 setg_gcc 函数的地址加载到 SI 寄存器中。\t// 这是 _cgo_init 函数的第二个参数。\tMOVQ\t$setg_gcc(SB), SI // arg 2: setg_gcc\t// 在使用平台的TLS时不使用这第3和第4个参数。\tMOVQ\t$0, DX MOVQ\t$0, CX#ifdef GOOS_android\tMOVQ\t$runtime·tls_g(SB), DX // arg 3: tls_g\t// arg 4: TLS base, stored in slot 0 (Androids TLS_SLOT_SELF).\t// Compensate for tls_g (+16).\tMOVQ\t-16(TLS), CX#endif#ifdef GOOS_windows\tMOVQ\t$runtime·tls_g(SB), DX // arg 3: tls_g\t// 调整 Win64 的调用约定。\tMOVQ\tCX, R9 // arg 4\tMOVQ\tDX, R8 // arg 3\tMOVQ\tSI, DX // arg 2\tMOVQ\tDI, CX // arg 1#endif\t// 前面 MOVQ\t_cgo_init(SB), AX，这里就是调用 _cgo_init\tCALL\tAX\t// 在 _cgo_init 之后更新 stackguard\tMOVQ\t$runtime·g0(SB), CX\tMOVQ\t(g_stack+stack_lo)(CX), AX\tADDQ\t$const_stackGuard, AX\tMOVQ\tAX, g_stackguard0(CX)\tMOVQ\tAX, g_stackguard1(CX)#ifndef GOOS_windows\tJMP ok#endif// 针对不同操作系统对 TLS 进行设置needtls: #ifdef GOOS_plan9\t// skip TLS setup on Plan 9\tJMP ok#endif#ifdef GOOS_solaris\t// skip TLS setup on Solaris\tJMP ok#endif#ifdef GOOS_illumos\t// skip TLS setup on illumos\tJMP ok#endif#ifdef GOOS_darwin\t// skip TLS setup on Darwin\tJMP ok#endif#ifdef GOOS_openbsd\t// skip TLS setup on OpenBSD\tJMP ok#endif#ifdef GOOS_windows\tCALL\truntime·wintls(SB)#endif\tLEAQ\truntime·m0+m_tls(SB), DI\tCALL\truntime·settls(SB)\t// 检查 TLS 是否正常工作\tget_tls(BX)\tMOVQ\t$0x123, g(BX)\tMOVQ\truntime·m0+m_tls(SB), AX\tCMPQ\tAX, $0x123\tJEQ 2(PC)\tCALL\truntime·abort(SB)ok:\t//设置 g0 和 m0 和 TLS\tget_tls(BX)\tLEAQ\truntime·g0(SB), CX\tMOVQ\tCX, g(BX)\tLEAQ\truntime·m0(SB), AX\tMOVQ\tCX, m_g0(AX)\tMOVQ\tAX, g_m(CX)\tCLD // 下面的 ifdef NEED_xxx 主要是在检查 CPU 是否支持 Go 运行时系统需要的特性。// 我们需要在设置了 TLS 之后做这个，// 如果失败就跳转到 bad_cpu 报告错误。#ifdef NEED_FEATURES_CX\tMOVL\t$0, AX\tCPUID\tCMPL\tAX, $0\tJE\tbad_cpu\tMOVL\t$1, AX\tCPUID\tANDL\t$NEED_FEATURES_CX, CX\tCMPL\tCX, $NEED_FEATURES_CX\tJNE\tbad_cpu#endif#ifdef NEED_MAX_CPUID\tMOVL\t$0x80000000, AX\tCPUID\tCMPL\tAX, $NEED_MAX_CPUID\tJL\tbad_cpu#endif#ifdef NEED_EXT_FEATURES_BX\tMOVL\t$7, AX\tMOVL\t$0, CX\tCPUID\tANDL\t$NEED_EXT_FEATURES_BX, BX\tCMPL\tBX, $NEED_EXT_FEATURES_BX\tJNE\tbad_cpu#endif#ifdef NEED_EXT_FEATURES_CX\tMOVL\t$0x80000001, AX\tCPUID\tANDL\t$NEED_EXT_FEATURES_CX, CX\tCMPL\tCX, $NEED_EXT_FEATURES_CX\tJNE\tbad_cpu#endif#ifdef NEED_OS_SUPPORT_AX\tXORL CX, CX\tXGETBV\tANDL\t$NEED_OS_SUPPORT_AX, AX\tCMPL\tAX, $NEED_OS_SUPPORT_AX\tJNE\tbad_cpu#endif#ifdef NEED_DARWIN_SUPPORT\tMOVQ\t$commpage64_version, BX\tCMPW\t(BX), $13 // cpu_capabilities64 undefined in versions 13\tJL\tbad_cpu\tMOVQ\t$commpage64_cpu_capabilities64, BX\tMOVQ\t(BX), BX\tMOVQ\t$NEED_DARWIN_SUPPORT, CX\tANDQ\tCX, BX\tCMPQ\tBX, CX\tJNE\tbad_cpu#endif\t// 检查完 AMD64 不同操作系统是否支持 Go 运行时系统需要的特性后，\t// 这里执行 runtime·check 对代码做一下运行时检查。\tCALL\truntime·check(SB)\t// 复制 argc（命令行参数的数量）到 AX 寄存器，\t// 然后把 AX 寄存器的值存到栈上。\tMOVL\t24(SP), AX\tMOVL\tAX, 0(SP)\t// 复制 argv（命令行参数的数组）到 AX 寄存器，\t// 然后把 AX 寄存器的值存到栈上。\tMOVQ\t32(SP), AX\tMOVQ\tAX, 8(SP)\t// 调用 runtime·args 函数处理命令行参数。\tCALL\truntime·args(SB)\t// 调用 runtime·osinit 函数初始化操作系统特定的设置。\tCALL\truntime·osinit(SB)\t// 调用 runtime·schedinit 函数初始化调度器。\tCALL\truntime·schedinit(SB) /** 补充：这是该文件下面对 runtime·mainPC 的声明 // mainPC is a function value for runtime.main, to be passed to newproc. // The reference to runtime.main is made via ABIInternal, since the // actual function (not the ABI0 wrapper) is needed by newproc. DATA\truntime·mainPC+0(SB)/8,$runtime·mainABIInternal(SB) */ // 取 runtime·mainPC 的地址，这其实就是 runtime 包下的 main() 方法。 // 它是 Go 语言程序的真正入口，而不是 main.main()。\tMOVQ\t$runtime·mainPC(SB), AX PUSHQ\tAX // 创建一个新的 goroutine 来运行程序的主函数。 // 这里还没有正在的运行，因为调度器还没有启动， // 只是将 runtime.main 放进 goroutine 的 queue 中等待执行。\tCALL\truntime·newproc(SB)\tPOPQ\tAX\t// 调用 runtime·mstart 函数启动 M（machine，代表一个操作系统线程），\t// 开始执行 goroutines。\tCALL\truntime·mstart(SB)\t// 如果 runtime·mstart 函数返回，那么就调用 runtime·abort 函数终止程序。\t// 因为 runtime·mstart 函数在正常情况下是不应该返回的，如果返回了，说明有错误发生。\tCALL\truntime·abort(SB)\t// mstart should never return\tRETbad_cpu: // 当前 CPU 不支持 Go 运行时系统需要的时候的错误报告。\tMOVQ\t$2, 0(SP)\tMOVQ\t$bad_cpu_msg(SB), AX\tMOVQ\tAX, 8(SP)\tMOVQ\t$84, 16(SP)\tCALL\truntime·write(SB)\tMOVQ\t$1, 0(SP)\tCALL\truntime·exit(SB)\tCALL\truntime·abort(SB)\tRET\t// Prevent dead-code elimination of debugCallV2, which is\t// intended to be called by debuggers.\tMOVQ\t$runtime·debugCallV2ABIInternal(SB), AX\tRET 整理一下，runtime·rt0_go 的大体过程如下： 读取命令行参数，复制参数变量 argc 和 argv 到栈上。 初始化 g0 栈，g0 是为了调度协程而产生的协程，是 g0 是运行时系统的一个特殊的 goroutine，它在程序启动时被创建，用于执行系统调用和协程调度。 获取 CPU 信息。 如果存在 _cgo_init，这调用它。 检查并设置线性局部存储（TLS）。 检查 CPU 是否支持 Go 运行时系统需要的特性。 完成运行时系统检查和初始化： 调用 runtime·check 对代码进行运行时检查。 调用 runtime·args 函数处理命令行参数。 调用 runtime·osinit 函数初始化操作系统特定的设置。 调用 runtime·schedinit 函数初始化调度器。 调用 runtime·newproc 创建一个新的 goroutine 来运行程序的主函数。 调用 runtime·mstart 启动当前的 machine，执行 goroutines，执行程序。 一句话：runtime·rt0_go 是 Go 语言运行时的入口点，它负责设置和初始化运行时环境，然后创建 g0 和 m0 来运行程序的主函数。 了解完 Go 程序的整体启动流程后，我们重点来分析一下其中的 runtime·check、runtime·args、runtime·osinit、runtime·schedinit、runtime·newproc 和 runtime·mstart。 对了，充分理解 Go 启动流程，可能需要你对 Go 的 GMP 模型有一定的了解。 // TODO runtime·check 在 Goland IDE 上，我们双击 Shift，全局搜索 runtime·check 会发现找不到函数的实现。 Go 语言的运行时系统大部分是用 Go 自己编写的，但是有一部分，特别是与平台相关的部分，是用汇编语言编写的。在汇编语言中，调用 Go 函数的一种方式是使用 CALL 指令和函数的全名，包括包名和函数名。在这种情况下，runtime·check 就是调用 runtime 包下的 check() 函数。 所以我们需要双击 Shift，搜索 runtine.check，即将 · 换成 .（后面所有函数均是这个道理）。我们会发现 check() 位于 runtime/runtime1.go 中。 func check() var ( a int8 b uint8 c int16 d uint16 e int32 f uint32 g int64 h uint64 i, i1 float32 j, j1 float64 k unsafe.Pointer l *uint16 m [4]byte\t)\ttype x1t struct x uint8 type y1t struct x1 x1t y uint8 var x1 x1t\tvar y1 y1t // 检查各种类型的变量的大小是否符合预期\tif unsafe.Sizeof(a) != 1 throw(bad a) ... // 检查指针操作\tif unsafe.Sizeof(k) != goarch.PtrSize throw(bad k) ...\t// 检查结构体中字段的偏移量是否符合预期 if unsafe.Offsetof(y1.y) != 1 throw(bad offsetof y1.y) // timediv 函数的目的是在 32 位处理器上实现 64 位的除法运算。 // 由于在 32 位处理器上，64 位的除法运算会被转换为 _divv() 函数调用， // 这可能会超出 nosplit 函数的栈限制，所以需要这个特殊的函数来进行处理。 // //go:nosplit 是一个编译器指令，它告诉编译器不要在这个函数中插入栈分割检查。 // 这意味着这个函数必须在当前的栈帧中运行，不能增加栈的大小。 // 如果这个函数需要更多的栈空间，那么它将会导致栈溢出。\tif timediv(12345*1000000000+54321, 1000000000, e) != 12345 || e != 54321 throw(bad timediv) // CAS 操作检查\tvar z uint32\tz = 1\tif !atomic.Cas(z, 1, 2) throw(cas1) ... // 检查 atomic 原子操作\tm = [4]byte1, 1, 1, 1\tatomic.Or8(m[1], 0xf0)\tif m[0] != 1 || m[1] != 0xf1 || m[2] != 1 || m[3] != 1 throw(atomicor8) // 测试浮点数 NaN（Not a Number）的行为\t*(*uint64)(unsafe.Pointer(j)) = ^uint64(0)\tif j == j throw(float64nan) if !(j != j) throw(float64nan1) // 测试 64 位原子操作\ttestAtomic64() // 检查栈大小是否是 2 的 n 次幂\tif fixedStack != round2(fixedStack) throw(FixedStack is not power-of-2) // 上报编代码的运行时检查中是否有异常\tif !checkASM() throw(assembly checks failed) 综上：runtime·check 主要是做一些运行时的检查。 使用 unsafe.Sizeof 函数检查各种类型的变量的大小是否符合预期。 使用 unsafe.Offsetof 函数检查结构体中字段的偏移量是否符合预期。 测试 timediv 函数检查在 32 位机器上进行 64 位除法运算的结果是否符合预期。 使用 atomic.Cas 函数（Compare and Swap）进行原子比较和交换测试。 使用 atomic.Or8 和 atomic.And8 函数进行原子位操作测试。 测试浮点数 NaN（Not a Number）的行为。 调用 testAtomic64 函数测试 64 位的原子操作。 检查 fixedStack 栈大小是否是 2 的幂。 调用 checkASM 函数检查汇编代码检查运行时中是否有异常。 runtime·args package runtimevar (\targc int32\targv **byte)func args(c int32, v **byte) argc = c\targv = v\tsysargs(c, v) 这个函数比较简单，就是将命令行参数拷贝到 runtime 包下的全局变量 argc 和 argv 上。后面在 shcedinit() 函数中会调用 goargs() 来遍历 argv 将参数复制到 slice 上。 func goargs() if GOOS == windows return argslice = make([]string, argc)\tfor i := int32(0); i argc; i++ argslice[i] = gostringnocopy(argv_index(argv, i)) runtime·osinit 这里函数主要是初始化操作系统特点的设置，可以看到这里针对不同操作系统都做了实现： 这里我们以 os_windows.go 为例： func osinit() // 获取 asmstdcall 函数的地址，并将其转换为一个不安全的指针。 // 这通常在需要直接操作内存或进行系统调用的时候使用。\tasmstdcallAddr = unsafe.Pointer(abi.FuncPCABI0(asmstdcall)) // 加载一些可选的系统调用。\tloadOptionalSyscalls() // 阻止显示错误对话框。这可能是为了防止在出现错误时打断用户。\tpreventErrorDialogs() // 初始化异常处理器，用于处理运行时发生的异常。\tinitExceptionHandler() // 初始化高分辨率计时器，用于精确的时间测量。\tinitHighResTimer()\ttimeBeginPeriodRetValue = osRelax(false) // 初始化系统目录\tinitSysDirectory() // 启用长路径支持。 // 在 Windows 中，路径的长度通常限制为 260 个字符。启用长路径支持可以突破这个限制。\tinitLongPathSupport() // 码获取处理器的数量并将其赋给 ncpu。 ncpu = getproccount() // 获取内存页的大小并将其赋给 physPageSize，为了后面进行内存管理。\tphysPageSize = getPageSize() // 调用 SetProcessPriorityBoost 函数，禁用动态优先级提升。 // 在 Windows 中，动态优先级提升是一种机制，可以根据线程的类型和行为自动调整其优先级。 // 但在 Go 的环境中，所有的线程都是等价的，都可能进行 GUI、IO、计算等各种操作， // 所以动态优先级提升可能会带来问题，因此这里选择禁用它。\tstdcall2(_SetProcessPriorityBoost, currentProcess, 1) runtime·schedinit ★ 这个函数就非常重要了，从名字就可以看出来，这是 Go 语言调度器的初始化过程。这个函数位于：runtime/proc.go。 我们可以先来看看 schedinit() 的函数注释，这里也透露了 Go 语言程序的启动流程的核心顺序。 // The bootstrap sequence is: 启动流程顺序：////\tcall osinit 1. 调用 osinit//\tcall schedinit 2. 调用 schedinit//\tmake queue new G 3. 创建一个协程 G//\tcall runtime·mstart 4. 调用 mstart//// The new G calls runtime·main. 5. G 执行 runtime.mainfunc schedinit() 接下来我们详细来看看 schedinit() 都做了些什么： func schedinit() // 初始化各种锁，其中 lockRankXXX 指定锁的级别。\tlockInit(sched.lock, lockRankSched)\tlockInit(sched.sysmonlock, lockRankSysmon)\tlockInit(sched.deferlock, lockRankDefer)\tlockInit(sched.sudoglock, lockRankSudog)\tlockInit(deadlock, lockRankDeadlock)\tlockInit(paniclk, lockRankPanic)\tlockInit(allglock, lockRankAllg)\tlockInit(allpLock, lockRankAllp)\tlockInit(reflectOffs.lock, lockRankReflectOffs)\tlockInit(finlock, lockRankFin)\tlockInit(cpuprof.lock, lockRankCpuprof)\ttraceLockInit()\tlockInit(memstats.heapStats.noPLock, lockRankLeafRank)\t// 如果启用了竞态检测，则初始化竞态检测器， // 即我们使用 -race 的时候会执行这里。\tgp := getg()\tif raceenabled gp.racectx, raceprocctx0 = raceinit() // 限制 M 的数量，即线程的数量。 // maxmcount int32 // maximum number of ms allowed (or die)\tsched.maxmcount = 10000\t// 将调度器设置为初始暂停状态，在必要的初始化完成之前不调度任何协程。\tworldStopped() // 进行一系列的系统初始化（内存管理、CPU 设置、栈、算法等）\tmoduledataverify()\tstackinit()\tmallocinit()\tgodebug := getGodebugEarly()\tinitPageTrace(godebug) // must run after mallocinit but before anything allocates\tcpuinit(godebug) // must run before alginit\talginit() // maps, hash, fastrand must not be used before this call\tfastrandinit() // must run before mcommoninit\tmcommoninit(gp.m, -1)\tmodulesinit() // provides activeModules\ttypelinksinit() // uses maps, activeModules\titabsinit() // uses activeModules\tstkobjinit() // must run before GC starts // 设置和保存当前 M 的信号掩码\tsigsave(gp.m.sigmask)\tinitSigmask = gp.m.sigmask // 解析程序参数和环境变量\tgoargs()\tgoenvs()\tsecure()\tparsedebugvars() // 初始化垃圾回收器\tgcinit()\t// 如果设置了 disableMemoryProfiling，即禁用内存分析， // 则将 MemProfileRate 置为 0，关闭内存分析。\tif disableMemoryProfiling MemProfileRate = 0 // 锁定调度器，处理环境变量 GOMAXPROCS，这是开发者可以设置的允许的最多的 P 的数量。\tlock(sched.lock)\tsched.lastpoll.Store(nanotime())\tprocs := ncpu\tif n, ok := atoi32(gogetenv(GOMAXPROCS)); ok n 0 procs = n if procresize(procs) != nil throw(unknown runnable goroutine during bootstrap) unlock(sched.lock)\t// 将调度器设置为开始状态。\tworldStarted() // 确保构建版本和模块信息被保留在最终的二进制文件中。\tif buildVersion == buildVersion = unknown if len(modinfo) == 1 modinfo = 总结：schedinit 是 Go 语言运行时中的一个函数，负责初始化调度器及其相关组件，如锁、信号掩码、内存分配、以及其他系统级别的设置，确保并发执行环境的正确配置和高效运作。 具体过程如下： 锁初始化: 函数开始时，通过 lockInit 调用初始化了多个锁。在 Go 的调度器中，锁用于保护共享资源和调度数据结构，确保在多个线程或协程中的安全访问。每个锁都有一个特定的级别，这有助于防止死锁。 竞态检测器初始化: 如果启用了竞态检测 (raceenabled)，则初始化竞态上下文。这对于在开发阶段检测和避免竞态条件非常重要。 调度器设置: sched.maxmcount = 10000 设置调度器可以管理的最大线程（M）数目，这对于控制资源使用和性能调优很重要。 worldStopped() 将调度器设置为初始暂停状态，在必要的初始化完成之前不调度任何协程。 系统初始化: 接下来调用一系列函数（如 moduledataverify, mallocinit, cpuinit, alginit 等）来初始化内存管理、CPU 设置、算法等，这些都是调度器正常工作的基础。 环境和调试变量设置: 解析程序参数、环境变量、安全设置和调试变量。 垃圾收集器初始化: gcinit() 初始化垃圾收集器，这是 Go 运行时的关键组成部分，负责自动内存管理。 内存分析设置: 根据 disableMemoryProfiling 标志决定是否关闭内存分析功能。 处理器数量设置和调度器锁: 锁定调度器来安全地基于环境变量 GOMAXPROCS 设置处理器（procs）数量。 使用 procresize 函数根据处理器数量调整调度器的内部结构。 最终步骤和错误检查: 调用 worldStarted() 表示调度器已准备好开始调度协程。 检查和设置构建版本和模块信息，保证这些信息在最终的二进制文件中。 这里有几个地方比较有趣，我们来做一下简单的了解。（可跳过） 初始化锁 lockInit(mutex, rank) 我们知道 lockInit(mutex,rank) 是用来初始化锁的，第 2 个参数 rank 便是锁的等级。如果这个时候你链接到 lcokInit 实现的地方，你会发现默认会跳到 lockrank_off.go，而且你会发现，它的实现是空的： //go:build !goexperiment.staticlockrankingpackage runtimefunc lockInit(l *mutex, rank lockRank) 其实 lockInit 还有另外一个实现，在 lockrank_on.go 文件中： //go:build goexperiment.staticlockrankingpackage runtimeconst staticLockRanking = truefunc getLockRank(l *mutex) lockRank return l.rank 这什么意思呢？通过文件名称我们其实就可以猜到了，lockrank_off.go 是提供了无锁级别的锁，而 lockrank_on.go 是提供了有锁级别的锁。至于应该采用哪一个，是通过 go build 中的 goexperiment.staticlockranking 参数来控制的。 这里涉及一个概念，叫做锁排序（Lock Ranking）： 锁排序是一种用于避免死锁的技术。在这种机制中，每个锁都被赋予一个等级（或称为 “rank”），并且有规则确保锁的获取遵循这些等级的顺序。 通常，这意味着一个线程在获取等级较低的锁之前，必须先释放所有等级较高的锁。这样可以防止死锁，因为它避免了循环等待条件的发生。 Go 语言中锁的等级和顺序定义在 lockrank.go 文件中。 锁排序的作用： 在 Go 的并发模型中，锁是同步共享资源访问的重要机制。lockInit 函数在运行时初始化锁，为其分配等级，有助于维护程序的稳定性和性能。 锁排序功能的开启或关闭取决于是否需要额外的死锁检测。在开发和调试阶段，开启锁排序可以帮助发现死锁问题。然而，它可能引入额外的性能开销，因此在生产环境中可能会被关闭。 最后我们来看一下 schedinit() 都初始化了哪些锁： Lock Description sched.lock 初始化调度器的主锁。这个锁用于控制对调度器的访问，保证调度过程的正确性。 sched.sysmonlock 系统监控锁，用于保护系统监控相关的数据结构。 sched.deferlock 用于控制延迟执行函数列表的锁。 sched.sudoglock sudog 是 Go 中表示等待通信的 goroutine 的结构。这个锁保护与 sudog 相关的操作。 deadlock 可能用于检测或防止死锁的锁。 paniclk 在处理 panic 时使用的锁。 allglock 用于控制对所有 goroutine 列表的访问。 allpLock 控制对所有处理器（P）的访问。 reflectOffs.lock 用于反射操作的锁。 finlock 管理终结器列表的锁。 cpuprof.lock 用于 CPU 分析数据的锁。 traceLockInit() 专门用于追踪系统的锁初始化函数。 memstats.heapStats.noPLock 这是一个特殊的锁，被标记为 lockRankLeafRank，意味着它应该是锁层级中的最末端（leaf）。这样的锁应该只在非常短的关键部分中使用，以避免成为死锁的源头。 信号掩码 initSigmask 这两行代码是在搞啥呢？ sigsave(gp.m.sigmask)initSigmask = gp.m.sigmask sigmask 的中文意思是 信号掩码。 先看一下源码中 initSigmast 的注释： // Value to use for signal mask for newly created Ms.var initSigmask sigset initSigmask 是一个变量，存储着用于新创建的 M（Machine，即操作系统线程）的初始信号掩码。 什么是信号掩码： 信号掩码是操作系统中用于控制信号传递给进程或线程的一种机制。它允许进程或线程指定哪些信号可以被阻塞（暂时忽略）或允许。在多线程环境中，这个机制尤其重要，因为它帮助确保线程安全地处理信号。 信号掩码的作用： 信号掩码定义了一组信号，这些信号在特定时间内不会传递给进程或线程，即使这些信号发生了也会被系统挂起。这允许进程或线程在一个稳定的状态下运行，不被特定信号中断。 这种机制对于处理那些可能在关键操作期间导致不稳定状态的信号特别重要。 信号掩码的重要性： 在多线程程序中，不同的线程可能需要响应不同的信号或以不同方式处理相同的信号。通过为每个线程设置适当的信号掩码，可以确保线程只处理对它们来说重要的信号。 这有助于防止线程在执行关键代码时被不相关的信号打断。 sigsave(gp.m.sigmask)： sigsave(gp.m.sigmask) 这个调用是在保存当前 M 的信号掩码。gp 指的是当前的 goroutine，gp.m 是该 goroutine 正在运行的 M（操作系统线程）。 sigsave 函数的作用是将 gp.m 的当前信号掩码保存到提供的地址（在这里是 gp.m.sigmask）。这对于恢复线程的信号掩码到一个已知状态是非常有用的。 initSigmask = gp.m.sigmask： 这一行将 gp.m 的信号掩码赋值给 initSigmask。这意味着 initSigmask 现在保存了当前 M 的信号掩码，这个掩码将被用作新创建的 M 的初始信号掩码。 这是一个重要的步骤，因为它确保了所有新创建的 M 都将具有与当前 M 相同的信号处理行为。 这意味着所有新线程都会以一致的信号掩码启动，这有助于避免由于不同线程处理信号的不一致性导致的问题。 总体来说，Go 语言在其运行时中这样处理信号掩码，是为了确保在并发执行和线程调度中能够安全、一致地处理信号，这对于维护高效和稳定的运行时环境至关重要。 初始化垃圾回收器 gcinit() func gcinit() // 检查 workbuf 结构体的大小是否等于预期的 _WorkbufSize。 // 如果不是，抛出异常。这是为了确保 workbuf 的大小是最优的， // workbuf 用于垃圾回收过程中的内部工作。 if unsafe.Sizeof(workbuf) != _WorkbufSize throw(size of Workbuf is suboptimal) // 第一个垃圾回收周期不进行扫描操作。 // 在 Go 的垃圾回收过程中，扫描是回收前清理内存的重要步骤。 sweep.active.state.Store(sweepDrainedMask) // 使用环境变量 GOGC 和 GOMEMLIMIT 来设置初始的垃圾回收百分比和内存限制。 gcController.init(readGOGC(), readGOMEMLIMIT()) // 初始化用于控制垃圾回收工作流程的信号量。 // 这些信号量用于同步垃圾回收过程中的不同阶段。 work.startSema = 1 work.markDoneSema = 1 // 初始化了用于垃圾回收过程中的各种锁。 // 这些锁用于保护垃圾回收相关数据结构的并发访问，确保垃圾回收过程的线程安全。 lockInit(work.sweepWaiters.lock, lockRankSweepWaiters) lockInit(work.assistQueue.lock, lockRankAssistQueue) lockInit(work.wbufSpans.lock, lockRankWbufSpans)func (c *gcControllerState) init(gcPercent int32, memoryLimit int64) // 设置 heapMinimum 为默认的最小堆大小。 // 这是垃圾回收器考虑启动新回收周期前的最小堆内存大小。\tc.heapMinimum = defaultHeapMinimum // 将 triggered 设置为 uint64 的最大值。 // 这个字段用于表示触发垃圾回收的内存阈值， // 这里的设置意味着在初始状态下不会自动触发垃圾回收\tc.triggered = ^uint64(0) // 设置垃圾回收的百分比阈值。 // gcPercent 参数表示触发垃圾回收的内存增长百分比。 // 这个设置控制了堆内存增长到多少百分比时会触发垃圾回收。\tc.setGCPercent(gcPercent) // 设置内存限制。 // memoryLimit 参数可能表示堆内存的最大限制， // 用于控制垃圾回收器在内存使用方面的行为。\tc.setMemoryLimit(memoryLimit) // 提交垃圾回收控制器的当前设置，并指示第一次垃圾回收周期没有扫描（sweep）阶段。 // 在 Go 的垃圾回收中，扫描是回收周期的一部分，这里指明在第一次垃圾回收时跳过扫描阶段。\tc.commit(true) runtime·newproc ★ 初始化完调度器后，就进入到创建 g0 的阶段了，我们需要一个协程来运行程序的入口：runtime.main。 newproc() 的作用如注释所说：创建一个新的 goroutine 来执行 fn，并将它放入等待运行的 g 队列中。 // Create a new g running fn.// Put it on the queue of gs waiting to run.// The compiler turns a go statement into a call to this.func newproc(fn *funcval) gp := getg() // 获取当前协程\tpc := getcallerpc() // 获取当前程序计数器\tsystemstack(func() // 在系统栈上执行新 goroutine 的创建 newg := newproc1(fn, gp, pc)\t// 创建新 goroutine pp := getg().m.p.ptr()\t// 获取当前 M 绑定的 P runqput(pp, newg, true)\t// 将新创建的 goroutine 放入 P 的本地队列中 if mainStarted wakep()\t// 如果主程序已经启动，则唤醒或启动一个 M，以确保新的 goroutine 有机会被执行 ) 重点来看一下 newproc1() 和 runqput()。 创建协程 newproc1() 这段代码的主要作用是创建一个新的 goroutine 并设置其初始状态，以便它可以被调度器安排运行。它处理了从分配 goroutine 的内存到设置其栈空间和调度信息等一系列步骤。 // 创建一个新的 goroutine，状态为 _Grunnable，从函数 fn 开始执行。// callerpc 是创建此 goroutine 的 go 语句的地址。// 调用者负责将新的 g 添加到调度器中。func newproc1(fn *funcval, callergp *g, callerpc uintptr) *g if fn == nil fatal(go of nil func value) // 如果 fn 是 nil，抛出致命错误 mp := acquirem() // 禁用抢占，因为我们在局部变量中持有 M 和 P\tpp := mp.p.ptr()\tnewg := gfget(pp) // 尝试从 P 的空闲列表中获取一个 g\tif newg == nil newg = malg(stackMin) // 如果没有空闲的 g，创建一个新的 casgstatus(newg, _Gidle, _Gdead) // 将 g 的状态从 _Gidle 改为 _Gdead allgadd(newg) // 将新的 g 添加到所有 goroutine 的列表中 if newg.stack.hi == 0 throw(newproc1: newg missing stack) // 如果新的 g 没有栈，抛出异常 if readgstatus(newg) != _Gdead throw(newproc1: new g is not Gdead) // 确保新的 g 的状态为 _Gdead totalSize := uintptr(4*goarch.PtrSize + sys.MinFrameSize) // 计算额外的栈空间大小\ttotalSize = alignUp(totalSize, sys.StackAlign) // 栈空间对齐\tsp := newg.stack.hi - totalSize // 设置栈指针\tspArg := sp\tif usesLR *(*uintptr)(unsafe.Pointer(sp)) = 0 // 针对 LR 架构，设置调用者的 LR prepGoExitFrame(sp) spArg += sys.MinFrameSize memclrNoHeapPointers(unsafe.Pointer(newg.sched), unsafe.Sizeof(newg.sched)) // 清除调度器的内存\tnewg.sched.sp = sp // 设置调度器的栈指针\tnewg.stktopsp = sp // 设置栈顶指针\t// 设置调度器的程序计数器，+PCQuantum 使得前一个指令在同一函数中\tnewg.sched.pc = abi.FuncPCABI0(goexit) + sys.PCQuantum newg.sched.g = guintptr(unsafe.Pointer(newg)) // 设置调度器的 g 指针\tgostartcallfn(newg.sched, fn) // 启动新的 g 执行函数 fn\tnewg.parentGoid = callergp.goid // 设置新 g 的父 goroutine ID\tnewg.gopc = callerpc // 设置新 g 的创建位置\tnewg.ancestors = saveAncestors(callergp) // 保存祖先信息\tnewg.startpc = fn.fn // 设置新 g 的起始函数地址\tif isSystemGoroutine(newg, false) sched.ngsys.Add(1) // 如果是系统 goroutine，增加计数 else if mp.curg != nil newg.labels = mp.curg.labels // 只有用户 goroutines 继承 pprof 标签 if goroutineProfile.active newg.goroutineProfiled.Store(goroutineProfileSatisfied) // 标记不需要纳入 goroutine 分析 newg.trackingSeq = uint8(fastrand()) // 设置追踪序列号\tif newg.trackingSeq%gTrackingPeriod == 0 newg.tracking = true // 是否启用追踪 casgstatus(newg, _Gdead, _Grunnable) // 将新 g 的状态从 _Gdead 改为 _Grunnable\tgcController.addScannableStack(pp, int64(newg.stack.hi-newg.stack.lo)) // 将新 g 的栈添加到可扫描栈列表\tif pp.goidcache == pp.goidcacheend pp.goidcache = sched.goidgen.Add(_GoidCacheBatch) // 分配新的 goroutine ID pp.goidcache -= _GoidCacheBatch - 1 pp.goidcacheend = pp.goidcache + _GoidCacheBatch newg.goid = pp.goidcache // 设置新 g 的 ID\tpp.goidcache++\tif raceenabled newg.racectx = racegostart(callerpc) // 设置竞态检测上下文 newg.raceignore = 0 if newg.labels != nil racereleasemergeg(newg, unsafe.Pointer(labelSync)) // 同步竞态检测和信号处理 if traceEnabled() traceGoCreate(newg, newg.startpc) // 记录追踪信息 releasem(mp) // 释放当前 M\treturn newg // 返回新创建的 goroutine 有几个地方比较有趣，我们可以来研究一下。 获取 g // The minimum size of stack used by Go codestackMin = 2048func newproc1() ... newg := gfget(pp) // 尝试从 P 的空闲列表中获取一个 g if newg == nil newg = malg(stackMin) // 如果没有空闲的 g，创建一个新的 casgstatus(newg, _Gidle, _Gdead) // 将 g 的状态从 _Gidle 改为 _Gdead allgadd(newg) // 将新的 g 添加到所有 goroutine 的列表中 ... 这里可以看出，Go 语言每个新创建的协程分配的默认大小就是 stackMin，即 2KB。 其实 statck.go 还定义了另外一个字段，即栈最大为 2GB，所以我们可以知道，Go 协程栈大小 [2KB, 2GB]。 var maxstacksize uintptr = 1 20 // enough until runtime.main sets it for real 另外我们可以看出来，Go 语言会尽可能重用现有的空闲 goroutine，以减少内存分配的开销，提供创建新 goroutine 的效率。 重用的具体逻辑在 gfget(pp) 中，这个函数的作用是从与当前 M 绑定的 P 的空闲列表中获取一个空闲的 g，如果没有，则尝试从全局空闲列表中获取 g。 // Get from gfree list.// If local list is empty, grab a batch from global list.func gfget(pp *p) *g retry: // 如果当前 P 的空闲队列为空，并且全局空闲队列中有可用的 goroutine，则进行下列操作。\tif pp.gFree.empty() (!sched.gFree.stack.empty() || !sched.gFree.noStack.empty()) // 枷锁全局空闲列表 lock(sched.gFree.lock) // 将最多 32 个空闲的 g 从全局列表中移动到当前 P 的空闲列表 for pp.gFree.n 32 // 优先选择有栈的 g gp := sched.gFree.stack.pop() if gp == nil // 实在没有栈，也可以接受 gp = sched.gFree.noStack.pop() if gp == nil break sched.gFree.n-- pp.gFree.push(gp) pp.gFree.n++ unlock(sched.gFree.lock) // 一直尝试，知道 P 有空闲 g，或者全局列表也没有空闲 g 了，就退出 for 循环，进行下面的操作。 goto retry // 从 P 的空闲列表中取出一个 g\tgp := pp.gFree.pop()\tif gp == nil return nil pp.gFree.n-- // 检查获取到的 g 是否有一个有效的栈，如果栈不符合预期的大小，则释放旧栈\tif gp.stack.lo != 0 gp.stack.hi-gp.stack.lo != uintptr(startingStackSize) systemstack(func() stackfree(gp.stack) gp.stack.lo = 0 gp.stack.hi = 0 gp.stackguard0 = 0 ) // 如果 g 没有有效的栈，或者刚刚被释放了，则分配新栈给 g\tif gp.stack.lo == 0 systemstack(func() gp.stack = stackalloc(startingStackSize) ) gp.stackguard0 = gp.stack.lo + stackGuard else if raceenabled racemalloc(unsafe.Pointer(gp.stack.lo), gp.stack.hi-gp.stack.lo) if msanenabled msanmalloc(unsafe.Pointer(gp.stack.lo), gp.stack.hi-gp.stack.lo) if asanenabled asanunpoison(unsafe.Pointer(gp.stack.lo), gp.stack.hi-gp.stack.lo) return gp 其中 startingStackSize 表示新创建的 goroutine 开始时的栈大小。它被初始化为 fixedStack 的值。startingStackSize 在每次垃圾回收（GC）后可能会更新，以反映在 GC 过程中扫描的栈的平均大小。 var startingStackSize uint32 = fixedStackfunc gcComputeStartingStackSize() ... // 求出栈平均大小\tavg := scannedStackSize/scannedStacks + stackGuard\tif avg uint64(maxstacksize) avg = uint64(maxstacksize) if avg fixedStack avg = fixedStack // 更新 startingStackSize\tstartingStackSize = uint32(round2(int32(avg))) 初始化协程栈 totalSize := uintptr(4*goarch.PtrSize + sys.MinFrameSize) // 计算额外的栈空间大小totalSize = alignUp(totalSize, sys.StackAlign) // 栈空间对齐sp := newg.stack.hi - totalSize // 设置栈指针spArg := spif usesLR *(*uintptr)(unsafe.Pointer(sp)) = 0 // 针对 LR 架构，设置调用者的 LR prepGoExitFrame(sp) spArg += sys.MinFrameSize 1. 计算额外的栈空间大小: totalSize := uintptr(4*goarch.PtrSize + sys.MinFrameSize) 这行代码计算新 goroutine 需要的额外栈空间大小。 4*goarch.PtrSize 是为了留出足够的空间来存储函数调用过程中的一些额外信息（例如返回地址、寄存器保存等）。 sys.MinFrameSize ：是系统为每个栈帧保留的最小空间，用于存储一些特定于架构的信息。 // MinFrameSize is the size of the system-reserved words at the bottom// of a frame (just above the architectural stack pointer).// It is zero on x86 and PtrSize on most non-x86 (LR-based) systems.// On PowerPC it is larger, to cover three more reserved words:// the compiler word, the link editor word, and the TOC save word.const MinFrameSize = goarch.MinFrameSize goarch.PtrSize：指针大小。 // PtrSize is the size of a pointer in bytes - unsafe.Sizeof(uintptr(0)) but as an ideal constant.// It is also the size of the machines native word size (that is, 4 on 32-bit systems, 8 on 64-bit).const PtrSize = 4 (^uintptr(0) 63) 2. 栈空间对齐: totalSize = alignUp(totalSize, sys.StackAlign): 根据系统的栈对齐要求调整 totalSize 的大小。栈对齐是为了确保栈上的数据按照硬件要求的边界对齐，这通常是为了提高访问效率或满足特定的硬件要求。 3. 设置栈指针 (sp): sp := newg.stack.hi - totalSize: 计算新 goroutine 的栈顶指针。newg.stack.hi 是分配给这个 goroutine 的栈的高地址（栈顶），从这里向下分配空间。通过从栈顶地址减去计算出的 totalSize，设置新的栈顶位置。 4. 处理链接寄存器（LR）架构: 在某些架构上（如 ARM、PowerPC），函数调用的返回地址不是存储在栈上，而是存储在一个名为链接寄存器（LR）的特殊寄存器中。这几行代码检查是否在这种架构上运行 (usesLR)。 如果是，则在栈上的适当位置存储一个 0 值作为返回地址，并调用 prepGoExitFrame 来准备 goroutine 退出时的栈帧。这是为了模拟在非 LR 架构上的栈帧结构。 spArg 是一个辅助变量，用于记录参数传递时应该使用的栈地址。在 LR 架构上，它需要根据 sys.MinFrameSize 进行调整，以保证函数参数的正确位置。 放入队列 runqput() runqput() 负责将 goroutine (gp) 放入到本地可运行队列或全局队列中。 // runqput 尝试将 g 放入当前的执行队列中// 如果 next=false，则将 g 放在队列末尾，// 如果 next=true，则将 g 放在 pp.runnext，即下一个要执行的 goroutine。// 如果本地队列满了，则加入到全局队列。func runqput(pp *p, gp *g, next bool) // 如果启用了随机调度器 (randomizeScheduler)， // 并且调用者指示将 goroutine 放入 runnext 位置 (next 为 true)， // 则有 50% 的概率将 next 设置为 false，以随机地将 goroutine 放入队列尾部。\tif randomizeScheduler next fastrandn(2) == 0 next = false if next retryNext: // 如果为 next，则尝试将 p 放入 pp.runnext 插槽 oldnext := pp.runnext if !pp.runnext.cas(oldnext, guintptr(unsafe.Pointer(gp))) goto retryNext // 如果这个槽之前没有被占用，则直接返回 if oldnext == 0 return // 如果这个槽之前已经被占用了，则剔除旧 goroutine， // 然后进行下面的逻辑，即将其放入常规的运行队列中 gp = oldnext.ptr()\tretry:\th := atomic.LoadAcq(pp.runqhead) // 取出队列头部\tt := pp.runqtail // 取出队列尾部 // 如果还没满，则将 gp 放入本地队列中（可能是新 g，也可能是之前在 runnext 的 g\tif t-h uint32(len(pp.runq)) pp.runq[t%uint32(len(pp.runq))].set(gp) atomic.StoreRel(pp.runqtail, t+1) // store-release, makes the item available for consumption return // 如果本地队列满了，则尝试将其放入全局队列中\tif runqputslow(pp, gp, h, t) return goto retry 其中 runqputslow() 不仅会尝试将 gp 放入全局队列中，还会尝试将本地队列的部分 g 放入全局队列中，因为这个时候本地队列已经满了，放入全局队列中就有机会被其他 P 所调度，减少饥饿。 // Put g and a batch of work from local runnable queue on global queue.// Executed only by the owner P.func runqputslow(pp *p, gp *g, h, t uint32) bool // 初始化一个数组 batch，大小为本地队列的一半， // 它用来存储将要移动到全局队列的 goroutine。\tvar batch [len(pp.runq)/2 + 1]*g\tn := t - h\tn = n / 2 // 只有本地队列满才这么操作\tif n != uint32(len(pp.runq)/2) throw(runqputslow: queue is not full) // 将本地队列一半的 g 复制到 batch 中\tfor i := uint32(0); i n; i++ batch[i] = pp.runq[(h+i)%uint32(len(pp.runq))].ptr() // CAS 更新本地队列头指针，如果失败，则返回\tif !atomic.CasRel(pp.runqhead, h, h+n) // cas-release, commits consume return false // 将当前要调度的 gp 放入 batch 的末尾\tbatch[n] = gp // 如果启动了随机调度器，则随机化 batch 数组\tif randomizeScheduler for i := uint32(1); i = n; i++ j := fastrandn(i + 1) batch[i], batch[j] = batch[j], batch[i] // 链接 goroutine，以便它们可以作为一个连续的队列被处理\tfor i := uint32(0); i n; i++ batch[i].schedlink.set(batch[i+1]) var q gQueue\tq.head.set(batch[0])\tq.tail.set(batch[n])\t// 将 batch 放入全局队列中\tlock(sched.lock)\tglobrunqputbatch(q, int32(n+1))\tunlock(sched.lock)\treturn true 总结 到这里我们可以总结，runtime·newproc 的核心功能就是初始化一个新的 goroutine，并将其放入队列中进行调度。其中 newproc1() 会新建或复用空闲的 goroutine，然后初始化其栈空间和调度信息； runqput() 会优先将 g 放入本地队列中调度，如果本地队列满了，会连带本地队列中一半的 goroutine 一起转移到全局队列中调度。 runtime·mstart 调度器 m0 和主协程 g0 都初始化完毕了，这个时候就可以启动调度器来调度协程工作了。 我们找到 mstart() 函数的声明，位于：proc.go // mstart is the entry-point for new Ms.// It is written in assembly, uses ABI0, is marked TOPFRAME, and calls mstart0.func mstart() 可以看到，这里 mstart() 是没用函数体的，通过注释我们可以知道这个函数的实现部分是用汇编实现的，Go 编译器会在编译的时候往这个函数里面插入相关指令。另外注释也告诉我们，这里最终其实就是调用 mstart0() 函数。我们找到相关的汇编代码，果然是如此： TEXT runtime·mstart(SB),NOSPLIT|TOPFRAME,$0\tCALL\truntime·mstart0(SB)\tRET // not reached mstart0() 就在 mstart() 的下面： func mstart0() gp := getg()\tosStack := gp.stack.lo == 0\tif osStack // Initialize stack bounds from system stack. // Cgo may have left stack size in stack.hi. // minit may update the stack bounds. size := gp.stack.hi if size == 0 size = 8192 * sys.StackGuardMultiplier gp.stack.hi = uintptr(noescape(unsafe.Pointer(size))) gp.stack.lo = gp.stack.hi - size + 1024 // Initialize stack guard so that we can start calling regular\t// Go code.\tgp.stackguard0 = gp.stack.lo + stackGuard\t// This is the g0, so we can also call go:systemstack\t// functions, which check stackguard1.\tgp.stackguard1 = gp.stackguard0\tmstart1()\t// Exit this thread.\tif mStackIsSystemAllocated() // Windows, Solaris, illumos, Darwin, AIX and Plan 9 always system-allocate // the stack, but put it in gp.stack before mstart, // so the logic above hasnt set osStack yet. osStack = true mexit(osStack) 简单过一下 mstart0() 后，我们会发现其实 mstart0() 也不是关键，关键是 mstart1()。 我们先对 mstart0() 做一个简单的总结：它是 Go 语言运行时中新 M（操作系统线程）的入口点。这个函数负责初始化新线程的栈和一些其他设置，然后调用 mstart1 来继续线程的初始化过程。 我们继续来看 mstart1()，它用于进一步设置新线程并最终将控制权交给调度器。 func mstart1() // 获取当前协程\tgp := getg() // 只有 g0 协程可以执行 mstart1()，即启动 m0。 // 每一个 M 都有一个特殊的 goroutine，其被称为 g0，它用于执行系统级任务。\tif gp != gp.m.g0 throw(bad runtime·mstart) // 设置 gp.sched 调度信息，以便 goroutine 能够在未来被正确调度。\tgp.sched.g = guintptr(unsafe.Pointer(gp))\t// goroutine 指针\tgp.sched.pc = getcallerpc()\t// 程序计数器\tgp.sched.sp = getcallersp()\t// 栈指针 // 初始化于汇编相关的设置。\tasminit() // 初始化当前 M 的线程局部存储和其他线程相关的数据。\tminit()\t// 如果是 m0，则安装信号处理器\tif gp.m == m0 mstartm0() // 如果 M 启动时配置了函数，则调用它\tif fn := gp.m.mstartfn; fn != nil fn() // 如果当前现场不是 m0（主线程），则获取一个 P，准备开始执行 goroutine\tif gp.m != m0 acquirep(gp.m.nextp.ptr()) gp.m.nextp = 0 // 调用 schedule() 将控制权交给调度器，开始执行 goroutine\tschedule()func mstartm0() if (iscgo || GOOS == windows) !cgoHasExtraM cgoHasExtraM = true newextram() // 安装信号处理器\tinitsig(false) 其中 schedule() 是调度器的具体调度过程，这部分会在 GMP 篇章进行展开（TODO 😁）。 注意这里： // 如果 M 启动时配置了函数，则调用它if fn := gp.m.mstartfn; fn != nil fn() 前面我们提到 runtime·newproc 的时候，获取并设置了 runtime.main 的函数地址： // 取 runtime·mainPC 的地址，这其实就是 runtime 包下的 main() 方法。// 它是 Go 语言程序的真正入口，而不是 main.main()。MOVQ\t$runtime·mainPC(SB), AX PUSHQ\tAX// 创建一个新的 goroutine 来运行程序的主函数。// 这里还没有正在的运行，因为调度器还没有启动，// 只是将 runtime.main 放进 goroutine 的 queue 中等待执行。CALL\truntime·newproc(SB)POPQ\tAX 所以这里其实就是调用 runtime.main()，到这里，我们终于开始执行程序的主函数了。 runtime.main ★ 终于我们到了 runtime.main 这个 Go 语言世界中 “真正” 的主函数了，它位于：proc.go。 // The main goroutine.func main() // 获取当前的 M\tmp := getg().m\tmp.g0.racectx = 0\t// 限制栈大小的上限，64 位系统为 1G，32 位系统为 250M\tif goarch.PtrSize == 8 maxstacksize = 1000000000 else maxstacksize = 250000000 // 这里就将栈的上限提升 2 倍，用于避免在分配过大的栈时崩溃。 // 所以其实 64 位系统最大栈 2G，32 位系统最大栈 500M。\tmaxstackceiling = 2 * maxstacksize\t// 将 mainStarted 置为 true，允许 newproc 启动新的 M。\tmainStarted = true // WebAssemby 上暂时没有线程和系统监视器，所以这里过滤掉。\tif GOARCH != wasm // 其他架构就启动系统监视器。 systemstack(func() newm(sysmon, nil, -1) ) // 在初始化期间将 g0 锁定在 m0 上。\tlockOSThread() // 只有 m0 可以运行 runtime.main\tif mp != m0 throw(runtime.main not on m0) // 记录 runtime 的开始时间，需要在 doInit() 之前，因为这样才把 init 也追踪上。\truntimeInitTime = nanotime()\tif runtimeInitTime == 0 throw(nanotime returning zero) // 初始化 trace\tif debug.inittrace != 0 inittrace.id = getg().goid inittrace.active = true // 执行 runtime 的 init() 方法\tdoInit(runtime_inittasks) // Must be before defer. // defer 解锁，以便在初始化期间调用 runtime.Goexit 时也能解锁。\tneedUnlock := true\tdefer func() if needUnlock unlockOSThread() () // 启动垃圾回收期\tgcenable() // 监听初始化完成的信号\tmain_init_done = make(chan bool) // 如果使用 cgo，则进行相关的初始化\tif iscgo ... cgocall(_cgo_notify_runtime_init_done, nil) // 执行所有模块的 init()\tfor _, m := range activeModules() doInit(m.inittasks) // 初始化任务都完成后，则禁用初始化 trace。\tinittrace.active = false // 关闭初始化完成的信号通道\tclose(main_init_done) // 解锁 m0 线程\tneedUnlock = false\tunlockOSThread() // 以 -buildmode=(c-archive|c-shared) 方式进行构建程序的话，则不执行 main.main\tif isarchive || islibrary // A program compiled with -buildmode=c-archive or c-shared // has a main, but it is not executed. return // 执行 main.main() 函数，也就是我们自己写的 main()\tfn := main_main fn() // 如果我们启动了一个 server 服务，这里就会被阻塞住，直到我们的 main 返回。 // 静态检测输出\tif raceenabled runExitHooks(0) // run hooks now, since racefini does not return racefini() // 处理在 main 返回时同时存在的其他 goroutine 的 panic\tif runningPanicDefers.Load() != 0 for c := 0; c 1000; c++ // 执行 defer if runningPanicDefers.Load() == 0 break Gosched() // 阻塞 g0 的执行，直到所有的 panic 都处理完毕\tif panicking.Load() != 0 gopark(nil, nil, waitReasonPanicWait, traceBlockForever, 1) // 执行 hook 退出函数\trunExitHooks(0) // 退出程序，0 表示正常退出\texit(0) // 理论上 exit(0) 应该退出程序的， // 如果还没退出，使用 nil 指针强行赋值，引发崩溃，强行退出程序。\tfor var x *int32 *x = 0 总的来说，runtime.main() 干这么几件事： 首先进行一些基本的设置和检查，包括设置栈大小限制和锁定主 goroutine 到主 OS 线程。 然后，函数执行一系列初始化操作，包括启动垃圾回收器、处理 CGo 交互、执行包的 init()。 在完成所有 init() 后，函数调用用户定义的 main.main 函数。 最后，函数处理程序退出，包括执行 defer、等待 panic 处理完成，并正式退出程序。 所以这里我们就知道了为什么 init() 会在 main.main() 之前被执行，而且如果一个 package 在整个程序路径都没有被 import 的时候，init() 是不会被执行的，就是因为 runtime.main() 只处理了 activeModules() 的 initTasks()。 补充说明：全局变量的初始化 到这里，还有个遗留问题，开发时我们需要关注的 init() 和 main.main() 可以讨论过了，那全局变量的初始化是在哪里做的呢？在 Go 语言的编译过程中，全局变量的初始化主要发生在链接阶段。编译器首先编译每个包，生成对象文件。然后在链接阶段，编译器或链接器将这些对象文件合并成一个可执行文件。在这个过程中，编译器或链接器负责生成初始化全局变量的代码，并安排这些代码在程序启动时执行。这些初始化代码通常嵌入在程序的启动序列中，确保在执行任何包级 init 函数或用户定义的 main 函数之前，所有全局变量已经被初始化。由于这些操作是编译器在内部执行的，它们不会直接显示在源代码或运行时代码中。 至此，我们就分析完 Go 语言程序的整个启动过程了。具体的启动流程总结，可以回到开头的 “结论先行” 查看。 参考 慕课网-深入Go底层原理 Go1.21.0 官方源码 ChatGPT-4","tags":["Go"],"categories":["Go"]},{"title":"Go1.21.0 程序编译过程","path":"/2023/11/29/go-compilation/","content":"版本说明 Go 1.21 官方文档 Go 语言官方文档详细阐述了 Go 语言编译器的具体执行过程，Go1.21 版本可以看这个：https://github.com/golang/go/tree/release-branch.go1.21/src/cmd/compile 大致过程如下： 解析 (cmd/compile/internal/syntax): 词法分析器和语法分析器：源代码被分词（词法分析）并解析（语法分析）。 语法树构建：为每个源文件构建一个语法树。 类型检查 (cmd/compile/internal/types2): 类型检查：types2 包是 go/types 的一个移植版本，它使用 syntax 包的 AST（抽象语法树）而不是 go/ast。 IR 构建（“noding”）: 编译器类型 (cmd/compile/internal/types) 编译器 AST (cmd/compile/internal/ir) AST 转换 (cmd/compile/internal/typecheck) 创建编译器 AST (cmd/compile/internal/noder) 这个阶段使用自己的 AST 定义和 Go 类型的表示，这些定义和表示形式是用 C 编写时遗留下来的。它的所有代码都是根据这些编写的，因此类型检查后的下一步是转换语法和 types2 表示形式到 ir 和 types。这个过程被称为“noding”。 中间阶段: 死代码消除 (cmd/compile/internal/deadcode) 函数调用内联 (cmd/compile/internal/inline) 已知接口方法调用的去虚拟化 (cmd/compile/internal/devirtualize) 逃逸分析 (cmd/compile/internal/escape) 在 IR 表示上执行几个优化过程：死代码消除、（早期的）去虚拟化、函数调用内联和逃逸分析。 Walk (cmd/compile/internal/walk): 求值顺序和语法糖：这是对 IR 表示的最后一次遍历，它有两个目的：将复杂的语句分解为简单的单个语句，引入临时变量并遵守求值顺序；将高级 Go 构造转换为更原始的构造。 通用 SSA (cmd/compile/internal/ssa 和 cmd/compile/internal/ssagen): 在这个阶段，IR 被转换为静态单赋值（SSA）形式，这是一种具有特定属性的低级中间表示，使得从中实现优化并最终生成机器代码变得更容易。 生成机器代码 (cmd/compile/internal/ssa 和 cmd/internal/obj): 这是编译器的机器依赖阶段，以“lower”过程开始，将通用值重写为它们的机器特定变体。然后进行最终的代码优化过程。最后，Go 函数被转换为一系列 obj.Prog 指令，这些指令被汇编器（cmd/internal/obj）转换为机器代码，并写出最终的目标文件。 编译过程 Go 程序的编译过程符合经典编译原理的过程拆解，即三阶段编译器，分别为编译器前端、中端和后端： 前端（Front End）： 前端的任务是进行语法分析和语义分析。这一阶段会将源代码转换为一个中间表示。在这个过程中，编译器会检查代码的语法和语义，比如语法错误、类型错误等。前端通常是依赖于具体语言的，比如 Go 的前端和 C++ 的前端就会有很大的不同。 中间端（Middle End）： 中间端的任务是对中间表示进行优化。这一阶段的优化是语言无关的，比如常量折叠、死代码消除、循环优化等。这些优化可以提高生成的代码的性能，但是不会改变程序的语义。 后端（Back End）： 后端的任务是将优化后的中间表示转换为目标机器代码。这一阶段会进行更多的优化，比如寄存器分配、指令选择、指令调度等。后端通常是依赖于具体机器的，比如 x86 的后端和 ARM 的后端就会有很大的不同。 参考《Go 语言底层原理剖析（郑建勋）》一书，本文将 Go 语言编译器执行流程拆分为以下几个阶段： 词法解析 语法解析 抽象语法树构建 类型检查 死代码消除 去虚拟化 函数内联 逃逸分析 变量捕获 闭包重写 遍历函数 SSA 生成 机器码生成 下面本文将以此书为参考并结合 Go1.21.0 版本，对每个过程进行阐述。 如果只想对 Go 程序的编译过程做一个简单的了解，那阅读到这里就已经足够了。 词法解析 词法解析过程主要负责将源代码中的字符序列转换成一系列的标记（tokens），这些标记是编译器更进一步处理的基本单位。在 Go 语言的编译器中，tokens.go 文件包含了与词法分析有关的标记定义。 词法解析的过程可以分为几个关键步骤： 扫描（Scanning）：编译器的扫描器会逐字符读取源代码，识别出基本的语法单位，如标识符、关键字、字面量、运算符等。 标记生成（Token Generation）：每当扫描器识别出一个有效的语法单位时，它会生成一个相应的标记。例如，对于一个变量名，扫描器会生成一个标识符标记。 去除空白字符和注释：在生成标记的过程中，扫描器还会忽略空白字符（如空格、换行符）和注释，因为它们对程序的逻辑没有影响。 错误处理：如果扫描器在源代码中遇到无法识别的字符或序列，它会生成一个错误消息。 我们来看以下 tokens.go 文件中的 token 定义，它们实质上是用 iota 声明的一系列整数： const (\t_ token = iota\t_EOF // EOF\t// names and literals\t_Name // name\t_Literal // literal\t// operators and operations\t// _Operator is excluding * (_Star)\t_IncOp // opop _Define // := ...\t// delimiters\t_Lparen // (\t_Rparen // )\t...\t// keywords\t_Break // break\t...\t// empty line comment to exclude it from .String\ttokenCount //) 举个例子，a := b + c(12) 这个表达式，被解析后，如下图所示： 语法解析 语法解析发生在词法解析之后，其主要目的是分析源代码中标记（tokens）的排列和结构，以确定它们是否形成了有效的语句。核心算法位于两个文件中： syntax/nodes.go：定义了语法节点（Syntax Nodes），这些节点是构成抽象语法树（AST）的基本元素。每个节点代表了 Go 语法中的一个构造，比如变量声明、函数调用、表达式等。通过这些节点，编译器能够理解和表示程序代码的结构。 syntax/parser.go：包含了解析器的实现。解析器负责读取词法分析阶段生成的标记流，并根据这些标记构建 AST。它遵循 Go 语言的语法规则，确保代码符合语法结构，并在遇到语法错误时提供相应的反馈。 Go 语言采用了标准的自上而下的递归下降（Top-Down Recursive-Descent）算法，以简单高效的方式完成无须回溯的语法扫描。 下面我们来看下 nodes.go 文件中对各个节点的声明（以下都省略了 struct 中的具体属性）： 声明 Declarations type (\tDecl interface Node aDecl() ImportDecl struct // 导入声明\tConstDecl struct // 常量声明\tTypeDecl struct // 类型声明\tVarDecl struct // 变量声明\tFuncDecl struct // 函数声明) 表达式 Expressions type (\tExpr interface Node typeInfo aExpr() // 省略了结构体属性\tBadExpr struct // 无效表达式\tName struct // Value\tBasicLit struct // Value\tCompositeLit struct // Type ElemList[0], ElemList[1], ... KeyValueExpr struct // Key: Value\tFuncLit struct // func Type Body ParenExpr struct // (X)\tSelectorExpr struct // X.Sel\tIndexExpr struct // X[Index]\tSliceExpr struct // X[Index[0] : Index[1] : Index[2]]\tAssertExpr struct // X.(Type)\tTypeSwitchGuard struct // Lhs := X.(type)\tOperation struct // 操作 +-*\\\tCallExpr struct // Fun(ArgList[0], ArgList[1], ...)\tListExpr struct // ElemList[0], ElemList[1], ...\tArrayType struct // [Len]Elem\tSliceType struct // []Elem\tDotsType struct // ...Elem\tStructType struct // struct FieldList[0] TagList[0]; FieldList[1] TagList[1]; ... Field struct // Name Type\tInterfaceType struct // interface MethodList[0]; MethodList[1]; ... FuncType struct // type FuncName func (param1, param2) return1, return2\tMapType struct // map[Key]Value\tChanType struct // chan Elem, -chan Elem, chan- Elem) 语句 Statements type ( // 所有语句的通用接口 Stmt interface Node aStmt() // 更加简单语句的通用接口 SimpleStmt interface EmptyStmt struct // 空语句 LabeledStmt struct // 标签语句 BlockStmt struct // 代码块语句 ExprStmt struct // 表达式语句 SendStmt struct // 发送语句，用于 channel DeclStmt struct // 声明语句 AssignStmt struct // 赋值语句 BranchStmt struct // 分支语句，break, continue CallStmt struct // 调用语句 ReturnStmt struct // 返回语句 IfStmt struct // if 条件语句 ForStmt struct // for 循环语句 SwitchStmt struct // switch 语句 SelectStmt struct // select 语句) 我们可以重点来看一下最常用的赋值语句： type AssignStmt struct Op Operator // 操作符 0 means no operation Lhs, Rhs Expr // 左右两个表达式 Rhs == nil means Lhs++ (Op == Add) or Lhs-- (Op == Sub) simpleStmt 举例 package mainimport fmtconst name = hedontype String stringvar s String = hello + wordfunc main() fmt.Println(s) 上面的源代码会被解析成如下图所示： 再来看一个赋值语句是如何解析的，就以之前的 a := b + c(12) 为例： 抽象语法树构建 编译器前端必须构建程序的中间表示形式，以便在编译器中端及后端使用，抽象语法树（Abstract Syntax Tree，AST）是一种常见的树状结构的中间态。 抽象语法树 抽象语法树（AST，Abstract Syntax Tree）是源代码的树状结构表示，它用于表示编程语言的语法结构，但不包括所有语法细节。AST 是编译器设计中的关键概念，广泛应用于编译器的各个阶段。 基本概念： 结构：AST 是一种树形结构，其中每个节点代表程序中的一种构造（如表达式、语句等）。 抽象性：它抽象出了代码的语法结构，省略了某些语法细节（如括号、特定的语法格式等）。 节点类型： 根节点：代表整个程序或一段完整代码。 内部节点：通常代表控制结构（如循环、条件语句）和操作符（如加、减、乘、除）。 叶节点：代表程序中的基本元素，如常量、变量和标识符。 构建过程： 词法分析：源代码首先经过词法分析，分解为一系列标记（tokens）。 语法分析：然后，基于这些标记，语法分析器根据编程语言的语法规则构建 AST。 树的构建：在这个过程中，分析器会根据语言的语法创建不同类型的节点，并按照程序的结构将它们组织成树。 使用场景： 语义分析：编译器使用 AST 来进行类型检查和其他语义分析。 代码优化：在优化阶段，编译器会对 AST 进行变换，以提高代码的执行效率。 代码生成：编译器根据 AST 生成中间代码或目标代码。 优点： 简化处理：由于省略了不必要的语法细节，AST 使得编译器的设计更为简洁和高效。 灵活性：AST 可以轻松地进行修改和扩展，便于实现各种编译器功能。 可视化：AST 的树形结构使得代码的逻辑结构一目了然，有助于理解和调试。 Go 构建抽象语法树 在 Go 语言源文件中的任何一种 Declarations 都是一个根节点，如下 pkgInit(decls) 函数将源文件中的所有声明语句都转换为节点（Node），代码位于：syntax/syntax.go 和 syntax/parser.go 中。 Parse() func Parse(base *PosBase, src io.Reader, errh ErrorHandler, pragh PragmaHandler, mode Mode) (_ *File, first error) defer func() if p := recover(); p != nil if err, ok := p.(Error); ok first = err return panic(p) ()\tvar p parser\tp.init(base, src, errh, pragh, mode)\tp.next()\treturn p.fileOrNil(), p.first 下面是对 Parse() 函数的一个简单解释： 作用：解析单个 Go 源文件并返回相应的语法树。 参数 base: 位置基础信息。 src: 要解析的源文件。 errh: 错误处理函数。 pragh: 用于处理每个遇到的编译指令（pragma）。 mode: 解析模式。 返回值：返回一个 File 类型的指针，表示解析后的 AST，以及可能的错误。 错误处理 如果 errh 不为空：将会调用它处理每个遇到的错误，解析器尽可能多地处理源文件。此时，只有在没有找到正确的包声明时，返回的语法树才为 nil。 如果 errh 为空：解析器在遇到第一个错误时立即终止，返回的语法树为 nil。 其中 File 类型结构如下： type File struct Pragma Pragma // 编译指令\tPkgName *Name // 包名\tDeclList []Decl // 源文件中的各种声明\tEOF Pos // 解析位置\tGoVersion string // go 版本 node // 该源文件的 AST 根节点 parser.fileOrNil() 具体的解析过程在 parser.fileOrNil() 方法中： func (p *parser) fileOrNil() *File if trace defer p.trace(file)() // 1. 初始化文件节点\tf := new(File)\tf.pos = p.pos()\t// 2. 解析包声明\tf.GoVersion = p.goVersion\tp.top = false\tif !p.got(_Package) // 包声明必须放在第一位，这跟我们学 Go 语法对应上了 p.syntaxError(package statement must be first) return nil f.Pragma = p.takePragma() // 获取编译指令\tf.PkgName = p.name()\t// 获取包名 p.want(_Semi) // _Semi 在之前的 tokens.go 中可以发现是分号（;)，是的，包声明后面就是得带分号\t// 3. 处理包声明错误\tif p.first != nil return nil // 4. 循环解析顶层声明 // 循环处理文件中的所有声明，包括 import、const、type、var 和 func // 对每种类型的声明，调用其解析函数，如 importDecl、constDecl 进行解析\tprev := _Import\tfor p.tok != _EOF if p.tok == _Import prev != _Import p.syntaxError(imports must appear before other declarations) prev = p.tok switch p.tok case _Import: p.next() f.DeclList = p.appendGroup(f.DeclList, p.importDecl) case _Const: p.next() f.DeclList = p.appendGroup(f.DeclList, p.constDecl) case _Type: p.next() f.DeclList = p.appendGroup(f.DeclList, p.typeDecl) case _Var: p.next() f.DeclList = p.appendGroup(f.DeclList, p.varDecl) case _Func: p.next() if d := p.funcDeclOrNil(); d != nil f.DeclList = append(f.DeclList, d) default: // 5. 处理异常和错误 if p.tok == _Lbrace len(f.DeclList) 0 isEmptyFuncDecl(f.DeclList[len(f.DeclList)-1]) p.syntaxError(unexpected semicolon or newline before ) else p.syntaxError(non-declaration statement outside function body) p.advance(_Import, _Const, _Type, _Var, _Func) continue // Reset p.pragma BEFORE advancing to the next token (consuming ;) // since comments before may set pragmas for the next function decl. p.clearPragma() if p.tok != _EOF !p.got(_Semi) p.syntaxError(after top level declaration) p.advance(_Import, _Const, _Type, _Var, _Func) // 6. 完成解析，记录文件结束的位置\tp.clearPragma()\tf.EOF = p.pos()\treturn f 总结 parser.fileOrNil() 方法的处理过程大致如下： 初始化文件节点： f := new(File): 创建一个新的 File 节点。 f.pos = p.pos(): 设置节点的位置信息。 解析包声明（Package Clause）： f.GoVersion = p.goVersion: 记录 Go 版本。 p.top = false: 设置状态，表示不再处于文件顶层。 if !p.got(_Package) ...: 检查是否存在包声明，如果没有，则报错并返回 nil。 f.Pragma = p.takePragma(): 获取与包声明相关的编译指令。 f.PkgName = p.name(): 获取包名。 p.want(_Semi): 确认包声明后有分号。 处理包声明错误： if p.first != nil ...: 如果已有错误，停止解析并返回 nil。 解析顶层声明： 通过一个循环处理文件中的所有声明，包括导入（import）、常量（const）、类型（type）、变量（var）和函数（func）。 对每种类型的声明，调用相应的解析函数（如 p.importDecl、p.constDecl 等）。 将解析得到的声明添加到 f.DeclList 中。 处理异常和错误： 在解析过程中遇到的任何不符合语法的情况都会触发错误处理。 使用 p.syntaxError 报告语法错误。 使用 p.advance 在遇到错误时跳过一些标记，以尝试恢复到一个已知的稳定状态。 完成解析： 当遇到文件结束标记（EOF）时，完成解析。 f.EOF = p.pos(): 记录文件结束的位置。 返回构建的 File 节点。 Op 字段 AST 每个节点都包含了当前节点属性的 Op 字段，定义在 ir/node.go 中，以 O 开头。与词法解析阶段中的 token 相同的是，Op 字段也是一个整数。不同的是，每个 Op 字段都包含了语义信息。例如，当一个节点的 Op 操作为 OAS 时，该节点代表的语义为 Left := Right，而当节点的操作为 OAS2 时，代码的语义为 x,y,z = a,b,c。 这里仅展示部分 Op 字段的定义： type Op uint8// Node ops.const (\tOXXX Op = iota\t// names\tONAME // var or func name\t// Unnamed arg or return value: f(int, string) (int, error) etc // Also used for a qualified package identifier that hasnt been resolved yet.\tONONAME\tOTYPE // type name\tOLITERAL // literal\tONIL // nil\t// expressions\tOADD // X + Y\t...\t// X = Y or (if Def=true) X := Y\t// If Def, then Init includes a DCL node for X.\tOAS\t// Lhs = Rhs (x, y, z = a, b, c) or (if Def=true) Lhs := Rhs\t// If Def, then Init includes DCL nodes for Lhs\tOAS2\t... // statements OLABEL // Label: ...\tOEND) 以前面举例的赋值语句 a := b + c(12) 为例，该赋值语句最终会编程如下图所示的抽象语法树，节点之间具有从上到下的层次结构和依赖关系。 类型检查 完成 AST 的初步构建后，就进入类型检查阶段遍历节点树并决定节点的类型。具体的代码在 types2/check,go。 checker.CheckFiles() 其中最核心的方法就是 checker.CheckFiles()： func (check *Checker) checkFiles(files []*syntax.File) (err error) // 1. 不检查 unsafe 包\tif check.pkg == Unsafe return nil // 2. 检查 go 版本\tcheck.version, err = parseGoVersion(check.conf.GoVersion)\tif err != nil return err if check.version.after(version1, goversion.Version) return fmt.Errorf(package requires newer Go version %v, check.version) if check.conf.FakeImportC check.conf.go115UsesCgo return errBadCgo // 3. 错误处理\tdefer check.handleBailout(err) // 4. 详细检查每个地方\tprint := func(msg string) if check.conf.Trace fmt.Println() fmt.Println(msg) print(== initFiles ==)\tcheck.initFiles(files)\tprint(== collectObjects ==)\tcheck.collectObjects()\tprint(== packageObjects ==)\tcheck.packageObjects()\tprint(== processDelayed ==)\tcheck.processDelayed(0) // incl. all functions\tprint(== cleanup ==)\tcheck.cleanup()\tprint(== initOrder ==)\tcheck.initOrder()\tif !check.conf.DisableUnusedImportCheck print(== unusedImports ==) check.unusedImports() print(== recordUntyped ==)\tcheck.recordUntyped()\tif check.firstErr == nil check.monomorph() check.pkg.goVersion = check.conf.GoVersion\tcheck.pkg.complete = true\t// 5. 更新和清理\tcheck.imports = nil\tcheck.dotImportMap = nil\tcheck.pkgPathMap = nil\tcheck.seenPkgMap = nil\tcheck.recvTParamMap = nil\tcheck.brokenAliases = nil\tcheck.unionTypeSets = nil\tcheck.ctxt = nil\treturn 总结 checker.checkFiles() 的过程大致如下： 检查特殊包：如果是 Unsafe 包，则直接返回，因为它不能进行类型检查且不应被修改。 解析Go版本：根据配置解析 Go 版本，并进行兼容性检查。 错误处理：设置一个延迟函数来处理任何可能出现的错误。 类型检查的步骤： initFiles: 初始化文件。 collectObjects: 收集对象。 packageObjects: 打包对象。 processDelayed: 处理延迟的任务（包括所有函数）。 cleanup: 清理。 initOrder: 初始化顺序。 unusedImports: 检查未使用的导入。 recordUntyped: 记录未定类型。 monomorph: 如果没有错误，进行单态化处理。 更新和清理： 更新包的 Go 版本和完成状态。 清理不再需要的内部数据结构，释放内存。 返回：函数完成类型检查并返回。 可以看出具体的检查步骤都封装在第 4 点的各个函数中，其实检查的东西我们学习 Go 语言时所需要掌握的那些语法，我们以 initFiles 为例子来分析一下，对于其他检查函数，你有兴趣的话也可以了解一下，这里推荐将函数源代码拷贝发给 ChatGPT-4，相信对你会有很大的帮助。 checker.initFiles() // initFiles 初始化与文件相关的类型检查器// 参数中的 files 必须都属于同一个 packagefunc (check *Checker) initFiles(files []*syntax.File) // 1. 初始化\tcheck.files = nil\tcheck.imports = nil\tcheck.dotImportMap = nil\tcheck.firstErr = nil\tcheck.methods = nil\tcheck.untyped = nil\tcheck.delayed = nil\tcheck.objPath = nil\tcheck.cleaners = nil\t// 2. 确定包名和有效文件\tpkg := check.pkg\tfor _, file := range files switch name := file.PkgName.Value; pkg.name case : if name != _ pkg.name = name else check.error(file.PkgName, BlankPkgName, invalid package name _) fallthrough case name: check.files = append(check.files, file) default: check.errorf(file, MismatchedPkgName, package %s; expected %s, name, pkg.name) // ignore this file // 3. 对每个文件，解析其中指定的 Go 版本\tfor _, file := range check.files v, _ := parseGoVersion(file.GoVersion) if v.major 0 if v.equal(check.version) continue // Go 1.21 introduced the feature of setting the go.mod // go line to an early version of Go and allowing //go:build lines // to “upgrade” the Go version in a given file. // We can do that backwards compatibly. // Go 1.21 also introduced the feature of allowing //go:build lines // to “downgrade” the Go version in a given file. // That cant be done compatibly in general, since before the // build lines were ignored and code got the modules Go version. // To work around this, downgrades are only allowed when the // modules Go version is Go 1.21 or later. // If there is no check.version, then we dont really know what Go version to apply. // Legacy tools may do this, and they historically have accepted everything. // Preserve that behavior by ignoring //go:build constraints entirely in that case. if (v.before(check.version) check.version.before(version1, 21)) || check.version.equal(version0, 0) continue if check.posVers == nil check.posVers = make(map[*syntax.PosBase]version) check.posVers[base(file.Pos())] = v 总结 checker.initFiles() 方法的大致流程如下： 初始化状态：清空 Checker 结构体中与文件相关的多个字段，如 files, imports, dotImportMap 等，为新的检查过程做准备。 确定包名和有效文件： 遍历提供的文件，确定包名，并收集有效的文件。 如果文件的包名与 Checker 中的包名不匹配，则报错并忽略该文件。 处理Go版本： 对每个文件，解析其中指定的 Go 版本。 处理 Go 版本的兼容性和升级逻辑，尤其是在 Go 1.21 引入的一些特性，如 //go:build 行的处理。 可以看到 Go 语言开发团队在这里写了一大段关于 Go1.21 的注释，这段注释描述了 Go 1.21 版本引入的关于 Go 版本设置的两个新特性,这里简单解释一下： 升级 Go 版本的特性：在 Go 1.21 版本中，可以在 go.mod 文件里设置一个较旧的Go版本，同时允许在源文件中通过 //go:build 行来指定一个更高的 Go 版本。这样做可以向后兼容，即允许旧版本代码在新版本的 Go 环境中运行。 降级 Go 版本的限制：Go 1.21 也允许通过 //go:build 行来降低源文件中的 Go 版本。但这通常不是向后兼容的，因为在以前，//go:build 行被忽略，代码总是使用模块定义的 Go 版本。为了避免兼容性问题，仅当模块的 Go 版本为 1.21 或更高时，才允许这种降级。 未指定版本的情况：如果没有明确指定 check.version，编译器就不确定应该使用哪个 Go 版本。为了保持与旧工具的兼容，如果没有明确的版本约束，编译器将忽略 //go:build 行的限制。 死代码消除 类型检查阶段完成后，编译器前端工作基本完成，后面就进入中端了。这个阶段 Go 语言编译器将对 AST 进行分析和重构，从而完成一系列优化。 第一部分是死代码消除（dead code elimination），过程识别并移除不会在运行时执行的代码。这包括未使用的变量、函数、常量等。通过删除这些无用代码片段，可以减小最终程序的大小并提高运行效率。 这部分的代码在：deadcode/deadcode.go。打开代码文件，可以看到核心就是 Func() 和 stmt() 这 2 个函数。 Func() func Func(fn *ir.Func) // 1. 对函数体进行预处理\tstmts(fn.Body) // 2. 空函数体直接返回\tif len(fn.Body) == 0 return // 3. 遍历函数体，对其中每个节点进行处理\tfor _, n := range fn.Body // 节点有任何初始化操作，则不可消除，提前返回。 if len(n.Init()) 0 return switch n.Op() case ir.OIF: n := n.(*ir.IfStmt) // 如果 if 语句判断条件不是常量，或者 if else 中的 body 不为空，则不可消除，提前返回 if !ir.IsConst(n.Cond, constant.Bool) || len(n.Body) 0 || len(n.Else) 0 return case ir.OFOR: n := n.(*ir.ForStmt) // 如果 for 循环条件不是常量或一直为真，则不可消除，提前返回 if !ir.IsConst(n.Cond, constant.Bool) || ir.BoolVal(n.Cond) return default: return // 4. 标记隐藏闭包为死代码\tir.VisitList(fn.Body, markHiddenClosureDead) // 5. 重置函数体，替换为一个空语句，进行清理和优化\tfn.Body = []ir.Nodeir.NewBlockStmt(base.Pos, nil) 语句处理（stmts(fn.Body)）：对函数体中的语句进行预处理或转换，以便于后续的分析和优化。 空函数体直接返回：如果函数体为空，没有任何代码需要执行，因此函数直接返回。这是一种优化，避免对空函数体进行不必要的分析。 遍历函数体: 节点初始化检查：如果任何节点有初始化操作，意味着可能存在副作用或必要的代码执行，因此函数提前返回。 If 和 For 语句特殊处理 ir.OIF：如果 If 语句的条件不是常量布尔值，或者 If 语句有非空的 body 或 else 分支，则提前返回，因为这些分支可能包含重要的代码。 ir.OFOR：对于 For 循环，如果条件不是常量布尔值或者布尔值为真，意味着循环可能执行，因此提前返回。 标记隐藏闭包为死代码（markHiddenClosureDead）：如果所有节点都不触发提前返回，意味着整个函数体可能没有有效的代码执行。此时，将隐藏的闭包标记为死代码，可能是为了进一步的优化处理，如移除这些代码。 重置函数体：最后，将函数体替换为一个空的新块语句，这表明原始的函数体被认为是无效的或不会被执行，从而进行了代码的清理和优化。 stmt() 这个函数的目的是通过分析和简化控制流结构，来识别和移除那些在程序执行中永远不会到达的代码部分。这样的优化可以减少编译后的代码量，并提高程序运行时的效率。 func stmts(nn *ir.Nodes) // 1. 标记最后一个标签，其对应的 Op 字段就是 OLABEL\tvar lastLabel = -1\tfor i, n := range *nn if n != nil n.Op() == ir.OLABEL lastLabel = i // 2. 处理 if 和 switch 语句\tfor i, n := range *nn cut := false if n == nil continue if n.Op() == ir.OIF n := n.(*ir.IfStmt) n.Cond = expr(n.Cond) // if 语句根据条件是否为常量来保留和移除分支 if ir.IsConst(n.Cond, constant.Bool) var body ir.Nodes if ir.BoolVal(n.Cond) ir.VisitList(n.Else, markHiddenClosureDead) n.Else = ir.Nodes body = n.Body else ir.VisitList(n.Body, markHiddenClosureDead) n.Body = ir.Nodes body = n.Else // 如果 then 或 else 分支以 panic 或 return 语句结束，那么可以安全地移除该节点之后的所有语句。 // 这是因为 panic 或 return 会导致函数终止，后续的代码永远不会被执行。 // 同时，注释提到要避免移除标签（labels），因为它们可能是 goto 语句的目标， // 而且为了避免 goto 相关的复杂性，没有使用 isterminating 标记。 // might be the target of a goto. See issue 28616. if body := body; len(body) != 0 switch body[(len(body) - 1)].Op() case ir.ORETURN, ir.OTAILCALL, ir.OPANIC: if i lastLabel cut = true // 尝试简化 switch 语句，根据条件值决定哪个分支始终被执行 if n.Op() == ir.OSWITCH n := n.(*ir.SwitchStmt) func() if n.Tag != nil n.Tag.Op() == ir.OTYPESW return // no special type-switch case yet. var x constant.Value // value were switching on if n.Tag != nil if ir.ConstType(n.Tag) == constant.Unknown return x = n.Tag.Val() else x = constant.MakeBool(true) // switch ... = switch true ... var def *ir.CaseClause for _, cas := range n.Cases if len(cas.List) == 0 // default case def = cas continue for _, c := range cas.List if ir.ConstType(c) == constant.Unknown return // cant statically tell if it matches or not - give up. if constant.Compare(x, token.EQL, c.Val()) for _, n := range cas.Body if n.Op() == ir.OFALL return // fallthrough makes it complicated - abort. // This switch entry is the one that always triggers. for _, cas2 := range n.Cases for _, c2 := range cas2.List ir.Visit(c2, markHiddenClosureDead) if cas2 != cas ir.VisitList(cas2.Body, markHiddenClosureDead) // Rewrite to switch case true: ... n.Tag = nil cas.List[0] = ir.NewBool(c.Pos(), true) cas.List = cas.List[:1] n.Cases[0] = cas n.Cases = n.Cases[:1] return if def != nil for _, n := range def.Body if n.Op() == ir.OFALL return // fallthrough makes it complicated - abort. for _, cas := range n.Cases if cas != def ir.VisitList(cas.List, markHiddenClosureDead) ir.VisitList(cas.Body, markHiddenClosureDead) n.Cases[0] = def n.Cases = n.Cases[:1] return // TODO: handle case bodies ending with panic/return as we do in the IF case above. // entire switch is a nop - no case ever triggers for _, cas := range n.Cases ir.VisitList(cas.List, markHiddenClosureDead) ir.VisitList(cas.Body, markHiddenClosureDead) n.Cases = n.Cases[:0] () // 3. 对节点的初始化语句递归调用 stmt 函数进行处理 if len(n.Init()) != 0 stmts(n.(ir.InitNode).PtrInit()) // 4. 遍历其他控制结构，递归处理它们的内部语句 switch n.Op() case ir.OBLOCK: n := n.(*ir.BlockStmt) stmts(n.List) case ir.OFOR: n := n.(*ir.ForStmt) stmts(n.Body) case ir.OIF: n := n.(*ir.IfStmt) stmts(n.Body) stmts(n.Else) case ir.ORANGE: n := n.(*ir.RangeStmt) stmts(n.Body) case ir.OSELECT: n := n.(*ir.SelectStmt) for _, cas := range n.Cases stmts(cas.Body) case ir.OSWITCH: n := n.(*ir.SwitchStmt) for _, cas := range n.Cases stmts(cas.Body) // 5. 如果确定了是可以消除的代码，则对函数体进行阶段，且标记其中的闭包为死代码 if cut ir.VisitList((*nn)[i+1:len(*nn)], markHiddenClosureDead) *nn = (*nn)[:i+1] break 标记最后一个标签：遍历所有节点，记录最后一个标签（OLABEL）的位置。这对于后面判断是否可以安全地移除代码非常重要。 处理 if 和 switch 语句： 对于 if 语句，它根据条件是否为常量来决定保留哪个分支，移除另一个分支。 对于 switch 语句，它尝试简化 switch，根据条件值决定哪个分支将始终被执行。 节点初始化：如果节点有初始化语句，对这些初始化语句递归调用 stmts 函数。 遍历其他控制结构：对于 for、if、range、select 和 switch 等控制结构，递归地处理它们的内部语句。 消除死代码：如果判断一个节点之后的所有代码都是无效的，它会标记这些代码为死代码并截断函数体。 去虚拟化 去虚拟化（Devirtualization）是编译器优化的一种技术，用于提高面向对象程序的性能。在面向对象编程中，方法调用通常是通过虚拟函数表（vtable）动态解析的，这被称为虚拟调用。虚拟调用允许对象在运行时表现出多态行为，但这也带来了一定的性能开销。 去虚拟化的目的是在编译时静态确定方法调用的目标，从而避免运行时的动态查找。如果编译器能够确定一个特定的接口调用总是调用同一个方法，它可以将这个虚拟调用替换为直接调用，减少运行时开销。这种优化特别适用于那些调用目标不会因为程序执行的不同路径而改变的情况。 这部分的代码在 devirtuailze/devirtualize.go。 核心就 2 个函数： Static() ：遍历函数中的所有节点，尤其注意跳过在 go 或 defer 语句中的调用，并对其他接口方法调用尝试进行静态去虚拟化优化。 staticCall() ：针对一个具体的接口方法调用，如果可能，将其替换为直接的具体类型方法调用，以优化性能。 Static() func Static(fn *ir.Func) ir.CurFunc = fn\tgoDeferCall := make(map[*ir.CallExpr]bool) // 1. VisitList 对 fn.Body 中所有节点调用后面的 func\tir.VisitList(fn.Body, func(n ir.Node) switch n := n.(type) // 2. 跳过 go 和 defer 语句 case *ir.GoDeferStmt: if call, ok := n.Call.(*ir.CallExpr); ok goDeferCall[call] = true return // 3. 调用 staticCall 尝试进行去虚拟化 case *ir.CallExpr: if !goDeferCall[n] staticCall(n) ) 设定当前函数为 fn。 遍历函数体内的节点，特别注意 go 和 defer 语句。如果调用发生在这些语句中，它会被跳过，因为去虚拟化可能改变程序的语义。 对于不在 go 或 defer 语句中的接口方法调用，调用 staticCall 函数尝试进行去虚拟化。 staticCall() func staticCall(call *ir.CallExpr) // 1. 检查调用是否为接口方法调用，如果不是，直接返回\tif call.Op() != ir.OCALLINTER return // 2. 获取接收器和相关类型\tsel := call.X.(*ir.SelectorExpr)\tr := ir.StaticValue(sel.X) // 3. 检查接收器是否是接口转换，如果不是，直接返回\tif r.Op() != ir.OCONVIFACE return recv := r.(*ir.ConvExpr) // 4. 提取接收器类型\ttyp := recv.X.Type()\tif typ.IsInterface() return // 5. shape 类型直接返回，因为这一般涉及到泛型，需要通过字典进行间接调用\tif typ.IsShape() return if typ.HasShape() if base.Flag.LowerM != 0 base.WarnfAt(call.Pos(), cannot devirtualize %v: shaped receiver %v, call, typ) return if sel.X.Type().HasShape() if base.Flag.LowerM != 0 base.WarnfAt(call.Pos(), cannot devirtualize %v: shaped interface %v, call, sel.X.Type()) return // 6. 类型断言和方法选择，尝试确定调用的具体方法\tdt := ir.NewTypeAssertExpr(sel.Pos(), sel.X, nil)\tdt.SetType(typ)\tx := typecheck.Callee(ir.NewSelectorExpr(sel.Pos(), ir.OXDOT, dt, sel.Sel))\tswitch x.Op() case ir.ODOTMETH: x := x.(*ir.SelectorExpr) if base.Flag.LowerM != 0 base.WarnfAt(call.Pos(), devirtualizing %v to %v, sel, typ) call.SetOp(ir.OCALLMETH) call.X = x\tcase ir.ODOTINTER: x := x.(*ir.SelectorExpr) if base.Flag.LowerM != 0 base.WarnfAt(call.Pos(), partially devirtualizing %v to %v, sel, typ) call.SetOp(ir.OCALLINTER) call.X = x\tdefault: if base.Flag.LowerM != 0 base.WarnfAt(call.Pos(), failed to devirtualize %v (%v), x, x.Op()) return // 7. 根据类型断言的结果，尝试将接口方法调用转换为直接方法调用或保留为接口方法调用。\ttypes.CheckSize(x.Type())\tswitch ft := x.Type(); ft.NumResults() case 0:\tcase 1: call.SetType(ft.Results().Field(0).Type)\tdefault: call.SetType(ft.Results()) // 8. 对可能修改后的方法调用进行进一步的类型检查和调整。\ttypecheck.FixMethodCall(call) 检查是否为接口方法调用：函数首先判断传入的调用是否是接口方法调用（ir.OCALLINTER），这是去虚拟化的前提条件。 处理形状类型：代码中提到，如果接收器的类型是形状类型（用于泛型），则无法去虚拟化，因为这需要通过字典进行间接调用。 处理形状类型的接收器：如果接收器的类型具有形状类型，则当前无法进行去虚拟化。注释中还提到了一些待实现（TODO）的优化点，例如处理非泛型的提升方法。 处理形状类型的接口：如果调用的接口本身是一个形状类型，由于指针身份的不同，类型断言可能会失败，因此在这种情况下也无法去虚拟化。 转换方法调用：根据调用的具体情况，将接口方法调用转换为直接的方法调用（OCALLMETH）或保留为接口方法调用（OCALLINTER）。 更新调用类型：为了正确处理函数返回值，需要更新调用的类型，确保参数大小和栈偏移量正确。 反糖化方法调用：如果创建了直接方法调用，需要对其进行后续的类型检查和调整。 函数内联 函数内联是将一个函数的代码直接插入到每个调用点，而不是进行常规的函数调用。这意味着函数的整个体被复制到每个调用该函数的地方。 优点： 减少开销：内联消除了函数调用的开销，如参数传递、栈操作等。 提升性能：有助于其他优化，比如循环展开、常量传播，因为编译器可以看到函数体内的代码。 选择哪些函数内联： 小函数：通常是小函数，因为它们的内联带来的性能提升相对于代码膨胀的代价来说是值得的。 调用频率高的函数：这些函数如果内联，可以显著减少运行时的调用开销。 在 Go 语言中，可以通过 //go:noinline 来禁止函数内联。 这部分的主要实现在 inline.inl.go，核心函数是：CanInline() 和 InlineImpossible()。 CanInline() // Inlining budget parameters, gathered in one placeconst ( // budget 是内联复杂度的衡量， // 超过 80 表示编译器认为这个函数太复杂了，就不进行函数内联了\tinlineMaxBudget = 80 )// CanInline 用于判断 fn 是否可内联。// 如果可以，会将 fn.Body 和 fn.Dcl 拷贝一份放到 fn.Inl，// 其中 fn 和 fn.Body 需要确保已经经过类型检查了。func CanInline(fn *ir.Func, profile *pgo.Profile) // 函数名必须有效\tif fn.Nname == nil base.Fatalf(CanInline no nname %+v, fn) // 如果不能内联，输出原因\tvar reason string\tif base.Flag.LowerM 1 || logopt.Enabled() defer func() if reason != if base.Flag.LowerM 1 fmt.Printf(%v: cannot inline %v: %s , ir.Line(fn), fn.Nname, reason) if logopt.Enabled() logopt.LogOpt(fn.Pos(), cannotInlineFunction, inline, ir.FuncName(fn), reason) () // 检查是否符合不可能内联的情况，如果返回的 reason 不为空，则表示有不可以内联的原因\treason = InlineImpossible(fn)\tif reason != return if fn.Typecheck() == 0 base.Fatalf(CanInline on non-typechecked function %v, fn) n := fn.Nname\tif n.Func.InlinabilityChecked() return defer n.Func.SetInlinabilityChecked(true)\tcc := int32(inlineExtraCallCost)\tif base.Flag.LowerL == 4 cc = 1 // this appears to yield better performance than 0. // 设置内联预算，后面如果检查函数的复杂度超过预算了，就不内联了\tbudget := int32(inlineMaxBudget)\tif profile != nil if n, ok := profile.WeightedCG.IRNodes[ir.LinkFuncName(fn)]; ok if _, ok := candHotCalleeMap[n]; ok budget = int32(inlineHotMaxBudget) if base.Debug.PGODebug 0 fmt.Printf(hot-node enabled increased budget=%v for func=%v , budget, ir.PkgFuncName(fn)) // 遍历函数体，计算复杂度，判断是否超过内联预算\tvisitor := hairyVisitor curFunc: fn, budget: budget, maxBudget: budget, extraCallCost: cc, profile: profile, if visitor.tooHairy(fn) reason = visitor.reason return // 前面检查都没问题，则标记为可以内联，并复制其函数体和声明到内联结构体中\tn.Func.Inl = ir.Inline Cost: budget - visitor.budget, Dcl: pruneUnusedAutos(n.Defn.(*ir.Func).Dcl, visitor), Body: inlcopylist(fn.Body), CanDelayResults: canDelayResults(fn), // 日志和调试\tif base.Flag.LowerM 1 fmt.Printf(%v: can inline %v with cost %d as: %v %v , ir.Line(fn), n, budget-visitor.budget, fn.Type(), ir.Nodes(n.Func.Inl.Body)) else if base.Flag.LowerM != 0 fmt.Printf(%v: can inline %v , ir.Line(fn), n) if logopt.Enabled() logopt.LogOpt(fn.Pos(), canInlineFunction, inline, ir.FuncName(fn), fmt.Sprintf(cost: %d, budget-visitor.budget)) 基本检查：验证函数是否已经进行了类型检查，以及函数名是否有效。 判断是否可以内联：调用 InlineImpossible 函数来检查是否有任何基本的限制条件阻止内联（例如函数太大、递归等）。 内联预算设置：根据函数的特征和可能的性能剖析信息来设定内联预算。这个预算是内联决策的关键参数之一。 详细分析：hairyVisitor 结构用于遍历函数体，判断是否超出了内联预算。这涉及对函数体的复杂度和大小的评估。 内联决策：如果函数通过了所有检查并且未超出预算，则标记为可以内联，并复制其函数体和声明（Dcl）到内联结构体中。 日志和调试：根据编译器的日志级别，输出关于内联决策的详细信息，例如为什么一个函数不能被内联或者它的内联成本是多少。 InlineImpossible() func InlineImpossible(fn *ir.Func) string var reason string // reason, if any, that the function can not be inlined.\tif fn.Nname == nil reason = no name return reason // If marked go:noinline, dont inline.\tif fn.Pragmair.Noinline != 0 reason = marked go:noinline return reason // If marked go:norace and -race compilation, dont inline.\tif base.Flag.Race fn.Pragmair.Norace != 0 reason = marked go:norace with -race compilation return reason // If marked go:nocheckptr and -d checkptr compilation, dont inline.\tif base.Debug.Checkptr != 0 fn.Pragmair.NoCheckPtr != 0 reason = marked go:nocheckptr return reason // If marked go:cgo_unsafe_args, dont inline, since the function\t// makes assumptions about its argument frame layout.\tif fn.Pragmair.CgoUnsafeArgs != 0 reason = marked go:cgo_unsafe_args return reason // If marked as go:uintptrkeepalive, dont inline, since the keep\t// alive information is lost during inlining.\t//\t// TODO(prattmic): This is handled on calls during escape analysis,\t// which is after inlining. Move prior to inlining so the keep-alive is\t// maintained after inlining.\tif fn.Pragmair.UintptrKeepAlive != 0 reason = marked as having a keep-alive uintptr argument return reason // If marked as go:uintptrescapes, dont inline, since the escape\t// information is lost during inlining.\tif fn.Pragmair.UintptrEscapes != 0 reason = marked as having an escaping uintptr argument return reason // The nowritebarrierrec checker currently works at function\t// granularity, so inlining yeswritebarrierrec functions can confuse it\t// (#22342). As a workaround, disallow inlining them for now.\tif fn.Pragmair.Yeswritebarrierrec != 0 reason = marked go:yeswritebarrierrec return reason // If a local function has no fn.Body (is defined outside of Go), cannot inline it.\t// Imported functions dont have fn.Body but might have inline body in fn.Inl.\tif len(fn.Body) == 0 !typecheck.HaveInlineBody(fn) reason = no function body return reason // If fn is synthetic hash or eq function, cannot inline it.\t// The function is not generated in Unified IR frontend at this moment.\tif ir.IsEqOrHashFunc(fn) reason = type eq/hash function return reason return 无函数名：如果函数没有名字，不能内联。 有 go:noinline 指令：显式标记为不内联。 有 go:norace 指令并在 -race 编译模式下：在竞态检测编译模式下不内联标记为 norace 的函数。 有 go:nocheckptr 指令并在 -d checkptr 编译模式下：在指针检查编译模式下不内联标记为 nocheckptr 的函数。 有 go:cgo_unsafe_args 指令：对于标记为 cgo_unsafe_args 的函数，由于参数布局的假设，不内联。 有 go:uintptrkeepalive 指令：不内联标记为 uintptrkeepalive 的函数。 有 go:uintptrescapes 指令：不内联标记为 uintptrescapes 的函数。 有 go:yeswritebarrierrec 指令：为了防止写屏障记录检查器的混淆，不内联标记为 yeswritebarrierrec 的函数。 无函数体：本地定义但没有函数体的函数（外部定义的 Go 函数）不可内联。 是合成的 hash 或 eq 函数：不能内联这些类型的函数。 举例 我们通过一段代码来看看编译器的函数内联情况。 func SayHello() string s := hello, + world\treturn sfunc Fib(index int) int if index 2 return index return Fib(index-1) + Fib(index-2)func ForSearch() int var s = []int1, 2, 3, 4, 5, 6, 7, 8, 9, 0\tres := 0\tfor i := 0; i len(s); i++ if s[i] == i res = i return resfunc main() SayHello()\tFib(65)\tForSearch() 在编译时我们可以加入 -m=2 标签，来打印函数的内联调试信息。在 main.go 目录下执行： go tool compile -m=2 main.go 输出： main.go:3:6: can inline SayHello with cost 7 as: func() string s := hello, + world; return s main.go:8:6: cannot inline Fib: recursivemain.go:15:6: can inline ForSearch with cost 45 as: func() int s := []int...; res := 0; for loop; return res main.go:26:6: cannot inline main: function too complex: cost 116 exceeds budget 80main.go:27:10: inlining call to SayHellomain.go:29:11: inlining call to ForSearchmain.go:16:15: []int... does not escapemain.go:29:11: []int... does not escape 可以看到 SayHello() 和 ForSearch 都被内联了，而 Fib() 因为有递归，所以不会被内联。 逃逸分析 逃逸分析是 Go 语言中非常重要的优化阶段，用于标识变量内存应该被分配在栈上还是堆上。 在传统的 C 或 C++ 开发中，开发者经常会犯的错误就是函数返回了一个栈上的对象指针，在函数执行完毕后，函数栈会被销毁，如果继续访问被销毁栈上的对象指针，那么就会出现问题。 Go 语言能够通过编译时的逃逸分析识别这种问题，自动将这类变量放置到堆区，并借助 Go 运行时的垃圾回收机制自动释放内存。编译器会尽可能地将变量放置在栈上，因为栈中的对象会随着函数调用结束被自动销毁，这可以减轻运行时分配和垃圾回收的负担。 在 Go 语言中，开发者模糊了栈区和堆区的区别，不管是字符串、数组字面量，还是通过 new、make 标识符创建的对象，都既可能被分配到栈上，也可能被分配到堆上。但是，整体上会遵循 2 个原则： 指向栈上对象的指针不能被存储到堆上； 指向栈上对象的指针不能超过该栈对象的生命周期。 这部分的代码主要在 escape。 分析过程 Go 语言通过对 AST 的静态数据流分析来实现逃逸分析（escape/graph.go），在这个过程，它会构建带权重的有向图，其中权重可以表面当前变量引用和解引用的数量。 引用（a） 减 1 解引用（*a）加 1 func (k hole) deref(where ir.Node, why string) hole return k.shift(1).note(where, why) // 解引用func (k hole) addr(where ir.Node, why string) hole return k.shift(-1).note(where, why) // 引用 具体来说，Go 逃逸分析会按照如下规则生成数据流图（带权重的有向图）： 每个变量作为一个节点（location）； 每个赋值动作是一个有向边（edge），赋值给谁则指向谁； 解引用（deref），即 *操作会给边的权重 +1； 引用（addr），即 操作会给边权重 -1。 其中：节点权重 = 指向的节点权重 + 边权重 逃逸分析的目标就是找到其中节点权重为 -1 的变量，并结合上述提到的 2 个原则，来判断要不要将变量分配到堆上。 分析实例 我们举一个例子来进行分析： package mainvar o *intfunc main() l := new(int) *l = 42\tm := l\tn := m\to = **n 再次回顾一下，* 是加 1， 是减一。按照常规思路，我们从上往下分析： 先画出节点的赋值顺序，赋值给谁，边就指向谁： 然后根据引用和解引用给边赋权重，因为 new(int) 其实就是分配一个 int(0) 并取地址，相当于 ，所以指向 l 的边权重是 -1： 节点权重 = 边权重 + 指向节点权重，因为没有对 o 变量进行任何的操作，所以 o 权重为 0，从右往左推可以得到： 经过分析，我们就找到了节点权重为 -1 的节点 new(int)，又由于它的节点变量地址最终会被传递到变量 o 上，结合之前的 2 个原则，o 是一个全局变量，声明周期是超过函数栈的，所以 new(int) 会被分配到堆上。 可以执行下面语句输出逃逸结果： go tool compile -m main.go 如： /escape/main.go:5:6: can inline main/escape/main.go:6:10: new(int) escapes to hea 也可以执行下面语句输出数据流图构建过程： go build -gcflags=-m -m -l main.go 如： # command-line-arguments./main.go:6:10: new(int) escapes to heap:./main.go:6:10: flow: l = storage for new(int):./main.go:6:10: from new(int) (spill) at ./main.go:6:10./main.go:6:10: from l := new(int) (assign) at ./main.go:6:4./main.go:6:10: flow: m = l:./main.go:6:10: from l (address-of) at ./main.go:8:7./main.go:6:10: from m := l (assign) at ./main.go:8:4./main.go:6:10: flow: n = m:./main.go:6:10: from m (address-of) at ./main.go:9:7./main.go:6:10: from n := m (assign) at ./main.go:9:4./main.go:6:10: flow: heap = **n:./main.go:6:10: from *n (indirection) at ./main.go:10:7./main.go:6:10: from *(*n) (indirection) at ./main.go:10:6./main.go:6:10: from o = *(*n) (assign) at ./main.go:10:4./main.go:6:10: new(int) escapes to heap 如果我们试一下，把 o 放在 main() 里面呢？ func main() var o *int\tl := new(int)\t*l = 42\tm := l n := m o = **n o = o // 让编译通过 执行下面语句： go tool compile -m main.go 输出： /escape/main.go:3:6: can inline main/escape/main.go:5:10: new(int) does not escape 如我们所想，虽然 new(int) 的权重为 -1，但是它的声明周期始终没有超过 main()，所以没必要逃逸到堆上。 变量捕获 变量捕获主要是针对闭包（closure）场景而言的，由于闭包函数中可能引用闭包外的变量，因此变量捕获需要明确在闭包中通过值引用或者地址引用的方式来捕获变量。 这一过程在前面提到的逃逸分析过程中进行，具体实现在 escape/escape.go 的 flowClosure() 函数中： func (b *batch) flowClosure(k hole, clo *ir.ClosureExpr) // 遍历闭包中的所有变量 for _, cv := range clo.Func.ClosureVars n := cv.Canonical() loc := b.oldLoc(cv) // 如果变量未被捕获，则触发错误 if !loc.captured base.FatalfAt(cv.Pos(), closure variable never captured: %v, cv) // 根据变量的特性决定是通过值还是引用捕获 // 如果变量未被重新赋值或取址，并且小于等于 128 字节，则通过值捕获 n.SetByval(!loc.addrtaken !loc.reassigned n.Type().Size() = 128) if !n.Byval() n.SetAddrtaken(true) // 特殊情况处理：字典变量不通过值捕获 if n.Sym().Name == typecheck.LocalDictName base.FatalfAt(n.Pos(), dictionary variable not captured by value) // 记录闭包捕获变量的方式（值或引用） if base.Flag.LowerM 1 how := ref if n.Byval() how = value base.WarnfAt(n.Pos(), %v capturing by %s: %v (addr=%v assign=%v width=%d), n.Curfn, how, n, loc.addrtaken, loc.reassigned, n.Type().Size()) // 建立闭包变量的数据流 k := k if !cv.Byval() k = k.addr(cv, reference) b.flow(k.note(cv, captured by a closure), loc) 举个例子： package mainfunc main() a := 1\tb := 2\tgo func() add(a, b)\t()\ta = 99func add(a, b int) a = a + b 执行下面语句看看变量的捕获方式： go tool compile -m=2 main.go | grep capturing 输出： main.go:4:2: main capturing by ref: a (addr=false assign=true width=8)main.go:5:2: main capturing by value: b (addr=false assign=false width=8) 可以看到 a 是通过 ref 地址引用 的方式进行引用的，而 b 是通过 value 值传递 的方式进行引用的。 简单分析一下：上述例子中，闭包引用了 a 和 b 这 2 个闭包外声明的变量，而变量 a 在闭包之前又做了一些其他的操作，而 b 没有，所以对于 a，因为闭包外有操作，所以闭包内的操作可能是有特殊意义的，需要反馈到闭包外，就需要用 ref 地址引用了，而 b 在闭包外并不关心，所以闭包内的操作不会影响到闭包外，故直接使用 value 值传递 即可。 闭包重写 逃逸分析后，现在我们进入 walk 阶段了。这里首先会进行闭包重写。其核心逻辑在 walk/closure.go 中。 闭包重写分为 2 种情况： 闭包定义后被立即调用 闭包定义后不立即调用 闭包定义后被立即调用 在闭包定义后被立即调用的情况下，闭包只会被调用一次，这时可以将闭包转换为普通函数的调用形式。 如： func main() a := 1\tb := 2\tgo func() add(a, b)\t()\ta = 99func add(a, b int) a = a + b 会被转换为普通函数的调用形式： func main() a := 1\tb := 2\tgo func1(a, b)\ta = 99// 注意这里 a 的类型的 *int，因为在变量捕获阶段，判断了 a 应该用地址引用func func1(a *int, b int) add(*a, b)func add(a, b int) a = a + b 编译器具体的处理逻辑在 directClosureCall() 中： // directClosureCall rewrites a direct call of a function literal into// a normal function call with closure variables passed as arguments.// This avoids allocation of a closure object.//// For illustration, the following call:////\tfunc(a int) // println(byval)// byref++//\t(42)//// becomes:////\tfunc(byval int, byref *int, a int) // println(byval)// (*byref)++//\t(byval, byref, 42)func directClosureCall(n *ir.CallExpr) clo := n.X.(*ir.ClosureExpr)\tclofn := clo.Func // 如果闭包足够简单，不进行处理，留给 walkClosure 处理。\tif ir.IsTrivialClosure(clo) return // leave for walkClosure to handle // 将闭包中的每个变量转换为函数的参数。对于引用捕获的变量，创建相应的指针参数。\tvar params []*types.Field\tvar decls []*ir.Name\tfor _, v := range clofn.ClosureVars if !v.Byval() // 对于引用捕获的变量，创建相应的指针参数。 addr := ir.NewNameAt(clofn.Pos(), typecheck.Lookup(+v.Sym().Name)) addr.Curfn = clofn addr.SetType(types.NewPtr(v.Type())) v.Heapaddr = addr v = addr v.Class = ir.PPARAM decls = append(decls, v) fld := types.NewField(src.NoXPos, v.Sym(), v.Type()) fld.Nname = v params = append(params, fld) // 创建一个新的函数类型，将捕获的变量作为前置参数，并更新函数的声明。\tf := clofn.Nname\ttyp := f.Type()\ttyp = types.NewSignature(nil, append(params, typ.Params().FieldSlice()...), typ.Results().FieldSlice())\tf.SetType(typ)\tclofn.Dcl = append(decls, clofn.Dcl...)\t// 将原始的闭包调用重写为对新函数的调用，并将捕获的变量作为实际参数传递。\tn.X = f\tn.Args.Prepend(closureArgs(clo)...)\t// 调整调用表达式的类型，以反映参数和返回值类型的变化。\tif typ.NumResults() == 1 n.SetType(typ.Results().Field(0).Type) else n.SetType(typ.Results()) // 虽然不再是传统意义上的闭包，但为了确保函数被编译，将其添加到待编译列表中。\tir.CurFunc.Closures = append(ir.CurFunc.Closures, clofn) 这段代码是 Go 编译器中的 directClosureCall 函数，用于将直接调用的函数字面量重写为正常的函数调用，同时将闭包变量作为参数传递。这避免了闭包对象的分配。 主要步骤如下： 检查闭包是否简单：如果闭包足够简单，不进行处理，留给 walkClosure 处理。 处理闭包变量：将闭包中的每个变量转换为函数的参数。对于引用捕获的变量，创建相应的指针参数。 更新函数类型和声明：创建一个新的函数类型，将捕获的变量作为前置参数，并更新函数的声明。 重写调用：将原始的闭包调用重写为对新函数的调用，并将捕获的变量作为实际参数传递。 更新调用表达式类型：调整调用表达式的类型，以反映参数和返回值类型的变化。 添加到待编译列表：虽然不再是传统意义上的闭包，但为了确保函数被编译，将其添加到待编译列表中。 这个函数的目的是优化闭包的调用，通过避免闭包对象的分配来提高性能。 闭包定义后不立即调用 如果闭包定义后不被立即调用，而是后续调用，那么同一个闭包可能会被调用多次，这个时候就必须创建闭包对象了。 编译器具体的处理逻辑在 walkClosure() 中： func walkClosure(clo *ir.ClosureExpr, init *ir.Nodes) ir.Node clofn := clo.Func\t// 如果没有闭包变量，闭包被视为全局函数，直接返回函数名。\tif ir.IsTrivialClosure(clo) if base.Debug.Closure 0 base.WarnfAt(clo.Pos(), closure converted to global) return clofn.Nname // 对于复杂闭包，设置需要上下文标记，并进行运行时检查。\tir.ClosureDebugRuntimeCheck(clo)\tclofn.SetNeedctxt(true)\t// 确保闭包函数不会被重复添加到编译队列。\tif !clofn.Walked() clofn.SetWalked(true) ir.CurFunc.Closures = append(ir.CurFunc.Closures, clofn) // 构造一个复合字面量表达式来表示闭包实例。\ttyp := typecheck.ClosureType(clo) // 将闭包函数和捕获的变量作为字段添加到闭包结构中。\tclos := ir.NewCompLitExpr(base.Pos, ir.OCOMPLIT, typ, nil)\tclos.SetEsc(clo.Esc())\tclos.List = append([]ir.Nodeir.NewUnaryExpr(base.Pos, ir.OCFUNC, clofn.Nname), closureArgs(clo)...)\tfor i, value := range clos.List clos.List[i] = ir.NewStructKeyExpr(base.Pos, typ.Field(i), value) // 创建闭包结构的地址，并进行类型转换以符合闭包类型。\taddr := typecheck.NodAddr(clos)\taddr.SetEsc(clo.Esc())\tcfn := typecheck.ConvNop(addr, clo.Type())\t// 如果存在预分配的闭包对象，进行相关处理。\tif x := clo.Prealloc; x != nil if !types.Identical(typ, x.Type()) panic(closure type does not match orders assigned type) addr.Prealloc = x clo.Prealloc = nil // 对最终构建的闭包表达式进行进一步处理。\treturn walkExpr(cfn, init) 检查是否为简单闭包：如果没有闭包变量，闭包被视为全局函数，直接返回函数名。 处理非简单闭包：对于复杂闭包，设置需要上下文标记，并进行运行时检查。 防止重复处理：确保闭包函数不会被重复添加到编译队列。 创建闭包结构：构造一个复合字面量表达式来表示闭包实例。 填充闭包参数：将闭包函数和捕获的变量作为字段添加到闭包结构中。 地址和类型转换：创建闭包结构的地址，并进行类型转换以符合闭包类型。 处理预分配的闭包：如果存在预分配的闭包对象，进行相关处理。 表达式处理：对最终构建的闭包表达式进行进一步处理。 遍历函数 闭包重写后，会进入 walk 阶段，如官方 文档所说：这是对 IR 表示的最后一次遍历，它有两个目的： 将复杂的语句分解为简单的单个语句，引入临时变量并遵守求值顺序； 将高级 Go 构造转换为更原始的构造。 举个例子，walkRange() 函数针对不同类型的 range 语句（数组、切片、映射、通道和字符串）进行处理，将其转换为更基本的循环结构，并应用必要的变换。 func walkRange(nrange *ir.RangeStmt) ir.Node // ... 省略代码 ... // 遍历 range 语句的不同情况 switch t.Kind() default: base.Fatalf(walkRange) // 处理数组、切片、指针（指向数组）的情况 case types.TARRAY, types.TSLICE, types.TPTR: // ... 省略代码 ... // 处理映射的情况 case types.TMAP: // ... 省略代码 ... // 处理通道的情况 case types.TCHAN: // ... 省略代码 ... // 处理字符串的情况 case types.TSTRING: // ... 省略代码 ... // ... 省略代码 ... // 构建并返回新的 for 语句 nfor.PtrInit().Append(init...) typecheck.Stmts(nfor.Cond.Init()) nfor.Cond = typecheck.Expr(nfor.Cond) nfor.Cond = typecheck.DefaultLit(nfor.Cond, nil) nfor.Post = typecheck.Stmt(nfor.Post) typecheck.Stmts(body) nfor.Body.Append(body...) nfor.Body.Append(nrange.Body...) var n ir.Node = nfor n = walkStmt(n) base.Pos = lno return n 这部分代码在 walk，对其他优化感兴趣的读者可以阅读这部分的代码。 SSA 生成 遍历函数（Walk）阶段后，编译器会将 AST 转换为下一个重要的中间表示形态，称为 SSA，其全称为 Static Single Assignment，静态单赋值。SSA 被大多数现代的编译器（包括 GCC 和 LLVM）使用，用于编译过程中的优化和代码生成。其核心特点和用途如下： 变量唯一赋值：在 SSA 形式中，每个变量只被赋值一次，使得变量的使用和修改更加清晰。 方便的数据流分析：SSA 使得数据流分析更加直接和高效，因为每个变量的赋值点只有一个。 优化算法的基础：许多编译器优化技术，如死代码消除、常量传播、强度削减等，在 SSA 形式下更易实现。 Phi 函数：SSA 引入了 Phi 函数来处理变量在不同控制流路径上的不同赋值。 代码生成：SSA 形式简化了目标代码生成的过程，因为它提供了更清晰的操作和变量使用视图。 官方对 SSA 生成阶段进行了详细的描述：Introduction to the Go compiler’s SSA backend Go 提供了强有力的工具查看 SSA 初始及其后续优化阶段生成的代码片段，可以通过编译时指定 GOSSAFUNC=pkg.func 实现。 以下面代码为例： package mainvar d uint8func main() var a uint8 = 1\ta = 2\tif true a = 3 d = a 我们可以自行简单分析一下，这段代码前面 a 的所有操作其实都是无意义的，整段代码其实就在说 d = 3 这件事。 在 linux 或者 mac 上执行： GOSSAFUNC=main.main go build main.go 在 Windows 上执行： $env:GOSSAFUNC=maingo build .\\main.go 可以看到输出： dumped SSA to .\\ssa.html 通过浏览器打开生成的 ssa.html 文件，我们可以看到 SSA 的初始阶段、优化阶段和最终阶段的代码片段。 我们直接看最终的结果，来看看我们前面的分析正确与否： 可以看到这一行：00003 (**+11**) MOVB $3, main.d(SB)，那其实就是直接 d = 3。 机器码生成 在 SSA 阶段，编译器先执行与特定指令集无关的优化，再执行与特定指令集有关的优化，并最终生成与特定指令集有关的指令和寄存器分配方式。如 ssa/_gen/genericOps.go 中包含了与特定指令集无关的 Op 操作，在 ssa/_gen/AMD64Ops.go 中包含了和 AMD64 指令集相关的 Op 操作。 机器码生成阶段是编译器的机器依赖阶段，主要过程如下： Lowering 过程：这个过程将通用的 SSA 形式转换为特定于目标机器的变体。这包括将通用操作符替换为针对特定硬件优化的操作。 代码优化：在机器特定的形式上执行最终优化，进一步提高代码效率。 生成机器指令：将 Go 函数转换为 obj.Prog 指令序列。 汇编和输出：这些指令由 cmd/internal/obj 模块的汇编器处理，转换为机器代码，并输出最终的目标文件。 Go 为我们了解 Go 语言程序的编译和链接过程提供了一个非常好用的命令： go build -n 其中 -n 表示只输出编译过程中将要执行的 shell 命令，但不执行。 以下面程序为例： package mainimport (\tfmt\tgithub.com/spf13/cast)func main() i := cast.ToInt(1)\tfmt.Println(i) 这个程序引入了标准库 fmt 以及第三方库 github.com/spf13/cast。 在工程目录下执行： go build -n -o main 可以看到输出： mkdir -p $WORK/b001/cat $WORK/b001/importcfg.link EOF # internalpackagefile go-compilation=/Users/wangjiahan/Library/Caches/go-build/48/48745ff5ef7f8945297b5894ec377f47e246d94739e0b8f00e86b6d58879e71d-dpackagefile fmt=/Users/wangjiahan/Library/Caches/go-build/10/10ab74ff0df27a2f4bdbe7651290f13ad466f3df63e11241e07ccd21c169b206-dpackagefile github.com/spf13/cast=/Users/wangjiahan/Library/Caches/go-build/77/77eed0b7028cfc4c90d78d6670325d982325399573dff9d7f82ffbf76e4559e8-d...packagefile net/url=/Users/wangjiahan/Library/Caches/go-build/72/72d0ef9b8f99a52bf1de760bb2f630998d6bb66a3d2a3fa66bd66f4efddfbc71-dmodinfo 0w\\xaf\\f\\x92t\\b\\x02A\\xe1\\xc1\\a\\xe6\\xd6\\x18\\xe6path\\tgo-compilation mod\\tgo-compilation\\t(devel)\\t dep\\tgithub.com/spf13/cast\\tv1.6.0\\th1:GEiTHELF+vaR5dhz3VqZfFSzZjYbgeKDpBxQVS4GYJ0= build\\t-buildmode=exe build\\t-compiler=gc build\\tCGO_ENABLED=1 build\\tCGO_CFLAGS= build\\tCGO_CPPFLAGS= build\\tCGO_CXXFLAGS= build\\tCGO_LDFLAGS= build\\tGOARCH=arm64 build\\tGOOS=darwin \\xf92C1\\x86\\x18 r\\x00\\x82B\\x10A\\x16\\xd8\\xf2EOFmkdir -p $WORK/b001/exe/cd ./opt/homebrew/opt/go/libexec/pkg/tool/darwin_arm64/link -o $WORK/b001/exe/a.out -importcfg $WORK/b001/importcfg.link -buildmode=pie -buildid=FDJiS-4glijTlqBbjVbe/UWsngURatTblImv3DE6-/OjO-hZGekrr-XpHFs_zA/FDJiS-4glijTlqBbjVbe -extld=cc /Users/wangjiahan/Library/Caches/go-build/48/48745ff5ef7f8945297b5894ec377f47e246d94739e0b8f00e86b6d58879e71d-d/opt/homebrew/opt/go/libexec/pkg/tool/darwin_arm64/buildid -w $WORK/b001/exe/a.out # internalmv $WORK/b001/exe/a.out main 这里建议你先尝试自行分析一下这个编译过程，再继续往下阅读。 经过分析，上述过程可以分为以下 8 个步骤： 创建工作目录：mkdir -p $WORK/b001/ 创建一个临时工作目录，用于存放编译过程中的临时文件。 生成导入配置文件：cat $WORK/b001/importcfg.link 'EOF' 命令开始创建一个名为 importcfg.link 的文件，这个文件包含了编译过程中需要的包文件路径。 写入包文件路径：接下来的多行内容是对 importcfg.link 文件的填充，指定了各个依赖包的存储位置。 结束文件写入：EOF 标志着 importcfg.link 文件内容的结束。 创建可执行文件目录：mkdir -p $WORK/b001/exe/ 创建一个目录，用于存放最终的可执行文件。 编译链接：/opt/homebrew/opt/go/libexec/pkg/tool/darwin_arm64/link -o $WORK/b001/exe/a.out ... 这一步是编译链接的核心，它使用Go的链接工具，根据之前生成的 importcfg.link 文件，将代码编译成可执行文件。 更新构建ID：/opt/homebrew/opt/go/libexec/pkg/tool/darwin_arm64/buildid -w $WORK/b001/exe/a.out 这一步更新了可执行文件的构建ID。 移动可执行文件：mv $WORK/b001/exe/a.out main 将编译好的可执行文件移动到当前目录，并重命名为 main。 如下图所示： 参考资料 Go1.21 官方文档 《Go 语言底层原理剖析》 《Go 语言设计与实现》 Go: Overview of the Compiler 维基百科 - AST 维基百科 - SSA Go 机制：逃逸分析学习笔记 ChatGPT-4 以上便是 Go 语言在 1.21.0 这个版本下编译过程的整个过程，笔者会在阅读完《用 Go 语言自制解释器》和《用 Go 语言自制编译器》这两本书后，若有对编译原理有更深入的体会和感悟，再回过来对本文的内容进行勘误和进一步提炼。","tags":["Go","编译原理"],"categories":["Go"]},{"title":"Kafka 顺序消息实现","path":"/2023/11/23/kafka-ordered-msg/","content":"版本说明 本文所有的讨论均在如下版本进行，其他版本可能会有所不同。 Kafka: 3.6.0 Pulsar: 2.9.0 RabbitMQ 3.7.8 RocketMQ 5.0 Go1.21 github.com/segmentio/kafka-go v0.4.45 结论先行 Kafka 只能保证单一分区内的顺序消息，无法保证多分区间的顺序消息。具体来说，要在 Kafka 完全实现顺序消息，至少需要保证以下几个条件： 同一生产者生产消息； 同步发送消息到 Kafka broker； 所有消息发布到同一个分区； 同一消费者同步按照顺序消费消息。 而要满足第 3 点，常用的有 2 种思路： 固定消息的 key，生产端采用 key hash 的方式写入 broker； 自定义分区策略，要保证顺序的消息都写入到指定的分区。 消息队列中的顺序消息如何实现 顺序消息定义 生产端发送出来的消息的顺序和消费端接收到消息的顺序是一样的。 消息存储结构 一般来说，消息队列都是基于顺序存储结构来存储数据的，不需要 B 树、B+ 树等复杂数据结构，利用文件的顺序读写，性能也很高。所以理想情况下，生产者按顺序发送消息，broker 会按顺序存储消息，消费者再按顺序消费消息，那么天然就实现了我们要的顺序消息了，如下： 基本条件 但是一般情况下，消息队列为了支持更高的并发和吞吐，大多数都有分区（partition）和消费者组（consumer group）机制，而为了高可用，一般也会有副本（replica）机制，所以情况就复杂得多了，如下面几个例子，就会导致消息失序： 多个生产者同时发送消息，那么到达 broker 的时间也是不确定的，所以 broker 就无法保证落盘的顺序性了； 单个生产者，但是采用异步发送，因为异步线程是并发执行的，由 CPU 进行调度，且有可能会因为发送失败而重试，所以也无法保证消息可以按照顺序到达 broker，同理，消费者异步处理消息，也无法保证顺序性； 一个 topic 有多个分区，那么即使是同一个生产者，由于分区策略，消息可能会被分发到多个分区中，消费者也就无法保证顺序性了。 所以到这里，我们可以总结出实现顺序消息，至少需要满足以下 3 点： 单一生产者同步发送； 单一分区； 单一消费者同步消费； 第 1、3 点比较简单，Kafka 通过分区和 offset 的方式保证了消息的顺序。每个分区都是一个有序的、不可变的消息序列，每个消息在分区中都有一个唯一的序数标识，称为 offset。生产者在发送消息到分区时，Kafka 会自动为消息分配一个 offset。消费者在读取消息时，会按照 offset 的顺序来读取，从而保证了消息的顺序。 下面我们主要来谈一谈第 2 点。 Kafka 顺序消息的实现 写入消息的过程 配置生产者：首先，你需要配置 Kafka 生产者。这包括指定 Kafka 集群的地址和端口，以及其他相关配置项，如消息序列化器、分区策略等。 创建生产者实例：在应用程序中，你需要创建一个 Kafka 生产者的实例。这个实例将用于与 Kafka 集群进行通信。 序列化消息：在将消息发送到 Kafka 集群之前，你需要将消息进行序列化。Kafka 使用字节数组来表示消息的内容，因此你需要将消息对象序列化为字节数组。这通常涉及将消息对象转换为 JSON、Avro、Protobuf 等格式。 选择分区：Kafka 的主题（topic）被分为多个分区（partition），每个分区都是有序且持久化的消息日志。当你发送消息时，你可以选择将消息发送到特定的分区，或者让 Kafka 根据分区策略自动选择分区。 发送消息：一旦消息被序列化并选择了目标分区，你可以使用 Kafka 生产者的 send() 方法将消息发送到 Kafka 集群。发送消息时，生产者会将消息发送到对应分区的 leader 副本。 异步发送：Kafka 生产者通常使用异步方式发送消息，这样可以提高吞吐量。生产者将消息添加到一个发送缓冲区（send buffer）中，并在后台线程中批量发送消息到 Kafka 集群。 消息持久化：一旦消息被发送到 Kafka 集群的 leader 副本，它将被持久化并复制到其他副本，以确保数据的高可靠性和冗余性。只有当消息被成功写入到指定数量的副本后，生产者才会收到确认（acknowledgement）。 错误处理和重试：如果发送消息时发生错误，生产者可以根据配置进行错误处理和重试。你可以设置重试次数、重试间隔等参数来控制重试行为。 实现单一分区 再 Kafka 中，我们要实现将消息写入到同一个分区，有 3 种思路： 配置 num.partitions=1 或者创建 topic 的时候指定只有 1 个分区，但这会显著降低 Kafka 的吞吐量。 固定消息的 key，然后采用 key hash 的分区策略，这样就可以让所有消息都被分到同一个分区中。 实现并指定自定义分区策略，可以根据业务需求，将需要顺序消费的消息都分到固定一个分区中。 // 如下例子，所有使用same-key作为key的消息都会被发送到同一个PartitionProducerRecordString, String record = new ProducerRecordString, String(topic, same-key, message);producer.send(record); 重平衡带来的问题 如果采用上述的第 2 种思路：固定消息 key，依靠 key hash 分区策略，实现单一分区。在我们只有 1 个消费者的情况下是没有问题的，但是如果我们使用的是消费者组，那么，在发生重平衡操作的时候，就可能会有问题了。 Kafka 的重平衡（Rebalance）是指 Kafka 消费者组（Consumer Group）中的消费者实例对分区的重新分配。这个过程主要发生在以下几种情况： 消费者组中新的消费者加入。 消费者组中的消费者离开或者挂掉。 订阅的 Topic 的分区数发生变化。 消费者调用了 #unsubscribe() 或者 #subscribe() 方法。 重平衡的过程主要包括以下几个步骤： Revoke：首先，Kafka 会撤销消费者组中所有消费者当前持有的分区。 Assignment：然后，Kafka 会重新计算分区的分配情况，然后将分区分配给消费者。 Resume：最后，消费者会开始消费新分配到的分区。 重平衡的目的是为了保证消费者组中的消费者能够公平地消费 Topic 的分区。通过重平衡，Kafka 可以在消费者的数量发生变化时，动态地调整消费者对分区的分配，从而实现负载均衡。 然而，当发生重平衡时，分区可能会被重新分配给不同的消费者，这可能会影响消息的消费顺序。 举个例子： 假设消费者 A 正在消费分区 P 的消息，它已经消费了消息 1，消息 2，正在处理消息 3。 此时，发生了重平衡，分区 P 被重新分配给了消费者 B。 消费者 B 开始消费分区 P，它会从上一次提交的偏移量（offset）开始消费。假设消费者 A 在处理消息 3 时发生了故障，没有提交偏移量，那么消费者 B 会从消息 3 开始消费。 这样，消息 3 可能会被消费两次，而且如果消费者 B 处理消息 3 的速度快于消费者A，那么消息 3 可能会在消息 2 之后被处理，这就打破了消息的顺序性。 再举个例子： topic-A 本来只有 3 个分区，按照 key hash，key 为 same-key 的消息应该都发到 第 2 个分区； 但是后来 topic-A 变成了 4 个分区，按照 key hash，key 为 same-key 的消息可能就被发到第 3 个分区了； 这就无法做到单一分区，可能会导致消息失序。 当然这个例子不是由重平衡直接引起的，但是这种情况也是有可能导致消息失序的。 缓解重平衡的问题 避免动态改变分区数：在需要严格保持消息顺序的场景下，应避免动态地改变分区数。这意味着在设计 Kafka 主题时，应提前规划好所需的分区数，以避免日后需要进行更改。 使用单个分区：对于严格顺序要求的场景，可以考虑使用单分区主题。虽然这会限制吞吐量和并发性，但可以保证消息的全局顺序。 使用其他策略保持顺序：在某些情况下，可以通过在应用层实现逻辑来保持顺序，比如在消息中包含顺序号或时间戳，并在消费时根据这些信息重建正确的顺序。 使用静态成员功能：它允许消费者在断开和重新连接时保持其消费者组内的身份，这可以减少因短暂的网络问题或消费者重启导致的不必要的重平衡。 上面这些措施，只能减少重平衡带来的问题，并无法根除，如果非要实现严格意义上的顺序消息，要么在消息中加入时间戳等标记，在业务层保证顺序消费，要么就只能采用 单一生产者同步发送 + 单一分区 +单一消费者同步消费 这种模式了。 静态成员功能 Kafka 2.3.0 版本引入了一项新功能：静态成员（Static Membership）。这个功能主要是为了减少由于消费者重平衡（rebalance）引起的开销和延迟。在传统的 Kafka 消费者组中，当新的消费者加入或离开消费者组时，会触发重平衡。这个过程可能会导致消息的处理延迟，并且在高吞吐量的场景下可能会对性能造成影响。静态成员功能旨在缓解这些问题。以下是它的一些关键点： 静态成员的工作原理： 静态成员标识：消费者在加入消费者组时可以提供一个静态成员标识（Static Member ID）。这允许 Kafka Broker 识别特定的消费者实例，而不是仅仅依赖于消费者组内的动态分配。 重平衡优化：当使用静态成员功能时，如果一个已知的消费者由于某种原因（如网络问题）短暂断开后重新连接，Kafka 不会立即触发重平衡。相反，Kafka 会等待一个预设的超时期限（session.timeout.ms），在此期间如果消费者重新连接，它将保留原来的分区分配。 减少重平衡次数：这大大减少了由于消费者崩溃和恢复、网络问题或维护操作引起的不必要的重平衡次数。 使用静态成员的优点： 提高稳定性：减少重平衡可以提高消费者组的整体稳定性，尤其是在大型消费者组和高吞吐量的情况下。 减少延迟：由于减少了重平衡的次数，可以减少因重平衡导致的消息处理延迟。 持久的消费者分区分配：这使得消费者在分区分配上更加持久，有助于更好地管理和优化消息的消费。 如何使用： 要使用静态成员功能，需要在 Kafka 消费者的配置中设置 group.instance.id。这个 ID 应该是唯一的，并且在消费者重启或重新连接时保持不变。同时，还需要配置 session.timeout.ms，以决定在触发重平衡之前消费者可以离线多长时间。 注意事项： 虽然静态成员功能可以减少重平衡的发生，但它不会完全消除重平衡。在消费者组成员的长期变化（如新消费者的加入或永久离开）时，仍然会发生重平衡。 需要合理设置 session.timeout.ms，以避免消费者由于短暂的网络问题或其他原因的断开而过早触发重平衡。 静态成员功能在处理大规模 Kafka 应用时尤其有用，它提供了一种机制来优化消费者组的性能和稳定性。 幂等性 Kafka 0.11 版本后提供了幂等性生产者，这意味着即使生产者因为某些错误重试发送相同的消息，这些消息也只会被记录一次。这是通过给每一批发送到 Kafka 的消息分配一个序列号实现的，broker 使用这个序列号来删除重复发送的消息。使用幂等性生产者，可以减少重复消息的风险，这意味着即使在网络重试等情况下，消息的顺序也能得到更好的保证。因为重复消息不会被多次记录，所以不会破坏已有消息的顺序。 其他常见消息队列顺序消息的实现 Pulsar Pulsar 和 Kafka 一样，都是通过生产端按 Key Hash 的方案将数据写入到同一个分区。 RabbitMQ RabbitMQ 在生产时没有生产分区分配的过程。它是通过 Exchange 和 Route Key 机制来实现顺序消息的。Exchange 会根据设置好的 Route Key 将数据路由到不同的 Queue 中存储。此时 Route Key 的作用和 Kafka 的消息的 Key 是一样的。 RocketMQ RocektMQ 支持消息组（MessageGroup）的概念。在生产端指定消息组，则同一个消息组的消息就会被发送到同一个分区中。此时这个消息组起到的作用和 Kakfa 的消息的 Key 是一样的。 实战 Kafka 实现顺序消息 代码仓库：https://github.com/hedon954/kafka-go-examples/tree/master/orderedmsg 下面我们来写一写实战用例，更加直观地感受一下 Kafka 顺序消息的实现细节。 首先我们在集群上创建一个 topic ordered-msg-topic，分区为 3 个，运行以下命令： /opt/kafka-3.6.0/bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic ordered-msg-topic --partitions 3 --replication-factor 1 搭建 Kafka 集群可以看这两篇：Kafka集群搭建(Zookeeper)、Kafka集群搭建(KRaft)。 单生产者单消费者 正常情况下，使用单一生产者同步发送和单一消费者同步发送，只要我们保证 key 是固定的，则所有消息都会写到同一个分区，是可以实现顺序消息的。 代码目录如下： ├─config│ config.go # 常量定义├─consumer│ consumer.go # 消费者└─producer producer.go # 生产者 首先我们先定义一些常量： import github.com/segmentio/kafka-govar (\tTopic = ordered-msg-topic\tBrokers = []stringkafka1.com:9092, kafka2.com:9092, kafka3.com:9092\tAddr = kafka.TCP(Brokers...)\tGroupId = ordered-msg-group\tMessageKey = []byte(message-key)) 我们先实现生产者端，主要是不断往 ordered-msg-topic 中写入数据： package mainimport (\tcontext\tfmt\ttime\tkafka-go-examples/orderedmsg/config\tgithub.com/segmentio/kafka-go)func NewProducer() *kafka.Writer return kafka.Writer Addr: config.Addr, Topic: config.Topic, Balancer: kafka.Hash, // 哈希分区\tfunc NewMessages(count int) []kafka.Message res := make([]kafka.Message, count)\tfor i := 0; i count; i++ res[i] = kafka.Message Key: config.MessageKey, Value: []byte(fmt.Sprintf(msg-%d, i+1)), return resfunc main() producer := NewProducer()\tmessages := NewMessages(100)\tif err := producer.WriteMessages(context.Background(), messages...); err != nil panic(err) _ = producer.Close() 我们再来实现消费者，目前我们就启动 1 个消费者： package mainimport (\tcontext\tfmt\ttime\tkafka-go-examples/orderedmsg/config\tgithub.com/segmentio/kafka-go)type Consumer struct Id string\t*kafka.Reader// NewConsumer 创建一个消费者，它属于 config.GroupId 这个消费者组func NewConsumer(id string) *Consumer c := Consumer Id: id, Reader: kafka.NewReader(kafka.ReaderConfig Brokers: config.Brokers, GroupID: config.GroupId, Topic: config.Topic, Dialer: kafka.Dialer ClientID: id, , ), return c// Read 读取消息，intervalMs 用来控制消费者的消费速度func (c *Consumer) Read(intervalMs int) fmt.Printf(%s start read , c.Id)\tfor msg, err := c.ReadMessage(context.Background()) if err != nil fmt.Printf(%s read msg err: %v , c.Id, err) return // 模拟消费速度 time.Sleep(time.Millisecond * time.Duration(intervalMs)) fmt.Printf(%s read msg: %s, time: %s , c.Id, string(msg.Value), time.Now().Format(03-04-05))\tfunc main() c1 := NewConsumer(consumer-1)\tc1.Read(500) 启动生产者生产消息，然后启动消费者，观察控制台，不难看出这种情况下就是顺序消费： consumer-1 read msg: msg-10, time: 04:29:10consumer-1 read msg: msg-11, time: 04:29:11consumer-1 read msg: msg-12, time: 04:29:12consumer-1 read msg: msg-13, time: 04:29:13consumer-1 read msg: msg-14, time: 04:29:14consumer-1 read msg: msg-15, time: 04:29:15consumer-1 read msg: msg-16, time: 04:29:16 重平衡带来的问题 我们先重建 topic，清楚掉之前的数据： /opt/kafka-3.6.0/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic ordered-msg-topic /opt/kafka-3.6.0/bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic ordered-msg-topic --partitions 3 --replication-factor 1 下面我们来采用消费者组的形式消费消息，在这期间，我们不断往消费者组中新增消费者，使其发生重平衡，我们来观察下消息的消费情况。 修改消费者端的 main()： func main() // 先启动 c1\tc1 := NewConsumer(consumer-1)\tgo func() c1.Read(500)\t()\t// 5 秒后启动 c2\ttime.Sleep(5 * time.Second)\tgo func() c2 := NewConsumer(consumer-2) c2.Read(300)\t()\t// 再 10 秒后启动 c3 和 c4\ttime.Sleep(10 * time.Second)\tgo func() c3 := NewConsumer(consumer-3) c3.Read(100)\t()\tgo func() c4 := NewConsumer(consumer-4) c4.Read(100)\t()\tselect 先启动生产者重新生产数据，然后再启动消费者消费数据，观察控制台： consumer-1 start readconsumer-1 read msg: msg-1, time: 04:44:28consumer-1 read msg: msg-2, time: 04:44:28consumer-1 read msg: msg-3, time: 04:44:29 # consumer-1 按顺序消费consumer-2 start read # consumer-2 进来consumer-1 read msg: msg-4, time: 04:44:30consumer-1 read msg: msg-5, time: 04:44:30consumer-1 read msg: msg-6, time: 04:44:31 # 这里相差了 6s，就是在进行重平衡consumer-2 read msg: msg-7, time: 04:44:37 # 重平衡后发现原来的分区给 consumer-2 消费了consumer-1 read msg: msg-7, time: 04:44:37 # 这里发生了重复消费consumer-2 read msg: msg-8, time: 04:44:37consumer-2 read msg: msg-9, time: 04:44:37consumer-2 read msg: msg-10, time: 04:44:38consumer-2 read msg: msg-11, time: 04:44:38consumer-2 read msg: msg-12, time: 04:44:38consumer-2 read msg: msg-13, time: 04:44:39consumer-2 read msg: msg-14, time: 04:44:39consumer-2 read msg: msg-15, time: 04:44:39 # consumer-2 按顺序消息consumer-4 start read # consumer-3 和 consumer-4 进来consumer-3 start readconsumer-2 read msg: msg-16, time: 04:44:40 consumer-4 read msg: msg-17, time: 04:44:46 # 这里发生重平衡consumer-4 read msg: msg-18, time: 04:44:46 # 重平衡后由 consumer-4 负责该分区consumer-2 read msg: msg-17, time: 04:44:46 # 这里由于 2 的速度比 4 慢很多，所以就乱序了，还重复消费consumer-4 read msg: msg-19, time: 04:44:46consumer-4 read msg: msg-20, time: 04:44:46# ... 总结 当我们采用消费者组的时候，由于重平衡机制的存在，单纯从 Kafka 的角度来说是无法完全实现顺序消息的，只能通过静态成员功能、避免分区数量变化和减少消费者组成员数量变化等方式来尽可能减少重平衡的发生，进而尽可能维持消息的顺序性。 参考 极客时间 - 深入拆解消息队列 47 讲（许文强） 《Kafka 权威指南（第 2 版）》 Pulsar 官方文档-分区topic-顺序保证 RocketMQ 官方文档-功能特性-顺序消息 RabbitMQ 官方文档","tags":["Kafka","中间件","消息队列"],"categories":["Kafka"]},{"title":"Kafka 集群部署（KRaft）","path":"/2023/11/22/kafka-kraft-deploy/","content":"版本说明 Ubuntu 18.04.6 Kafka 3.6.0 JDK8 集群配置 操作系统 ip 域名 Kafka Broker 端口 Kafka Controller 端口 Ubuntu 18.04.6 192.168.50.131 kafka1.com 9092 9093 Ubuntu 18.04.6 192.168.50.132 kafka2.com 9092 9093 Ubuntu 18.04.6 192.168.50.133 kafka3.com 9092 9093 安装 vim, curl sudo apt updatesudo apt install vimsudo apt install curl 配置静态 ip 和 hosts 为了使用域名，更加方便的进行配置，这里将虚拟机的 DHCP 改成了静态分配 IP，所以需要手动设置一下每台机器 IP 地址，这里以 192.168.50.131 为例。 找到网络接口名称，运行以下命令： ip addr 查找以 ens 或 eth 开头的接口名称。例如，ens33 或 eth0。 hedon@ubuntu:~$ ip addr1: lo: LOOPBACK,UP,LOWER_UP mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: BROADCAST,MULTICAST,UP,LOWER_UP mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:82:9e:69 brd ff:ff:ff:ff:ff:ff inet 192.168.50.133/24 brd 192.168.50.255 scope global dynamic noprefixroute ens33 valid_lft 1644sec preferred_lft 1644sec inet6 fe80::c367:c7cc:3ad4:23b3/64 scope link valid_lft forever preferred_lft forever 可以找到 ens33，其中 inet 192.168.50.133/24 表示 IP 地址为 192.168.50.133，子网掩码为 /24（等于 255.255.255.0）。 这个 IP 地址是 DHCP 动态分配的，说明宿主机分配给虚拟机的 IP 范围就在 192.168.50.xxx，所以我们会将静态 IP 配置在这个范围内。 获取网关地址 ip route | grep default 输出： hedon@ubuntu:~$ ip route | grep defaultdefault via 192.168.50.2 dev ens33 proto dhcp metric 100 说明默认网关是 192.168.50.2， 编辑 /etc/network/interfaces 文件，配置静态 IP 地址，内容如下： auto ens33iface ens33 inet static address 192.168.50.131 netmask 255.255.255.0 gateway 192.168.50.2 dns-nameservers 8.8.8.8 8.8.4.4 重启 su reboot 再次查看 ip 地址 ip addr 有以下输出便说明静态 IP 配置成功了。 1: lo: LOOPBACK,UP,LOWER_UP mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: BROADCAST,MULTICAST,UP,LOWER_UP mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:82:9e:69 brd ff:ff:ff:ff:ff:ff inet 192.168.50.131/24 brd 192.168.50.255 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe82:9e69/64 scope link valid_lft forever preferred_lft forever 配置域名 sudo vim /etc/hosts 追加内容如下： 192.168.50.131 kafka1.com192.168.50.132 kafka2.com192.168.50.133 kafka3.com ping 一下 hedon@ubuntu:~$ ping kafka1.comPING kafka1.com (192.168.50.131) 56(84) bytes of data.64 bytes from kafka1.com (192.168.50.131): icmp_seq=1 ttl=64 time=0.024 ms64 bytes from kafka1.com (192.168.50.131): icmp_seq=2 ttl=64 time=0.021 ms64 bytes from kafka1.com (192.168.50.131): icmp_seq=3 ttl=64 time=0.029 ms^C--- kafka1.com ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2029msrtt min/avg/max/mdev = 0.021/0.024/0.029/0.006 ms ping 一下百度，看看能不能访问外网 hedon@ubuntu:~$ ping baidu.comping: baidu.com: Name or service not known 如果这里可以访问，则直接跳过进入下一步，不可以的话，需要配置一下域名解析系统。 配置域名解析系统 Ubuntu 系统使用 systemd-resolved 服务来管理 DNS，你可以在 /etc/systemd/resolved.conf 文件中进行 DNS 配置。 sudo vim /etc/systemd/resolved.conf 取消或添加 DNS 的注释，并修改为： [Resolve]DNS=8.8.8.8 8.8.4.4 重启启动 systemd-resolved： sudo systemctl restart systemd-resolved 再尝试 ping 一下百度： hedon@ubuntu:~$ ping www.baidu.comPING www.a.shifen.com (153.3.238.110) 56(84) bytes of data.64 bytes from 153.3.238.110 (153.3.238.110): icmp_seq=1 ttl=128 time=15.9 ms64 bytes from 153.3.238.110 (153.3.238.110): icmp_seq=2 ttl=128 time=15.9 ms64 bytes from 153.3.238.110 (153.3.238.110): icmp_seq=3 ttl=128 time=16.1 ms64 bytes from 153.3.238.110 (153.3.238.110): icmp_seq=4 ttl=128 time=15.3 ms^C--- www.a.shifen.com ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 14104msrtt min/avg/max/mdev = 15.368/15.850/16.145/0.291 ms 补充说明：/etc/network/interfaces 文件的配置 这是一个用于配置 Linux 系统上网络接口的文件。在这个示例中，我们为名为 ens33 的网络接口配置了静态 IP 地址和相关的网络设置。下面是各行的解释：auto ens33: 这一行表示在系统启动时自动激活 ens33 网络接口。auto 关键字后面跟着接口名称。iface ens33 inet static: 这一行定义了 ens33 网络接口的配置。iface 关键字后面跟着接口名称，inet 表示我们正在配置 IPv4 地址，static 表示我们要为接口分配一个静态 IP 地址（而不是通过 DHCP 获得）。address 192.168.50.131: 这一行设置了网络接口的静态 IP 地址。在这个例子中，我们为 ens33 接口分配了 192.168.50.131 IP 地址。IP 地址是 Internet 协议（IP）用于在网络中唯一标识设备的数字标签。每个连接到网络的设备都需要一个唯一的 IP 地址，以便其他设备可以找到并与之通信。IP 地址通常分为两种版本：IPv4 和 IPv6。在此示例中，我们使用了一个 IPv4 地址。netmask 255.255.255.0: 这一行定义了子网掩码。在这个例子中，子网掩码是 255.255.255.0，表示前三个字节（24 位）是网络地址，最后一个字节（8 位）是主机地址。子网掩码用于划分 IP 地址的网络部分和主机部分。子网掩码与 IP 地址进行按位与操作，从而得到网络地址。这有助于确定哪些 IP 地址属于同一子网，以便正确地将数据包路由到目的地。子网划分有助于组织网络、提高安全性和管理性。gateway 192.168.50.2: 这一行设置了默认网关。在这个例子中，我们将默认网关设置为 192.168.50.2。默认网关是用于将数据包发送到其他网络的路由器或设备的 IP 地址。网关是一个充当网络中数据包传输的中继点的设备，通常是一个路由器。当一个设备需要将数据包发送到不同子网的另一个设备时，它会将数据包发送到网关。网关负责将数据包路由到正确的目的地。默认网关是设备用于将数据包发送到其他网络的首选网关。dns-nameservers 8.8.8.8 8.8.4.4: 这一行指定了 DNS 服务器的 IP 地址。在这个例子中，我们使用了谷歌的公共 DNS 服务器 8.8.8.8 和 8.8.4.4。DNS 服务器用于将主机名解析为 IP 地址。域名系统（DNS）是将人类可读的域名（例如 www.baidu.com）IP 地址的系统。DNS 服务器是负责执行此解析过程的服务器。当您在浏览器中输入一个网址时，计算机会向 DNS 服务器查询该域名对应的 IP 地址，然后将请求发送到该 IP 地址以获取网页内容。配置文件中的这些设置将在系统启动时生效。要立即应用更改，您可以使用以下命令重启网络服务：sudo systemctl restart networking 安装 jdk sudo apt updatesudo apt install openjdk-8-jdk 验证 java8 是否已经安装成功： java -version 有以下类似输出的话则表明安装成功： openjdk version 1.8.0_362OpenJDK Runtime Environment (build 1.8.0_362-8u372-ga~us1-0ubuntu1~18.04-b09)OpenJDK 64-Bit Server VM (build 25.362-b09, mixed mode) 安装 Kafka 下载并解压 Kafka wget https://archive.apache.org/dist/kafka/3.6.0/kafka_2.13-3.6.0.tgztar -zxvf kafka_2.13-3.6.0.tgz 将解压缩后的文件夹移动到 /opt 目录中： sudo mv kafka_2.13-3.6.0 /opt/kafka-3.6.0 使用 Kafka 提供的脚本生成一个 ClusterID export KAFKA_CLUSTER_ID=$(/opt/kafka-3.6.0/bin/kafka-storage.sh random-uuid) 输出 ClusterID hedon@ubuntu:/opt/kafka-3.6.0$ echo $KAFKA_CLUSTER_IDXiMRcbJ-QEO694L7sfDdBQ 在其他节点上将 KAFKA_CLUSTER_ID 设置为上面的值： export KAFKA_CLUSTER_ID=XiMRcbJ-QEO694L7sfDdBQ 备份配置文件，注意这里的配置文件是 config/kraft/server.properties，在 config 目录下的 kraft 目录中： cp /opt/kafka-3.6.0/config/kraft/server.properties /opt/kafka-3.6.0/config/kraft/server.properties.bak 修改配置 vim /opt/kafka-3.6.0/config/kraft/server.properties 主要修改内容如下： # 节点 ID，分别为 1，2，3node.id=1# 日志目录log.dirs=/opt/kafka-3.6.0/kafka-combined-logs# 可以成为控制器的节点和它们的端口controller.quorum.voters=1@kafka1.com:9093,2@kafka2.com:9093,3@kafka3.com:9093# 定义 Kafka Broker 如何向外部公布它的地址。# 这是 Kafka Broker 通知 Producer 和 Consumer 如何连接到自己的方式。# 例如，如果你设置 advertised.listeners=PLAINTEXT://my.public.ip:9092，# 那么 Kafka Broker 将告诉 Producer 和 Consumer 它的公共 IP 地址是 my.public.ip，并且它在 9092 端口上监听连接。# 这里我们需要在 3 个节点分别设置对应的地址advertised.listeners=PLAINTEXT://kafka1.com:9092 格式化日志目录 /opt/kafka-3.6.0/bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c /opt/kafka-3.6.0/config/kraft/server.properties 输出： Formatting /opt/kafka-3.6.0/kraft-combined-logs with metadata.version 3.6-IV2. 三个节点都启动 Kafka /opt/kafka-3.6.0/bin/kafka-server-start.sh -daemon /opt/kafka-3.6.0/config/kraft/server.properties 选择任意一个节点创建一个新 topic /opt/kafka-3.6.0/bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic test --replication-factor 1 --partitions=2 输出： Created topic test. 在其他节点获取 test 这个 topic 的信息 /opt/kafka-3.6.0/bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic test 可以看到关于 test 这个 topic 的信息是可以获取到的，说明集群之前信息是互通的，集群搭建完毕。 Topic: test\tTopicId: svJClTUpSFa9Z6FWDvkARg\tPartitionCount: 2\tReplicationFactor: 1\tConfigs: segment.bytes=1073741824\tTopic: test\tPartition: 0\tLeader: 2\tReplicas: 2\tIsr: 2\tTopic: test\tPartition: 1\tLeader: 3\tReplicas: 3\tIsr: 3 随便选择一个节点，往 test 里面写入数据： /opt/kafka-3.6.0/bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test 输入数据后按回车即发送一条数据，可以随时按 Ctrl + C 退出： hedon@ubuntu:~/Downloads$ /opt/kafka-3.6.0/bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic testmsg1msg2msg 3^ 随便选择一个节点，启动消费者消费 topic 中的数据： /opt/kafka-3.6.0/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 输出： hedon@ubuntu:/opt/kafka-3.6.0$ /opt/kafka-3.6.0/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginningmsg1msg2msg 3^CProcessed a total of 3 messages 至此，Kafka 的 KRaft 版本集群就部署完毕了！ 补充说明 - KRaft 配置文件 下面是 Kafka KRaft 版本配置文件每个配置项的解释：配置项说明process.rolesKafka 服务器的角色，设置此项将 Kafka 置于 KRaft 模式。可能的值包括 “broker” 和 “controller”。node.id与此实例关联的节点 ID。controller.quorum.voters控制器选举的投票节点，格式为 node-id@host:port。listeners服务器监听的地址，格式为 listener_name://host_name:port。inter.broker.listener.name用于 broker 之间通信的监听器名称。advertised.listeners服务器向客户端宣告的监听器名称、主机名和端口。controller.listener.names控制器使用的监听器名称列表。listener.security.protocol.map监听器名称到安全协议的映射。默认情况下，它们是相同的。num.network.threads服务器用于从网络接收请求和向网络发送响应的线程数。num.io.threads服务器用于处理请求（可能包括磁盘 I/O）的线程数。socket.send.buffer.bytes服务器用于发送数据的缓冲区大小。socket.receive.buffer.bytes服务器用于接收数据的缓冲区大小。socket.request.max.bytes服务器接受的请求的最大大小（用于防止内存溢出）。log.dirs用于存储日志文件的目录列表。num.partitions每个主题的默认日志分区数。num.recovery.threads.per.data.dir每个数据目录在启动时用于日志恢复和关闭时用于刷新的线程数。offsets.topic.replication.factor内部主题 “__consumer_offsets” 和 “__transaction_state” 的复制因子。transaction.state.log.replication.factor事务状态日志的复制因子。transaction.state.log.min.isr事务状态日志的最小同步副本数。log.flush.interval.messages强制将数据刷新到磁盘之前接受的消息数。log.flush.interval.ms消息在日志中停留的最大时间，超过这个时间就会强制刷新到磁盘。log.retention.hours由于年龄而使日志文件有资格被删除的最小年龄。log.retention.bytes基于大小的日志保留策略。log.segment.bytes日志段文件的最大大小。log.retention.check.interval.ms检查日志段是否可以根据保留策略被删除的间隔。请注意，这只是 Kafka 配置的一部分，Kafka 配置的完整列表可以在 Kafka 的官方文档中找到。","tags":["Kafka","部署","中间件","消息队列"],"categories":["Kafka"]},{"title":"Kafka 集群部署","path":"/2023/11/22/kakfa-cluster-deploy/","content":"版本说明 Ubuntu 18.04.6 Zookeeper 3.5.9 Kafka 2.7.0 JDK8 集群配置 操作系统 ip 域名 Zookeeper 端口 Kafka 端口 Ubuntu 18.04.6 192.168.50.131 kafka1.com 2181 9092 Ubuntu 18.04.6 192.168.50.132 kafka2.com 2181 9092 Ubuntu 18.04.6 192.168.50.133 kafka3.com 2181 9092 安装 vim, curl sudo apt updatesudo apt install vimsudo apt install curl 配置静态 ip 和 hosts 为了使用域名，更加方便的进行配置，这里将虚拟机的 DHCP 改成了静态分配 IP，所以需要手动设置一下每台机器 IP 地址，这里以 192.168.50.131 为例。 找到网络接口名称，运行以下命令： ip addr 查找以 ens 或 eth 开头的接口名称。例如，ens33 或 eth0。 hedon@ubuntu:~$ ip addr1: lo: LOOPBACK,UP,LOWER_UP mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: BROADCAST,MULTICAST,UP,LOWER_UP mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:82:9e:69 brd ff:ff:ff:ff:ff:ff inet 192.168.50.133/24 brd 192.168.50.255 scope global dynamic noprefixroute ens33 valid_lft 1644sec preferred_lft 1644sec inet6 fe80::c367:c7cc:3ad4:23b3/64 scope link valid_lft forever preferred_lft forever 可以找到 ens33，其中 inet 192.168.50.133/24 表示 IP 地址为 192.168.50.133，子网掩码为 /24（等于 255.255.255.0）。 这个 IP 地址是 DHCP 动态分配的，说明宿主机分配给虚拟机的 IP 范围就在 192.168.50.xxx，所以我们会将静态 IP 配置在这个范围内。 获取网关地址 ip route | grep default 输出： hedon@ubuntu:~$ ip route | grep defaultdefault via 192.168.50.2 dev ens33 proto dhcp metric 100 说明默认网关是 192.168.50.2， 编辑 /etc/network/interfaces 文件，配置静态 IP 地址，内容如下： auto ens33iface ens33 inet static\taddress 192.168.50.131\tnetmask 255.255.255.0\tgateway 192.168.50.2\tdns-nameservers 8.8.8.8 8.8.4.4 重启 su reboot 再次查看 ip 地址 ip addr 有以下输出便说明静态 IP 配置成功了。 1: lo: LOOPBACK,UP,LOWER_UP mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: BROADCAST,MULTICAST,UP,LOWER_UP mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:82:9e:69 brd ff:ff:ff:ff:ff:ff inet 192.168.50.131/24 brd 192.168.50.255 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe82:9e69/64 scope link valid_lft forever preferred_lft forever 配置域名 sudo vim /etc/hosts 追加内容如下： 192.168.50.131 kafka1.com192.168.50.132 kafka2.com192.168.50.133 kafka3.com ping 一下 hedon@ubuntu:~$ ping kafka1.comPING kafka1.com (192.168.50.131) 56(84) bytes of data.64 bytes from kafka1.com (192.168.50.131): icmp_seq=1 ttl=64 time=0.024 ms64 bytes from kafka1.com (192.168.50.131): icmp_seq=2 ttl=64 time=0.021 ms64 bytes from kafka1.com (192.168.50.131): icmp_seq=3 ttl=64 time=0.029 ms^C--- kafka1.com ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2029msrtt min/avg/max/mdev = 0.021/0.024/0.029/0.006 ms ping 一下百度，看看能不能访问外网 hedon@ubuntu:~$ ping baidu.comping: baidu.com: Name or service not known 如果这里可以访问，则直接跳过进入下一步，不可以的话，需要配置一下域名解析系统。 配置域名解析系统 sudo vim /etc/resolv.conf 追加下面内容： nameserver 8.8.8.8nameserver 8.8.4.4 再尝试 ping 一下百度： hedon@ubuntu:~$ ping www.baidu.comPING www.a.shifen.com (153.3.238.110) 56(84) bytes of data.64 bytes from 153.3.238.110 (153.3.238.110): icmp_seq=1 ttl=128 time=15.9 ms64 bytes from 153.3.238.110 (153.3.238.110): icmp_seq=2 ttl=128 time=15.9 ms64 bytes from 153.3.238.110 (153.3.238.110): icmp_seq=3 ttl=128 time=16.1 ms64 bytes from 153.3.238.110 (153.3.238.110): icmp_seq=4 ttl=128 time=15.3 ms^C--- www.a.shifen.com ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 14104msrtt min/avg/max/mdev = 15.368/15.850/16.145/0.291 ms 补充说明：/etc/network/interfaces 文件的配置 这是一个用于配置 Linux 系统上网络接口的文件。在这个示例中，我们为名为 ens33 的网络接口配置了静态 IP 地址和相关的网络设置。下面是各行的解释：auto ens33: 这一行表示在系统启动时自动激活 ens33 网络接口。auto 关键字后面跟着接口名称。iface ens33 inet static: 这一行定义了 ens33 网络接口的配置。iface 关键字后面跟着接口名称，inet 表示我们正在配置 IPv4 地址，static 表示我们要为接口分配一个静态 IP 地址（而不是通过 DHCP 获得）。address 192.168.50.131: 这一行设置了网络接口的静态 IP 地址。在这个例子中，我们为 ens33 接口分配了 192.168.50.131 IP 地址。IP 地址是 Internet 协议（IP）用于在网络中唯一标识设备的数字标签。每个连接到网络的设备都需要一个唯一的 IP 地址，以便其他设备可以找到并与之通信。IP 地址通常分为两种版本：IPv4 和 IPv6。在此示例中，我们使用了一个 IPv4 地址。netmask 255.255.255.0: 这一行定义了子网掩码。在这个例子中，子网掩码是 255.255.255.0，表示前三个字节（24 位）是网络地址，最后一个字节（8 位）是主机地址。子网掩码用于划分 IP 地址的网络部分和主机部分。子网掩码与 IP 地址进行按位与操作，从而得到网络地址。这有助于确定哪些 IP 地址属于同一子网，以便正确地将数据包路由到目的地。子网划分有助于组织网络、提高安全性和管理性。gateway 192.168.50.2: 这一行设置了默认网关。在这个例子中，我们将默认网关设置为 192.168.50.2。默认网关是用于将数据包发送到其他网络的路由器或设备的 IP 地址。网关是一个充当网络中数据包传输的中继点的设备，通常是一个路由器。当一个设备需要将数据包发送到不同子网的另一个设备时，它会将数据包发送到网关。网关负责将数据包路由到正确的目的地。默认网关是设备用于将数据包发送到其他网络的首选网关。dns-nameservers 8.8.8.8 8.8.4.4: 这一行指定了 DNS 服务器的 IP 地址。在这个例子中，我们使用了谷歌的公共 DNS 服务器 8.8.8.8 和 8.8.4.4。DNS 服务器用于将主机名解析为 IP 地址。域名系统（DNS）是将人类可读的域名（例如 www.baidu.com）IP 地址的系统。DNS 服务器是负责执行此解析过程的服务器。当您在浏览器中输入一个网址时，计算机会向 DNS 服务器查询该域名对应的 IP 地址，然后将请求发送到该 IP 地址以获取网页内容。配置文件中的这些设置将在系统启动时生效。要立即应用更改，您可以使用以下命令重启网络服务：sudo systemctl restart networking 安装 jdk sudo apt updatesudo apt install openjdk-8-jdk 验证 java8 是否已经安装成功： java -version 有以下类似输出的话则表明安装成功： openjdk version 1.8.0_362OpenJDK Runtime Environment (build 1.8.0_362-8u372-ga~us1-0ubuntu1~18.04-b09)OpenJDK 64-Bit Server VM (build 25.362-b09, mixed mode) 安装 zookeeper 在 Ubuntu 上，您可以通过以下步骤安装 Apache Zookeeper 3.5.9： 下载 Apache Zookeeper 3.5.9 的二进制文件。使用以下命令下载并解压缩 Zookeeper： wget https://archive.apache.org/dist/zookeeper/zookeeper-3.5.9/apache-zookeeper-3.5.9-bin.tar.gztar -xzf apache-zookeeper-3.5.9-bin.tar.gz 将解压缩后的文件夹移动到 /opt 目录中： sudo mv apache-zookeeper-3.5.9-bin /opt/zookeeper-3.5.9 在 /opt/zookeeper-3.5.9 目录中创建一个名为 data 的文件夹，用于存储 Zookeeper 的数据： sudo mkdir /opt/zookeeper-3.5.9/data 在 /opt/zookeeper-3.5.9/data 下创建 myid 文件并设置内容为 1，其他两台机器则为 2 和 3： echo 1 | sudo tee /opt/zookeeper-3.5.9/data/myid 复制 Zookeeper 配置文件样本，并将其命名为 zoo.cfg： sudo cp /opt/zookeeper-3.5.9/conf/zoo_sample.cfg /opt/zookeeper-3.5.9/conf/zoo.cfg 使用文本编辑器（例如 vim）编辑 zoo.cfg 文件： sudo vim /opt/zookeeper-3.5.9/conf/zoo.cfg 修改 zoo.cfg 文件： # The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# 设置数据存储目录dataDir=/opt/zookeeper-3.5.9/data# the port at which the clients will connectclientPort=2181# 设置集群信息server.1=kafka1.com:2888:3888server.2=kafka2.com:2888:3888server.3=kafka3.com:2888:3888 在 Zookeeper 的配置文件中，server.x=hostname:port1:port2 这种格式的配置项是用来设置 Zookeeper 集群（集群模式下）的。其中，x 是服务器的 ID，hostname 是服务器的主机名或 IP 地址，port1 和 port2 是用于集群间通信的端口。 具体来说： port1（2888）：这是服务器之间用于相互通信的端口。Zookeeper 服务器使用这个端口进行 leader 选举以及同步 follower 和 leader 之间的状态。 port2（3888）：这个端口用于服务器之间的 leader 选举。在 Zookeeper 集群启动或者在 leader 服务器崩溃后，follower 服务器会通过这个端口进行新一轮的 leader 选举。 这两个端口可以根据你的网络配置进行修改，但必须在所有的 Zookeeper 服务器上保持一致。 三个节点都启动 Zookeeper 服务器： /opt/zookeeper/bin/zkServer.sh start 可以连接到 Zookeeper 的端口上（默认是 2181），通过发送四字命令 srvr 来验证 Zookeeper 是否安装正确（部署集群的话需要把所有 Zookeeper 启动）： hedon@ubuntu:/opt/zookeeper-3.5.9$ telnet localhost 2181Trying 127.0.0.1...Connected to localhost.Escape character is ^].srvrZookeeper version: 3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 19:49 GMTLatency min/avg/max: 0/0/0Received: 1Sent: 0Connections: 1Outstanding: 0Zxid: 0x0Mode: standaloneNode count: 5Connection closed by foreign host. 要停止 Zookeeper 服务器，可以使用以下命令： /opt/zookeeper/bin/zkServer.sh stop 安装 Kafka 下载并解压 Kafka wget https://archive.apache.org/dist/kafka/2.7.0/kafka_2.13-2.7.0.tgztar -zxvf kafka_2.13-2.7.0.tgz 将解压缩后的文件夹移动到 /opt 目录中： sudo mv kafka_2.13-2.7.0 /opt/kafka-2.7.0 创建日志目录 sudo mkdir /opt/kafka-2.7.0/kafka-logs 备份 Kafka 默认配置 sudo cp /opt/kafka-2.7.0/config/server.properties /opt/kafka-2.7.0/config/server.properties.bak 修改 Kafka 配置 sudo vim /opt/kafka-2.7.0/config/server.properties 主要是修改下面几个配置： # 集群中每个 broker 的 id 必须唯一，这里分别为 1，2，3broker.id=1# 日志目录log.dirs=/opt/kafka-2.7.0/kafka-logs# 配置 Zookeeperzookeeper.connect=kafka1.com:2181,kafka2.com:2181,kafka3.com:2181# 定义 Kafka Broker 在哪些网络地址上监听连接，下面配置表示在所有的 IP 地址上监听 9092 端口listeners=PLAINTEXT://:9092# 定义 Kafka Broker 如何向外部公布它的地址。这是 Kafka Broker 通知 Producer 和 Consumer 如何连接到自己的方式。例如，如果你设置 advertised.listeners=PLAINTEXT://my.public.ip:9092，那么 Kafka Broker 将告诉 Producer 和 Consumer 它的公共 IP 地址是 my.public.ip，并且它在 9092 端口上监听连接。advertised.listeners=PLAINTEXT://kafka1.com:9092 三个节点都启动 Kafka /opt/kafka-2.7.0/bin/kafka-server-start.sh -daemon /opt/kafka-2.7.0/config/server.properties 选择任意一个节点创建一个新 topic /opt/kafka-2.7.0/bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic test --replication-factor 1 --partitions=2 输出： Created topic test. 在其他节点获取 test 这个 topic 的信息 /opt/kafka-2.7.0/bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic test 可以看到关于 test 这个 topic 的信息是可以获取到的，说明集群之前信息是互通的，集群搭建完毕。 Topic: test\tPartitionCount: 2\tReplicationFactor: 1\tConfigs: segment.bytes=1073741824\tTopic: test\tPartition: 0\tLeader: 1\tReplicas: 1\tIsr: 1\tTopic: test\tPartition: 1\tLeader: 2\tReplicas: 2\tIsr: 2","tags":["Kafka","部署","中间件","消息队列"],"categories":["Kafka"]},{"title":"Raft-Extended 论文翻译","path":"/2023/11/18/raft/","content":"原文：https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf 辨析 consensus vs consistency 一致性（consistency）往往指分布式系统中多个副本对外呈现的数据的状态。如顺序一致性、线性一致性，描述了多个节点对数据状态的维护能力。 共识（consensus）则描述了分布式系统中多个节点之间，彼此对某个提案达成一致结果的过程。 因此，一致性描述的是结果，共识则是一种手段。 有的人会说一致性和共识实际上是一个问题的一体两面，某种程度上来说，共识方法确实可以看作是实现强一致性的一种方法。事实上在工业界有许多以共识算法作为核心组件的多副本状态机（Replicated State Machine）实现，本质上利用了共识算法保证了所有副本的操作日志具有完全相同的顺序，从而实现了副本的一致性。但是，即使是在这样的场景下，讨论一个共识算法的一致性也是不合适的，因为整个分布式系统最终的一致性并不单单取决于共识算法，共识算法只是解决了其中一个问题。 参考：https://zhuanlan.zhihu.com/p/68743917 0. 摘要 Raft 是用来管理复制日志（replicated log）的一致性协议。它跟 multi-Paxos 作用相同，效率也相当。但是它的组织结构跟 Paxos 不同，也是因为 Raft 更简单的架构使得它更容易被理解，并且更容易在实际工程中得以实现。 为了让 Raft 更容易被理解，Raft 将共识算法的关键性因素切分成几个部分，比如： leader election（领导者选举） log replication（日志复制） safety（安全性） 并且 Raft 实施了一种更强的共识性以便减少必须要考虑的状态（states）的数量。 用户研究表明，对于学生来说，Raft 相比于 Paxos 是更容易学习的。 Raft 还包括一个用于解决变更集群成员问题的新机制，它使用重写多数来保证安全性。 1. 介绍 共识算法允许多台机器作为一个集群协同工作，并且在其中的某几台机器出故障时集群仍然能正常工作。正因为如此，共识算法在建立可靠的大规模软件系统方面发挥了重要作用。在过去十年中，Paxos [15,16] 主导了关于共识算法的讨论：大多数共识性的实现都是基于 Paxos 或受其影响，Paxos 已经成为教授学生关于共识知识的主要工具。 比较遗憾的是，尽管很多人一直在努力尝试使 Paxos 更易懂，Paxos 还是太难理解了。此外，Paxos 的架构需要复杂的改变来支持实际系统。这导致的结果就是系统开发者和学生在学生和使用 Paxos 过程中都很挣扎。 在我们自己与 Paxos 斗争之后，我们开始着手寻找一个新的共识算法，希望可以为系统开发和教学提供更好的基础。 我们的方法是不寻常的，因为我们的主要目标是可理解性：我们可以设计一个比 Paxos 更适合用于实际工程实现并且更易懂的共识算法吗？ 在该算法的设计中，重要的不仅是如何让算法起作用，还要清晰地知道该算法为什么会起作用。 这项工作的结果是一个称为 Raft 的共识性算法。在设计 Raft 时，我们使用了特定的技术来提高它的可理解性，包括： 分解（Raft 分离出三个关键点：leader election、log replication、safety） 减少状态空间（相比于 Paxos，Raft 降低了不确定性的程度和服务器之间的不一致） 一项针对 2 所大学共 43 名学生的用户研究表明，Raft 比 Paxos 更容易理解：在学习两种算法后，其中 33 名学生能够更好地回答 Raft 的相关问题。 Raft 在许多方面类似于现有的公式算法（尤其是 Oki、Liskov 的 Viewstamped Replication [29,22]），但它有几个新特性： Strong leader（强领导性）：相比于其他算法，Raft 使用了更强的领导形式。比如，日志条目只能从 leader 流向 follower（集群中除 leader 外其他的服务器）。这在使 Raft 更易懂的同时简化了日志复制的管理流程。 Leader election（领导选举）：Raft 使用随机计时器来进行领导选举。任何共识算法都需要心跳机制（heartbeats），Raft 只需要在这个基础上，添加少量机制，就可以简单快速地解决冲突。 Membership changes（成员变更）：Raft 在更改集群中服务器集的机制中使用了一个 联合共识（joint consensus） 的方法。在联合共识（joint consensus）下，在集群配置的转换过程中，新旧两种配置大多数是重叠的，这使得集群在配置更改期间可以继续正常运行。 我们认为 Raft 跟 Paxos 以及其他共识算法相比是更优的，这不仅体现在教学方面，还体现在工程实现方面。 它比其他算法更简单且更易于理解 它被描述得十分详细足以满足实际系统的需要 它有多个开源实现，并被多家公司使用 它的安全性已被正式规定和验证 它的效率与其他算法相当 本文剩余部分： 所在节 内容 第 2 节 复制状态机问题（replicated state machine problem） 第 3 节 Paxos 的优缺点 第 4 节 实现 Raft 易理解性的措施 第 5-8 节 Raft 共识性算法详细阐述 第 9 节 评估 Raft 第 10 节 其他相关工作 2. 复制状态机 共识算法一般都是在复制状态机 [37] 的背景下实现的。在这种方法下，一组服务器在的状态机计算相同状态的相同副本，即使某些服务器崩溃，它们也可以继续运行。 复制状态机是用来解决分布式系统中的各种容错问题。比如说，具有单个 leader 的大规模的系统，如 GFS [8]，HDFS [38] 和 RAMCloud [33] ，他们通常都使用单独的复制状态机来管理 leader election 和保存 leader 崩溃后重新选举所需的配置信息。像 Chubby [2] 和 ZooKeeper [11] 都是复制状态机。 复制状态机通常都是使用日志复制（log replication）来实现。如图1：每个服务器都保存着一份拥有一系列命令的日志，然后服务器上的状态机会按顺序执行日志中的命令。每一份日志中命令相同并且顺序也相同，因此每个状态机可以处理相同的命令序列。所以状态机是可确定的，每个状态机都执行相同的状态和相同的输出序列。 共识算法的主要工作就是保证复制日志（replicated log）的一致性。每台服务器上的共识模块接收来自客户端的命令，并将这些命令添加到其日志当中。它（指共识模块）与其他服务器上的共识模块进行通信，以确保每台服务器上最终以相同的顺序包含相同的命令，即使部分服务器崩溃了，这个条件也可以满足。一旦命令被正确复制，每台服务器上的状态机就会按日志顺序处理它们，并将输出返回给客户端。这样就形成了高可用的复制状态机。 适用于实际系统的共识算法通常都包含以下几点特征： 它们确保在所有非拜占庭错误下的安全性，也就是从不返回一个错误的结果。（即使是网络延迟、分区、数据包丢失、数据包重复和数据包乱序） 拜占庭错误： 出现故障（crash 或 fail-stop，即不响应）但不会伪造信息的情况称为“非拜占庭错误”。 伪造信息恶意响应的情况称为“拜占庭错误”，对应节点称为拜占庭节点。 只要任何大多数（过半）服务器是可运行的，并且可以互相通信和与客户端通信，那么共识算法就可用。假设服务器崩溃了，一小段时间后，它们很可能会根据已经稳定存储的状态来进行恢复，并重新加入集群。 它们在保证日志一致性上不依赖于时序：错误的时钟和极端消息延迟在最坏的情况下会产生影响可用性的一系列问题。 在通常情况下，只要集群中大部分（过半）服务器已经响应了单轮远程过程调用（RPC），命令就可以被视为完成。少数（一半以下）慢服务器不会影响整个系统的性能。 3. Paxos 存在的问题 在过去的十年间，Leslie Lamport 的 Paxos 协议 [15] 几乎成为共识性（consensus）的同义词。它是课堂上被教授最多的共识协议，大多数共识性的实现也是以它为起点。Paxos 首先定义了能在单个决策问题（例如单个复制日志条目）上达成共识的协议。我们将这个子集称为 signle-degree Paxos。然后 Paxos 组合该协议的多个实例去实现一系列决策，比如日志（mutil-Paxos）。Paxos 保证了安全性和活性，它也支持改变集群中的成员，它的安全性也已经被论证了，并且大多数情况下都是高效的。 美中不足的是，Paxos 有两个严重的缺点： Paxos 非常难理解 众所周知，Paxos 非常晦涩难懂，除非下了很大的功夫，很少有人能够成功理解它。因此，尽管目前已经有几个尝试希望将 Paxos [16,20,21] 解释得通俗易懂一些，而且这些解释都集中在 single-decree Paxos，但是它们还是很难懂。 在对 NSDI 2012 参会者的非正式调查中，我们发现很少人会喜欢 Paxos，即使是经验丰富的研究人员。我们自己也一直在跟 Paxos 作斗争，我们也无法完全理解整个 Paxos 协议，直到阅读了几个更简单的描述和自己设计了替代 Paxos 的协议，我们才对 Paxos 有了比较深刻的理解。但这个过程，花了将近一年。 我们推测 Paxos 这么晦涩难懂，主要是因为作者选择了 Single-decree Paxos 来作为基础。Single-decree Paxso 非常搞人：它分为两个阶段，但是并没有对这两个阶段进行简单直观的说明，而且这两个阶段也不能分开了单独理解，所以使用者将就很难理解为什么该算法能起作用。Multi-Paxos 的合成规则又增加了许多复杂性。我们相信，对多个决定（日志，并非单个日志条目）达成共识的总体问题可以用其他更直接和更明显的方式进行分解。 Paxos 没有为实际实现提供一个良好的基础 其中一个原因是没有广泛认同的针对 Multi-Paxos 的算法。Lamport 的描述主要是针对 signle-decree Paxos 的，他描述了针对 multi-Paxos 的可能方法，但缺少了很多细节。 目前已经有人在尝试具体化和优化 Paxos，比如 [26]，[39] 和 [13]，但是这些尝试都互不相同并且它们跟 Lamport 描述的也不尽相同。虽然像 Chubby [4] 这样的系统已经实现了类 Paxos（Paxos-like）算法，但是他们并没有透露出很多的实现细节。 此外，Paxos 的架构对于构建实际系统来说其实是一个糟糕的设计，这是 single-decree Paxos 分解的另一个结果。举个例子，这对于独立选择地日志条目的集合，然后再将它们合并到顺序日志当中没有任何好处，这只会增加复杂性。围绕日志来设计系统是更加简单和高效的方法，其中新条目按受约束的顺序依次附加。另外一个问题是 Paxos 在其核心使用了对称对等方法（尽管它最终表明了这会被用作一种性能优化的弱领导模式）。这在只有一个决策的情况下是有意义的，但是尽管如此，还是很少有实际系统采用了这种方法。如果有一系列的决策需要制定，更简单和更快速的方法应该是首先选择一个 leader，然后由 leader 去协调这些决策。 因此，按照 Paxos 来实现的实际系统往往跟 Paxos 相差很大。几乎所有的实现都是从 Paxos 开始，然后在实现的过程中发现了一系列的难题，在解决难题的过程中，开发出了跟 Paxos 完全不一样的架构。这样既费时又容易出错，而且 Paxos 本身的晦涩难懂又使得问题变得更加严重。Paxos 公式可能是证明其正确性的一个很好的公式，但真正的实现与 Paxos 又相差很大，这证明了它其实没有什么价值。下面来自 Chubby 作者的评论非常典型： 在 Paxos 算法描述和现实实现系统之间有着巨大的鸿沟… （如果一直按照 Paxos 算法走下去），最终的系统往往会建立在一个还未被证明的协议之上。 综合上述问题，我们觉得 Paxos 在教学端和系统构建端都没有提供一个良好的基础。考虑到共识性在大规模软件系统中的重要性，我们决定去尝试一下看看能不能设计一个替代 Paxos 并且具有更好特性的共识算法。Raft 就是这次实验的结果。 4. 为可理解性而设计 在设计 Raft 算法过程中我们有几个目标： 它必须为系统构建提供一个完整且实际的基础，这样才能大大减少开发者的工作 它必须在任何情况下都是安全的并且在典型的应用条件下是可用的，并且在正常情况下是高效的 但是我们最重要的目标，也是我们遇到的最大的挑战： 它必须具有易理解性，它必须保证能够被大多数人轻松地理解。而且它必须能够让人形成直观的认识，这样系统构建者才能在实现过程中对它进行不可避免的拓展。 在设计 Raft 算法的过程中，很多情况下我们需要在多个备选方案下做出抉择。在这种情况下，我们往往会基于可理解性来进行抉择： 解释各个备选方案的难度有多大？例如，它的状态空间有多复杂？它是否具有难以理解的含义？ 对于一个读者来说，完成理解这个方案和方案中的各种含义是否简单？ 我们意识到这一的分析具有高度的主观性。所以我们采取了两种通用的措施来解决这个问题。 第一个措施就是众所周知的问题分解：只要有可能，我们就将问题划分成几个相对独立地解决、解释和理解的子问题。例如，Raft 算法被我们划分成 leader 选举、日志复制、安全性和成员变更几个部分。 第二个措施是通过减少状态的数量来简化状态空间，尽可能地使系统变得更加连贯和尽可能地消除不确定性。很明显的一个例子就是，所有的日志都是不允许有空挡的，并且 Raft 限制了日志之间可能不一样的方式。尽管在大多数情况下我们都极力去消除不确定性，但是在某些情况下不确定性却可以提高可理解性。一个重要的例子就是随机化方法，它们虽然引入了不确定性，但是它们往往能够通过以类似的方式处理所有可能的选择来减少状态空间（随便选，没关系）。所有我们使用了随机化来简化 Raft 中的 leader election 算法。 5. Raft 共识算法 Raft 是一种用来管理第 2 节中提到的复制日志（replicated log）的算法。图 2 是该算法的浓缩，可以作为参考。图 3 列举了该算法的一些关键特性。这两张图中的内容将会在后面的各个章节中逐一介绍。 Raft 在实现共识算法的过程中，首先选举一个 distinguished leader，然后由该 leader 全权负责复制日志的一致性。Leader 从客户端接收日志条目，然后将这些日志条目复制给其他服务器，并且在保证安全性的情况下通知其他服务器将日志条目应用到他们的状态机中。拥有一个 leader 大大简化了对复制日志的管理流程。例如，leader 可以在不跟其他服务器商议的情况下决定新的日志条目应该存放在日志的什么位置，并且数据都是从 leader 流向其他服务器。当然了，一个 leader 可能会崩溃，也可能与其他服务器断开连接，那么这个时候，Raft 就会选举出一个新的 leader 出来。 通过选举一个 leader 的方式，Raft 将共识问题分解成三个独立的子问题，这些问题将会在接下来的子章节中进行讨论： Leader election（领导选举） 一个 leader 倒下之后，一定会有一个新的 leader 站起来。 Log replication（日志复制） leader 必须接收来自客户端的日志条目然后复制到集群中的其他节点，并且强制其他节点的日志和自己的保持一致。 Safety（安全性） Raft 中安全性的关键是图 3 中状态机的安全性：只要有任何服务器节点将一个特定的日志条目应用到它的状态机中，那么其他服务器节点就不能在同一个日志索引位置上存储另外一条不同的指令。第 5.4 节将会描述 Raft 如何保证这种特性，而且该解决方案在 5.2 节描述的选举机制上还增加了额外的限制。 在展示了 Raft 共识算法后，本章节将讨论可用性的一些问题以及时序在系统中的所用。 5.1 Raft 基础 一个 Raft 集群中包含若干个服务器节点，5 个一个比较典型的数字，5 个服务器的集群可以容忍 2 个节点的失效。在任何一个时刻，集群中的每一个节点都只可能是以下是三种身份之一： leader：它会处理所有来自客户端的请求（如果一个客户端和 follower 通信，follower 会将请求重定向到 leader 上） follower：它们被动的：它们不会发送任何请求，只是简单的响应来自 leader 和 candidate 的请求 candidate：这是用来选举一个新的 leader 的时候出现的一种临时状态，这将在第 5.2 节中详细描述 在正常情况下，集群中只有一个 leader，然后剩下的节点都是 follower。图 4 展示了这些状态和它们之间的转换关系，这些转换关系将会在接下来进行讨论。 如图 5 所示，Raft 将时间划分成任意长度的任期（term）。每一段任期从一次选举开始，在这个时候会有一个或者多个 candidate 尝试去成为 leader。如果某一个 candidate 赢得了选举，那么它就会在任期剩下的时间里承担一个 leader 的角色。在某些情况下，一次选举无法选出 leader，这个时候这个任期会以没有 leader 而结束。同时一个新的任期（包含一次新的选举）会很快重新开始。这是因为 Raft 会保证在任意一个任期内，至多有一个 leader。 集群中不同的服务器观察到的任期转换的次数也许是不同的，在某些情况下，一个节点可能没有观察到 leader 选举过程甚至是整个任期过程。 任期在 Raft 中还扮演着一个逻辑时钟（logical clock）的角色，这使得服务器可以发现一些过期的信息，比如过时的 leader。 每一个节点都存储着一个当前任期号（current term number），该任期号会随着时间单调递增。节点之间通信的时候会交换当前任期号，如果一个节点的当前任期号比其他节点小，那么它就将自己的任期号更新为较大的那个值。如果一个 candidate 或者 leader 发现自己的任期号过期了，它就会立刻回到 follower 状态。如果一个节点接收了一个带着过期的任期号的请求，那么它会拒绝这次请求。 Raft 算法中服务器节点之间采用 RPC 进行通信，一般的共识算法都只需要两种类型的 RPC。 RequestVote RPCs（请求投票）：由 candidate 在选举过程中发出（5.2 节中描述） AppendEntries RPCs（追加条目）：由 leader 发出，用来做日志复制和提供心跳机制（5.3 节中描述）。 在第 7 节中为了在节点之间传输快照（snapshot）增加了第三种 RPC。当节点没有及时的收到 RPC 的响应时，会进行重试，而且节点之间都是以并行（parallel）的方式发送 RPC 请求，以此来获得最佳的性能。 5.2 Leader election Raft 采用一种心跳机制来触发 leader 选举。当服务器启动的时候，他们都会称为 follower。一个服务器节点只要从 candidate 或者 leader 那接收到有效的 RPC 就一直保持 follower 的状态。Leader 会周期性地向所有的 follower 发起心跳来维持自己的 leader 地位，所谓心跳，就是不包含日志条目的 AppendEntries RPC。如果一个 follower 在一段时间内没有收到任何信息（这段时间我们称为选举超时 election timeout），那么它就会假定目前集群中没有一个可用的 leader，然后开启一次选举来选择一个新的 leader。 开始进行选举的时候，一个 follower 会自增当前任期号然后切换为 candidate 状态。然后它会给自己投票，同时以并行的方式发送一个 RequestVote RPCs 给集群中的其他服务器节点（企图得到它们的投票）。一个 candidate 会一直保持当前状态直到以下的三件事之一发生（这些情况都会在下面的章节里分别讨论）： 它赢得选举，成为了 leader 其他节点赢得了选择，那么它会变成 follower 一段时间之后没有任何节点在选举中胜出 当一个 candidate 获取集群中过半服务器节点针对同一任期的投票时，它就赢得了这次选举并成为新的 leader。对于同一个任期，每一个服务器节点会按照 先来先服务原则（first-come-first-served） 只投给一个 candidate（在5.4 节会在投票上增加额外的限制）。这种要求获得过半投票才能成为 leader 的规则确保了最多只有一个 candidate 赢得此次选举（图 3 中的选举安全性）。只要有一个 candidate 赢得选举，它就会成为 leader。然后它就会向集群中其他节点发送心跳消息来确定自己的地位并阻止新的选举。 一个 candidate 在等待其他节点给它投票的时候，它也有可能接收到另外一个自称为 leader 的节点给它发过来的 AppendEntries RPC。 如果这个 leader 的任期号（这个任期号会在这次 RPC 中携带着）不小于这个 candidate 的当前任期号，那么这个 candidate 就会觉得这个 leader 是合法的，然后将自己转变为 follower 状态。 如果这个 leader 的任期号小于这个 candidate 的当前任期号，那么这个 candidate 就会拒绝这次 RPC，然后继续保持 candidate 状态。 第三种可能的结果是 candidate 既没有赢得选举也没有输。可以设想一下这么一个情况。所有的 follower 同时变成 candidate，然后它们都将票投给自己，那这样就没有 candidate 能得到超过半数的投票了，投票无果。当这种情况发生的时候，每个 candidate 都会进行一次超时响应（time out），然后通过自增任期号来开启一轮新的选举，并启动另一轮的 RequestVote RPCs。然而，如果没有额外的措施，这种无结果的投票可能会无限重复下去。 为了解决上述问题，Raft 采用 随机选举超时时间（randomized election timeouts） 来确保很少发生无果的投票，并且就算发生了也能很快地解决。为了防止选票一开始就被瓜分，选举超时时间是从一个固定的区间（比如，150-300ms）中随机选择。这样可以把服务器分散开来以确保在大多数情况下会只有一个服务器率先结束超时，那么这个时候，它就可以赢得选举并在其他服务器结束超时之前发送心跳（译者注：乘虚而入，不讲武德）。 同样的机制也可以被用来解决选票被瓜分（split votes）的情况。每个 candidate 在开始一轮选举之前会重置一个随机选举超时时间，然后一直等待直到结束超时状态。这样减少了在一次投票无果后再一次投票无果的可能性。9.3 节展示了该方案能够快速地选出一个 leader。 选举的例子可以很好地展现可理解性是如何指导我们在多种备选设计方案中做出抉择的。在一开始，我们本打算使用一种等级系统（rank system）：每一个 candidate 被赋予一个一次的等级（rank），如果一个 candidate 发现另外一个 candidate 有着更高的登记，那么它就会返回 follower 状态，这样可以使高等级的 candidate 更加容易地赢得下一轮选举。但是我们发现这种方法在可用性方面会有一些小问题： 如果等级较高的服务器崩溃了，那么等级较低的服务器可能需要进入超时状态，然后重新成为一个 candidate。如果这种操作出现得太快，那么它可能会重启进程去开启一轮新的选举。 经过我们对该算法做出了多次的调整，我们最终还是认为随机重试的方法更加通俗易懂。 5.3 Log replication Leader 一旦被选举出来，它就要开始为客户端的请求提供服务了。每一个客户端请求都包含一条将被复制状态机执行的命令。leader 会以一个新条目的方式将该命令追加到自己的日志中，并且以同步的方式向集群中的其他节点发起 AppendEntires RPCs，让它们复制该条目。当条目被安全地复制（何为安全复制，后面会介绍）之后，leader 会将该条目应用到自己的状态机中，状态机执行该指令，然后把执行的结果返回给客户端。如果 follower 崩溃了或者运行缓慢，或者网络丢包，leader 会不断地重试 AppendEntiries RPCs（即使已经对客户端作出了响应）直到所有的 follower 都成功存储了所有的日志条目。 日志以图 6 展示的方式组织着。每条日志条目都存储着一条状态机指令和 leader 收到该指定时的任期号。日志条目中的任期号可以用来检测多个日志副本之间是否不一致，以此来保证图 3 中的某些性质。每个日志条目还有一个整数索引值来表明它在日志中的位置。 那么问题就来了，leader 什么时候会觉得把日志条目应用到状态机是安全的呢？ 这种日志条目被称为已提交的日志条目。Raft 保证这种已提交的日志条目都是持久化的并且最终都会被所有可用的状态机执行。 一旦创建该日志条目的 leader 将它复制到过半的节点上时（比如图 6 中的条目 7），该日志条目就会被提交。 同时，leader 日志中该日志条目之前的所有日志条目也都会被提交，包括由之前的其他 leader 创建的日志条目。5.4 节会讨论在 leader 变更之后应用该规则的一些细节，并证明这种提交的规则是安全的。leader 会追踪它所知道的要提交的最高索引，并将该索引包含在未来的 AppendEntries RPC 中（包括心跳），以便其他的节点可以发现这个索引。一旦一个 follower 知道了一个日志条目被提交了。它就会将该日志条目按日志顺序应用到自己的状态机中。 我们设计 Raft 日志机制来使得不同节点上的日志之间可以保持高水平的一致性。这么做不仅简化了系统的行为也使得系统更加可预测，同时该机制也是保证安全性的重要组成部分。Raft 会一直维护着以下的特性，这些特性也同时构成了图 3 中的日志匹配特性（Log Matching Property）： 如果不同日志中的两个条目有着相同的索引和任期值，那么它们就存储着相同的命令 如果不同日志中的两个条目有着相同的索引和任期值，那么他们之前的所有日志条目也都相同 第一条特性源于这样一个事实，在给定的一个任期值和给定的一个日志索引中，一个 leader 最多创建一个日志条目，而且日志条目永远不会改变它们在日志中的位置。 第二条特性是由 AppendEntries RPC 执行的一个简单的一致性检查所保证的。当 leader 发送一个 AppendEntries RPC 的时候，leader 会将前一个日志条目的索引位置和任期号包含在里面（紧邻最新的日志条目）。如果一个 follower 在它的日志中找不到包含相同索引位置和任期号的条目，那么它就会拒绝该新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性（Log Matching Property）的，然后一致性检查保证了日志扩展时的日志匹配特性。因此，当 AppendEntries RPC 返回成功时，leader 就知道 follower 的日志一定和自己相同（从第一个日志条目到最新条目）。 正常操作期间，leader 和 follower 的日志都是保持一致的，所以 AppendEntries 的一致性检查从来不会失败。但是，如果 leader 崩溃了，那么就有可能会造成日志处于不一致的状态，比如说老的 leader 可能还没有完全复制它日志中的所有条目它就崩溃了。这些不一致的情况会在一系列的 leader 和 follower 崩溃的情况下加剧。图 7 解释了什么情况下 follower 的日志可能和新的 leader 的日志不同。follower 可能会确实一些在新 leader 中有的日志条目，也有可能拥有一些新的 leader 没有的日志条目，或者同时存在。缺失或多出日志条目的情况有可能会涉及到多个任期。 在 Raft 算法中，leader 通过强制 follower 复制 leader 日志来解决日志不一致的问题。也就是说，follower 中跟 leader 冲突的日志条目会被 leader 的日志条目所覆盖。5.4 节会证明通过增加一个限制，这种方式就可以保证安全性。 为了使 follower 的日志跟自己（leader）一致，leader 必须找到两者达成一致的最大的日志条目索引，删除 follower 日志中从那个索引之后的所有日志条目，并且将自己那个索引之后的所有日志条目发送给 follower。所有的这些操作都发生在 AppendEntries RPCs 的一致性检查的回复中。leader 维护着一个针对每一个 follower 的 nextIndex，这个 nextIndex 代表的就是 leader 要发送给 follower 的下一个日志条目的索引。当选出一个新的 leader 时，该 leader 将所有的 nextIndex 的值都初始化为自己最后一个日志条目的 index 加 1（图7 中的 11）。如果一个 follower 的日志跟 leader 的是不一致的，那么下一次的 AppendEntries RPC 的一致性检查就会失败。AppendEntries RPC 在被 follower 拒绝之后，leader 对 nextIndex 进行减 1，然后重试 AppendEntries RPC。最终 nextIndex 会在某个位置满足 leader 和 follower 在该位置及之前的日志是一致的，此时，AppendEntries RPC 就会成功，将 follower 跟 leader 冲突的日志条目全部删除然后追加 leader 中的日志条目（需要的话）。一旦 AppendEntries RPC 成功，follower 的日志就和 leader 的一致了，并且在该任期接下来的时间里都保持一致。 如果需要的话，下面的协议可以用来优化被拒绝的 AppendEntries RPCs 的个数。 比如说，当拒绝一个 AppendEntries RPC 的时候，follower 可以包含冲突条目的任期号和自己存储的那个任期的第一个 index。借助这些信息，leader 可以跳过那个任期内所有的日志条目来减少 indexIndex。这样就变成了每个有冲突日志条目的任期只需要一个 AppendEntries RPC，而不是每一个日志条目都需要一次 AppendEntires RPC。 在实践中，我们认为这种优化是没有必要的，因为失败不经常发生并且也不可能有很多不一致的日志条目。 通过上述机制，leader 在当权之后就不需要任何特殊的操作来使日志恢复到一致状态。leader 只需进行正常的操作，然后日志就能在回复 AppendEntries RPC 一致性检查的时候自动趋于一致。leader 从来不会重写或者删除自己的日志条目（图3 中的 Leader Append-Only 属性）。 上述这种日志复制机制展现了第 2 节中描述的 Raft 算法的共识特性：只要过半的节点能正常运行，Raft 就能接受、复制并处理新的日志条目。在通常情况下，一个新的条目可以在一轮 RPC 中被复制给集群中过半的节点，并且单个运行缓慢的 follower 并不会影响整个集群的性能。 译者注：总结 Leader 收到 Client 的写请求，向所有 Follower 发起一个日志同步请求，得到集群内过半节点（包括 Leader 自己）的响应，就推进 commitIndex，然后 apply 日志到状态机，再推进 applyIndex，返回 Client 成功。 状态机同步分为两轮 RPC 广播： 第一轮：同步日志 AppendEntries，得到过半节点回复，Leader 状态机推进，返回 Client 成功。 第二轮：在下一次的 AppendEntries 中附带上一次的 commitIndex，Follower 收到后，apply 日志条目到各自的状态机。 5.4 Safety 前面的章节描述了 Raft 如何做 Leader Election 和 Log Replication。然而，到目前为止所讨论的机制并不能充分地保证每一个状态机会按相同的顺序执行相同的指令。比如说，一个 follower 可能会进入不可用状态，在此期间，leader 可能提交了若干的日志条目，然后这个 follower 可能被选举为新的 leader 并且用新的日志条目去覆盖这些日志条目。这样就会造成不同的状态机执行不同的指令的情况。 本节通过对 Leader Election 增加一个限制来完善 Raft 算法。这个限制保证了对于给定的任意任期号，该任期号对应的 leader 都包含了之前各个任期所有被提交的日志条目（图3 中的 Leader Completeness 性质）。有了这个限制，我们也可以使日志提交规则更加清晰。最后，我们会展示对于 Leader Completeness 性质的简要证明并且说该性质是如何保证状态机执行正确的行为的。 5.4.1 选举限制 在任何基于 leader 的共识算法中，leader 最终都必须存储所有已经提交的日志条目。在某些共识算法中，例如 Viewstamped Replication [22]，即使一个节点它一开始并没有包含所有已经提交的日志条目，它也有可能被选举为 leader。这些算法包含一些额外的机制来识别丢失的日志条目并将它们传送给新的 leader，这个机制要么发生在选举阶段，要么在选举完成之后很快进行。比较遗憾的是，这种方法会增加许多额外的机制，使得算法复杂性大大增加。Raft 使用了一种更加简单的方法，它可以保证新 leader 在当选时就包含了之前所有任期中已经提交的日志条目，根本就不需要再传送这些日志条目给新的 leader。这就意味着日志条目的传送只有一个方向，那就是从 leader 到 follower，leader 从来不会覆盖本地日志中已有的日志。 Raft 采用投票的方式来保证一个 candidate 只有拥有之前所有任期中已经提交的日志条目之后，才有可能赢得选举。一个 candidate 如果想要被选为 leader，那它就必须跟集群中超过半数的节点进行通信，这就意味这些节点中至少一个包含了所有已经提交的日志条目。如果 candidate 的日志至少跟过半的服务器节点一样新，那么它就一定包含了所有以及提交的日志条目，一旦有投票者自己的日志比 candidate 的还新，那么这个投票者就会拒绝该投票，该 candidate 也就不会赢得选举。 所谓 “新” ： Raft 通过比较两份日志中的最后一条日志条目的索引和任期号来定义谁的日志更新。 如果两份日志最后条目的任期号不同，那么任期号大的日志更新 如果两份日志最后条目的任期号相同，那么谁的日志更长，谁就更新 5.4.2 提交之前任期内的日志条目 译者注：注意！这一节「提交之前任期内的日志条目」这种操作 Raft 的不允许的！本小节只是用来举一种错误情况！ 如 5.3 节中提到的那样，一旦当前任期内的某个日志条目以及存储到过半的服务器节点上，leader 就知道该日志可以被提交了。如果这个 leader 在提交某个日志条目之前崩溃了，以后的 leader 会尝试完成该日志条目的复制。然而，如果是之前任期内的某个日志条目已经存储到了过半的服务器节点上了，新任期内的 leader 也无法立即断定该日志条目已经被提交了。图 8 展示了一种情况：一个已经被存储到过半节点的老日志条目，仍然有可能会被未来的 leader 覆盖掉。 译者注：对图 8 的理解的补充。 参考： 知乎 核心： 图 8 用来说明为什么 leader 不能提交之前任期的日志，只能通过提交自己任期的日志，从而间接提交之前任期的日志。 分析： 先按错误的情况，也就是 leader 提交之前任期的日志，那么上述的流程： (a) S1 是任期 2 的 leader，日志已经复制给了 S2，此时还没过半； (b) S1 崩溃，S5 获得了 S3、S4、S5 的投票成为 leader，然后写了一个日志条目（index=2，term=3）； © S5 刚写完日志，还没来得及复制，就崩溃了，此时 S1 和 S2 都可能当选，加入 S1 当选（currentTerm=4），此刻还没有新的请求进来，S1 将日志条目（index=2，term=2）复制给了 S3，多数派达成，S1 提交了这个日志条目（index=2，term=2）， 注意，该日志不是当前任期内的日志，我们在讨论错误的情况！ 然后请求进来，S1 写日志条目（index=3，term=4），然后 S1 崩溃。 情况一：(d) S5 重启，因为 S5 最后的日志条目的任期号比 S2、S3 大，所以 S5 可以赢得选举（currentTerm=5），S5 将日志条目（index=2，item=3）复制给其他所有节点并提交， 此时 index=2 的日志条目被提交了两次！一次 term=2，一次term=3，这是不被允许的，因为已经提交的日志条目是不能被覆盖的！ ✖️ 情况二：(e) S1 在崩溃之前将自己的日志条目（index=3，term=4）复制到了过半节点上，这种情况下，S5 不可能选举成功。这是 S1 不发生故障，这是正确复制的情况。✔️ 所以 「leader 可以提交之前任期的日志」 这种操作是不允许的，我们需要加上约束： 「leader 只能提交自己任期的日志」 。 加了约束之后，前面的 (a) 和 (b) 没有改变，从 © 开始： © S1 还是将日志条目（index=2，term=2）复制给其他节点，它复制给了 S3，此时已经复制给了过半的节点了，但是由于 currentTerm=4，所以 S1 还是不能提交该日志条目。如果 S1 将日志条目（index=3，term=4）也复制给了过半的节点，S1 是可以提交该日志条目的，那么这个时候，前面的日志条目（index=2，term=2）也会被间接提交，这就是 (e) 所展示的情况。 (d) S1 还是将日志条目（index=2，term=2）复制给其他节点，它复制给了 S3，此时已经复制给了过半的节点了，但是由于 currentTerm=4，所以 S1 还是不能提交该日志条目。但是这个时候，S1 只是日志条目（index=3，term=4）写入自己的日志，还没来得及复制就崩溃了。然后 S5 重启并赢得了选举（currentTerm=5），然后将日志条目（index=2，term=3）复制给其他所有节点，现在 index=2 的日志条目是没有提交过的，S5 能提交该日志吗？ 不能！因为 leader 不能提交之前任期的日志！只有等新的请求进来，超过半数节点复制了 1-3-5 之后，term=3 的日志才能跟着 term=5 的日志一起被提交。 延伸： 加了上述约束后，就不会出现同一个 index 上的日志条目被重复提交的情况了，但是这又多出了另外一个问题了：如果一直没有新的请求进来，那么日志条目（index=2，term=3）岂不是就一直不能提交？那不就阻塞了吗？ 这里如果是 kv 数据库，问题就很明显了。假设 © 或 (d) 中的日志条目（index=2）里的 Command 是 Set(k, 1)，S5 当选 leader 后，客户端来查询 Get(k)，leader 查到日志有记录但又不能回复 1 给客户端（因为按照约束这条日志未提交），线性一致性要求不能返回陈旧的数据，leader 迫切地需要知道这条日志到底能不能提交。 所以 Raft 论文提高了引入 no-op 日志来解决这个问题，这个在 etcd 中有实现。 no-op 日志： no-op 日志即只有 index 和 term 信息，command 信息为空。也是要写到磁盘存储的。 具体流程是在 leader 刚选举成功的时候，立即追加一条 no-op 日志，并立即复制到其它节点，no-op 日志一经提交，leader 前面那些未提交的日志全部间接提交，问题就解决了。像上面的 kv 数据库，有了 no-op 日志之后，Leader 就能快速响应客户端查询了。 本质上，no-op 日志使 leader 隐式地快速提交之前任期未提交的日志，确认当前 commitIndex，这样系统才会快速对外正常工作。 为了解决图 8 中描述的问题，Raft 永远不会通过计算副本数目的方式来提交之前任期内的日志条目。只有 leader 当期内的日志条目才通过计算副本数目的方式来提交。一旦当前任期内的某个日志条目以这种方式被提交（如图 8 中的 e），那么由于日志匹配特性（Log Matching），之前的所有日志条目也会被间接地提交。在某些情况下，leader 可以安全地断定一个老的日志条目已经被提交（例如，如果该条目已经被存储到每一个节点上了）。但是 Raft 为了简化问题，采取了上述描述的更加保守的方法。 Raft 会在提交规则上增加额外的复杂性是因为当 leader 复制之前任期内的日志条目时，这些日志条目都保留原来的任期号。在其他的共识算法中，如果一个新的 leader 要重新复制之前任期里的日志时，它必须使用当前新的任期号。Raft 的做法使得更加容易推导出日志条目，因为它们自始至终都使用同一个任期号。另外，和其他的算法相比，Raft 中的新 leader 只需要发送更少的日志条目（其他算法中必须在它们被提交之前发送更多的冗余日志条目来给它们重新编号）。 5.4.3 安全性论证 给出了完整的 Raft 算法后，我们现在可以更严格地来论证 leader 完整性特性（Leader Completeness Property）（这一讨论基于 9.2 节的安全性证明）。我们先假设 Leader Completeness Property 是不满足的，然后再推出矛盾来。 假设： 假设任期 T 的 leaderT 在任期内提交了一个日志条目，但是该日志条目没有存在未来某些任期的 leader 中，假设 U 是大于 T 的没有存储该日志条目的最小任期号，处在任期 U 的 leader 称为 leaderU。 论证： 因为 leader 从来不删除或重写自己的日志条目，所以如果一个已提交的日志要做到不存在未来的 leaderU 中的话，那么它只可能在 leaderU 选举的过程中被丢失。 leaderT 将该日志复制给了集群中过半的节点，leaderU 从集群中过半的节点得到了投票。因此，至少有一个节点（这里称它为 voter）同时接收了来自 leaderT 的日志条目并且给 leaderU 投票了。 voter 必然在给 leaderU 投票之前就已经接收了这个已经提交的日志条目了。否则，它就会拒绝来自 leaderT 的 AppendEntries RPC 请求，因为如果它在给 leaderU 投票之后再接收条目的话，那么它的当前任期号会比 T 大。 译者注：因为要举行 Leader election 的话需要开一轮新的任期，这个时候前一轮任期已经结束了。我们这里假设了 T U，上述所说的已提交日志条目是在任期 T 中的，如果 voter 先投票的话，那么就说明它已经进入了任期 U 了，而 U T，voter 是不可能接受 leaderT 的 AppendEntries 请求的。 而且，voter 在给 leaderU 投票的时候，它依旧保有该日志条目，因为任何 U、T 之间的 leader 都包含该日志条目（因为我们前面假设了 U 是大于 T 的没有存储该日志条目的最小任期号），而且 leader 从来不会删除条目，并且 follower 只有再跟 leader 冲突的时候才会删除条目。 该投票者把自己的选票投给 leaderU 的时候，leaderU 的日志至少跟 voter 一样新（可以更新），这就导致了以下的两个矛盾之一了。 第一个矛盾： 如果 voter 和 leaderU 最后一个日志条目的任期号相同的话，那么 leaderU 的日志至少和 voter 的一样长，所以 leaderU 的日志一定包含 voter 日志中的所有日志条目。 这是一个矛盾，因为 voter 包含了该已提交的日志条目，所以 leaderU 必定也包含该日志条目，而前面我们假设了 leaderU 是不包含的，这就产生了矛盾。 第二个矛盾： 如果不是上面描述的情况的话，那么 leaderU 最后一个日志条目的任期号必然需要比 voter 的更大。此外，它还比 T 要大，因为 voter 拥有在任期号为 T 提交的日志条目，所以 voter 最后一个日志条目的任期号至少为 T。创建了 leaderU 的最后一个日志条目的之前的 leader 一定已经包含了该已被提交的日志条目（因为我们上面假设了 leaderU 是第一个没有该日志条目的 leader）。所以，根据日志匹配特性，leaderU 一定也包含了该已被提交的日志条目，这样也产生了矛盾。 上述讨论就证明了假设是不成立的。因此，所有比 T 大的任期的 leader 一定包含了任期 T 中提交的所有日志条目。 日志匹配特性保证了未来的 leader 也会包含被间接提交的日志条目，如图 8 (d) 中的索引 2。 通过 leader 的完整性特性，我们就可以证明图 3 中的状态机安全特性了，即如果某个节点已经将某个给定的索引处的日志条目应用到自己的状态机里了，那么其他的节点就不会在相同的索引处应用一个不同的日志条目。在一个节点应用一个日志条目到自己的状态机中时，它的日志和 leader 的日志从开始到该日志条目都是相同的，并且该日志条目必须被提交。现在考虑一个最小的任期号，在该任期中任意节点应用了一个给定的最小索引上面的日志条目，那么 Log 的完整性特性就会保证该任期之后的所有 leader 将存储相同的日志条目，因此在后面的任期中应用该索引上的日志条目的节点会应用相同的值。所以，状态机安全特性是可以得到保证的。 最后，因为 Raft 要求服务器节点按照日志索引顺序应用日志条目，再加上状态机安全特性，这样就意味着我们可以保证所有的服务器都会按照相同的顺序应用相同的日志条目到自己的状态机中了。 5.5 follower 和 candidate 崩溃 到目前为止，我们只关注了 leader 崩溃的情况。follower 和 candidate 崩溃后的处理方式要比 leader 崩溃简单得多，而且它们的处理方式是相同的。如果一个 follower 或者 candidate 崩溃的话，后面发送给它们的 RequestVote 和 AppendEntries RPCs 都会失败。Raft 通过无限重试来处理这种失败。如果崩溃的节点重启了，那么这些 RPC 就会被成功地完成。如果一个节点在完成了一个 RPC，但是还没来得及响应就崩溃了的话，那么在它重启之后它会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以重复发送相同的 RPCs 不会对系统造成危害。实际情况下，一个 follower 如果接收了一个 AppendEntries 请求，但是这个请求里面的这些日志条目在它日志中已经有了，它就会直接忽略这个新的请求中的这些日志条目。 译者注：幂等 在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“setTrue()”函数就是一个幂等函数,无论多次执行，其结果都是一样的.更复杂的操作幂等保证是利用唯一交易号(流水号)实现。 5.6 时序和可用性 Raft 中有一个要求就是 Raft 的安全性不能依赖于时序（timing）：整个系统不能因为某些事件运行得比预期快一点或者慢一点就产生错误的结果。然而，可用性（即系统能够及时响应客户端的请求）不可避免的要依赖于时序。比如说，如果信息交换的时间比一般服务器崩溃所持续的时间还要长的话，那么 candidate 可能等不到赢得选举了，而缺少了一个稳定的 leader，Raft 将无法工作。 Raft 中时序最关键的地方就是 Leader election。只要整个系统满足下面的时间要求，Raft 就可以选举并维持一个稳定的 leader： 广播时间（broadcastTime） 选举超时时间（electionTimeout） 平均故障间隔时间（MTBF） 在这个不等式中，广播时间指的是一个节点并行地发送 RPCs 给集群中其他所有的节点并得到响应的平均时间。选举超时时间就是在 5.2 节中介绍的选举超时时间。平均故障间隔时间就是对于一台服务器而言，两次故障间隔时间的平均值。广播时间必须选举超时时间小一个量级，这样 leader 才能够有效发送心跳信息来组织 follower 进入选举状态。再加上随机化选举超时时间的方法，这个不等式也使得无果选票（split vote）变得几乎不可能。而选举超时时间需要比平均故障间隔时间小上几个数量级，这样整个系统才可以稳定地运行。有了这个限制后，当 leader 崩溃后，整个系统会有一段大约选举超时时间的时长不可用，我们希望该情况在整个系统运行时间里只占一小部分。 广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们可以自定义的。Raft 的 RPCs 需要接收方将信息持久化地保存到稳定存储中，所以广播时间大约是 0.5ms ~ 20ms 之间，取决于存储的技术。因此，选举超时时间可能需要在 10ms ~ 500ms 之间。而大多数的服务器的平均故障间隔时间都在几个月甚至更长，所以很容易满足时间的要求。 6. 集群成员变更 到目前为止，我们都假设集群的配置（参与共识算法的服务器节点集合）是固定不变的。但是在实际情况中，我们有时候是需要去改变集群配置的，比如说在服务器崩溃的时候去更换服务器或者是更改副本的数量。尽管可以通过下线整个集群，更新所有配置，然后重启整个集群的方式来实现这个需求，但是这会导致集群在更改过程中是不可用的。另外，如果这个过程中存在一些操作需要人工干预，那么就会有操作失误的风险。为了避免这些问题，我们决定将配置变更自动化并将其纳入到 Raft 的共识算法中来。 为了使配置变更机制足够安全，在配置变更过程中不能存在任何一个时刻使得同一任期中选出两个 leader。遗憾的是，任何服务器直接从旧的配置转换为新的配置的方案都是不安全的。一次性自动地转换所有服务器的配置的不可能的，所以在转换期间整个集群可能划分为两个独立的大多数（如图 10 所示）。 译者注：图 10 补充 上图中，在中间位置 Server1 可以通过自身和 Server2 的选票成为 leader（满足旧配置下收到大多数选票的原则）；Server3 可以通过自身和 Server4、Server5 的选票成为 leader（满足新配置线，即集群有 5 个节点的情况下的收到大多数选票的原则）；此时整个集群可能在同一任期中出现了两个 leader，这和 Raft 协议是违背的。 为了保证安全性，配置变更必须采取一种两段式方法。目前有很多种两段式的实现。例如，有些系统（如 [22] ）在第一阶段停掉旧的配置，所以在这个阶段不能处理用户的请求，然后在第二阶段启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为 联合共识（joint consensus） 。一旦联合共识配置已经被提交了，系统就可以切换到新的配置上了。联合共识配置是新旧配置的并集： 日志条目被复制给集群中处于新、老配置的所有节点 新、旧配置的节点都可能成为 leader 达成一致（针对选举和提交）需要分别得到在两种配置上过半的支持 联合共识允许每一个节点在不妥协安全性的前提下，在不同的时刻进行配置转换过程。此外，联合共识还允许在集群配置变更期间响应客户端的请求。 集群配置在复制日志中以特殊的日志条目来存储和通信。图 11 展示了配置变更的过程。 当 leader 接收到一个更新配置的请求的时候，它就创建一个联合共识日志条目 Cold,new，并以前面描述的方式复制该条目。 一旦某个节点将该配置日志条目增加到自己的日志中。那么这个节点就会用该配置来做出未来的所有决策（一个节点总是使用日志中最新的配置，无论该日志是否已经被提交）。 这就意味着 leader 会使用 Cold,new 的规则来判断 Cold,new 日志条目是什么时候被提交的。如果 leader 崩溃了，新的 leader 有可能处于 Cold 配置，也可能处于 Cold,new 配置，这取决于赢得选举的 candidate 是否已经接收到了 Cold,new 配置。在任何情况下，处于 Cnew 状态的节点在此期间都是不能单独做出决定的。 当 Cold,new 被提交了，那么 Cold 和 Cnew 都不能在没有得到对方认可的情况下做出决定，并且 Leade 完整特性（Leader Completeness Property）保证了只有拥有 Cold,new 日志的 candidate 有可能被选为 leader。所以现在 leader 就可以安全地创建一个描述 Cnew 的日志条目并将其复制给集群中的其他节点了。一样的，新的配置被节点收到后就会立刻生效。当新的配置在 Cnew 的规则下被提交了之后，旧配置就变得无关紧要了，处于旧配置的节点也可以关闭了。如图 11 所示，没有任何一个时刻 Cold 和 Cnew 是可以单独做决定的，这保证了安全性。 关于配置变更有三个问题需要解决： 第一个问题：新的节点可能在一开始并没有存储任何的日志条目。当这些节点以这种状态加入到集群中的时候，它们需要一段时间来更新自己的日志，以便赶上其他节点，在这个时间段里面它们是不可能提交一个新的日志条目的。 为了避免因此造成的系统短时间的不可用，Raft 在配置变更前引入了一个额外的阶段。在该阶段中，新的节点以没有投票权身份加入到集群中来（leader 会把日志复制给它们，但是考虑过半的时候不需要考虑它们）。 一旦新节点的日志已经赶上了集群中的其他节点，那么配置变更就可以按照之前描述的方式进行了。 第二个问题：leader 有可能不是新配置中的一员（译者注：也就是说这个 leader 后面是需要被下线的）。在这种情况下，leader 一旦提交了 Cnew 日志条目，它就会退位为 follower（译者注：Cold,new 状态下依旧可用）。这就意味着有这样一段时间（leader 提交 Cnew 期间）：leader 管理着一个不包括自己的集群，它会复制日志给其他节点，但是算副本数量的时候不会算上自己。leader 转换发生在 Cnew 被提交的时候，因为这是新配置可以独立运行的最早时刻（在这个时刻之后，一定是从 Cnew 中选出新的 leader）。在这个时间点之前，有可能只能从 Cold 中选出 leader。 第三个问题：那么被移除的节点（不处于 Cnew 状态的节点）有可能会扰乱集群。这些节点将不会收到心跳信息，所以当选举超时时，它们就会进行新的选举过程。它们会发送带有新任期号的 RequestVote RPCs，这样会导致当前的 leader 回到 follower 状态，然后选出一个新的 leader。但是这些被移除的节点还是会收不到心跳，然后再次超时，再次循环这个过程，导致系统的可用性很差。 为了避免这个问题，当节点认为当前有 leader 存在时，节点会忽略 RequestVote RPCs。具体来说，当一个节点在最小选举超时时间内收到一个 RequestVote RPC，它不会更新它的任期或授予它的投票。这不会影响正常的选举，每个节点在开启一轮选举之前，它会至少等待一次最小选举超时时间。相反，这有利于避免被移除的节点的扰乱：如果一个 leader 能够发送心跳给集群，那它就不会被更大的任期号废黜。 译者注：对配置变更的归纳 配置变更过程 leader 在本地生成一个新的日志条目，其内容是 Cold ∪ Cnew，代表当前时刻新旧成员配置共存，写入本地日志，称为 Cold,new。后面 leader 就以该日志作为自己的配置了。同时将该日志条目复制集群中是所有节点中。在此之后新的日志同步需要保证得到 Cold 和 Cnew 两个多数派的确认。 follower 收到 Cold.new 的日志后更新本地日志，并且此时就以该配置作为自己的成员配置。 如果 Cold 和 Cnew 中的两个多数派确认了 Cold.new 这个日志条目，leader 就提交它。 接下来 leader 生成一条新的日志条目，其内容是新成员配置 Cnew，同样将该日志条目写入本地日志，同时复制给集群中其他节点。 follower 收到新成员配置 Cnew 后，将其写入日志，并且从此刻起，就以该配置作为自己的成员配置，并且如果发现自己不在 Cnew 这个成员配置中会自动退出。 leader 收到 Cnew 的多数派确认后，表示成员变更成功，后续的日志只要得到 Cnew 多数派确认即可。 完成上述两阶段后，leader 就可以给客户端回复配置变更执行成功。 如果当前的 leader 不在 Cnew 的配置中会怎么样？ 因为当前 leader 不在 Cnew 配置中，所以当 Cnew 日志条目被提交的时候，leader 其实是要被下线的（比如说集群节点数从 5 缩容为 3，且刚好下线的节点中包含当前 leader）。那这样的话，在 Cold,new 状态下，leader 还是可用的，但是一旦 Cnew 日志条目被提交了，leader 就需要下线了，这个时候不用当心，因为 Cnew 已经被复制过半了，重新选 leader 也一定是选有 Cnew 的。 如果在配置分发过程中 leader 崩溃了怎么办？ 分两种情况： Cnew 已经分发过半 集群开始重新选举，此时在 Cnew 的规则下，不存在新配置中的节点不会赢得选举（因为他们要在Cold,new 的情况下决定，但是拿不到 Cnew 的选票），只有拿到 Cnew 的节点可能成为 leader 并继续下发 Cnew 配置，流程恢复。 Cnew 没有分发过半 这种情况下，Cold,new 和 Cnew 的节点都可以成为 leader，但是无所谓，因为无论谁成为 leader，都能根据当前的配置继续完成后续流程（如果是 Cnew 那么相当与完成了最终的配置，不在 Cnew 的节点会因为没有心跳数据而失效）。 旧配置节点下线造成的问题 Raft 的处理方式：当节点确信有 leader 存在时，不会进行投票（在 leader 超时之前收到新的投票请求时不会提升任期号和做出投票）。且开始选举之前等待一个选举超时时间，这样在新 leader 正常工作的情况下，不会受到旧节点的影响。 旧配置节点在发起选举前需要等待一段时间，那么这段时间新 leader 可以发送心跳，这样就减少了影响。 对正常流程的影响不大。（leader 失效后要等一段时间，没有及时触发，然而本身这里就有一个判断失效的时间，好像影响不大；比如原先超时时间是 10s，那么如果设置成 5s，原策略下 10s 超时就是 10s 后开始选举，新策略下 5s 超时就是超时后再等 5s 再开始选举，影响就是超时时间变短） 无数据的新节点加入集群中的问题 新加入的节点需要时间复制数据，在这个过程完成之前，Raft 采用以下机制来保证可用性： 新加入节点没有投票权（ leader 复制日志给他们，但计算已复制日志条目的副本数的时候不考虑它们），直到这些节点的日志追上其他节点。 如果在配置变更过程中接收到用户请求的话，是用旧配置响应还是用新配置响应？ 按照笔者的理解，这个方面，对 Raft 协议的具体实现可以根据自身需求来自定义实现，Raft 的联合共识是为了避免同一时刻出现了 2 个 leader，避免了对客户端的一个请求同时有两个不同的响应出现。而在具体实现中，在某个阶段，究竟是采取新配置响应还是旧配置响应，可以再斟酌。 比如说可以这样： Cold 阶段：使用旧配置，需要过半旧配置节点确认 Cnew 已提交阶段：使用新配置，需要过半新配置节点确认 Cold,new 阶段：配置信息中有节点数量（这样才可能判断是否过半），这个时候新旧配置都需要过半节点确认，而响应新配置执行的结果还是响应旧配置执行的结果，就看 old 多还是 new 多，谁多用谁。 如果 leader 要下线，客户端发来的新的请求如何处理？ 如果是在 leader 复制 Cnew 之后，提交 Cnew 之前的话，leader 工作在新的集群配置下，所以会将日志复制到新集群的节点下，当收到新集群（不包含 leader 本身）超过半数节点确认后，就可以提交日志。 在其他阶段，leader 就是正常可用的。 所谓 Cnew 和 Cold,new 日志条目，里面没有数据，只有指令，里面的指令就是让节点执行对应的配置项。 7. 日志压缩 在正常情况下，Raft 的日志会随着客户端请求的增加而不断增长。但在实际系统中，日志不可能无限制地增长。随着日志越来越长，它会占用越来越多的空间，并且需要花更多的时间来重新执行日志中的日志条目。如果没有一定的机制来清除日志中积累的过期的信息，那么最终一定会影响系统的可用性。 快照技术（snapshotting） 是日志压缩最简单的方法。在快照技术中，某个时间点下的前整个系统的状态都会以快照的形式持久化起来，然后该时间点之前的日志会被全部丢弃。快照技术呗使用在 Chubby 和 ZooKeeper 当中，接下来的章节会介绍 Raft 中的快照技术。 增量压缩方法（Incremental approach to compaction），例如日志清洗（log cleaning）[36] 和日志结构合并树（log-structured merge trees）[30, 5]，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，选择一个积累了大量被删除或被覆盖的对象的数据区域，然后重写该区域内还活着的对象，之后释放该区域。和快照技术相比，这需要大量额外的机制，并且增加了更多的复杂性，快照技术通过操作整个数据集来简化问题。虽然日志清理需要对 Raft 进行修改，但是状态机可以使用与快照技术相同的接口来实现 LSM（日志结构合并） 树。 图 12 展示了 Raft 快照技术的基本思想。每一个节点独立地生成快照，快照中只包含自己日志中已经被提交的条目，这个过程主要的工作是状态机将自己的状态写入快照中。Raft 在快照中还保留了少量的元数据： last included index：指的是最后一个被快照取代的日志条目的索引值（状态机最后应用的日志条目） last included term：指的是该条目所处的任期号 保留这些元数据是为了支持快照后第一个条目的 AppendEntries 一致性检查，因为该条目需要一个之前的日志索引和任期号。为了支持集群成员变更（第 6 节中讨论的），快照中还包含日志中到 last included index 为止的最新的配置。一旦节点完成了快照的写入，它可能就会删除 last included index 及之前的所有日志条目，以及之前的快照。 尽管通常情况下，节点都是独立生成快照的，但是 leader 不可避免偶尔需要发送快照给一些落后的 follower。这通常发生在 leader 已经丢弃了需要发给 follower 的下一条日志条目的时候。幸运的是，这种情况在正常操作中是不会出现的：一个与 leader 保持同步的 follower 通常都会拥有该日志条目。不过如果一个 follower 运行比较缓慢，或者是它刚加入集群，那么它就可能会没有该日志条目。这个时候 leader 会通过网络将该快照发送给该 follower，以使得该 follower 可以更新到最新的状态。 这个时候 leader 使用了一种新的 RPC 来发送快照给那些太落后的 followers，如图 13 所示，这种 RPC 叫做 InstallSnapshot。当一个 follower 通过这种 RPC 收到快照的时候，它必须决定如何处理当前已经存在的日志条目。通常情况下，这份快照会包含接受者日志者没有的信息。所以这种情况下 follower 会丢弃它的整个日志，它的日志会全部被快照取代，并且可能有与快照冲突的未提交的条目。相反，如果一个 follower 收到一个描述其日志前缀的快照（可能是由于重传或错误），则被快照覆盖的日志条目将被删除，但是快照之后的条目仍然有效，且必须要保留。 这种快照的方式违反了 Raft 的 strong leader 原则，因为 follower 可能在不知道 leader 的情况下创建快照。但是我们认为这种违背是合乎情理的。leader 的存在，是为了防止在达成共识的时候产生冲突，但是在创建快照的时候，共识已经达成了，因此没有决策会出现冲突。这种情况下，数据还是跟之前一样，只能从 leader 流向 follower，只不过现在允许 follower 可以重新组织它们的数组而已。 我们曾经考虑过一种可替代的方案，那就是只有 leader 可以创建快照，然后由 leader 将这份快照发送给其他所有的 follower。但是，这种方案有两个缺点： 发送快照给每个 follower 会浪费网络带宽和延缓了快照处理过程。实际上每一个 follower 已经拥有了创建自己快照所需要的全部信息了，所以很显然，follower 根据本地的状态创建快照要比通过网络来接收别人发过来的要更加实惠。 这会造成 leader 的实现更加复杂。比如说，leader 发送快照给 follower 的同时要能够做到并行地将新的日志条目发送给它们，这样才不会阻塞新的客户端请求，这就复杂得多了。 还有两个问题会影响快照的性能： 每一个节点必须判断何时去生成快照。如果一个节点生成快照的频率太高，那么就会浪费大量的磁盘带宽和其他资源；如果一个节点生成快照的频率太低，那么就要承担耗尽存储容量的风险，同时也增加了重启时重新执行日志的时间。 一个简单的策略就是当日志大小达到一个固定的阈值的时候就生成一份快照。如果这个阈值设置得显著大于期望的快照的大小，那么快照的磁盘带宽开销将较小。 第二个影响性能的就是写快照需要花费一定的时间，而我们又不希望它会影响到正常的操作。 解决方案就是使用 写时复制的技术（copy-on-write） ，这样新的更新就可以在不影响正在写的快照的情况下被接收。例如，具有泛型函数结构的状态机天然支持这样的功能。另外，操作系统对写时复制技术的支持（如 Linux 上的 fork）可以被用来创建整个状态机的内存快照（我们的实现用的就是这种方法）。 8. 客户端交互 本节介绍客户端如何和 Raft 进行交互，包括客户端如何找到 leader 和 Raft 是如何支持线性化语义的 [10]。这些问题对于所有的基于共识算法的系统都是存在的，Raft 的解决方案也跟其他的系统差不多。 Raft 的客户端们将所有的请求发送给 leader。当客户端第一次启动的时候，它会随机挑选一个节点来进行通信。如果客户端首选的不是 leader，那么被客户端选中的节点就会拒绝客户端的请求并且提供关于它最近收到的 leader 的信息（AppendEntries RPC 包含了 leader 的网络地址）。如果 leader 崩溃了，客户端请求就会超时，这个时候客户端需要随机选择一个节点来重试发送请求。 我们对 Raft 的期许是希望它可以实现线性化语义（即每次操作看起来似乎都是在调用和响应之间的某个点上即时执行一次）。但是，按照上面描述的，Raft 可能会对同一条指令执行多次。例如，如果 leader 在提交了某个日志条目后，在还没来得及响应客户端的时候就崩溃了，那么客户端会和新的 leader 重试该指令，这就造成了同一指令被执行了两次。解决方案是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每个客户端已经处理的最新的序列号以及相关联的响应。如果状态机接收到了一条已经执行过的指令了，就立即作出响应，并且不会重复执行该指令。 只读操作（Read-Only）可以直接处理而不记录日志。但是，如果不采取任何措施的话，这可能会有返回过期数据（stale data）的风险。因为 leader 响应客户端请求的时候它可能已经被新的 leader 代替了，但是它还不知道自己已经不是最新的 leader 了。 译者补充：为什么一个 leader 好好的会有另外一个 leader 出现？ 参考：https://segmentfault.com/a/1190000039264427 实际上，老的 leader 可能不会马上消失，例如：网络分区将 leader 与集群的其余部分分隔，其余部分选举出了一个新的 leader。然后老的 leader 崩溃后重新连接，可能会不知道新的 leader 已经被选出来了。 线性化的操作肯定不会返回过期的数据。Raft 需要使用两个额外的预防措施来在不适用日志的时候保证这一点。 leader 必须拥有那些已提交的日志条目的最新信息。Leader 完整性特性（Leader Completeness Property）保证了 leader 一定拥有所有已被提交的日志条目，但是在它任期刚开始的时候，它可能还不知道哪些是已经被提交的。为了知道这些信息，它需要在它的任期里提交一个日志条目。 Raft 通过让 leader 在任期开始的时候提交一个空的日志条目到日志中来解决该问题。（译者注：这就是前面 5.4.2 节提到的 no-op 日志） leader 在处理只读请求的时候必须检查自己是否已经被替代了（因为如果一个新 leader 被选出来了，那么这个旧 leader 的数据可能就过时了）。 Raft 通过让 leader 在响应只读请求之前，先和集群中过半的节点交换一次心跳信息来解决该问题。 另一种可选的方案，leader 可以依赖心跳机制来实现一种租约的形式 [9]，但是这种方式的安全性需要依赖于时序（假设时间误差是有界的）。 9. 算法实现与评估 我们已经实现了 Raft 作为复制状态机的一部分，该状态机存储了 RAMCloud [33] 的配置信息，并帮助 RAMCloud 协调器进行故障转移。这个 Raft 实现大概包含了 2000+ 行 C++ 代码，但是这里面没有包含测试、注释和空行。这些代码是开源的 [23]。同时也有大约 25 个其他独立的第三方、针对不同的开发场景、基于这篇论文草稿的开源实现。同时，很多公司已经部署了基于 Raft 算法的系统了。 本节剩下的篇幅将从三个方面来评估 Raft 算法： 可理解性 正确性 性能 9.1 可理解性 为了衡量 Raft 相对于 Paxos 的可理解性，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一项实验研究。我们为 Raft 和 Paxos 分别录制了一个视频教程，并且准备了相应的小测验。其中 Raft 课程覆盖了本篇论文除了日志压缩之外的全部内容，而 Paxos 课程涵盖了创建一个与 Raft 等价的复制状态机的全部资料，包括 signle-decree Paxos、multi-decree Paxos、重新配置和一切实际系统需要的性能优化（比如 leader 选举）。这个小测验主要是测试一些对算法的理解和解释一些边缘情况。每个学生都是看完第一个视频，然后做对应的测验，然后再看第二个视频，再做第二份测验。为了解释个人表现与从第一部分研究中获得的经验差异的原因，大约有一半的学生先进行 Paxos 的部分，然后另一半学生先进行 Raft 的部分。我们通过计算参与人员的每一份测验的得分来看参与者是否更加容易理解 Raft 算法。 我们尽可能的使得在比较 Raft 和 Paxos 过程中是公平的。这个实验从两个方面偏向了 Paxos： 43 个参与者中有 15 个人在之前有一些 Paxos 的经验 Paxos 视频教程的时长要长 14% 如表格 1 总结的那样，我们采取了一些措施来减轻这种潜在的偏向。我们所有的材料都可供审查 [28, 31]。 关注点 缓和偏向采取的手段 可供查看的材料 相同的讲课质量 两份教程采用同一个讲师。Paxos 的教程是在现有的一些大学使用的材料基础上改进的。Paxos 的教程要长 14%。 视频 相同的测验难度 问题以难度分组，在两个测验里成对出现。 小测验 公平评分 使用评价量规。随机顺序打分，两个测验交替进行。 评分细则 表格1：考虑到潜在的实验偏向，我们对于每种情况的解决方法，以及相应的材料。 平均上看，参与者在 Raft 测验上的得分要比在 Paxos 测验上的得分高处 4.9 分（在 60 分中，Raft 的平均得分是 25.7 分，Paxos 的平均得分是 20.8 分）。图 14 展示了每个参与者的得分。配对 t 检验（paired t-test）表明，在 95% 的置信度下，Raft 分数的真实分布的平均值至少要比 Paxos 的大 2.5 分。 我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，这个模型基于以下三点： 他们使用的是哪个测验 之前对于 Paxos 的经验 学习算法的顺序 该模型预测，对小测验的选择会产生 12.5 分的有利于 Raft 的差别，这很明显高于观察到的 4.9 分的分差。这是因为实际上许多的学生之前有学习过 Paxos，这对 Paxos 的有很大帮助的，但是对 Raft 的帮助就较小了。但是奇怪的是，模型预测对于先进行 Paxos 小测验的人而言，Raft 的得分低了 6.3 分。虽然我们不知道这是为什么，但是这似乎在统计上是有意义的。 我们同时也在测验之后对参与者进行了调查，调查的内容是他们认为哪个算法更容易去实现或解释。这些调查结果展示在图 15。调查结果是碾压性的，结果表明 Raft 算法更加容易实现和解释（41 人中的 33 个）。然而，这种自我报告的感觉可能没有参与者的测试分数来得可靠，而且参与者可能由于我们假设 Raft 更容易理解而存在偏向。 在参考文献 [33] 中有一个关于 Raft 用户学习的更加详细的讨论。 9.2 正确性 在第 5 节中，我们已经对共识机制制定了正式的规范并且对其安全性做了证明。这份正式的规范使用 TLA+ 规范语言 [17] 使图 2 中对算法的总结的信息非常清晰。它差不多有 400 行并且作为了我们要证明的核心。同时这份规范对于任何想实现 Raft 的人都是十分有用的。我们用 TLA 证明系统 [7] 机械地证明了日志完整性（Log Completeness Property）。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明规范中的类型安全）。而且，我们已经编写了状态机安全特性的非正式证明 [31]，它是完整的（它仅依赖于规范）和相对精确的（大约 3500 字长）。 9.3 性能 Raft 的性能跟其他像 Paxos 的共识算法很接近。在性能方面，最重要的关注点就是，当一个 leader 被选举出来后，它要在什么时候复制新的日志条目。Raft 通过很少量的消息包（一轮从 leader 到集群中过半节点的的消息传递）就解决了这个问题。同时，进一步提升 Raft 的性能也是有可能的。比如说，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他共识算法已经提出过很多性能优化方案，其中很多都可以应用到 Raft 上，但是我们暂时把这些工作放到未来的工作中。 我们使用我们自己的 Raft 实现来衡量 Raft 的 leader election 算法的性能并且回答两个问题： leader 选举过程收敛是否足够快？ 在 leader 崩溃之后，最小的系统崩溃时间是多久？ 为了衡量 leader election 的性能，我们反复使一个拥有 5 个节点的集群的 leader 宕机，并计算它检测崩溃和重新选一个新的 leader 所需的时间（见图 16）。为了构建一个最坏的情景，我们使各个节点中的日志长度都是不同的，这样某些 candidate 是无法成为 leader 的。而已，为了尽可能出现无结果的投票（split vote）情况，我们的测试脚本在终止 leader 的进程之前从 leader 那触发了一个同步的发送了一次心跳广播（类似于 leader 在崩溃前复制一个日志条目给其他节点）。leader 在其心跳间隔内均匀随机地崩溃，这个心跳间隔也是所有测试中最小选举超时时长的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。 图 16 中上面的图表明，只需要在选举超时时间上使用很小的随机化就可以大大避免出现没有结果的投票的情况。在没有随机化的情况下（译者注：见图 16 中上面的图右边的橙色虚线），由于出现了很多没有结果的投票的情况，leader election 往往都需要花费超过 10s 的时间。仅仅加入 5ms 的随机化时间，就大大改善了选举过程，现在平均的宕机时间只有 287ms。继续增大随机性可以大大改善最坏的情况：通过增加 50ms 的随机化时间，最坏的完成情况（即完成 1000 次实验）只需要 513 ms。 图 16 中下面的图表明，通过减少选举超时时间可以禁烧系统的宕机时间。在选举超时时间为 12~24ms 的情况下，只需要平均 35ms 就可以选举出新的 leader（最长的一次花费了 152ms）。然而，进一步降低选举超时时间可能就会违反 Raft 不等式的要求。 广播时间（broadcastTime） 选举超时时间（electionTimeout） 平均故障间隔时间（MTBF） 因为这会使得在其他节点开启一轮新的选举之前，当前的 leader 要完成发送一次心跳广播变得很难。这会造成不必要的 leader 更换，从而降低了系统的可用性。我们推荐使用一个更为保守的选举超时时间，比如 150~300ms。这样的时间不大可能导致不必要的 leader 更换，同时还能提供不错的可用性。 10. 相关工作 现在已经有很多关于共识算法相关的产物了，其中很多都属于以下类别之一： Lamport 对于 Paxos 的最初的描述 [15]，以及尝试将 Paxos 解释地更清晰的描述 [16, 20, 21 ]。 关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础 [26, 39, 13]。 实现共识算法的系统，例如 Chubby [2, 4]，ZooKeeper [11, 12] 和 Spanner [6]。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 着实有着很大的差别。 对于 Paxos 的性能优化 [18, 19, 3, 25, 1, 27]。 Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述 [29] 和分布式传输协议耦合在了一起，但是核心的共识算法在最近更新的版本 [22] 里被分离了出来。VR 使用了一种基于 leader 的方法，和 Raft 有很多相似之处。 Raft 和 Paxos 最大的不同就在于 Raft 的强领导性（strong leadership）。Raft 将 leader election 作为共识协议中非常重要的一环，并且将尽可能多的功能集中到了 leader 身上。这种方法使得算法更加简单和更容易理解。比如说，在 Paxos 中，leader election 和基本的共识协议是正交的：它只是作为一种性能优化，而不是实现共识所必需的。然而，这带来了很多额外的机制： Paxos 中包含了一个两段式的基本共识协议 Paxos 中还包含了一个单独的 leader election 机制 相比之下，Raft 将 leader election 直接纳入了共识算法并且将其作为共识两阶段中的第一个阶段，这使得 Raft 使用的机制要比 Paxos 少得多。 像 Raft 一样，VR 和 ZooKeeper 也是基于 leader 的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制。因为 Raft 尽可能的减少了非 leader 者的功能。例如，Raft 中日志条目都遵循着从 leader 发送给 follower 这一个方向：AppendEntries RPCs 是向外发送的。在 VR 中，日志条目的流动是双向的（leader 人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。 跟我们上述提到的其他基于共识性的日志复制算法相比，Raft 的消息类型更少。例如，我们计算了一下 VR 和 ZooKeeper 用来实现基本功能和集群成员变更（不包括日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）所需要的消息类型。VR 和 ZooKeeper 都分别定义了 10 种不同的消息类型。相比之下，Raft 只有 4 种消息类型（两种 RPC Request 及其对应的两种 RPC Response）。Raft 的消息的消息量比其他算法的要大一点，但总的来说，它们更加简单。另外，VR 和 ZooKeeper 都在 leader 改变的时候传输了整个日志，所以这些算法为了能在实践中使用，就不得不增加额外的消息类型了。 Raft 的强 leader 模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有 leader 的情况下可以达到很高的性能 [27]。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。 一些集群成员变更的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论 [15]，VR [22] 和 SMART [24]。我们选择使用联合共识的方法是因为它利用了共识协议的其余部分，这样我们只需要很少的一些机制就可以实现成员变更。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有 leader 的情况下也可以达到共识性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行。相比之下，VR 在配置变更期间需要停止所有正常的处理过程，而 SMART 对未完成请求的数量实施了类似 α 方法的限制。另外，和 VR、SMART 相比，Raft 的方法也只需要增加更少的额外机制来实现。 11. 结论 算法的设计通常以正确性、效率和简洁性为主要目标。虽然这些都是有价值的目标，但我们相信可理解性同样重要。在开发人员将算法转化为实际实现之前，其他任何目标都不能实现，而实际实现将不可避免地偏离和扩展发布的形式。除非开发人员对算法有深刻的理解，并能对算法有直观的认识，否则他们很难在实现中保留算法理想的特性。 在本文中，我们讨论了分布式共识的问题，在这个问题上，一个被广泛接受但难以理解的算法：Paxos，多年来一直让学生和开发人员非常挣扎。我们开发了一种新的算法：Raft，我们已经证明它比 Paxos 更容易理解。我们也相信 Raft 会为系统建设提供更好的基础。将可理解性作为主要设计目标改变了我们处理 Raft 设计的方式。随着设计的进展，我们发现自己反复使用了一些技术，比如分解问题和简化状态空间。这些技术不仅提高了 Raft 的可理解性，而且使我们更容易证实它的正确性。 12. 致谢 这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie`res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生，没有他们的大力支持，这项研究是不可能完成的。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。 参考文献 [1] BOLOSKY, W. J., BRADSHAW, D., HAAGENS, R. B., KUSTERS, N. P., AND LI, P. Paxos replicated state machines as the basis of a high-performance data store. In Proc. NSDI’11, USENIX Conference on Networked Systems Design and Implementation (2011), USENIX, pp. 141–154. [2] BURROWS, M. The Chubby lock service for loosely- coupled distributed systems. In Proc. OSDI’06, Sympo- sium on Operating Systems Design and Implementation (2006), USENIX, pp. 335–350. [3] CAMARGOS, L. J., SCHMIDT, R. M., AND PEDONE, F. Multicoordinated Paxos. In Proc. PODC’07, ACM Sym- posium on Principles of Distributed Computing (2007), ACM, pp. 316–317. [4] CHANDRA, T. D., GRIESEMER, R., AND REDSTONE, J. Paxos made live: an engineering perspective. In Proc. PODC’07, ACM Symposium on Principles of Distributed Computing (2007), ACM, pp. 398–407. [5] CHANG, F., DEAN, J., GHEMAWAT, S., HSIEH, W. C., WALLACH, D. A., BURROWS, M., CHANDRA, T., FIKES, A., AND GRUBER, R. E. Bigtable: a distributed storage system for structured data. In Proc. OSDI’06, USENIX Symposium on Operating Systems Design and Implementation (2006), USENIX, pp. 205–218. [6] CORBETT, J. C., DEAN, J., EPSTEIN, M., FIKES, A., FROST, C., FURMAN, J. J., GHEMAWAT, S., GUBAREV, A., HEISER, C., HOCHSCHILD, P., HSIEH, W., KAN- THAK, S., KOGAN, E., LI, H., LLOYD, A., MELNIK, S., MWAURA, D., NAGLE, D., QUINLAN, S., RAO, R., ROLIG, L., SAITO, Y., SZYMANIAK, M., TAYLOR, C., WANG, R., AND WOODFORD, D. Spanner: Google’s globally-distributed database. In Proc. OSDI’12, USENIX Conference on Operating Systems Design and Implemen- tation (2012), USENIX, pp. 251–264. [7] COUSINEAU, D., DOLIGEZ, D., LAMPORT, L., MERZ, S., RICKETTS, D., AND VANZETTO, H. TLA+ proofs. In Proc. FM’12, Symposium on Formal Methods (2012), D. Giannakopoulou and D. Me ́ry, Eds., vol. 7436 of Lec- ture Notes in Computer Science, Springer, pp. 147–154. [8] GHEMAWAT, S., GOBIOFF, H., AND LEUNG, S.-T. The Google file system. In Proc. SOSP’03, ACM Symposium on Operating Systems Principles (2003), ACM, pp. 29–43. [9] GRAY,C.,ANDCHERITON,D.Leases:Anefficientfault- tolerant mechanism for distributed file cache consistency. In Proceedings of the 12th ACM Ssymposium on Operating Systems Principles (1989), pp. 202–210. [10] HERLIHY, M. P., AND WING, J. M. Linearizability: a correctness condition for concurrent objects. ACM Trans- actions on Programming Languages and Systems 12 (July 1990), 463–492. [11] HUNT, P., KONAR, M., JUNQUEIRA, F. P., AND REED, B . ZooKeeper: wait-free coordination for internet-scale systems. In Proc ATC’10, USENIX Annual Technical Con- ference (2010), USENIX, pp. 145–158. [12] JUNQUEIRA, F. P., REED, B. C., AND SERAFINI, M. Zab: High-performance broadcast for primary-backup sys- tems. In Proc. DSN’11, IEEE/IFIP Int’l Conf. on Depend- able Systems Networks (2011), IEEE Computer Society, pp. 245–256. [13] KIRSCH, J., AND AMIR, Y. Paxos for system builders. Tech. Rep. CNDS-2008-2, Johns Hopkins University, 2008. [14] L A M P O RT, L . Time, clocks, and the ordering of events in a distributed system. Commununications of the ACM 21, 7 (July 1978), 558–565. [15] L A M P O RT, L . The part-time parliament. ACM Transac- tions on Computer Systems 16, 2 (May 1998), 133–169. [16] LAMPORT, L. Paxos made simple. ACM SIGACT News 32, 4 (Dec. 2001), 18–25. [17] L A M P O RT, L . Specifying Systems, The TLA+ Language and Tools for Hardware and Software Engineers. Addison- Wesley, 2002. [18] LAMPORT, L. Generalized consensus and Paxos. Tech. Rep. MSR-TR-2005-33, Microsoft Research, 2005. [19] L A M P O RT, L . Fast paxos. (2006), 79–103. [20] LAMPSON, B. W. How to build a highly available system using consensus. In Distributed Algorithms, O. Baboaglu and K. Marzullo, Eds. Springer-Verlag, 1996, pp. 1–17. [21] LAMPSON, B. W. The ABCD’s of Paxos. In Proc. PODC’01, ACM Symposium on Principles of Distributed Computing (2001), ACM, pp. 13–13. [22] LISKOV, B., AND COWLING, J. Viewstamped replica- tion revisited. Tech. Rep. MIT-CSAIL-TR-2012-021, MIT, July 2012. [23] LogCabin source code. http://github.com/ logcabin/logcabin. [24] LORCH, J. R., ADYA, A., BOLOSKY, W. J., CHAIKEN, R., DOUCEUR, J. R., AND HOWELL, J. The SMART way to migrate replicated stateful services. In Proc. Eu- roSys’06, ACM SIGOPS/EuroSys European Conference on Computer Systems (2006), ACM, pp. 103–115. [25] MAO, Y., JUNQUEIRA, F. P., AND MARZULLO, K. Mencius: building efficient replicated state machines for WANs. In Proc. OSDI’08, USENIX Conference on Operating Systems Design and Implementation (2008), USENIX, pp. 369–384. [26] MAZIE` RES, D. Paxos made practical. http://www.scs.stanford.edu/ ̃dm/home/ papers/paxos.pdf, Jan. 2007. [27] MORARU, I., ANDERSEN, D. G., AND KAMINSKY, M. There is more consensus in egalitarian parliaments. In Proc. SOSP’13, ACM Symposium on Operating System Principles (2013), ACM. [28] Raft user study. http://ramcloud.stanford. edu/ ̃ongaro/userstudy/. [29] OKI, B. M., AND LISKOV, B. H. Viewstamped replication: A new primary copy method to support highly-available distributed systems. In Proc. PODC’88, ACM Symposium on Principles of Distributed Computing (1988), ACM, pp. 8–17. [30] O’NEIL, P., CHENG, E., GAWLICK, D., AND ONEIL, E. The log-structured merge-tree (LSM-tree). Acta Informat- ica 33, 4 (1996), 351–385. [31] ONGARO, D. Consensus: Bridging Theory and Practice. PhD thesis, Stanford University, 2014 (work in progress). [32] ONGARO, D., AND OUSTERHOUT, J. In search of an understandable consensus algorithm. In Proc ATC’14, USENIX Annual Technical Conference (2014), USENIX. [33] OUSTERHOUT, J., AGRAWAL, P., ERICKSON, D., KOZYRAKIS, C., LEVERICH, J., MAZIE`RES, D., MI- TRA, S., NARAYANAN, A., ONGARO, D., PARULKAR, G., ROSENBLUM, M., RUMBLE, S. M., STRATMANN, E., AND STUTSMAN, R. The case for RAMCloud. Com- munications of the ACM 54 (July 2011), 121–130. [34] Raft consensus algorithm website. http://raftconsensus.github.io. [35] REED, B. Personal communications, May 17, 2013. [36] ROSENBLUM, M., AND OUSTERHOUT, J. K. The design and implementation of a log-structured file system. ACM Trans. Comput. Syst. 10 (February 1992), 26–52. [37] S C H N E I D E R , F. B . Implementing fault-tolerant services using the state machine approach: a tutorial. ACM Com- puting Surveys 22, 4 (Dec. 1990), 299–319. [38] SHVACHKO, K., KUANG, H., RADIA, S., AND CHANSLER, R. The Hadoop distributed file system. In Proc. MSST’10, Symposium on Mass Storage Sys- tems and Technologies (2010), IEEE Computer Society, pp. 1–10. [39] VAN RENESSE, R. Paxos made moderately complex. Tech. rep., Cornell University, 2012.","tags":["分布式","Raft","原创"],"categories":["论文翻译"]}]